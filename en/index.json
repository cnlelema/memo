[
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/basic-concepts/",
	"title": "Basic Concepts",
	"tags": [],
	"description": "",
	"content": " References:\nTerms Orderings Model Checking Temporal Logic https://plato.stanford.edu/entries/logic-temporal/\nIn order to ensure correct behavior of a reactive program, in which computations are non-terminating (e.g. an operating system), it is necessary to formally specify and verify the acceptable infinite executions of that program. In addition, to ensure correctness of a concurrent program, where two or more processors are working in parallel, it is necessary to formally specify and verify their interaction and synchronization.\nKey properties of infinite computations that can be captured by temporal patterns are liveness, safety, and fairness (see Manna and Pnueli 1992):\n Liveness properties or eventualities involve temporal patterns of the forms Fp,q→Fp, or G(q→Fp), which ensure that if a specific precondition (q) is initially satisfied, then a desirable state (satisfying p) will eventually be reached in the course of the computation. Examples:\n “If a message is sent, it will eventually be delivered” “Whenever a printing job is activated, it will eventually be completed”.  Safety or invariance properties involve temporal patterns of the forms Gp,q→Gp, or G(q→Gp), which ensure that if a specific precondition (q) is initially satisfied, then undesirable states (violating the safety condition p) will never occur. Examples:\n “No more than one process will be in its critical section at any moment of time” “A resource will never be used by two or more processes simultaneously” “The traffic lights will never show green in both directions” “A train will never pass a red semaphore”.  Fairness properties involve combinations of temporal patterns of the forms GFp (“infinitely often p”) or FGp (“eventually always p”). Intuitively, fairness requires that whenever several processes that share resources are run concurrently, they must be treated ‘fairly’ by the operating system, scheduler, etc. A typical fairness requirement says that if a process is persistent enough in sending a request (e.g. keeps sending it over and over again), its request will eventually be granted.\n  An infinite computation is formally represented by a model of the linear time temporal logic LTL. Non-deterministic systems are modeled by branching time structures. Thus, both LTL and the computation tree logics CTL and CTL* have been very important for specification and verification of reactive and concurrent systems.\nLTL Linear\nCTL ITL TLA Kripke Structure OBDD ordered binary tree More  Monads  References: Monad Brian Beckman: Don\u0026rsquo;t fear the Monad What is a Monad? - Computerphile Haskell: Monads. A 5-minute introduction Monads Monad: a software design pattern. In functional programming, a monad is a software design pattern with a structure that combines program fragments (functions) and wraps their return values in a type with additional computation. General purpose languages use monads to reduce [boilerplate code] needed for common operations (such as dealing undefined values of fallible functions, or encapsulating bookkeeping code.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/temporal/",
	"title": "Temporal",
	"tags": [],
	"description": "",
	"content": " References:\n[1] CETS: Compiler-Enforced Temporal Safety for C, ISMM, 2010. [paper]\nBasics Temporal safety Temporal safety erros include:\n dangling pointer dereferences (referencing an object that has been deallocated);  dangling pointer to stack; dangling pointer to reallocated heap objects;  double free\u0026rsquo;s (calling free() on the same object multiple times); invalid frees (calling free() with a non-heap address or pointer to the middle of a heap-allocated region).\nLocation-based temporal checking  Use location (or address) to determine whether it is allocated or not. Metadata records the allocated/deallocated status of each location.\nUpdate the metadata upon all memory allocations/deallocations. Metadtata is checked during memory access.\n Cannot detect the re-allocated dangling pointers.   Meta-data can be implemented in\n tree structure, such as splay tree. shadowspace, a large, directly accessed memory region, a hashtable, or a trie-based data structure.  Identifier-based temporal checking Associates a unique (never reused) identifier with each memory allocation.\nPer-pointer metadata via fat pointers Pointers are extended into multi-words.\n Memory layout thus is changed. Interfacing with libraries is challenging. SoftBound: disjoint pointer-based metadata shadowspace for compatibility, but no temporal.  Set-based indentifier checking\nSet data structure (such as hash table) is used to track allocation/deallocation.\n O(1) lookups. overheads on every memory reference.  Lock-and-key identifier checking\nEvery pointer is a tuple consisting of an address and a key. Every object in the heap begins with a lock. A pointer to an object in the heap is valid only if the key in the pointer matches the lock in the object.\n A new key value is created when a new heap object is created; When an object is reclaimed, its lock is changed to some arbitrary value, so that the keys in any remaining pointers will not match. Overhead: add extra words of storage for every pointer and every object in the heap; comparing the lock and key on every memory access.  Research Works  CETS: Compiler Enforced Temporal Safety for C\n CHERI temporal safety\n   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/book-soft/",
	"title": "Software Foundations",
	"tags": [],
	"description": "",
	"content": " References:\n Software Foundations\n [Video Class, Benjamin C. Pierce]()\n Video Class2, Micheal Ryan Clarkson @ Cornell\n Peking, Software foundations\n   Building reliable software is really hard \u0026ndash; really hard. The scale and complexity of modern systems, the number of people involved, and the range of demands placed on them make it challenging to build software that is even more-or-less correct, much less 100% correct. At the same time, the increasing degree to which information processing is woven into every aspect of society greatly amplifies the cost of bugs and insecurities.\nComputer scientists and software engineers have responded to these challenges by developing a host of techniques for improving software reliability, ranging from recommendations about managing software project teams (e.g., extreme programming) to design philosophies for libraries (e.g., model-view-controller, publish-subscribe, etc.) and programming languages (e.g., object-oriented programming, aspect-oriented programming, functional programming, \u0026hellip;) to mathematical techniques for specifying and reasoning about properties of software and tools for helping validate these properties. The Software Foundations series is focused on this last set of tools.\n More  V1 Logical Foundations  References: Software Foundations, Volume 1, Logical Foundations Video Class2, Micheal Ryan Clarkson [QED at large, Ringer et al., 2019]() Preface Source of Knowledge Source of Knowledge [Mechanizing Proof. MacKenzie 2001] Authority Inductive reasoning Deductive reasoning Inductive vs. Deductive cite: https://www.voxco.com/blog/inductive-vs-deductive-reasoning/ Inductive reasoning Inductive reasoning is a logical thinking process that integrates observations with experiential information to draw a conclusion. You are employing the use of inductive reasoning every time you\n V2 Programming Language Foundations   References: reference More  Volume 3 Verified Functional Algorithms   References: Software Foundations Volume 3, Verified Functional Algorithms, by Andrew W. Appel, with contributions from Andrew Tolmach and Micheal Clarkson. More  V4 Quick Chick: Property-Based Testing in Coq   References: reference More  V5 Verifiable C  References: Verifiable C, version 2.11, 2022-08-19 Overview Verifiable C is a a language. The language is a subset of CompCert C light; it is a dialect of C in which side-effects and loads have been factored out of expressions. Verifiable C is a program logic. The program logic is a higher-order separation logic, a kind of Hoare logic with better support for reasoning about pointer data structures, function pointers, and data abstraction.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-compart-papers/",
	"title": "Cheri Compartmentalization Papers",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  2016 Thesis: Hardware support for compartmentalisation   References: Norton, Robert M. Hardware support for compartmentalisation. No. UCAM-CL-TR-887. University of Cambridge, Computer Laboratory, 2016. More  2017 Asplos: CHERI JNI: Sinking the Java security model into the C   References: Chisnall, David, Brooks Davis, Khilan Gudka, David Brazdil, Alexandre Joannou, Jonathan Woodruff, A. Theodore Markettos et al. \u0026ldquo;CHERI JNI: Sinking the Java security model into the C.\u0026rdquo; ACM SIGARCH Computer Architecture News 45, no. 1 (2017): 569-583. More  2016 Micro: Fast Protection-Domain Crossing in the CHERI Capability-System Architecture   References: Watson, Robert NM, Robert M. Norton, Jonathan Woodruff, Simon W. Moore, Peter G. Neumann, Jonathan Anderson, David Chisnall et al. \u0026ldquo;Fast protection-domain crossing in the cheri capability-system architecture.\u0026rdquo; IEEE Micro 36, no. 5 (2016): 38-49. More  2015 SP: CHERI: A Hybrid Capability-System Architecture for Scalable Software Compartmentalization   References: Watson, Robert NM, Jonathan Woodruff, Peter G. Neumann, Simon W. Moore, Jonathan Anderson, David Chisnall, Nirav Dave et al. \u0026ldquo;Cheri: A hybrid capability-system architecture for scalable software compartmentalization.\u0026rdquo; In 2015 IEEE Symposium on Security and Privacy, pp. 20-37. IEEE, 2015. More  Capsicum  References: Capsicum: practical capabilities for UNIX Capsicum for Linux  Reasoning About a Machine with Local Capabilities: Provably Safe Stack and Return Pointer Management  Reference 1 Reasoning About a Machine with Local Capabilities: Provably Safe Stack and Return Pointer Management. By Lau Skorstengaard, Dominique Devriese, and Lars Birkedal. ESOP 2018. ↩  Beyond Good and Evil: Formalizing the Security Guarantees of Compartmentalizing Compilation  Reference 1 A new security property, secure compartmentalizing compilation (SCC), that formally characterizes the guarantees provided by compartmentalizing compilation and clarifies its attacker model. Starting from the fully abstract compilation; Identify three important limitations that make full abstract compilation unsuitable for compartmentalization; Lifting the three limitations; ??? How Illustrate this with a compiler from a simple unsafe imperative language with procedures to a compartmentalized abstract machine; Fully Abstract Compilation Notion of fully abstract compilation: 2 3 4 5 6 7 8 9 10 11 12.\n Declarative, Temporal, and Practical Programming with Capabilities  References: William R. Harris, Somesh Jha, Thomas Reps, Jonathan Anderson, and Robert N. M. Watson. Declarative, Temporal, and Practical Programming with Capabilities, 2013, IEEE Security and Privacy (Oakland). Motivation Network utilities process data read directly from a network connection, but execute vulnerable code (tcpdump1, wget2, etc.). Traditional OS environment, \u0026ldquo;if a programmer wants to verify that his program is secure, he typically must first verify that the program satisfies very strong properties, such as memory safety.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/deep/intro/",
	"title": "Intro: Artificial Intelligence and Deep Learning",
	"tags": [],
	"description": "",
	"content": " Reference 1\nArtificial Intelligence Early stage of AI: problems can be described by a list of formal, mathematical rules: Relatively easy for computers but hard for humans.\nNow Challenging Task: that are easy for people to perform but hard for people to describe formally. ==\u0026gt; LLM: but not impossible to describe formally, yes???\nDeep Learning: a solution to solve tasks that easy for people but hard to describe formally.\n This solution is to allow computers to learn from experience and understand the world in terms of a hierarchy of concepts, with each concept defined in terms of its relation to simpler concepts.\nBy gathering knowlege from experience, this approach avoids the need for human operators to formally specify all of the knowledge that the computer needs.\nThe hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones. If we draw a graph showing how these concepts are built on top of each other, the graph is deep, with many layers. For this reason, we call this approach to AI deep learning.\n Early days of AI - formal sterile and formal environments, and did not require computer to have much knowlege about the world.\nIBM\u0026rsquo;s Deep Blue chess-playing system. Chess can be completely described by a very brief list of completely formal rules, easily provided ahead of time by the programmer.\nEarly days of AI - informal A person\u0026rsquo;s everyday life requires an immense amount of knowlege about the world. Much of this knowledge is subjective and intuitive, and therefore difficult to articulate in a formal way.\nHardcode knowledge does not work:\n Cyc, an inference engine and a database of statements in a language called CycL  entity of FredWhileShaving   ==\u0026gt; AI systems need the ability to their own knowledge.\n==\u0026gt; Machine learning:, find their own knowledge by extracting patterns from raw data.\nMachine Learning and Features in its Core Algorithms to discover knowledge:\n logistic regression: whether to recommend cesarean delivery.  given features and outcomes, it will correlate them as training. if some feature values given, it will suggest the possible outcomes by the correlations it learned from the history. But features are defined by humans. It cannot discover new feature by itself.  navie Bayes: separate legitimate e-mail from spam e-mail.  ==\u0026gt; dependence on representations: a general phenomenon that appears throughout computer science and even everyday life.\n Arabic numbers vs. Roman numerals. Data storage format for faster searching.   Many artificial intelligence tasks can be solved by designing the right set of features to extract for that task, then providing these features to a simple machine learn algorithm. For example, a useful feature for speaker identification from sound is an estimate of the size of speaker\u0026rsquo;s vocal tract. It therefore gives a strong clue as to whether the speaker is a man, woman, or child.\n Feature is hard to determine For many tasks, it is difficult to know what features should be extracted.\nFor example, a program to detect cars/wheels in photographs. Wheels has a simple geometric shape but its image may be complicated by shadows falling on the wheel, the sun glaring off the metal parts of the wheel, the fender of the car or an object in the forground obscuring part of the wheel, and so on.\n==\u0026gt; LLM: a much easier approach: add new features for us to detect more easily??? In this example, we can put a sensor in the car/wheel, it will tell you whether its a car/wheel, or more things about itself you want to know. (the picture taken is also a feature of car/wheel, but is badly choosen feature that is hard to learn something from it)\nExamples: Atomic fluorescence (原子荧光用于物体跟踪的技术)\n  Deep Learning Book, by Ian Goodfellow, Yoshua Bengio, Aaron Courville. pdf ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/regs/",
	"title": "Regs",
	"tags": [],
	"description": "",
	"content": " CHERI-MIPS From CHERI ISA v7. 2019.\nConventions  Specialregs  Permissions is required to read special purpose capability registers, but CR3 is not included since it is not a capability register.  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/sail-desc/",
	"title": "Sail Desc",
	"tags": [],
	"description": "",
	"content": " References:\n CHERI ISAv9 draft, 20221121  Sail is a domain specific imperative language designed for describing processor architectures.\nSail in RISC-V instr. descriptions Constant Definitions Constants for 64-bit ISA with 128 bit capability:\ntype xlen : Int = 64 type cap_addr_width : Int = xlen type cap_len_width : Int = cap_addr_width + 1 type cap_size : Int = 16 type cap_mantissa_width : Int = 14 type cap_hperms_width : Int = 12 type cap_uperms_width : Int = 4 type cap_uperms_shift : Int = 15 type cap_flags_width : Int = 1 type cap_otype_width : Int = 18 let cap_max_otype = MAX(cap_otype_width) - reserved_otypes Function Definitions Functions for integer and bit vector manipulation func 1:\nunsigned : forall 'n. bits('n) -\u0026gt; range(0, 2 ^ 'n - 1)  This converts a bit vector of length $n$ to an integer in the range $0$ to $2^n - 1$.\nfunc 2:\nsigned : forall ’n, ’n \u0026gt; 0. bits(’n) -\u0026gt; range(- (2 ^ (’n - 1)), 2 ^ (’n - 1) - 1)  This converts a bit vector of length $n$ to an integer in the range $-2^{n-1}$ to $2^{n-1} - 1$ using twos-complement.\nfunc 3:\nto_bits : forall ’l, ’l \u0026gt;= 0. (int(’l), int) -\u0026gt; bits(’l)  func 4\u0026frasl;5:\nbool_to_bit : bool -\u0026gt; bit bool_to_bits : bool -\u0026gt; bits(1)  func 6:\ntruncate : forall 'm 'n, ('m \u0026gt;= 0 \u0026amp; 'm \u0026lt;= 'n). (bits('n), int('m)) -\u0026gt; bits('m)  truncate(v,n) truncates v, keeping only the least significant n bits.\nfunc 7:\npow2 : forall 'n. int('n) -\u0026gt; int(2^'n)  func 8\u0026frasl;9:\nEXTZ: Addes zeros in most significant bits of vector to obtain a vector of desired length.\nEXTS: Extends the most significant bits of vector preserving the sign bit.\nfunc 10\u0026frasl;11:\nzeros: Produces a bit vector of all zeros\nones: Produces a bit vector of all ones\nTypes used in function defs Source code, common Source code, rv64\ntype CapBits = bits(8 * cap_size) type CapAddrBits = bits(cap_addr_width) type CapLenBits = bits(cap_len_width) type CapPermsBits = bits(cap_perms_width) struct Capability = {...}  Functions to convert Compressed Cap capBitsToCapability : (bool, CapBits) -\u0026gt; Capability capToBits : Capability -\u0026gt; CapBits  Functions for reading and writing regs and mem C(n) : regno -\u0026gt; Capability C(n) : (regno, Capability) -\u0026gt; unit  The overloaded function C(n) is used to read or write capability register n.\nX(n) : regno -\u0026gt; xlenbits X(n) : (regno, xlenbits) -\u0026gt; unit  The overloaded function X(n) is used to read or write integer register n.\nF(n) : regno -\u0026gt; xlenbits F(n) : (regno, xlenbits) -\u0026gt; unit  The overloaded function F(n) is used to read or write floating-point register n.\nmemBitsToCapability : (bool, CapBits) -\u0026gt; Capability capToMemBits : Capability -\u0026gt; CapBits int_to_cap : CapAddrBits -\u0026gt; Capability  get_cheri_mode_cap_addr : (regidx, xlenbits) -\u0026gt; (Capability, xlenbits, capreg_idx)   handle_load_cap_via_cap : (regidx, capreg_idx, Capability, xlenbits) -\u0026gt; Retired handle_load_data_via_cap : (regidx, capreg_idx, Capability, xlenbits, bool, word_width) -\u0026gt; Retired handle_store_cap_via_cap : (regidx, capreg_idx, Capability, xlenbits) -\u0026gt; Retired handle_store_data_via_cap : (regidx, capreg_idx, Capability, xlenbits, word_width) -\u0026gt; Retired  Functions for ISA exception behavior handle_exception : ExceptionType -\u0026gt; unit handle_illegal : unit -\u0026gt; unit handle_mem_exception : (xlenbits, ExceptionType) -\u0026gt; unit handle_cheri_cap_exception : (CapEx, capreg_idx) -\u0026gt; unit handle_cheri_reg_exception : (CapEx, regidx) -\u0026gt; unit /* Is as `handle_cheri_cap_exception` except that the capability register number uses the special value 0x10 indicating the PCC register. */ handle_cheri_pcc_exception : CapEx -\u0026gt; unit pcc_access_system_regs : unit -\u0026gt; bool privLevel_to_bits : Privilege -\u0026gt; priv_level min_instruction_bytes : unit -\u0026gt; CapAddrInt legalize_epcc : Capability -\u0026gt; Capability legalize_tcc : (Capability, Capability) -\u0026gt; Capability  Functions for Manipulating Capabilities The address of a capability has a range as below (the base is the first byte of the range, and top is one greater than last byte):\n{ $a\\in N | base \\le a \\lt top$ }\nNote: for 64-bit arch, the top can be $2^{64}$, meaning that the entire 64-bit address space can be addressed.\ngetCapBounds : Capability -\u0026gt; (CapAddrInt, CapLen) /* return base and top */ getCapBaseBits : Capability -\u0026gt; CapAddrBits getCapTop : Capability -\u0026gt; CapLen getCapLength : Capability -\u0026gt; CapLen inCapBounds : (Capability, CapAddrBits, CapLen) -\u0026gt; bool /* check addr and addr+size is in Cap */  cursor: the Capability\u0026rsquo;s address;\noffset: relative to base.\n$base + offset$ $mod$ $2^{64}$ = $cursor$\ngetCapCursor : Capability -\u0026gt; CapAddrInt getCapOffsetBits : Capability -\u0026gt; CapAddrBits  Adjust the bounds and offsets of capabilities. Not all combinations of bounds and offset are representable, so these functions return a boolean value indicating whether the requested operation was successfull. Even in the case of failure a capability is still returned, although it may not preserve the bounds of the original capability.\nsetCapBounds : (Capability, CapAddrBits, CapLenBits) -\u0026gt; (bool, Capability) setCapAddr : (Capability, CapAddrBits) -\u0026gt; (bool, Capability) setCapOffset : (Capability, CapAddrBits) -\u0026gt; (bool, Capability) incCapOffset : (Capability, CapAddrBits) -\u0026gt; (bool, Capability)  Adjust the tag:\nclearTag : Capability -\u0026gt; Capability clearTagIf : (Capability, bool) -\u0026gt; Capability clearTagIfSealed : Capability -\u0026gt; Capability  About the compression ability:\ngetRepresentableAlignmentMask : xlenbits -\u0026gt; xlenbits getRepresentableLength : xlenbits -\u0026gt; xlenbits  Operation on sealing:\nsealCap : (Capability, bits(cap_otype_width)) -\u0026gt; Capability unsealCap : Capability -\u0026gt; Capability isCapSealed : Capability -\u0026gt; bool  Operation on Object Types:\nhasReservedOType : Capability -\u0026gt; bool  Operations on permissions and flags:\ngetCapPerms : Capability -\u0026gt; CapPermsBits setCapPerms : (Capability, CapPermsBits) -\u0026gt; Capability /* * Get the architecture specific capability flags for given capability. */ getCapFlags : Capability -\u0026gt; CapFlagsBits /* * setCapFlags(cap, flags): * Set the architecture specific capability flags on `cap` to `flags` * and returns the result as new capability. */ setCapFlags : (Capability, CapFlagsBits) -\u0026gt; Capability  Checking ISA features haveRVC : unit -\u0026gt; bool haveFExt : unit -\u0026gt; bool haveNExt : unit -\u0026gt; bool haveSupMode : unit -\u0026gt; bool  Instruction Definitions Instructions dependent on encoding modes More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/attack-jop/2015ccs-jujutsu/",
	"title": "Jujutsu",
	"tags": [],
	"description": "",
	"content": " References:\n[1] Control Jujutsu: On the Weaknesses of Fine-Grained Control Flow Integrity. CCS, 2015.\nA new attack on fine-grained CF that exploit the incompleteness of pointer analysis, when combined with common software engineering practices, to enable an attacker to execute arbitrary malicious code.\nConcepts:  ICS: Indirect Call Site ACICS: Argument Corruptible Indirect Call Site RCE: Remote Code Execution DSA: Data Structure Analysis DEP: Data Execution Prevention ASLR: Address Space Layout Randomization SSP: Stack Smashing Protection ROP: Return-oriented Programming JOP: Jump-Oriented Programming  Threat Model The threat model in this paper is a remote attacker trying to hijack control of a machine by exploiting memory vulnerabilities.\nSecure Part:\n Fine-grained CFI, with unlimited tags for the forward edge and a shadow stack DEP deployed. ASLR deployed.  Insecure Part:\n Memory corruption vulnerability exits, which allows an attacker to corrupt certain values on stack or heap.  Exploit Design Searching ACICS Candidate Searching among all ICS:\n The forward edge pointer and its arguments that reside on the heap or a global variable. The argument at ICS can be altered without crashing the program, before reaching a target function. The ICS should be reachable from external input, e.g., a network request.  ap_run_dirwalk_stat() contains pHook[n].pFunc, which invokes a function pointer.\nSelect Target Apache HTTPD and Nginx\npiped_log_spawn\nExploit  use heap memory corruption vulnerability to corrupt an entry in the _hooks structure\u0026rsquo;s link_dirwalk_stat field to point to piped_log_spawn.\n use same vulnerability to corrupt the struct in the request_rec-\u0026gt;finfo field such that, when viewed as a piped_log struct, the fields read_fd and write_fd are null, and the field program points to a string with the name and arguments of the program we intend to invoke, such as /bin/sh -c ....\n  Why success with fine-grained CFI? Short answer: No fine-grained CFI with CFG generated by static analysis.\nLong story:\nBuilding control flow graph with static analysis  A precise CFG requires a pointer analysis to determine the set of functions to which the pointer at each indirect call site can point.\n Challenges\n Global Struct. _hooks is a global struct variable in Apache HTTPD. Each filed of it contains an array of function pointers. For example, field link_dirwalk_stat contains an array of function pointers to implementation functions of the functionality dirwalk_stat. Customized Container API to manipulate function pointers. The analysis has to capture inter-procedural data flows via customized container APIs. For example, function pointers are stored and manipulated using customized array APIs apr_array_push(), apr_array_make(). Macro Generated Code. Those code are structurally similar. This imposes a significant additional precision requirement on the static analysis, as it needs to consider a (potentially) large number of similar functions that can manipulate the data structures inside _hooks.  Static Analysis Trade-offs\nPrecise(sound and complete) pointer analysis is undecidable[41], for languages with if statements, loops, dynamic storage, and recursive data structures.\nQuestions: Could we restrict the language features in different ways so that the pointer analysis could either be sound, or complete, or decidable? "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/instructions/",
	"title": "Instructions",
	"tags": [],
	"description": "",
	"content": " MIPS pseudo instructions\nRISC-V Instructions Instructions dependent on encoding modes More  Csc  (ISAv7: Ch 7, p240) Format CSC cs, rt, offset(cb) CSCR cs, rt(cb) CSCI cs, offset(cb) Capability register cs is stored at memory location [cb.base + cb.offset + rt + 16 * offset], and the bit in the tag memory associated with this address is set to the value of cs.tag. Capability cb must contain a capability that grants permission to store capabilities. The virtual address of [cb.base + cb.offset + rt + 16 * offset] must be capability_size aligned.\n CGet/SetDefault  (ISAv7, ch7.5) CGetDefault and CSetDefault get and set the capability register that is implicitly employed by the legacy MIPS load and store instructions. In the current version of ISA, this register is special-purpose capability register 0. # The following are equivalent: CGetDDC $c1 CGetDefault $c1 CReadHWR $c1, $0 # The following are equivalent: CSetDDC $c1 CSetDefault $c1 CWriteHWR $c1, $0  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-otype/",
	"title": "Cheri Object Types",
	"tags": [],
	"description": "",
	"content": " Questions  from ISAv7 ch3.3.3: The capability is unsealed ( has otype of $2^64 -1$ ). What the $2^64 -1$ comming from? don\u0026rsquo;t we only have 23 bits for object type?  ans01: in version 7 of ISA, sealed/unsealed capabilities are no longer distinguished by flag s. Unsealed capabilities were redefined as having otype of $2^64 -1$ and this bit was reclaimed as reserved.   User/Kernel Split \u0026ldquo;The CHERI object-type space is split between userspace and kernel, permitting kernel object references to be delegated to userspace (if desired). Currently, we provide 23 bits of namespace to each, with the top bit set for kernel object types, but it is easy to imagine other splits. User and kernel software should be written so as to not place assumptions about the specific values used here, as they may change.\u0026rdquo;\n//file: // ./sys/mips/include/cherireg.h  #define\tCHERI_OTYPE_USER_MIN\t(0) #define\tCHERI_OTYPE_USER_MAX\t((1 \u0026lt;\u0026lt; 23) - 1) #define\tCHERI_OTYPE_KERN_MIN\t(1 \u0026lt;\u0026lt; 23) #define\tCHERI_OTYPE_KERN_MAX\t((1 \u0026lt;\u0026lt; 24) - 1) #define\tCHERI_OTYPE_KERN_FLAG\t(1 \u0026lt;\u0026lt; 23) #define\tCHERI_OTYPE_ISKERN(x)\t(((x) \u0026amp; CHERI_OTYPE_KERN_FLAG) != 0) #define\tCHERI_OTYPE_ISUSER(x)\t(!(CHERI_OTYPE_ISKERN(x)))  Bit 22: Disable/enable capability flow control \u0026ldquo;When performing a userspace-to-userspace CCall, capability flow-control checks normally prevent local capabilities from being delegated. This can be disabled on call (but not return) by using an object type with the 22nd bit set \u0026ndash; combined with a suitable selector on the CCall instruction to ensure that this behaviour is intended.\n//file: // ./sys/mips/include/cherireg.h  #define\tCHERI_OTYPE_LOCALOK_SHIFT\t(22) #define\tCHERI_OTYPE_LOCALOK_FLAG\t(1 \u0026lt;\u0026lt; CHERI_OTYPE_LOCALOK_SHIFT #define\tCHERI_OTYPE_IS_LOCALOK(x)\t(((x) \u0026amp; CHERI_OTYPE_LOCALOK_FLAG) != 0)  Common low level functions cheri_maketype() cheri_maketype() is used to \u0026ldquo;construct a capability suitable to describe a type identified by \u0026lsquo;ptr\u0026rsquo;; set it to zero-length with the offset equal to the base.\u0026rdquo; The caller must provide a root capability (in the old world order, derived from $ddc, but in the new world order, likely extracted from the kernel using sysarch(2)).\nThe caller may wish to assert various properties about the returned capability, including that CHERI_PERM_SEAL is set.\nNote: type value passed in is stored as the offset of the returned otype_t, which is a capability. (LLM: This means this capability is a pointer that stores an \u0026lsquo;address\u0026rsquo; of a type???)\n// file: // sys/cheri/cheric.h  static __inline otype_t cheri_maketype(void * __capability root_type, register_t type) { void * __capability c; c = root_type; c = cheri_setoffset(c, type); /* Set type as desired. */ c = cheri_csetbounds(c, 1); /* ISA implies length of 1. */ c = cheri_andperm(c, CHERI_PERM_GLOBAL | CHERI_PERM_SEAL); /* Perms. */ return (c); }  User Object  User space object manipulation is mainly implemented in lib/libcheri/libcheri_type.c. User space type range Total user space type range is [0 , $2^{23}$ - 1 ], and kernel space is [$2^{23}$, $2^{24}$ -1 ]. The user space is further splited into two ranges: non-system type numbers: [1, $2^{22}$ - 1 ]; system type numbers: [$2^{22}$, $2^{23}$ - 1 ]; // file: // lib/libcheri/libcheri_type.c /* The number of bits in the type field of a capability.\n Kernel Object  Kernel object manipulation is mainly defined in sys/cheri/cheri_otype.c. Kernel Sealing capability A global sealing capability kernel_sealcap is used throughout the kernel; it is initiliazed in _start(). kernel_sealcap is initialized to have PCC with offset CHERI_SEALCAP_KERNEL_BASE, bounds CHERI_SEALCAP_KERNEL_LENGTH, perms CHERI_SEALCAP_KERNEL_PERMS. See more on Cheri kernel booting structs for objects management A struct unrhdr *cheri_otypes is used to maintain a unit number space for type value allocations. The unit number space is created as a set of all possible type values for allocation.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/concrete-semantics/",
	"title": "Concrete Semantics",
	"tags": [],
	"description": "",
	"content": " References:\n Concrete Semantics  Imperative language\nStatement: declaration of fact or claim. e.g. \u0026ldquo;Semantics is easy.\u0026rdquo;\n声明/断言：对一个事实或者断言的声明。比如，“语义学是简单的”。\nCommand：order to do something. e.g. \u0026ldquo;Study the book until you have understood it.\u0026rdquo;\n命令：指示去做某一件事。比如，“好好学习这本书，一直学到懂为止。”\nExpressions are evaluated, Commands are executed.\nBig step semantics: $(c,s) \\Rightarrow t$. Command $c$ started in state $s$, terminates in state $t$.\nBig step rules use $\\Rightarrow$:\n$(Skip, s) \\Rightarrow s$\n$(x ::= a, s)$ $\\Rightarrow$ $ s(x:= aval\\ a \\ s)$\n$\\frac{(c_1,s_1)\\Rightarrow s_2 \\ \\ (c_2,s_2)\\Rightarrow s_3}{(c_1;;c_2, s_1) \\Rightarrow s_3}$\nInverted Rules:\n$\\frac{(c_1;;c_2, s_1) \\Rightarrow s_3}{\\exists s_2. (c_1,s_1)\\Rightarrow s_2 \\ \\wedge \\ (c_2,s_2)\\Rightarrow s_3}$\nBig step rules:\n cannot directly describe nonterminating computations cannot directly describe parallel computations  Small step rules use $\\rightarrow$:\n(commands, state) $\\rightarrow$ (commands, state)\nor\n$(c,s) \\rightarrow (c\u0026rsquo;, s\u0026rsquo;)$\n==\u0026gt; \u0026ldquo;fist step in the execution of c in state s leaves a \u0026ldquo;remainder\u0026rdquo; command c' to be executed in state s'\u0026ldquo;\nA pair (c,s) is called a configuration.\nIf $cs \\rightarrow cs\u0026rsquo;$ we say that cs reduces to cs'.\nA configuration is final iff $\\nexists$ $cs\u0026rsquo;. \\ cs \\rightarrow cs\u0026rsquo;$\n$(SKIP, s)$ is final since $SKIP$ is the empty program. Nothing more to be done.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/mipstop/",
	"title": "MIPSTop.bsv",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A What is the specification of memory interface ? No mater what the capability width is, the MIPS processor has a memory interface of 256-bit data width (WORD width), 35-bit WORD address width. As there are 2^5 = 32 bytes = 256 bits per word, this is equivalent to a 35 + 5 = 40 byte address.\n==\u0026gt; Memory interface is not byte addressable, but only world addressable; But processor could address in bytes inside itself.\n==\u0026gt; Not 64-bit addressable processor. 24-bits left unused for memory access.\nCan CPU reuse the 24-bit unused memory address? This is physical address, which highly depends on the actual hardware interface implementation. So if this is possible, it will not have much portability.\nIf MMU exists: will also have the unused bits of virtual address, and the physical address. OS can manage both virtual and physical address, but application will not be able to inspect the physical address.\nIf no MMU: probably can embed more infomation in the address.\nThe mkMIPSTop module instantiates the main processor pipeline and memory hierarchy. 1\nOverview Methods:\n reset_n() getPause() putState(\u0026hellip;)  Rules:\n instructionFetch debugInstructionFetch fromFetchToScheduler fromSchedulerToDecode fromDecodeToExecute fromExecuteToMemAccess tick putResetOut Other Rules:  doInit0(init0) cop1ToMem memToCop1 cop3ToMem MemToCop3 reportCacheConfig reportCommittingToDCache   interface MIPSTopIfc MIPSTopIfc is the top level processor interface, exporting the memory interface, interrupts, and debug interface.\nNo mater what the capability width is, the MIPS processor, has a memory interface of 256-bit data width,\n35-bit WORD address width. As there are 2^5 = 32 bytes = 256 bits per word, this is equivalent to a 35 + 5 = 40 byte address.\n// file: cheri/trunk/MIPSTopIfc.bsv // MIPSTopIfc is the interface for the processor top level, exporting the memory // interface as well as interrupts and a debug interface. interface MIPSTopIfc; `ifdef MULTI // Instruction cache invalidate interface method Action invalidateICache(PhyAddress addr); // Data cache invalidate interface method Action invalidateDCache(PhyAddress addr); method ActionValue#(Bool) getInvalidateDone; interface Master#(CheriMemRequest, CheriMemResponse) imemory; interface Master#(CheriMemRequest, CheriMemResponse) dmemory; `else // Memory client interface (which initializes transactions), 256 bit data // width, 35-bit WORD address width. As there are 2^5 = 32 bytes per word, // this is equivalent to a 35 + 5 = 40-bit byte address. interface Master#(CheriMemRequest, CheriMemResponse) memory; `endif // interface below is required for the multiport L2Cache //interface Client#(MemoryRequest#(35, 32), BigMemoryResponse#(256)) memory; // 5 interrupt lines, matching the standard MIPS spec. (* always_ready, always_enabled *) // Deliver common state to this core. method Action putState(Bit#(48) count, Bool pause, Bit#(5) interruptLines); // Tell the system to pause. This should pause all cores. method Bool getPause(); // The debug interface is a byte stream interface, a channel of bytes in and a // channel of bytes out. interface Server#(Bit#(8), Bit#(8)) debugStream; // Also a reset out interface. This allows us to reset the system and also // ourselves (if it is fed back in). method Bool reset_n(); // Whether we want the trace unit to be recording at each cycle. // For testing the memory sub-system interface MIPSMemory mipsMemory; `ifdef DMA_VIRT interface Vector#(2, Server#(TlbRequest, TlbResponse)) tlbs; `endif endinterface CAP related Module initiation Memory protection modules in the pipeline\n mkMIPSMemory mkCapCop mkMemAccess mkWriteback mkScheduler mkExecute  Full code of memory access module initiation:\n// cheri/trunk/MIPSTop.bsv: 167 // theMem is the memory hierarchy which needs the system control processor // for TLB integration. MIPSMemory theMem \u0026lt;- mkMIPSMemory(coreId,theCP0); //cheri/trunk/MIPSTop.bsv: 178 // These are the module instantiations for the \u0026#34;Capability\u0026#34; case which // includes our memory protection extensions. `ifdef USECAP // theCapCop is the \u0026#34;Capability coprocessor\u0026#34;, logically MIPS coprocessor // 2, which inserts itself into the general purpose pipeline for register // reads and writes and which also becomes part of the memory path. CapCopIfc theCapCop \u0026lt;- mkCapCop(coreId); // memAccess is the memory access stage of the pipeline which imports data // memory and the capability coprocessor interface PipeStageIfc memAccess \u0026lt;- mkMemAccess(theMem.dataMemory, theCapCop); // The writeback stage of the pipeline imports lots of interfaces because // it updates all system state that results from an instruction commit. `ifndef STATCOUNTERS WritebackIfc writeback \u0026lt;- mkWriteback(theMem, theRF, theCP0, branch, theDebug, cop1, theCapCop, memAccess); `else WritebackIfc writeback \u0026lt;- mkWriteback(theMem, theRF, theCP0, branch, theDebug, cop1, theCapCop, theMem.statCounters, memAccess); `endif // The scheduler pulls the instruction out of the instruction memory interface // and reports any branches to the branch unit. The scheduler also submits // register read addresses to the register file `ifndef STATCOUNTERS PipeStageIfc scheduler \u0026lt;- mkScheduler(branch, theRF, theCP0, cop1, theCapCop, theMem.instructionMemory); `else PipeStageIfc scheduler \u0026lt;- mkScheduler(branch, theRF, theCP0, cop1, theCapCop, theMem.instructionMemory, theMem.statCounters); `endif // The execute stage of the pipeline has access to the coprocessor // interfaces since they may hold their own uncommitted temporary values, // and also the decode interface which it directly accesses so that it can // check conditions of the next instruction before consuming and also the // writeback interface so that it can receive values loaded from memory // for forwarding. PipeStageIfc execute \u0026lt;- mkExecute(theRF, writeback, theCP0, cop1, theCapCop, decode); `else ... `endif Note:\n execute:  access to the coprocessor interface for uncommitted CP values access to decode interface to check conditions of the next instruction before consuming access to writeback interface for forwarding of memory loaded values   Rules for pipelining  instructionFetch fromFetchToScheduler fromSchedulerToDecode fromDecodeToExecute fromExecuteToMemAccess  instructionFetch Ininitalize control token:\n // Initialize a default control token to insert in the pipeline. ControlTokenT ct = defaultControlToken;  Submit read request to instruction memory:\ntheMem.instructionMemory.reqInstruction(nextPC, ct.id, ct.inst);\nfromFetchToScheduler // This rule deqs from the toScheduler fifo and enqs to the scheduler, likely // because the instruction fetch has finished. rule fromFetchToScheduler; // Assign the name ct to the top element of the toScheduler fifo. ControlTokenT ct = toScheduler.first; // Enq ct to the scheduler module fifo interface. The logic for the // scheduler/register rename stage happens./simn the enq. scheduler.enq(ct); // Deq the toScheduler fifo. toScheduler.deq(); endrule fromSchedulerToDecode // This rule takes a token from the scheduler/register rename stage and enqs // it to the decode stage. The conditions on this rule only allow it to fire // when a CP0 write is pending and we are about to decode (and fetch the // registers for) another CP0 instruction. rule fromSchedulerToDecode(!(scheduler.first.observesCP0 \u0026amp;\u0026amp; theCP0.writePending)); // Enq the top element in the scheduler output fifo to decode. // The enq interface of this module actually performs the decode pipeline stage. decode.enq(scheduler.first); // Deq the first element from the scheduler output fifo. scheduler.deq(); endrule fromDecodeToExecute // The fromDecodeToExecute rule enqs the top element from the output fifo in // the decode stage to the execute stage of the pipeline. //(* descending_urgency = \u0026#34;fromDecodeToExecute, execute_doReadReport\u0026#34; *) rule fromDecodeToExecute; // Enq the top element of the output fifo of the decode stage to the execute // input fifo. execute.enq(decode.first); // Deq the decode stage output fifo. decode.deq(); endrule fromExecuteToMemAccess // The fromExecteToMemAccess rule deqs the top element of the execute stage // output fifo and enqs it to memAccess. rule fromExecuteToMemAccess; // Enq the control token in the output fifo of the execute stage to the enq // method of memAccess which implements the memory access stage of the // pipeline. memAccess.enq(execute.first); // Remove the control token from the output fifo in the execute stage of the // pipeline. execute.deq(); endrule   beri ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-perm/",
	"title": "Cheri Permission Constants",
	"tags": [],
	"description": "",
	"content": " CHERI ISA defined permissions 11 permission bits are hardware defined in CHERI ISA.\n//file: // ./sys/mips/include/cherireg.h  /* * CHERI ISA-defined constants for capabilities -- suitable for inclusion from * assembly source code. * * XXXRW: CHERI_UNSEALED is not currently considered part of the perms word, * but perhaps it should be. */ #define\tCHERI_PERM_GLOBAL\t(1 \u0026lt;\u0026lt; 0)\t/* 0x00000001 */#define\tCHERI_PERM_EXECUTE\t(1 \u0026lt;\u0026lt; 1)\t/* 0x00000002 */#define\tCHERI_PERM_LOAD\t(1 \u0026lt;\u0026lt; 2)\t/* 0x00000004 */#define\tCHERI_PERM_STORE\t(1 \u0026lt;\u0026lt; 3)\t/* 0x00000008 */#define\tCHERI_PERM_LOAD_CAP\t(1 \u0026lt;\u0026lt; 4)\t/* 0x00000010 */#define\tCHERI_PERM_STORE_CAP\t(1 \u0026lt;\u0026lt; 5)\t/* 0x00000020 */#define\tCHERI_PERM_STORE_LOCAL_CAP\t(1 \u0026lt;\u0026lt; 6)\t/* 0x00000040 */#define\tCHERI_PERM_SEAL\t(1 \u0026lt;\u0026lt; 7)\t/* 0x00000080 */#define\tCHERI_PERM_CCALL\t(1 \u0026lt;\u0026lt; 8)\t/* 0x00000100 */#define\tCHERI_PERM_UNSEAL\t(1 \u0026lt;\u0026lt; 9)\t/* 0x00000200 */#define\tCHERI_PERM_SYSTEM_REGS\t(1 \u0026lt;\u0026lt; 10)\t/* 0x00000400 */ ./sys/mips/include/cherireg.h CHERI_PERM_SYSTEM_REGS, or Permit_Access_System_Registers in 3.3.5 of ISAv71, can be used to restrict the access of special capability registers, such as $PCC, $DDC, $EPCC, $KCC, $KDC, $CULR (User Thread Local Storage), $CPLR (Privileged Thread-Local Storage), and other architectural specific registers.\nUser defined permissions 15 permission bits for 256-bit CHERI; 4 permission bits for 128-bit CHERI.\nCHERIxxx_PERMI_SWx:\n// file: // ./sys/mips/include/cherireg.h  /* * User-defined permission bits. * * 256-bit CHERI has a substantially larger number of software-defined * permissions. */ #define\tCHERI256_PERM_SW0\t(1 \u0026lt;\u0026lt; 15)\t/* 0x00008000 */#define\tCHERI256_PERM_SW1\t(1 \u0026lt;\u0026lt; 16)\t/* 0x00010000 */#define\tCHERI256_PERM_SW2\t(1 \u0026lt;\u0026lt; 17)\t/* 0x00020000 */#define\tCHERI256_PERM_SW3\t(1 \u0026lt;\u0026lt; 18)\t/* 0x00040000 */#define\tCHERI256_PERM_SW4\t(1 \u0026lt;\u0026lt; 19)\t/* 0x00080000 */#define\tCHERI256_PERM_SW5\t(1 \u0026lt;\u0026lt; 20)\t/* 0x00100000 */#define\tCHERI256_PERM_SW6\t(1 \u0026lt;\u0026lt; 21)\t/* 0x00200000 */#define\tCHERI256_PERM_SW7\t(1 \u0026lt;\u0026lt; 22)\t/* 0x00400000 */#define\tCHERI256_PERM_SW8\t(1 \u0026lt;\u0026lt; 23)\t/* 0x00800000 *///... #define\tCHERI256_PERM_SW15\t(1 \u0026lt;\u0026lt; 30)\t/* 0x40000000 */ #define\tCHERI128_PERM_SW0\t(1 \u0026lt;\u0026lt; 15)\t/* 0x00008000 */#define\tCHERI128_PERM_SW1\t(1 \u0026lt;\u0026lt; 16)\t/* 0x00010000 */#define\tCHERI128_PERM_SW2\t(1 \u0026lt;\u0026lt; 17)\t/* 0x00020000 */#define\tCHERI128_PERM_SW3\t(1 \u0026lt;\u0026lt; 18)\t/* 0x00040000 */ #if (CHERICAP_SIZE == 32) #define\tCHERI_PERM_SW0\tCHERI256_PERM_SW0 #define\tCHERI_PERM_SW1\tCHERI256_PERM_SW1 #define\tCHERI_PERM_SW2\tCHERI256_PERM_SW2 //... #define\tCHERI_PERM_SW15\tCHERI256_PERM_SW15 #else /* (!(CHERICAP_SIZE == 32)) */#define\tCHERI_PERM_SW0\tCHERI128_PERM_SW0 #define\tCHERI_PERM_SW1\tCHERI128_PERM_SW1 #define\tCHERI_PERM_SW2\tCHERI128_PERM_SW2 #define\tCHERI_PERM_SW3\tCHERI128_PERM_SW3 #endif /* (!(CHERICAP_SIZE == 32)) */ System call permission bit One of user permission bits, CHERI_PERMI_SW0, is used as CHERI_PERM_SYSCALL for authorising system calls from $pcc.\n// file: // ./sys/mips/include/cherireg.h  /* * The kernel snags one for the software-defined permissions for the purposes * of authorising system calls from $pcc. This is a bit of an oddity: * normally, we check permissions on data capabilities, not code capabilities, * but aligns with \u0026#39;privilege\u0026#39; checks: e.g., $epcc access. We may wish to * switch to another model, such as having userspace register one or more * class capabilities as suitable for system-call use. */ #define\tCHERI_PERM_SYSCALL\tCHERI_PERM_SW0 Page mapping permission bit (VMMAP) Another user defined permission bit, CHERI_PERM_SW1 is used to restrict the ability to change the page mapping underlying a capability. \u0026ldquo;This can\u0026rsquo;t be the same permission bit as CHERI_PERM_SYSCALL because $pcc should not confer the right rewrite or remap executable memory.\u0026rdquo;\n// file: // ./sys/mips/include/cherireg.h  #define\tCHERI_PERM_CHERIABI_VMMAP\tCHERI_PERM_SW1 Initial permission sets (kernel) Initial permission sets for various scenarios are defined in macros, different between 256-bit and 128-bit CHERI.\nAll permissions (SWALL/HWALL)  CHERI_PERMS_SWALL: Mask of all available software-defined permissions; From CHERI_PERM_SW0 to CHERI_PERM_SW15 for 256 bits, or to CHERI_PERM_SW3 for 128 bits; CHERI_PERMS_HWALL: Mask of all available hardware-defined permissions; From CHERI_PERM_GLOBAL to CHERI_PERM_SYSTEM_REGS;  Root obj-type cap for kernel Global + Seal + Unseal: Root \u0026ldquo;object-type\u0026rdquo; capability for the kernel. This can be used neither as a data nor code capability.\nCHERI_PERM_GLOBAL (LLM: what is permission for? Global variables ???)\n// file: // ./sys/mips/include/cherireg.h  #define\tCHERI_PERM_KERN_TYPE\t(CHERI_PERM_GLOBAL | CHERI_PERM_SEAL |\t\\ CHERI_PERM_UNSEAL) Basic kernel permission The following defines \u0026ldquo;the permission masks for kernel code and data; these are currently a bit broad, and should be narrowed over time as the kernel becomes more capability-aware\u0026rdquo;.\n// file: // ./sys/mips/include/cherireg.h  #define\tCHERI_PERMS_KERNEL\t\\ (CHERI_PERM_GLOBAL | CHERI_PERM_LOAD | CHERI_PERM_LOAD_CAP)\t\\ #define\tCHERI_PERMS_KERNEL_CODE\t\\ (CHERI_PERMS_KERNEL | CHERI_PERM_EXECUTE | CHERI_PERM_SYSTEM_REGS)  #define\tCHERI_PERMS_KERNEL_DATA\t\\ (CHERI_PERMS_KERNEL | CHERI_PERM_STORE | CHERI_PERM_STORE_CAP |\t\\ CHERI_PERM_STORE_LOCAL_CAP)  #define\tCHERI_PERMS_KERNEL_SEALCAP\t\\ (CHERI_PERM_GLOBAL | CHERI_PERM_SEAL | CHERI_PERM_UNSEAL) Super kernel privilege \u0026ldquo;The following definition is a highly privileged kernel capability able to name the entire address space, and is suitable to derive all other kernel-related capabilities from, including sealing capabilities.\u0026rdquo;\n#define\tCHERI_CAP_KERN_PERMS\t\\ (CHERI_PERMS_SWALL | CHERI_PERMS_HWALL) #define\tCHERI_CAP_KERN_BASE\t0x0 #define\tCHERI_CAP_KERN_LENGTH\t0xffffffffffffffff #define\tCHERI_CAP_KERN_OFFSET\t0x0 Root sealing cap for kernel managed objects #define\tCHERI_SEALCAP_KERNEL_PERMS\tCHERI_PERMS_KERNEL_SEALCAP #define CHERI_SEALCAP_KERNEL_BASE\tCHERI_OTYPE_KERN_MIN #define\tCHERI_SEALCAP_KERNEL_LENGTH\t\\ (CHERI_OTYPE_KERN_MAX - CHERI_OTYPE_KERN_MIN + 1) #define\tCHERI_SEALCAP_KERNEL_OFFSET\t0x0 Initial permission sets (user) Basic user space permission CHERI_PERM_EXECUTE for executable capabilities ($pcc);\nCHERI_PERM_STORE, CHERI_PERM_STORE_CAP, and CHERI_PERM_STORE_LOCAL_CAP for data permissions ($c0).\n\u0026ldquo;No variation required between 256-bit and 128-bit CHERI.\u0026rdquo;\n// file: // ./sys/mips/include/cherireg.h  #define\tCHERI_PERMS_USERSPACE\t\\ (CHERI_PERM_GLOBAL | CHERI_PERM_LOAD | CHERI_PERM_LOAD_CAP |\t\\ CHERI_PERM_CCALL | (CHERI_PERMS_SWALL \u0026amp; ~CHERI_PERM_CHERIABI_VMMAP))  #define\tCHERI_PERMS_USERSPACE_CODE\t\\ (CHERI_PERMS_USERSPACE | CHERI_PERM_EXECUTE)  #define\tCHERI_PERMS_USERSPACE_SEALCAP\t\\ (CHERI_PERM_GLOBAL | CHERI_PERM_SEAL | CHERI_PERM_UNSEAL) /* * _DATA includes _VMMAP so that we can derive the MMAP cap from it. * * XXX: Should it include \u0026#34;unallocated\u0026#34; user permissions so * userspace can use them? */ #define\tCHERI_PERMS_USERSPACE_DATA\t\\ (CHERI_PERMS_USERSPACE |\t\\ CHERI_PERM_STORE |\t\\ CHERI_PERM_STORE_CAP |\t\\ CHERI_PERM_STORE_LOCAL_CAP |\t\\ CHERI_PERM_CHERIABI_VMMAP) Userspace capability Definition for userspace \u0026ldquo;unprivileged\u0026rdquo; capability able to name the user portion of the address space:\n// file: // ./sys/mips/include/cherireg.h  #define\tCHERI_CAP_USER_CODE_PERMS\tCHERI_PERMS_USERSPACE_CODE #define\tCHERI_CAP_USER_CODE_BASE\tVM_MINUSER_ADDRESS #define\tCHERI_CAP_USER_CODE_LENGTH\t(VM_MAXUSER_ADDRESS - VM_MINUSER_ADDRESS) #define\tCHERI_CAP_USER_CODE_OFFSET\t0x0  #define\tCHERI_CAP_USER_DATA_PERMS\tCHERI_PERMS_USERSPACE_DATA #define\tCHERI_CAP_USER_DATA_BASE\tVM_MINUSER_ADDRESS #define\tCHERI_CAP_USER_DATA_LENGTH\t(VM_MAXUSER_ADDRESS - VM_MINUSER_ADDRESS) #define\tCHERI_CAP_USER_DATA_OFFSET\t0x0  #define\tCHERI_CAP_USER_MMAP_PERMS\t\\ (CHERI_PERMS_USERSPACE_DATA | CHERI_PERMS_USERSPACE_CODE |\t\\ CHERI_PERM_CHERIABI_VMMAP) /* Start at 256MB to avoid low PC values in sandboxes */ #define\tCHERI_CAP_USER_MMAP_BASE\t(VM_MINUSER_ADDRESS + 0x10000000) #define\tCHERI_CAP_USER_MMAP_LENGTH\t\\ (VM_MAXUSER_ADDRESS - CHERI_CAP_USER_MMAP_BASE) #define\tCHERI_CAP_USER_MMAP_OFFSET\t0x0 Root sealing cap for userspace Root sealing capability for all userspace object capabilities. This is made available to userspace via a sysarch(2).\n#define\tCHERI_SEALCAP_USERSPACE_PERMS\tCHERI_PERMS_USERSPACE_SEALCAP #define\tCHERI_SEALCAP_USERSPACE_BASE\tCHERI_OTYPE_USER_MIN #define\tCHERI_SEALCAP_USERSPACE_LENGTH\t\\ (CHERI_OTYPE_USER_MAX - CHERI_OTYPE_USER_MIN + 1) #define\tCHERI_SEALCAP_USERSPACE_OFFSET\t0x0   CheriISA v7. 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/kernel-changes/",
	"title": "Kernel Change List",
	"tags": [],
	"description": "",
	"content": " References:\n[1] CHERI programmer\u0026rsquo;s guide, UCAM-CL-TR-877, 2015.\nOverview  booting: enable capability coprocessor. per-thread TCB:  a saved capability register file; a per-thread trusted stack  context-switching: save/restore capability register file for userspace. kernel debugger: print capability register file and other CHERI-related info. virtual-memory subsystem:  anonymous (swap-backed) memory objects: memory tags preserved; memory mappings are permitted to set the CHERI TLB bits enabling tagged loads and stores. other objects not yet to preserve tags.  kernel memory copying:  new routines preserve tags; selectively used: in copying register files and explicit tag-preserving copies; majority of kernel memory copies are not tag-preserving.  system call permission:\n rejects whose $PCC register does not have CHERI_PERM_SYSCALL user-defined permission bit, preventing sandboxes from directly invoking system services; sandbox must invoke a system class that is authorized to invoke system calls; should also have new system calls that does not need for interposition \u0026ndash; similar to the behavior of Capsicum.  ccall and creturn fast exception handers:\n unseal invoked object; push the caller state to trusted stack; retore it on return; return to caller if fault occurs.  ktrace facility: allow object invocation/return to be traced.\n cap faults:\n fault in userspace deliver as signals, extending signal trap frame to include capability registers; allows userspace software ( in particular, language runtimes) to catch and handle software protection faults.  extended to allow processes to export class, method, and object statistics.\n supports CheriABI: a new ABI and system call interface:\n all pointers passed to and from the kernel are implemented as capabilities; allows userspace processes to execute pure-capability-ABI binaries that have no dependence on conventional MIPS pointers.   Source code src/sys/mips/cheri/ and src/sys/mips/include contains the majority of CHERI-specific code:\n- coprocessor 2 initialization - context management  headers  cheri.h: C-language definitions relating to capabilities\n kernel-only context structures: cheri_kframe, cheri_signal; kernel/user shared structures: cheri_frame, cheri_stack; macro wrappers for inline assembly are provided for CHERI-aware software implemented via CHERI-unaware C, such as the kernel.  cheriasm.h: definitions for CHERI-aware assembly\n kernel/userspace deinitions: CHERI register names kernel-specific code used in exception handling  cheric.h: compiler builtin wrapper for register access, such as cheri_getbase(), cheri_andperm(). This is used only in userpsace due to dependencies on CHERI-aware Clang/LLVM.\n cherireg.h: C macros suitable for use in both C and assembly that specify low-level CHERI constants, such as permission-mask values. For both kernel and userspace.\n sys/sys/cheri_serial.h: provides a structure and definitions supporting serialization of capabilities independent of their size and micro-architectural details.\n  Source files ccall.S: fast exception handlers for ccall and creturn. Errors go to a regular MipsUserGenException hander.\nccall_ktrace.S: a slow path exception handlers used to trace ccall and creturn invocations.\ncheri.c: majority of CHERI-specific C code including:\n debugging features; sysctls; initializaitoni for the capability state of threads/processes; handling of fork; portion of signal handling; exception logging; system call authorization.   cheri_bcopy.S: CHERI version of memcpy and bcopy\n suitable for use throughout the kernel copyin and copyout do not use them? [ch 8.1, p49]  cheri_debug.c: CHERI commands for in-kenrel debugger.\ncheri_exception.c: reporting CHERI exceptions and registers on the system console.\ncheri_signal.c: CHERI signal handling infrastructure.\ncheri_stack.c: CHERI trusted-stack initialization, copying, and unwinding, and sysarch system calls to get/set current trusted stack.\ncheri_syscall.c: CHERI related system-call infrastructure.\ncheriabi_machdep.c: ISA dependent CheriABI support including\n system call vector declaration; argument parsing; return handling; signal handling; process memory initialization.  sys/compat/cheriabit/* CheriABI ISA-independent implementation. The implementation is modelled on the support for 32-bit binaries in sys/compat/freebsd32.\nQuestions Todo list:\n in cheri.h: \u0026ldquo;Macro wrappers for inline assembly are provided for CHERI-aware software implemented via CHERI-unaware C, such as the kernel\u0026rdquo;, what is this? How does the CHERI-aware and CHERI-unaware code interface each other here?  Lele: See CheriABI, which defines how userspace (full capability) interfaces with kernel that has partial capability. \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/intro/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " CHERI Background Material cite: CHERI Background @RISC-V SIG CHERI\nCHERI Talks/Videos  Motivation for CHERI YouTube video (3-minutes) HotChips 2022 - Talk on Morello (CHERI on ARM): YouTube Slides CHERI Session at RISC-V Week in Paris Slides  Industry Announcements about CHERI  ARM Morello (CHERI on ARM) Web site Microsoft announce CHERI-RSIC-V embedded core Blog Microsoft security analysis of CHERI Report PDF on GitHub  Background Research  See the Cambridge CHERI project Web site An introduction to CHERI Report CHERI ISA reference Report  More informative introductions:\n An Armful of CHERIs, Security Research \u0026amp; Defense, By Saar Amar, January 20, 2022  Questions  Code pointers in Cheri is protected from being corrupted. Can it prevent the code reuse attack also? If not, how to enhance it?\n Code reuse that depends on the corruption of return address might be prevented if ret addr is \u0026lsquo;well protected\u0026rsquo;.  Sadly not. Any executable capability in the \u0026lsquo;valid\u0026rsquo; set of current process can overwrite the return address on the stack;  Code reuse that depends on the corruption of return address might be prevented if no memory error can be used to overwrite the return address.\n How to prove there is no memory error in CHERI?   Code reuse by data corruption (data oriented programming) might be prevented if data is well protected.\n How to prove there is no memory error in CHERI?    The heavy and deep motivations of CHERI: Motivations\nHistory CHERI ISA Refinement History   2016 v5: Initial in-kernel privilege limitation 2017 v6: Exception free domain transition 2019 v7: Temporal memory safety\n Initial CHERI architecture in 2012-resolve1, 2014-ISCA2;\n Compartmentalization framework in 2016-MICRO3, 2015-SP4;\n C language compilation mode where all pointers are capabilities in 2015-ASPLOS 5;\n Use of capabilities to implement a safe JNI, 2017-ASPLOS6.\n A complete userspace execution environment with CheriABI: 2019-ASPLOS7;\n  Basics Address validity vs pointer safety  Address validity associates protection properties with regions of address space, (such as a virtual page), regardless what is stored in the region.\n Pointer safety associates protection properties with object references, a higher abstraction over the raw memory regions.\n  Capabilities Capability systems are hardware, software, or distributed systems designed to implement the principle of least privilege[^11, ^12].\nCapabilities are unforgeable tokens of authority granting rights to objects in the system. They can be selectively delegated between constrained programs to enforce security policies.\nCompartmentalization Software compartmentalization, as known as privilege separation, mitigates vulnerabilities by decomposing applications into isolated components \u0026ndash; each granted only the rights it requires to operate.\nCompartmentalization granularity describes the degree of program decompositioin. Fine-grained compartmentalization improves mitigation by virtue of the principle of least privilege: attackers must exploit\nMMU\u0026rsquo;s granularity and address validation  process-granularity fault isolation, but\n \u0026ldquo;When OS kernels act on userspace, e.g., via pointers passed in to system calls, they must act on correct set of physical pages correpsonding to the process.\u0026rdquo;  conflated protection and translation: the granularity of both is one virtual page. But\n do not scale easily to handle finer-grain protection, and do not distinguish virtual addresses from arbitrary integers: while the MMU protects the structure of the virtual memory space, the references to virtual memory are unprotected.   Overview --\nCHERI Capabilities  Tags protect capabilities in registers and memory Bounds limit range of address space accessible via pointer Permissions limit operations, e.g., load, store, fetch Sealing for encapsulation: immutable, non-dereferenceable. The seal bit tag is removed from ISAv7. Instead, unsealed capability is redefined as having otype of $2^64 -1$. Compressed bounds relative to 64-bit virutal address.  Protection Semantics for Pointers  Integrity and provenance validity  ensure that valid pointers are derived from other valid pointers via valid transformations; invalid pointers cannot be used  Bounds prevent pointers form being manipulated to access the wrong object; Permissions limit unintended use of pointers; e.g., W^X for pointers; Monotonicity prevents pointer privilege escalation; e.g., broadening bounds.  However, bounds and permissions must be initialized correctly by software \u0026ndash; e.g. stack allocator, heap allocator, dynamic linker\nTwo levels of abstraction (v5:) Cheri allows software privilege to be minimized at two levels of abstraction.\n architectural least privilege: memory capability.\n data pointers: against data-oriented vulnerabilities, such as buffer overflows. code pointers: support CFI by preventing corruption of code pointers/return addresses.  application-level least privilege: software compartmentalization using object capabilities.\n  Code pointers  CHERI: A Research Platform Deconflating Hardware Virtualization and Protection. RESoLVE, 2012. ↩ The CHERI capability model: Revisiting RISC in an age of risk. ISCA, 2014. ↩ Fast Protection-Domain Crossing in the CHERI Capability-System Architecture. MICRO, 2016. ↩ CHERI: A Hybrid Capability-System Architecture for Scalable Software Compartmentalization. SP, 2015. ↩ Beyond the PDP-11: Processor support for a memory-safe C abstract machine. ASPLOS, 2015. ↩ CHERI JNI: Sinking the Java Security Model into the C. ASPLOS, 2017. ↩ CheriABI: Enforcing Valid Pointer Provenance and Minimizing Pointer Privilege in the POSIX C Run-time Environment. ASPLOS, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/book-soft/v1-lf/",
	"title": "V1 Logical Foundations",
	"tags": [],
	"description": "",
	"content": " References:\n Software Foundations, Volume 1, Logical Foundations\n Video Class2, Micheal Ryan Clarkson\n [QED at large, Ringer et al., 2019]()\n  Preface Source of Knowledge Source of Knowledge [Mechanizing Proof. MacKenzie 2001]\n Authority Inductive reasoning Deductive reasoning  Inductive vs. Deductive cite: https://www.voxco.com/blog/inductive-vs-deductive-reasoning/\nInductive reasoning  Inductive reasoning is a logical thinking process that integrates observations with experiential information to draw a conclusion. You are employing the use of inductive reasoning every time you look at a set of data and then form general conclusions on knowledge from past experiences.\nInductive research is usually used when there is a lack of existing literature on a topic. This is because there is no existing theory that can be tested on the concept. The inductive training approach can be categorized into the following three stages:\n  Observation Observe a Pattern Develop a Theory  e.g. Use history data, observe a pattern, and to predict the future: Given $6, 9, 12, 15, \u0026hellip;$, then what is $n$th number?\ncite: https://www.khanacademy.org/math/algebra-home/alg-series-and-induction/alg-deductive-and-inductive-reasoning/v/u12-l1-t3-we1-inductive-reasoning-1\nWeakness:\nA drawback of inductive reasoning is that inferences are made from specific situations that may not have significance in the real world.\nDeductive reasoning  When employing deductive reasoning in research, you begin with a theory. This theory is then narrowed down into more specific hypotheses that can be tested. These are further narrowed down into observations that allow us to test the hypothesis to confirm whether the data supports or rejects the hypothesis.\n The deductive training approach can therefore be categorized into the following four stages:\n Begin with an Existing Theory Formulate a Hypothesis based on the Existing Theory Collect Data to Test the Hypothesis Analyze the results to see whether the Data Supports or Rejects the Hypothesis  Weakness:\nRelies on initial premises being correct. Deductive reasoning heavily relies on the initial premises being correct. The final argument is invalid if even one premise is found to be incorrect.\ne.g. Mathematic equation solving in the class: $5+\\sqrt{(x+14)} = x + 7$\nType Theory (Static) Type System.\n Compiler: deductive reasoning to check types. Not strong enough:  strong enough to express that a function takes an integer as input, and produces an integer as output; not strong enough to express that the function computes, say, a factorial.  Sound: well-typed programs don\u0026rsquo;t go wrong. Might not complete: there could be programs that would never go wrong and yet cannot be typed with it. Type casts might need to be inserted that cann\u0026rsquo;t be statically checked and could fail at runtime.  Usage Example of type system:\n Python -\u0026gt; Dropbox.\n Martin-Lof\n ? Cornell. NuPRL [Robert Constable] \u0026ndash; extract verified programs from proof of correctness.\n 1980s. France. Calculus of Constructions [Gerard Huet and Thierry Coquand]\n 1990s. Calculus of Inductive Constructions [Coquand and Christine PaulinMohring]\n 2003. Coq 8.0.   The software crisis \u0026ndash; The begining of formal methods\nFormal Methods  Formal Specifications.  Z notations  Formal Spec + Proofs about programs  \u0026ldquo;The Science of Programming\u0026rdquo;, David Gries.  Formal SPec + Proofs about programs + Machine checking.  with some defeats:  Godel: (1931) Turing: Halting problem is undecidable. Rice: every property of a software program is undecidable, unless is trivial (eg. compilers do).  TLA+   Foundations of Mathematics \u0026ndash; incomplete/undedidable @1931. Godel. Incompleteness theorem.\n Any logic strong enough to reason about arithmetic must be incomplete. Arithmetic There will be propositions that can neither be proved nor disproved.  ==\u0026gt; We have to admit a certain amount of defeat: if the correctness of our program involves such a proposition, we cannot succeed.\n@ 1936. Turing. Halting \u0026ndash; Undecidable.\n No computer program can perfectly deterime whether another program will either terminate or run forever in an infinite loop on a given input.  @1951, Henry Gordon Rice. Syracuse University.\n It is not just the halting problem that is undecidable: every property of a program is undecidable, unless that property is in some way he called trivial.  Trivial property: For example, it\u0026rsquo;s true of all programs, or it\u0026rsquo;s a property of the syntax of the program rather than its semantics. \u0026ndash; Compilers, based on syntax; Truely interesting semantic properties of programs are undecidable.   Overview 这一卷介绍三个内容：\n 用于阐述和判定程序特性的基本的逻辑工具 如何使用推理辅助器来构造严密的逻辑语句 函数式编程（既作为一个简化程序分析的编程工具，也是一个计算机编程与逻辑学之间的桥梁）  This volume weaves together three conceptual threads:\n basic tools from logic for making and justifying precise claims about programs; the use of proof assistants to construct rigorous logical arguments; functional programming, both as a method of programming that simplifies reasoning about programs and as a bridge between programming and logic.  Logic  事实发现，逻辑学对于计算机的作用效果，远远大于在数学领域所起的作用。这个发现起到了标志性的作用，因为近100年来所有的关于逻辑的研究都是来自数学领域。\n在计算机领域，归纳证明几乎无处不在。你肯定在以前的离散数学或者算法分析的课程上见到过归纳证明，但是在这个课程中，我们将更为深入的探讨这个方法。\n\u0026ldquo;As a matter of fact, logic has turned out to be siginicantly more effective in computer science than it has been in mathematics. This is quite remarkable, especially since much of the impetus for the development of logic during the past one hundred years came from mathematics.\u0026rdquo;\n\u0026ldquo;In particular, the fundamental tools of inductive proof are ubiquitous in all of computer science. You have surely seen them before, perhaps in a course on discrete math or analysis of algorithms, but in this course we will examine them more deeply than you have probably done so far.\u0026rdquo;\n Proof Assistants 逻辑学与计算机科学是互补的学科：计算机学科对逻辑学也是有贡献的。其中一个贡献便是用计算机开发出的用于构造证明的软件工具。这些软件工具包括两大类。\n两大类证明器：\n 自动定理证明器提供了一个按钮式的功能：你给他一个断言(proposition)，他给你一个结果(对、错或者不知道\u0026ndash;超时)。这些工具的应用仍然局限在特定领域中，但是近几年已经取得了较好的发展，其应用范围有所扩大。  比如 SAT求解器；SMT求解器(Z3)；模型检测工具等。  辅助证明器是一种混合的工具：它把相对规范而容易自动化的特性证明用机器来做，而较难以自动化的证明采用人工诱导的方式。  应用较广的辅助证明器有：Isabelle, Agda, Twelf, ACL2, PVS, Coq等。   Two broad categories of proof assistants:\n Automated theorem provers provide \u0026ldquo;push-button\u0026rdquo; operation: you give them a proposition and they return either true or false (or, sometimes, don\u0026rsquo;t know: ran out of time).  Examples: SAT solvers, SMT solvers, and model checkers.  Proof assistants are hybrid tools that automate the more routine aspects of building proofs while depending on human guidance for more difficult aspects.  Examples: Isabelle, Agda, Twelf, ACL2, PVS, and Coq.   本教程基于Coq。\nCoq Coq的开发开始于1983年，并在近几年获得了学术界和产业界诸多用户的关注。 Coq为机器检查的形式化推理提供了一个丰富的交互式环境。\nCoq的核心（kernel）是一个简单的证明检查器（Proof-checker），这个检查器能够保证，只有当推理（deduction）步骤完全正确，才能通过检查。\n在核心之外，Coq提供了多种高级手段来辅助证明的构造，包括：\n 一个汇聚了诸多公共定义和定理的证明库 各种可以辅助构造复杂证明的证明策略（Tactics） 一个可以用于构造新的证明策略的定制语言。  Kernel of Coq:\na simple proof-checker, guarantees that only correct deduction steps are ever performed.\nFacilities in Coq:\n A large library of common definitions and lemmas Powerful tactics for constructing complex proofs semi-automatically A special-purpose programming language for defining new proof-automation tactics for specific situations  Coq 在计算机科学和数学领域中的应用有很多方面：\n 作为一个构造编程语言模型的平台。Coq已经成为编程语言设计人员的标准工具，用于分析复杂的语言定义。比如，Coq曾经被用于JavaCard平台的安全性  Usages of Coq:\n As a platform for modeling programming languages. Examples:\n check the security of the JavaCard platform formal specifications of the X86 and LLVM instruction sets and programming languages such as C.  As an environment for developing formally certified software and hardware. Examples:\n CompCert, a fully-verified optimizing compiler for C. CertiKOS, a fully verified hypervisor. Proving the correctness of subtle algorithms involving floating point numbers. As basis for CertiCrypt, an environment for reasoning about the security of cryptographic algorithms. Build verified implementations of the open-source RISC-V processor architecture.  As a realistic environment for functional programming with dependent types. Examples:\n \u0026ldquo;Relational Hoare reasoning\u0026rdquo; embeded in Ynot system.  As a proof assistant for higher-order logic. Examples:\n Proof of 4-color theorem. Proof of Feit-Thompson Theorem.   Functional programming Functional programming is:\n a collection of programming idioms that can be used in almost any programming language a family of programming languages designed to emphasize these idioms, including\n Haskell, Ocaml, Standard ML, F#, Scala, Scheme, Racket, Common Lisp, Clojure, Erlang, and Coq.  Its roots go back to Church\u0026rsquo;s lambda-calculus, invented in 1930s, well before the first electronic computers.\n Playing a key role in high-value systems at companies like Jane Street Capital, Microsoft, Facebook, Twitter, and Ericsson.\n  Most basic tenet: computation should be pure:\n the only effect of execution should be to produce a result; It should be free from side effects such as I/O, assignments to mutable variables, redirecting pointers, etc. For example:\n an imperative sorting function might take a list of numbers and rearrange its pointers to put the list in order; a pure sorting function would take the original list and return a new list containing the same numbers in sorted order. (A relative pure??? Numbers in the original list can semantically \u0026lsquo;point\u0026rsquo; to some information??? Like, 127 means the ID of a car, and 128 another car?).  Benefits of pure functional programming\n It makes programs easier to understand and reason about. If every operation on a data structure yields a new data structure, leaving the old one intact, then there is no need to worry about how that data structure is being shared and whether a change by one part of the program might break an invariant relied on by another part of the program. These considerations are particularly critical for concurrent systems, where every piece of mutable state that is shared between threads is a potential source of pernicious bugs. Indeed, a large part of the recent interest in functional programming in industry is due to its simpler behavior in the presence of concurrency. Functional programs are often much easier to parallelize and physically distribute than their imperative counterparts. If running a computation has no effect other than producing a result, then it does not matter where it is run. Similary, if a data structure is never modified destructively, then it can be copied freely, across cores or across the network. The \u0026ldquo;Map-Reduce\u0026rdquo; idiom, which lies at the heart of massively distributed query processors like Hadoop and is used by Google to index the entire web is a classic example of functional programming. Functional programming serves as a bridge between logic and computer science. Coq itself can be viewed as a comnbination of a small but extremely expressive functional programming language plus a set of tools for stating and proving logical assertions.  These two side of Coq are actually aspects of the very same underlying machinery \u0026ndash; i.e., proofs are programs.    More  Coq  References: Basics: Functional Programming in Coq Functional style of programming is founded on simple, everyday mathematical intuition: If a procedure or method has no side effects, then (ignoring efficiency) all we need to understand about it is how it maps input to outputs. The direct connection between programs and simple mathematical objects supports both formal correctness proofs and sound informal reasoning about program behavior. Features of functional programming in Coq:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-process/",
	"title": "Process or thread-like solutions for Privilege Separation",
	"tags": [],
	"description": "",
	"content": "  Many used in automatic separtion  More  2009 Eurosys: Isolating Web Programs in Modern Browser Architectures   References: Reis, Charles, and Steven D. Gribble. \u0026ldquo;Isolating web programs in modern browser architectures.\u0026rdquo; In Proceedings of the 4th ACM European conference on Computer systems, pp. 219-232. 2009. More  Preventing Privilege Escalation  2003 USENIX Security1: Privilege Escalation Services that require special privilege for their operation are critically sensitive. A programming error here may allow an adversary to obtain and abuse the special privilege. Privilege Separation Privilege Seperation: a generic approach to limit the scope of programming bugs. The basic priciple of privilege separation is to reduce the amount of code that runs with special privilege without affecting or limiting the functionality of the service.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-cap/",
	"title": "Capability based privilege separation",
	"tags": [],
	"description": "",
	"content": " More  Capsicum CHERI Compartmentalization   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxsw/box-lang-sep/",
	"title": "Lang Sep",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Fidelius Charm: Isolating Unsafe Rust Code  Reference 1 Rust: memory safety is lost when any unsafe blocks are used. Fedelius Charm(FC): limiting access to the program\u0026rsquo;s memory while executing unsafe libraries: move sensitive program data to protected pages before entering unsafe code; call userspace lib e.g. fc_immutable in which call system call mprotect to change page permission bits and switch to isolated mode; allow unsafe code to run normally without modifications; restore visibility of the protected state when unsafe code completes; call userspace lib e.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/2018-nsdi-safebricks/",
	"title": "SafeBricks: Shielding NetworkFunctions in the Cloud",
	"tags": [],
	"description": "",
	"content": " References:\n Poddar, Rishabh, Chang Lan, Raluca Ada Popa, and Sylvia Ratnasamy. \u0026ldquo;Safebricks: Shielding network functions in the cloud.\u0026rdquo; In 15th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 18), pp. 201-216. 2018.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/attack-sgx/2018-accs-rsa/",
	"title": "Single Trace Attack Against RSA Key Generation inIntel SGX SSL",
	"tags": [],
	"description": "",
	"content": " References:\n Weiser, Samuel, Raphael Spreitzer, and Lukas Bodner. \u0026ldquo;Single trace attack against RSA key generation in Intel SGX SSL.\u0026rdquo; In Proceedings of the 2018 on Asia Conference on Computer and Communications Security, pp. 575-586. 2018.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/2018-sp-hypertd/",
	"title": "Racing in Hyperspace: Closing Hyper-ThreadingSide Channels on SGX with Contrived Data Races",
	"tags": [],
	"description": "",
	"content": " References:\n Chen, Guoxing, Wenhao Wang, Tianyu Chen, Sanchuan Chen, Yinqian Zhang, XiaoFeng Wang, Ten-Hwang Lai, and Dongdai Lin. \u0026ldquo;Racing in hyperspace: Closing hyper-threading side channels on sgx with contrived data races.\u0026rdquo; In 2018 IEEE Symposium on Security and Privacy (SP), pp. 178-194. IEEE, 2018.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/attack-sgx/2018-sec-dilemma/",
	"title": "The Guard’s Dilemma: Efficient Code-Reuse Attacks Against Intel SGX",
	"tags": [],
	"description": "",
	"content": " References:\n Biondo, Andrea, Mauro Conti, Lucas Davi, Tommaso Frassetto, and Ahmad-Reza Sadeghi. \u0026ldquo;The Guard\u0026rsquo;s Dilemma: Efficient Code-Reuse Attacks Against Intel {SGX}.\u0026rdquo; In 27th {USENIX} Security Symposium ({USENIX} Security 18), pp. 1213-1227. 2018.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/2018-ndss-sgx-filesys/",
	"title": "2018NDSS: OBLIVIATE: A Data Oblivious File Systemfor Intel SGX",
	"tags": [],
	"description": "",
	"content": " References:\n Ahmad, Adil, Kyungtae Kim, Muhammad Ihsanulhaq Sarfaraz, and Byoungyoung Lee. \u0026ldquo;OBLIVIATE: A Data Oblivious Filesystem for Intel SGX.\u0026rdquo; In NDSS. 2018.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/attack-sgx/2020-sp/",
	"title": "2020SP: LVI: Hijacking Transient Execution throughMicroarchitectural Load Value Injection",
	"tags": [],
	"description": "",
	"content": " References:\n Van Bulck, Jo, Daniel Moghimi, Michael Schwarz, Moritz Lippi, Marina Minkin, Daniel Genkin, Yuval Yarom, Berk Sunar, Daniel Gruss, and Frank Piessens. \u0026ldquo;LVI: Hijacking transient execution through microarchitectural load value injection.\u0026rdquo; In 2020 IEEE Symposium on Security and Privacy (SP), pp. 54-72. IEEE, 2020.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/attack-sgx/2019-eurosp/",
	"title": "2019 Eurosp",
	"tags": [],
	"description": "",
	"content": " References:\n Chen, Guoxing, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and Ten H. Lai. \u0026ldquo;SgxPectre: Stealing Intel secrets from SGX enclaves via speculative execution.\u0026rdquo; In 2019 IEEE European Symposium on Security and Privacy (EuroS\u0026amp;P), pp. 142-157. IEEE, 2019.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/attack-sgx/2018-sec-defend/",
	"title": "2018SEC: Varys: Protecting SGX enclaves from  practical side-channel attacks",
	"tags": [],
	"description": "",
	"content": " References:\n Oleksenko, Oleksii, Bohdan Trach, Robert Krahn, Mark Silberstein, and Christof Fetzer. \u0026ldquo;Varys: Protecting {SGX} enclaves from practical side-channel attacks.\u0026rdquo; In 2018 {Usenix} Annual Technical Conference ({USENIX}{ATC} 18), pp. 227-240. 2018.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/attack-sgx/2018-sec/",
	"title": "2018SEC: Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution",
	"tags": [],
	"description": "",
	"content": " References:\n Van Bulck, Jo, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F. Wenisch, Yuval Yarom, and Raoul Strackx. \u0026ldquo;Foreshadow: Extracting the keys to the intel {SGX} kingdom with transient out-of-order execution.\u0026rdquo; In 27th {USENIX} Security Symposium ({USENIX} Security 18), pp. 991-1008. 2018.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/attack-sgx/2017-sec/",
	"title": "2017SEC: Telling Your Secrets Without Page Faults: Stealthy Page Table-Based Attacks on Enclaved Execution",
	"tags": [],
	"description": "",
	"content": " References:\n Van Bulck, Jo, Nico Weichbrodt, Rüdiger Kapitza, Frank Piessens, and Raoul Strackx. \u0026ldquo;Telling your secrets without page faults: Stealthy page table-based attacks on enclaved execution.\u0026rdquo; In 26th {USENIX} Security Symposium ({USENIX} Security 17), pp. 1041-1056. 2017.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/attack-sgx/",
	"title": "Attack Sgx",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Single Trace Attack Against RSA Key Generation inIntel SGX SSL   References: Weiser, Samuel, Raphael Spreitzer, and Lukas Bodner. \u0026ldquo;Single trace attack against RSA key generation in Intel SGX SSL.\u0026rdquo; In Proceedings of the 2018 on Asia Conference on Computer and Communications Security, pp. 575-586. 2018. More  The Guard’s Dilemma: Efficient Code-Reuse Attacks Against Intel SGX   References: Biondo, Andrea, Mauro Conti, Lucas Davi, Tommaso Frassetto, and Ahmad-Reza Sadeghi. \u0026ldquo;The Guard\u0026rsquo;s Dilemma: Efficient Code-Reuse Attacks Against Intel {SGX}.\u0026rdquo; In 27th {USENIX} Security Symposium ({USENIX} Security 18), pp. 1213-1227. 2018. More  2020SP: LVI: Hijacking Transient Execution throughMicroarchitectural Load Value Injection   References: Van Bulck, Jo, Daniel Moghimi, Michael Schwarz, Moritz Lippi, Marina Minkin, Daniel Genkin, Yuval Yarom, Berk Sunar, Daniel Gruss, and Frank Piessens. \u0026ldquo;LVI: Hijacking transient execution through microarchitectural load value injection.\u0026rdquo; In 2020 IEEE Symposium on Security and Privacy (SP), pp. 54-72. IEEE, 2020. More  2019 Eurosp   References: Chen, Guoxing, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and Ten H. Lai. \u0026ldquo;SgxPectre: Stealing Intel secrets from SGX enclaves via speculative execution.\u0026rdquo; In 2019 IEEE European Symposium on Security and Privacy (EuroS\u0026amp;P), pp. 142-157. IEEE, 2019. More  2018SEC: Varys: Protecting SGX enclaves from practical side-channel attacks   References: Oleksenko, Oleksii, Bohdan Trach, Robert Krahn, Mark Silberstein, and Christof Fetzer. \u0026ldquo;Varys: Protecting {SGX} enclaves from practical side-channel attacks.\u0026rdquo; In 2018 {Usenix} Annual Technical Conference ({USENIX}{ATC} 18), pp. 227-240. 2018. More  2018SEC: Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution   References: Van Bulck, Jo, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F. Wenisch, Yuval Yarom, and Raoul Strackx. \u0026ldquo;Foreshadow: Extracting the keys to the intel {SGX} kingdom with transient out-of-order execution.\u0026rdquo; In 27th {USENIX} Security Symposium ({USENIX} Security 18), pp. 991-1008. 2018. More  2017SEC: Telling Your Secrets Without Page Faults: Stealthy Page Table-Based Attacks on Enclaved Execution   References: Van Bulck, Jo, Nico Weichbrodt, Rüdiger Kapitza, Frank Piessens, and Raoul Strackx. \u0026ldquo;Telling your secrets without page faults: Stealthy page table-based attacks on enclaved execution.\u0026rdquo; In 26th {USENIX} Security Symposium ({USENIX} Security 17), pp. 1041-1056. 2017. More  Glamdring: Automatic Application Partitioning for Intel SGX  Reference: Glamdring @ 2017ATC 1 Glamdring: Automatic Application Partitioning for Intel SGX. USENIX ATC, 2017. ↩  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/mem-tag/2004-flow/",
	"title": "2004 SigNotice: Secure Program Execution via Dynamic Information Flow Tracking",
	"tags": [],
	"description": "",
	"content": " References:\n Suh, G. Edward, Jae W. Lee, David Zhang, and Srinivas Devadas. \u0026ldquo;Secure program execution via dynamic information flow tracking.\u0026rdquo; ACM Sigplan Notices 39, no. 11 (2004): 85-96.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-compart-papers/2016-phd/",
	"title": "2016 Thesis: Hardware support for compartmentalisation",
	"tags": [],
	"description": "",
	"content": " References:\n Norton, Robert M. Hardware support for compartmentalisation. No. UCAM-CL-TR-887. University of Cambridge, Computer Laboratory, 2016.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-process/2009-eurosys-chrome/",
	"title": "2009 Eurosys: Isolating Web Programs in Modern Browser Architectures",
	"tags": [],
	"description": "",
	"content": " References:\n Reis, Charles, and Steven D. Gribble. \u0026ldquo;Isolating web programs in modern browser architectures.\u0026rdquo; In Proceedings of the 4th ACM European conference on Computer systems, pp. 219-232. 2009.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-compart-papers/2017-asplos/",
	"title": "2017 Asplos: CHERI JNI: Sinking the Java security model into the C",
	"tags": [],
	"description": "",
	"content": " References:\n Chisnall, David, Brooks Davis, Khilan Gudka, David Brazdil, Alexandre Joannou, Jonathan Woodruff, A. Theodore Markettos et al. \u0026ldquo;CHERI JNI: Sinking the Java security model into the C.\u0026rdquo; ACM SIGARCH Computer Architecture News 45, no. 1 (2017): 569-583.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-compart-papers/2016-micro/",
	"title": "2016 Micro: Fast Protection-Domain Crossing in the CHERI Capability-System Architecture",
	"tags": [],
	"description": "",
	"content": " References:\n Watson, Robert NM, Robert M. Norton, Jonathan Woodruff, Simon W. Moore, Peter G. Neumann, Jonathan Anderson, David Chisnall et al. \u0026ldquo;Fast protection-domain crossing in the cheri capability-system architecture.\u0026rdquo; IEEE Micro 36, no. 5 (2016): 38-49.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-compart-papers/2015-sp/",
	"title": "2015 SP: CHERI: A Hybrid Capability-System Architecture for Scalable Software Compartmentalization",
	"tags": [],
	"description": "",
	"content": " References:\n Watson, Robert NM, Jonathan Woodruff, Peter G. Neumann, Simon W. Moore, Jonathan Anderson, David Chisnall, Nirav Dave et al. \u0026ldquo;Cheri: A hybrid capability-system architecture for scalable software compartmentalization.\u0026rdquo; In 2015 IEEE Symposium on Security and Privacy, pp. 20-37. IEEE, 2015.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/smart-sep/2019-ccs-pm/",
	"title": "2019 CCS: Program-mandering: Quantitative Privilege Separation",
	"tags": [],
	"description": "",
	"content": " References:\n Liu, Shen, Dongrui Zeng, Yongzhe Huang, Frank Capobianco, Stephen McCamant, Trent Jaeger, and Gang Tan. \u0026ldquo;Program-mandering: Quantitative privilege separation.\u0026rdquo; In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pp. 1023-1040. 2019.  Input: a) source code + user annoations on sensitive functions/globals; b) metircs budgets and the optimization goal.\nOutput: A set of functions and globals that should be included in the sensitive domain. The rest of the code stays in the insensitive domain.\nManual partition implementation.\nKey techniques Isolation mechanism: Process separation.\nEvaluation Benchmarks\n telnet  a tool used to control a remote machine. data from internet server(3) isolate the component that processed untrusted data.  thttpd  an http server program authentication file (1): .htpasswd isolated domain to process .htpasswd on the server.  wget  data from internet servers(29): isolated less secure domain to process the downloaded data from servers.  nginx  web server authentication (1) protect the server-side password file from being leaked.  Linux shadow utils, 30 small programs, such as:  chsh sens. data: pwd file (1) chage sens. data: pwd file (1) passwd sens. data: pwd \u0026amp; shadow files (1) useradd sens. data: pwd \u0026amp; shadow files (4)   Questions As stated in the paper, it cannot partition individual functions. But this can be useful:\n split the main function manually as in telnet example.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/mizhang/fl-nas-idea/",
	"title": "Idea of improving FL using NAS",
	"tags": [],
	"description": "",
	"content": " References:\n reference  NAS for Better Federated Learning Models in Different FL Topologies?\n(Another direction might also be enticing: using FL to improve NAS.)\nIn Mi Zhang\u0026rsquo;s FL benchmark paper ArXiv\u0026rsquo;20: FedML: A Research Library and Benchmark for Federated Learning, I found several important features that an FL can have, such as computing paradigms, topology, exchanged information, and training procedures.\nIt also mentions FedNAS as one category of FL algorithm (in Section 4.1). However, based on a survey paper about Fed + NAS, I am thinking there can be many different ways to improve FL using NAS. Recalling Song Han\u0026rsquo;s Once for All paper, what he do is to adopt NAS to find the best model for machine constraints. Similarly, we probably can use NAS to find the best model for FL constraints, and these constraints seems more complicated than just the machine resource constraints \u0026ndash; FL has multiple constraints (or features?), such as computing paradigms, topology, exchanged information and training procedures.\nSo tracking down this direction, let\u0026rsquo;s see whether there are anything has been done in improving FL models using NAS.\n arXiv\u0026rsquo;2020, from Cisco, Direct Federated Neural Architecture Search  Aim to provide NAS to meet the heterogeneous data and resource distribution of FL. Find read-to-deploy network to any type of client hardware by searching on a super network (basd on DSNAS, similar to once for all?)  arXiv\u0026rsquo;2020, from USC, Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep Learning via Neural Architecture Search  A collaborated Neural Arch search on edge servers; Put NAS at each client and get the weight $w$ and arch $\\alpha$ Then merge them in the coordinator as normally done in FL.  arXiv\u0026rsquo;2020, from Peking, Federated Neural Architecture Search  Wrong paper? It seems they are improving NAS using FL, instead of improving FL using NAS, right?   New ideas:\n Where do we search? How about at the server level instead of at the client level?  Need a new training method without data (since data is only available at client) Can we use only the trained $w$ as the data for training in the NAS?  What do we search for? For optimization goals (or search objectives) of the NAS, we might have more choices than just the accuracy or device resource constraints:  Can we search by balancing more factors, such as computing paradigms, topology, or communication cost, or training procedure?   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/mizhang/2020-fedml/",
	"title": "2020 Fedml",
	"tags": [],
	"description": "",
	"content": " ArXiv\u0026rsquo;20: FedML: A Research Library and Benchmark for Federated Learning\nOverview Problem: Existing Federated Learning libraries:\n Cannot adequately support diverse algorithm development;  Lack of Diverse FL computing paradigms: TensorFlow-Federated, PySyft, LEAF, only support centralized topology-based FL algorithms; FATE, PaddleFL, does not support new algorithms; Lack of diverse FL configurations FL is diverse in network topology, exchanged information, and training procedures. These diversity is not supported in exisitng FL lib.  Has inconsistent dataset and model usage, which makes fair algorithm comparison challenging  Papers in top ML conferences (NeurIPS, ICLR, ICML) in past 2 years. Several factors could affect results: non-I.I.D distribution characteristic of FL datasets models number of clients involved in each round   Solution: FedML, an open research library and benchmark to facilitate FL algorithm development and fair performance comparison:\n Supports three computing paradigms:  On-device training for edge devices; Distributed computing; Single-machine simulation;  Flexible and generic API Reference baseline implementations (optimize, model, and datasets) Realwork hardware platforms:  Mobile, Android IoT, Raspberry PI 4 and NVIDIA Jetson Nano   Evaluation  Trained two CNNs (ResNet-56 and MobileNet) using the standard FedAvg algorithm.  Result: accuracy of non-I.I.D setting is lower than that of the I.I.D setting, which is consistent with findings reported in prior work.  Compare the training time of distributed computing with that of standalone simulation.  Result: Standalone simulation is 8 times slower than 10 parallel workers. Conclusion: FedML\u0026rsquo;s distributed paradigm is useful, but not available in existing FL lib such PySyft, LEAF and TTF.  Multiprocessing in a single GPU:  Training ResNet on CIFAR-10, FedML can run 112 workers in a server with 8 GPUs. (No performance data here??)   Can we do the same thing? Lele: No. Two Challenges:\n The idea cannot come out unless I have a relatively rich experience in FL research. But frankly, I am just a newbie at FL now. That is, right now, I do not know there could be a benchmark and library problem in FL research. Even if I was assigned with a task to build up a new standard lib for FL, I am afraid I cannot build it up very well due to the lack of experience. This kind of standarization work, especially for a newbie, could take for a while (years also??). We need to first research all the existing libraries and how they work, and then come out a way of how to merging them into one and provide a rich but consistent interfaces that will cover most existing functionalities. This kind of work is really useful, but the result cannot be made excellent in a short time (half to one year). Instead, I believe, more time spent, better result will come out for this kind of work. (Like the standarization of C languages or other protocols in IEEE standard, looks like they are always a \u0026lsquo;slow\u0026rsquo; process)  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/mizhang/2020-scylla/",
	"title": "2020 Scylla",
	"tags": [],
	"description": "",
	"content": " INFOCOM\u0026rsquo;20: SCYLLA: QoE-aware Continuous Mobile Vision with FPGA-based Dynamic Deep Neural Network Reconfiguration.\nOverview In one sentence: Use FPGA for fast switching between different neural network models.\nProblem: multiple neural network models are hard to be made efficient to run on the same device concurrently.\n Heterogeneous multi-tenacy GPU (SIMT) requires several seconds to switch from one neural network model to another; ASIC AI chips, not designed for concurrency and heterogeneity.  Solution: Use FPGA to run several neural network models.\n It can fit several models into one FPGA board; The model running on FPGA can also be replaced with new models very quickly (in 80-90 ms, Xilinx ZCU102)  Challenges:\n Hard to fast switch different QoE profiles; Addressed by:  Pre-generates a pool of FPGA design and DNN model profiles Dynamically re-configure FPGA  Hard to optimize overall performance across multipel cocurrently running tasks; Solution:  Encode QoE metrics together Use a QoE-aware scheduler Select the \u0026ldquo;optimal\u0026rdquo; software-hardware configuration and achive best QoE.   Key techniques  Run Multiple DNN models on FPGA and reconfigure FPGA to replace models on the fly.  Evaluation Device: Xilinx ZCU102 board ($2495)\nThree DNN Models (Design 1, 2, 3, No name?), use generic convolution kernels with differnt parallelism.\n Based on CHaiDNN from Xilinx; Evaluated the FPGA resource usage, DNN model accuracy, and energy cost.  Task scheduling evaluation:\n Written in C++, run on ARM co-processor; Three tasks: Object Detection, License Plate Recongnition, Car Type Classification. Three optimize sub-goals: T (time/latency), A (Accuracy), E (Energy) Keep one goal fixed, exploring other two goals. Latency bound experiment: SCYLLA has more applications meet deadlines. Compared with CPU solution (Caffe framework).  Can we do it? Lele: probably can since this is a more system-like paper, and most concepts are understandable for me. The key challenge here would be the FPGA programming experience which I only have a little bit and not sure how long it will take to run a DNN model on it.\nQuestions or new ideas? Lele: No matter how good is the novelty you guys think, I think this style of work is somehow fit my experience very well \u0026ndash; It uses the ML algorithms as a black box, instead of trying to update the algorithm itself. So from this sense, this paper is different from NAS related paper we have read, where NAS algorithms are changed as their novelty.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/mizhang/2020-neurips/",
	"title": "2020 Neurips",
	"tags": [],
	"description": "",
	"content": " NeurIPS\u0026rsquo;20 Unsupervised Learning NeurIPS\u0026rsquo;20: Does Unsupervised Architecture Representation Learning Help Neural Architecture Search?\nOverview: This proposed a method to avoid bias in NAS.\nProblem: jointly learn architecture representations (Training) and optimize search (Search) could introduce bias.\nSolution: Decouple training and search, realized by unsupervised learning:\n First, The Training: use unsupervised training to find a set of architecture representationss in latent space;  Unsupervised training captures structural information of architectures; These architectures cluster better and distribute more smoothly in the latent space, which facilitates the downstream architecture search (the next step). These architectures are visualized in the latent space (Figure 4), which shows this method is better than traditional ones in the following way: It better preserve structural similarity of local neighborhoods; It capture topology and operation similarity, which helps cluster architectures with similar accuracy.  Second, The Search: Used two strategies.  Reinforcement learning (RL); Bayesian optimization (BO).   Key techniques  Variational Graph Isomorphism Autoencoder (for Unsupervised Learning)  Evaluation  Search space used in NAS best practices checklist. From three works:\n NAS-Bench-101 NAS-Bench-201 DARTS  Evaluated two aspects:\n Performance of Training (titled Pre-training performance in the paper), compared with GAE, VGAE; for a) Accuracy b) Validty c) Uniqueness (Table 1) Supervised architecture representation learning;  for predictive performance (Figure 2) for Distribution of L2 distance (Figure 3) Latent space 2D visualization (Figure 4) Architecture cells decoded from the latent space (Figure 5)  Performance of Search. Compared with Adjacency matrix-based encoding  Random Search (RS) Regularized Evolution (RE) REINFORCE BOHB  Cell-based NAS methods  Random Search (RS) ENAS ASHA RS WS SNAS DARTS BANANAS    Can we do it? Lele: No. For me, this contains only pure ML concepts, which most of them I do not understand, both the novel method (the new autoencoder) and the steps in evaluation strategy.\nQuestions or New ideas? Lele: It seems like another way to decouple the two NAS stage: search space training and searching. From this aspect, it is similar to what we have read from Song Han\u0026rsquo;s paper once for all.\n Once for all designs a special super netowork that could be used as the only trained network as \u0026ldquo;search space\u0026rdquo; in down stream search stage; during search, only a subnetwork will be \u0026ldquo;choosen\u0026rdquo; with simple rules. Here the \u0026ldquo;search space\u0026rdquo; are get from unsupervised learning.  But the goal of once-for-all is different with this paper. Once-for-all is to use NAS to search for \u0026ldquo;small\u0026rdquo; enough networks in size; But this paper aims to improve the NAS in general way, without considering the actual application scenarios of the network.\nFor potential new ideas, we can have two directions here:\n One is to improve NAS itself, by exploring some statistical features of the \u0026ldquo;latent space\u0026rdquo;, like this paper; Another is to customize the NAS to better fix certain usage scenarios: such as once for all paper, they target using NAS to quickly find a best network with size constraints (for smaller devices).  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/mizhang/",
	"title": "Reading Notes on Dr. Mi Zhang&#39;s Publications",
	"tags": [],
	"description": "",
	"content": " References:\n Mi Zhang - Publications  Publications in 2020 Mutual Net ECCV\u0026rsquo;20: MutualNet: Adaptive ConvNet via Mutual Learning from Network Width and Resolution\nDistream SenSys\u0026rsquo;20: Distream: Scaling Live Video Analytics with Workload-Adaptive Distributed Edge Intelligence\nWiFi SenSys\u0026rsquo;20: WiFi See It All: Generative Adversarial Network-augmented Versatile WiFi Imaging.\nSecWIR MobiSys\u0026rsquo;20: SecWIR: Securing Smart Home IoT Communications via WiFi Routers with Embedded Intelligence.\nFlexDNN SEC\u0026rsquo;20: FlexDNN: Input-Adaptive On-Device Deep Learning for Efficient Mobile Vision.\nAdaptive IEEE Pervasive\u0026rsquo;20: Adaptive On-Device Deep Learning: A New Frontier of Mobile Vision.\nDL in IoT Book in Fog Computing\u0026rsquo;20: Deep Learning in the Era of Edge Computing: Challenges and Opportunities.\nMore  Idea of improving FL using NAS  References: reference NAS for Better Federated Learning Models in Different FL Topologies? (Another direction might also be enticing: using FL to improve NAS.) In Mi Zhang\u0026rsquo;s FL benchmark paper ArXiv\u0026rsquo;20: FedML: A Research Library and Benchmark for Federated Learning, I found several important features that an FL can have, such as computing paradigms, topology, exchanged information, and training procedures. It also mentions FedNAS as one category of FL algorithm (in Section 4.\n 2020 Fedml  ArXiv\u0026rsquo;20: FedML: A Research Library and Benchmark for Federated Learning Overview Problem: Existing Federated Learning libraries: Cannot adequately support diverse algorithm development; Lack of Diverse FL computing paradigms: TensorFlow-Federated, PySyft, LEAF, only support centralized topology-based FL algorithms; FATE, PaddleFL, does not support new algorithms; Lack of diverse FL configurations FL is diverse in network topology, exchanged information, and training procedures. These diversity is not supported in exisitng FL lib.\n 2020 Scylla  INFOCOM\u0026rsquo;20: SCYLLA: QoE-aware Continuous Mobile Vision with FPGA-based Dynamic Deep Neural Network Reconfiguration. Overview In one sentence: Use FPGA for fast switching between different neural network models. Problem: multiple neural network models are hard to be made efficient to run on the same device concurrently. Heterogeneous multi-tenacy GPU (SIMT) requires several seconds to switch from one neural network model to another; ASIC AI chips, not designed for concurrency and heterogeneity.\n 2020 Neurips  NeurIPS\u0026rsquo;20 Unsupervised Learning NeurIPS\u0026rsquo;20: Does Unsupervised Architecture Representation Learning Help Neural Architecture Search? Overview: This proposed a method to avoid bias in NAS. Problem: jointly learn architecture representations (Training) and optimize search (Search) could introduce bias. Solution: Decouple training and search, realized by unsupervised learning: First, The Training: use unsupervised training to find a set of architecture representationss in latent space; Unsupervised training captures structural information of architectures; These architectures cluster better and distribute more smoothly in the latent space, which facilitates the downstream architecture search (the next step).\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/songhan/2020-ofa/training/",
	"title": "Training",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  ofa_net is always called with pretrained=True, which means it will works without training. But how to train the super network ?  References:\n reference\n# file: # ofa/model_zoo.py def ofa_net(net_id, pretrained=True): if net_id == \u0026#39;ofa_proxyless_d234_e346_k357_w1.3\u0026#39;: net = OFAProxylessNASNets( dropout_rate=0, width_mult=1.3, ks_list=[3, 5, 7], expand_ratio_list=[3, 4, 6], depth_list=[2, 3, 4], ) elif net_id == \u0026#39;ofa_mbv3_d234_e346_k357_w1.0\u0026#39;: net = OFAMobileNetV3( dropout_rate=0, width_mult=1.0, ks_list=[3, 5, 7], expand_ratio_list=[3, 4, 6], depth_list=[2, 3, 4], ) elif net_id == \u0026#39;ofa_mbv3_d234_e346_k357_w1.2\u0026#39;: net = OFAMobileNetV3( dropout_rate=0, width_mult=1.2, ks_list=[3, 5, 7], expand_ratio_list=[3, 4, 6], depth_list=[2, 3, 4], ) elif net_id == \u0026#39;ofa_resnet50\u0026#39;: net = OFAResNets( dropout_rate=0, depth_list=[0, 1, 2], expand_ratio_list=[0.2, 0.25, 0.35], width_mult_list=[0.65, 0.8, 1.0] ) net_id = \u0026#39;ofa_resnet50_d=0+1+2_e=0.2+0.25+0.35_w=0.65+0.8+1.0\u0026#39; else: raise ValueError(\u0026#39;Not supported: %s\u0026#39; % net_id) if pretrained: url_base = \u0026#39;https://hanlab.mit.edu/files/OnceForAll/ofa_nets/\u0026#39; init = torch.load( download_url(url_base + net_id, model_dir=\u0026#39;.torch/ofa_nets\u0026#39;), map_location=\u0026#39;cpu\u0026#39;)[\u0026#39;state_dict\u0026#39;] net.load_state_dict(init) return net  Call site:\n# In tutorial ofa_network = ofa_net(\u0026#39;ofa_mbv3_d234_e346_k357_w1.2\u0026#39;, pretrained=True) print(\u0026#39;The OFA Network is ready.\u0026#39;) # What will happen if we give `pretrained=False`??? More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/deep/horovod/",
	"title": "Horovod",
	"tags": [],
	"description": "",
	"content": " References:\n Meet Horovod: Uber’s Open Source Distributed Deep Learning Framework for TensorFlow  Motivation Problems in the standard distributed TensorFlow technique:\n not always clear which code modifications needed to be made to distribute the model training code; Many new concepts introduced hard-to-diagnose bugs that slowed training.\n The standard distributed TensorFlow package introduces many new concepts: workers, parameter servers, tf.Server(), tf.ClusterSpec(), tf.train.SyncReplicasOptimizer(), and tf.train.replicas_device_setter() to name a few. While beneficial for certain scenarios, this also introduced hard-to-diagnose bugs that slowed training.  Does not scale well;\n Both the Inception V3 and ResNet-101 models were unable to leverage nearly half of our GPU resources.   New insights on parallel optimizations:\n Facebook: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\n demostrated usage of data parallelism with an innovative learning rate adjustment technique. Train ResNet-50 in one hour on 256 GPUs. What is the effective GPU usage ratio???  Baidu: ring-allreduce: Bringing HPC Techniques to Deep Learning\n A different algorithm for averaging gradients and communicating those gradients to all nodes (Step 2 and 3 below), called ring-allreduce. A demonstrated implementation based on TensorFlow. Based on 2009 paper Bandwidth Optimal All-reduce Algorithms for Clusters of Workstations   Horovod based on Baidu Distributed training in steps:\n Run multiple copies of the training script and each copy:  a) reads a chunk of the data b) runs it through the model c) computes model updates (Gradients)  Average gradients among those multiple copies; Update the model; Repeat (from step 1a).  Parameter Server based approach:\n Parameter Server to average gradients; Worker server to process the training data, compute gradients, and send gradients to parameter servers;  Two challenges for this approach (standard distributed TensorFlow package):\n Identify the right ratio of worker to parameter servers;  If one parameter server, likely becoming a networking or computational bottleneck; If multiple parameter servers, the all-to-all connections may saturate the network;  Handling increased TensorFlow program complexity: A steep learning curve and a significant amount of code restructuring, taking time away from the acutal modeling.  explicitly starts each worker and parameter server; pass around service discovery information such as hosts and ports of all the workers and parameter servers; modify the training program to construct tf.Server() with an approprate tf.ClusterSpec(). ensure all the operations were placed appropriately using tf.train.device_replica_setter() modify code to use towers to leverage multiple GPUs within the server.   Baidu\u0026rsquo;s ring-allreduce:\n Each of N nodes communicates with two of its peers 2*(N-1) times. Each node sends and receives chunks of the data buffer.  First N-1 iterations: received values are added to the values in the node\u0026rsquo;s buffer. Second N-1 iterations: received values replace the values held in the node\u0026rsquo;s buffer.  Algorithm is bandwidth optimal: If the buffer is large enough, it will optimally utilize the avaiable network. Much easier to understand and adopt.  Users utilize a Message Passing Interface (MPI), such as OpenMPI, to launch all copies of the TensorFlow program. MPI then transparently sets up the distributed infrastructure necessary for workers to communicate with each other. All the users need to do is to modify their program to average gradients using an allreduce() operation.   Horovod:\n Adopted Baidu\u0026rsquo;s draft implementation.  converted into standalone Python package called Horovod; compatiable with different versions of TensorFlow. Used NVIDIA\u0026rsquo;s NCCL implementation, a highly optimized version of ring-allreduce. Added support for models that fit inside a single server, potentially on multiple GPUs Original version only supported models that fit on a single GPU. Serveral API improvements. Broadcast operation that enforces consistent initialization of the model on all workers.  Cut down the num of operations a user had to introduce to their single GPU program to four.    Use Horovod Reference: https://eng.uber.com/horovod/\n  use horovod   import tensorflow as tf import horovod.tensorflow as hvd ############################## # 1/4. Initialize Horovod ############################## hvd.init() ############################## # 2/4. GPU assignment ############################## # Pin GPU to be used to process local rank (one GPU per process) config = tf.ConfigProto() # Assigns a GPU to each of the TensorFlow processes config.gpu_options.visible_device_list = str(hvd.local_rank()) # Build model… loss = … opt = tf.train.AdagradOptimizer(0.01) ############################## # 3/4. Averaging. ############################## # Add Horovod Distributed Optimizer # This wraps any regular TensorFlow optimizer with Horovod optimizer which takes care of averaging gradients using ring-allreduce. opt = hvd.DistributedOptimizer(opt) ############################## # 4/4. Broadcasting ############################## # Add hook to broadcast variables from rank 0 to all other processes during # initialization. # Note: If program does not use `MonitoredTrainingSession`, users can run the # hvd.broadcast_gloabl_variables(0) operations instead. hooks = [hvd.BroadcastGlobalVariablesHook(0)] # Make training operation train_op = opt.minimize(loss) # The MonitoredTrainingSession takes care of session initialization, # restoring from a checkpoint, saving to a checkpoint, and closing when done # or an error occurs. with tf.train.MonitoredTrainingSession(checkpoint_dir=“/tmp/train_logs”, config=config, hooks=hooks) as mon_sess: while not mon_sess.should_stop(): # Perform synchronous training. mon_sess.run(train_op) {{/expand}}\nRun using the mpirun command:\n$ mpirun -np 16 -x LD_LIBRARY_PATH -H server1:4, server2:4,server3:4,server4:4 python train.py The command above distributes train.py to four nodes and runs it on four GPUs per node.\nHorovod can also distribute Keras programs. Examples on Github\nMore    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/intro-ml/kernel/",
	"title": "Kernel Functions",
	"tags": [],
	"description": "",
	"content": " References:\n Kernel Functions    Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed. \u0026ndash; Arthur Samuel in 1959.\nA computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. \u0026ndash; Tom Michell, CMU.\n Support Vector Machines:\nKernel Function:\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/intro-ml/",
	"title": "Intro Ml",
	"tags": [],
	"description": "",
	"content": " Two Ways to Categorize ML algorithms References:\n A Tour of Machine Learning Algorithms  Two ways: Group them by learning style, and by their similarity in form or function.\nBy Learning Styles cite: https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/\n Supervised learning: all training data with known labels.\n e.g. Logistic Regression, Back propagation neural network.  Unsupervised learning: Input data is not labeled.\n e.g. Apriori algorithm, K-Means.  Semi-Supervised learning: input data is a mixture of labeled and unlabelled examples.\n e.g.   By Forms or Functions cite: https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/\nAlgorithms grouped by similarities of how they work:\nRegression Algorithms. Modeling the relationship between variables that is iteratively refined using a measure of error in the predictions made by the model. used in statistical machine learning.\n Ordinary Least Squares Regression (OLSR) Linear Regression Logistic Regression Stepwise Regression Multivariate Adaptive Regression Splines (MARS) Locally Estimated Scaterplot Smoothing (LOESS)  Instance-based Algorithms. Winner-take-all methods, memory-based learning. Find the best match between new data and existing data. Focus is on the representation of the stored instances and similarity measures used between instances.\n k-Nearest Neighbor (KNN) Learning Vector Quantization (LVQ) Self-Organizing Map (SOM) Locally Weighted Learning (LWL) Support Vector Machines (SVM)  Regularization Algorithms.\n Ridge regression. Least Absolute Shrinkage and Selection Operator (LASSO) Elastic Net Least-Angle Regression (LARS)  Decision Tree Algorithms.\n Classification and Regression Tree (CART) Iterative Dichotomiser 3 (ID3) C4.5. Using concept of information entropy. Choose best attribute to split data into subsets according to normalized information gain (difference in entropy). C5.0. Chi-squared Automatic Interaction Detection (CHAID) Decision Stump M5 Conditional Decision Trees  Clustering Algorithms.\n k-Means k-Medians Expectation Maximisation (EM) Hierachical Clustering  Association Rule Learning Algorithms. extract rules that best explain observed relationships between variables in the data.\n Apriori Algorithm Eclat Algorithm  Aritificial Neural Network ALgorithm. inspired by the structure/function of biological neural networks. Enormous field comprised of hundreds of algorithms and variants for all manner of problem types.\n Perceptron. Multilayer Perceptrons (MLP), Back-Propagation. Stochastic Gradient Descent. Hopfield Network. Radial Basis Function Network (RBFN). Deep Learning algorithms. exploit abundant cheap computation.  Convolutional Neural Network (CNN) Recurrent Neural Networks (RNNs) Long Short-Term Memory Networks (LSTMs) Stacked Auto-Encoders Deep Boltzmann Machine (DBM) Deep Belief Networks (DBN)   Dimensionality Reduction Algorithms. Unsupervised manner. Describe data using less information. Useful to visualize dimensional data or to simplify data then to be used by supervised learning. Classification, regression.\n Principle Component Analysis (PCA) Principle Component Regression (PCR) Partial Least Squares Regression (PLSR) Sammon Mapping Multidimensional Scaling (MDS) Projection Pursuit Linear Discriminant Analysis (LDA) Mixture Discriminant Analysis (MDA) Quadratic Discriminant Analysis (QDA) Flexible Discriminant Analysis (FDA)  Ensemble Algorithms. combination of weaker models. Focus on what types of weak learners to combine and the ways in which to combine them.\n Boosting Bootstrapped Aggregation (Bagging) AdaBoost Weighted Average (Blending) Stacked Generalization (Stacking) Gradient Boosting Machines (GBM) Gradient Boosted Regression Trees (GBRT) Random Forest. Combining uncorrelated decision trees.  Evolutionary Algorithms (EA).\nwiki\n Particle swarm optimization. iteratively trying to improve a candidate solution with regard to a given measure of quality.  https://en.wikipedia.org/wiki/List_of_metaphor-based_metaheuristics)   \u0026hellip;  Algorithms of subfields in ML.\n Computational intelligence (evolutionary algorithms, etc.) Computer Vision (CV) Natural Language Processing (NLP) Recommender Systems Reinforcement Learning Graphical Models \u0026hellip;  Algorithms for special tasks in ML.\n Feature selection algorithms Algorithm accuracy evaluation Performance measures Optimization algorithms  More  Kernel Functions  References: Kernel Functions Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed. \u0026ndash; Arthur Samuel in 1959. A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. \u0026ndash; Tom Michell, CMU. Support Vector Machines:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/songhan/2020-ofa/tutorial/",
	"title": "Tutorial",
	"tags": [],
	"description": "",
	"content": " References:\n Hands-on Tutorial of Once-for-All Network, See tutorial/ofa.ipynb  How to Get Your Specialized Neural Networks on ImageNet in Minutes With OFA Networks In this notebook, we will demonstrate - how to use pretrained specialized OFA sub-networks for efficient inference on diverse hardware platforms - how to get new specialized neural networks on ImageNet with the OFA network within minutes.\nOnce-for-All (OFA) is an efficient AutoML technique that decouples training from search. Different sub-nets can directly grab weights from the OFA network without training. Therefore, getting a new specialized neural network with the OFA network is highly efficient, incurring little computation cost.\n1. Preparation Let\u0026rsquo;s first install all the required packages:\nprint(\u0026#39;Installing PyTorch...\u0026#39;) ! pip install torch 1\u0026gt;/dev/null print(\u0026#39;Installing torchvision...\u0026#39;) ! pip install torchvision 1\u0026gt;/dev/null print(\u0026#39;Installing numpy...\u0026#39;) ! pip install numpy 1\u0026gt;/dev/null # thop is a package for FLOPs computing. print(\u0026#39;Installing thop (FLOPs counter) ...\u0026#39;) ! pip install thop 1\u0026gt;/dev/null # ofa is a package containing training code, pretrained specialized models and inference code for the once-for-all networks. print(\u0026#39;Installing OFA...\u0026#39;) ! pip install ofa 1\u0026gt;/dev/null # tqdm is a package for displaying a progress bar. print(\u0026#39;Installing tqdm (progress bar) ...\u0026#39;) ! pip install tqdm 1\u0026gt;/dev/null print(\u0026#39;Installing matplotlib...\u0026#39;) ! pip install matplotlib 1\u0026gt;/dev/null print(\u0026#39;All required packages have been successfully installed!\u0026#39;) Then, we can import the packages used in this tutorial:\nimport os import torch import torch.nn as nn from torchvision import transforms, datasets import numpy as np import time import random import math import copy from matplotlib import pyplot as plt from ofa.model_zoo import ofa_net from ofa.utils import download_url # from ofa.tutorial.accuracy_predictor import AccuracyPredictor # from ofa.tutorial.flops_table import FLOPsTable # from ofa.tutorial.latency_table import LatencyTable # from ofa.tutorial.evolution_finder import EvolutionFinder # from ofa.tutorial.imagenet_eval_helper import evaluate_ofa_subnet, evaluate_ofa_specialized from ofa.tutorial import AccuracyPredictor, FLOPsTable, LatencyTable, EvolutionFinder from ofa.tutorial import evaluate_ofa_subnet, evaluate_ofa_specialized # set random seed random_seed = 1 random.seed(random_seed) np.random.seed(random_seed) torch.manual_seed(random_seed) print(\u0026#39;Successfully imported all packages and configured random seed to %d!\u0026#39;%random_seed) Successfully imported all packages and configured random seed to 1!\nNow it\u0026rsquo;s time to determine which device to use for neural network inference in the rest of this tutorial. If your machine is equipped with GPU(s), we will use the GPU by default. Otherwise, we will use the CPU.\n#os.environ[\u0026#39;CUDA_VISIBLE_DEVICES\u0026#39;] = \u0026#39;0\u0026#39; cuda_available = torch.cuda.is_available() if cuda_available: torch.backends.cudnn.enabled = True torch.backends.cudnn.benchmark = True torch.cuda.manual_seed(random_seed) print(\u0026#39;Using GPU.\u0026#39;) else: print(\u0026#39;Using CPU.\u0026#39;) Good! Now you have successfully configured the environment! It\u0026rsquo;s time to import the OFA network for the following experiments. The OFA network used in this tutorial is built upon MobileNetV3 with width multiplier 1.2, supporting elastic depth (2, 3, 4) per stage, elastic expand ratio (3, 4, 6), and elastic kernel size (3, 5 7) per block.\nofa_network = ofa_net(\u0026#39;ofa_mbv3_d234_e346_k357_w1.2\u0026#39;, pretrained=True) print(\u0026#39;The OFA Network is ready.\u0026#39;) Now, let\u0026rsquo;s build the ImageNet dataset and the corresponding dataloader. Notice that if you\u0026rsquo;re using the CPU, we will skip ImageNet evaluation by default since it will be very slow. If you are using the GPU, in case you don\u0026rsquo;t have the full dataset, we will download a subset of ImageNet which contains 2,000 images (~250M) for testing. If you do have the full ImageNet dataset on your machine, just specify it in imagenet_data_path and the downloading script will be skipped.\nif cuda_available: # path to the ImageNet dataset print(\u0026#34;Please input the path to the ImageNet dataset.\\n\u0026#34;) imagenet_data_path = input() # if \u0026#39;imagenet_data_path\u0026#39; is empty, download a subset of ImageNet containing 2000 images (~250M) for test if not os.path.isdir(imagenet_data_path): os.makedirs(imagenet_data_path, exist_ok=True) download_url(\u0026#39;https://hanlab.mit.edu/files/OnceForAll/ofa_cvpr_tutorial/imagenet_1k.zip\u0026#39;, model_dir=\u0026#39;data\u0026#39;) ! cd data \u0026amp;\u0026amp; unzip imagenet_1k 1\u0026gt;/dev/null \u0026amp;\u0026amp; cd .. ! cp -r data/imagenet_1k/* $imagenet_data_path ! rm -rf data print(\u0026#39;%sis empty. Download a subset of ImageNet for test.\u0026#39; % imagenet_data_path) print(\u0026#39;The ImageNet dataset files are ready.\u0026#39;) else: print(\u0026#39;Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.\u0026#39;) Now you have configured the dataset. Let\u0026rsquo;s build the dataloader for evaluation. Again, this will be skipped if you are in a CPU environment.\nif cuda_available: # The following function build the data transforms for test def build_val_transform(size): return transforms.Compose([ transforms.Resize(int(math.ceil(size / 0.875))), transforms.CenterCrop(size), transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ), ]) data_loader = torch.utils.data.DataLoader( datasets.ImageFolder( root=os.path.join(imagenet_data_path, \u0026#39;val\u0026#39;), transform=build_val_transform(224) ), batch_size=250, # test batch size shuffle=True, num_workers=16, # number of workers for the data loader pin_memory=True, drop_last=False, ) print(\u0026#39;The ImageNet dataloader is ready.\u0026#39;) else: data_loader = None print(\u0026#39;Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.\u0026#39;) 2. Using Pretrained Specialized OFA Sub-Networks The specialized OFA sub-networks are \u0026ldquo;small\u0026rdquo; networks sampled from the \u0026ldquo;big\u0026rdquo; OFA network as is indicated in the figure above. The OFA network supports over $10^{19}$ sub-networks simultaneously, so that the deployment cost for multiple scenarios can be saved by 16$\\times$ to 1300$\\times$ under 40 deployment scenarios. Now, let\u0026rsquo;s play with some of the sub-networks through the following interactive command line prompt (Notice that for CPU users, this will be skipped). We recommend you to try a smaller sub-network (e.g., the sub-network for pixel1 with 20ms inference latency constraint) so that it takes less time to evaluate the model on ImageNet.\nif cuda_available: net_id = evaluate_ofa_specialized(imagenet_data_path, data_loader) print(\u0026#39;Finished evaluating the pretrained sub-network: %s!\u0026#39; % net_id) else: print(\u0026#39;Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.\u0026#39;) ## ouputs: Please select a hardware platform from (\u0026#39;pixel1\u0026#39;, \u0026#39;pixel2\u0026#39;, \u0026#39;note10\u0026#39;, \u0026#39;note8\u0026#39;, \u0026#39;s7edge\u0026#39;, \u0026#39;lg-g8\u0026#39;, \u0026#39;1080ti\u0026#39;, \u0026#39;v100\u0026#39;, \u0026#39;tx2\u0026#39;, \u0026#39;cpu\u0026#39;, \u0026#39;flops\u0026#39;)! pixel1 Now, please specify a latency constraint for model specialization among [20, 28, 40, 58, 79, 132, 143] ms. (Please just input the number.) 20 Validate: 100%|██████████| 200/200 [01:28\u0026lt;00:00, 2.27it/s, loss=1.21, top1=71.4, top5=89.8, img_size=152] Results: loss=1.21306,\ttop1=71.4,\ttop5=89.8 Finished evaluating the pretrained sub-network: pixel1_lat@20ms_top1@71.4_finetune@25! 3 Efficient Deployment with OFA Networks You have now successfully prepared the whole environment for the experiment! In the next step, we will introduce how to get efficient, specialized neural networks within minutes powered by the OFA network.\n3.1 Latency-Constrained Efficient Deployment on Samsung Note10 The key components of very fast neural network deployment are accuracy predictors and efficiency predictors. For the accuracy predictor, it predicts the Top-1 accuracy of a given sub-network on a holdout validation set (different from the official 50K validation set) so that we do NOT need to run very costly inference on ImageNet while searching for specialized models. Such an accuracy predictor is trained using an accuracy dataset built with the OFA network.\n# accuracy predictor accuracy_predictor = AccuracyPredictor( pretrained=True, device=\u0026#39;cuda:0\u0026#39; if cuda_available else \u0026#39;cpu\u0026#39; ) print(\u0026#39;The accuracy predictor is ready!\u0026#39;) print(accuracy_predictor.model) ## outputs The accuracy predictor is ready! Sequential( (0): Linear(in_features=128, out_features=400, bias=True) (1): ReLU() (2): Linear(in_features=400, out_features=400, bias=True) (3): ReLU() (4): Linear(in_features=400, out_features=400, bias=True) (5): ReLU() (6): Linear(in_features=400, out_features=1, bias=True) ) Now, we have the powerful accuracy predictor. We then introduce two types of efficiency predictors: the latency predictor and the FLOPs predictor.\nThe intuition of having efficiency predictors, especially the latency predictor, is that measuring the latency of a sub-network on-the-fly is also costly, especially for mobile devices. The latency predictor is designed to eliminate this cost. Let\u0026rsquo;s load a latency predictor we built beforehand for the Samsung Note10.\ntarget_hardware = \u0026#39;note10\u0026#39; latency_table = LatencyTable(device=target_hardware) print(\u0026#39;The Latency lookup table on %sis ready!\u0026#39; % target_hardware) ## outputs /home/ec2-user/SageMaker/ofa-tutorial-dev/latency_table.py:17: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. self.lut = yaml.load(fp) Built latency table for image size: 160. Built latency table for image size: 176. Built latency table for image size: 192. Built latency table for image size: 208. Built latency table for image size: 224. The Latency lookup table on note10 is ready! So far, we have defined both the accuracy predictor and the latency predictor. Now, let\u0026rsquo;s experience very fast model specialization on Samsung Note10 with these two powerful predictors!\nNotice: The predicted accuracy is on a holdout validation set of 10K images, not the official 50K validation set. But they are highly positive-correlated.\n\u0026#34;\u0026#34;\u0026#34; Hyper-parameters for the evolutionary search process You can modify these hyper-parameters to see how they influence the final ImageNet accuracy of the search sub-net. \u0026#34;\u0026#34;\u0026#34; latency_constraint = 25 # ms, suggested range [15, 33] ms P = 100 # The size of population in each generation N = 500 # How many generations of population to be searched r = 0.25 # The ratio of networks that are used as parents for next generation params = { \u0026#39;constraint_type\u0026#39;: target_hardware, # Let\u0026#39;s do FLOPs-constrained search \u0026#39;efficiency_constraint\u0026#39;: latency_constraint, \u0026#39;mutate_prob\u0026#39;: 0.1, # The probability of mutation in evolutionary search \u0026#39;mutation_ratio\u0026#39;: 0.5, # The ratio of networks that are generated through mutation in generation n \u0026gt;= 2. \u0026#39;efficiency_predictor\u0026#39;: latency_table, # To use a predefined efficiency predictor. \u0026#39;accuracy_predictor\u0026#39;: accuracy_predictor, # To use a predefined accuracy_predictor predictor. \u0026#39;population_size\u0026#39;: P, \u0026#39;max_time_budget\u0026#39;: N, \u0026#39;parent_ratio\u0026#39;: r, } # build the evolution finder finder = EvolutionFinder(**params) # start searching result_lis = [] st = time.time() best_valids, best_info = finder.run_evolution_search() result_lis.append(best_info) ed = time.time() print(\u0026#39;Found best architecture on %swith latency \u0026lt;= %.2fms in %.2fseconds! \u0026#39; \u0026#39;It achieves %.2f%spredicted accuracy with %.2fms latency on %s.\u0026#39; % (target_hardware, latency_constraint, ed-st, best_info[0] * 100, \u0026#39;%\u0026#39;, best_info[-1], target_hardware)) # visualize the architecture of the searched sub-net _, net_config, latency = best_info ofa_network.set_active_subnet(ks=net_config[\u0026#39;ks\u0026#39;], d=net_config[\u0026#39;d\u0026#39;], e=net_config[\u0026#39;e\u0026#39;]) print(\u0026#39;Architecture of the searched sub-net:\u0026#39;) print(ofa_network.module_str) ## outputs Searching with note10 constraint (25): 100%|██████████| 500/500 [00:22\u0026lt;00:00, 22.63it/s] Found best architecture on note10 with latency \u0026lt;= 25.00 ms in 22.17 seconds! It achieves 81.71% predicted accuracy with 24.73 ms latency on note10. Architecture of the searched sub-net: 3x3_Conv_O24 (3x3_MBConv1_RELU_O24, Identity) ((O32, E3.0, K5), None) ((O32, E3.0, K3), Identity) (SE(O48, E4.0, K5), None) (SE(O48, E4.0, K3), Identity) ((O96, E6.0, K7), None) ((O96, E3.0, K7), Identity) ((O96, E4.0, K3), Identity) (SE(O136, E4.0, K5), None) (SE(O136, E4.0, K5), Identity) (SE(O136, E4.0, K7), Identity) (SE(O136, E3.0, K3), Identity) (SE(O192, E6.0, K3), None) (SE(O192, E6.0, K3), Identity) (SE(O192, E6.0, K5), Identity) 1x1_Conv_O1152 1x1_Conv_O1536 1536x1000_Linear Great! You get your specialized neural network with just a few seconds! You can go back to the last cell and modify the hyper-parameters to see how they affect the search time and the accuracy.\nWe also provided an interface below to draw a figure comparing your searched specialized network and other efficient neural networks such as MobileNetV3 and ProxylessNAS.\nNotice: For ease of comparison, we recommend you to choose a latency constraint between 15ms and 33ms.\n# evaluate the searched model on ImageNet if cuda_available: top1s = [] latency_list = [] for result in result_lis: _, net_config, latency = result print(\u0026#39;Evaluating the sub-network with latency = %.1fms on %s\u0026#39; % (latency, target_hardware)) top1 = evaluate_ofa_subnet( ofa_network, imagenet_data_path, net_config, data_loader, batch_size=250, device=\u0026#39;cuda:0\u0026#39; if cuda_available else \u0026#39;cpu\u0026#39;) top1s.append(top1) latency_list.append(latency) plt.figure(figsize=(4,4)) plt.plot(latency_list, top1s, \u0026#39;x-\u0026#39;, marker=\u0026#39;*\u0026#39;, color=\u0026#39;darkred\u0026#39;, linewidth=2, markersize=8, label=\u0026#39;OFA\u0026#39;) plt.plot([26, 45], [74.6, 76.7], \u0026#39;--\u0026#39;, marker=\u0026#39;+\u0026#39;, linewidth=2, markersize=8, label=\u0026#39;ProxylessNAS\u0026#39;) plt.plot([15.3, 22, 31], [73.3, 75.2, 76.6], \u0026#39;--\u0026#39;, marker=\u0026#39;\u0026gt;\u0026#39;, linewidth=2, markersize=8, label=\u0026#39;MobileNetV3\u0026#39;) plt.xlabel(\u0026#39;%sLatency (ms)\u0026#39; % target_hardware, size=12) plt.ylabel(\u0026#39;ImageNet Top-1 Accuracy (%)\u0026#39;, size=12) plt.legend([\u0026#39;OFA\u0026#39;, \u0026#39;ProxylessNAS\u0026#39;, \u0026#39;MobileNetV3\u0026#39;], loc=\u0026#39;lower right\u0026#39;) plt.grid(True) plt.show() print(\u0026#39;Successfully draw the tradeoff curve!\u0026#39;) else: print(\u0026#39;Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.\u0026#39;) ## outputs Evaluating the sub-network with latency = 24.7 ms on note10 Validate: 100%|██████████| 200/200 [01:36\u0026lt;00:00, 2.07it/s, loss=0.99, top1=76.9, top5=93.2, img_size=192] Results: loss=0.99038,\ttop1=76.9,\ttop5=93.2 Successfully draw the tradeoff curve! Notice: You can further significantly improve the accuracy of the searched sub-net by fine-tuning it on the ImageNet training set. Our results after fine-tuning for 25 epochs are as follows: 3.2 FLOPs-Constrained Efficient Deployment Now, let\u0026rsquo;s proceed to the final experiment of this tutorial: efficient deployment under FLOPs constraint. We use the same accuracy predictor since accuracy predictors are agnostic to the types of efficiency constraint (mobile latency / FLOPs). For the efficiency predictor, we change the latency lookup table to a flops lookup table. You can run the code below to setup it in a few seconds.\nflops_lookup_table = FLOPsTable( device=\u0026#39;cuda:0\u0026#39; if cuda_available else \u0026#39;cpu\u0026#39;, batch_size=1, ) print(\u0026#39;The FLOPs lookup table is ready!\u0026#39;) Now, you can start a FLOPs-constrained neural architecture search. Here, we directly generate an entire tradeoff curve for you. Please notice that the time it takes to get each data point will get longer and longer (but always less than 30 seconds) because smaller FLOPs-constraint is more difficult to meet.\nIf you are using CPUs, you will be able to see a \u0026ldquo;predicted holdout validation set accuracy - FLOPs\u0026rdquo; tradeoff curve, which can be obtained in just a minute.\nIf you are using GPUs, besides the curve mentioned above, we will also evaluate all the models you designed on the ImageNet validation set (Again, it will be better if you have the full ImageNet validation set, but it\u0026rsquo;s also OK if you downloaded the subset above) and generate an \u0026ldquo;ImageNet 50K validation set accuracy - FLOPs\u0026rdquo; tradeoff curve. We will also plot competing methods such as ProxylessNAS, MobileNetV3, and EfficientNet in this curve for your reference. The estimated time to get the two curves is less than 10 minutes.\nPlease notice that it usually takes ** hundreds/thousands of hours** to generate an accuracy-FLOPs tradeoff curve for ProxylessNAS / MobileNetV3 / EfficientNet, but generating the tradeoff curve for our OFA takes just a few minutes, as you will experience soon.\n\u0026#34;\u0026#34;\u0026#34; Hyper-parameters for the evolutionary search process You can modify these hyper-parameters to see how they influence the final ImageNet accuracy of the search sub-net. \u0026#34;\u0026#34;\u0026#34; P = 100 # The size of population in each generation N = 500 # How many generations of population to be searched r = 0.25 # The ratio of networks that are used as parents for next generation params = { \u0026#39;constraint_type\u0026#39;: \u0026#39;flops\u0026#39;, # Let\u0026#39;s do FLOPs-constrained search \u0026#39;efficiency_constraint\u0026#39;: 600, # FLops constraint (M), suggested range [150, 600] \u0026#39;mutate_prob\u0026#39;: 0.1, # The probability of mutation in evolutionary search \u0026#39;mutation_ratio\u0026#39;: 0.5, # The ratio of networks that are generated through mutation in generation n \u0026gt;= 2. \u0026#39;efficiency_predictor\u0026#39;: flops_lookup_table, # To use a predefined efficiency predictor. \u0026#39;accuracy_predictor\u0026#39;: accuracy_predictor, # To use a predefined accuracy_predictor predictor. \u0026#39;population_size\u0026#39;: P, \u0026#39;max_time_budget\u0026#39;: N, \u0026#39;parent_ratio\u0026#39;: r, } # build the evolution finder finder = EvolutionFinder(**params) # start searching result_lis = [] for flops in [600, 400, 350]: st = time.time() finder.set_efficiency_constraint(flops) best_valids, best_info = finder.run_evolution_search() ed = time.time() # print(\u0026#39;Found best architecture at flops \u0026lt;= %.2f M in %.2f seconds! It achieves %.2f%s predicted accuracy with %.2f MFLOPs.\u0026#39; % (flops, ed-st, best_info[0] * 100, \u0026#39;%\u0026#39;, best_info[-1])) result_lis.append(best_info) plt.figure(figsize=(4,4)) plt.plot([x[-1] for x in result_lis], [x[0] * 100 for x in result_lis], \u0026#39;x-\u0026#39;, marker=\u0026#39;*\u0026#39;, color=\u0026#39;darkred\u0026#39;, linewidth=2, markersize=8, label=\u0026#39;OFA\u0026#39;) plt.xlabel(\u0026#39;FLOPs (M)\u0026#39;, size=12) plt.ylabel(\u0026#39;Predicted Holdout Top-1 Accuracy (%)\u0026#39;, size=12) plt.legend([\u0026#39;OFA\u0026#39;], loc=\u0026#39;lower right\u0026#39;) plt.grid(True) plt.show() ## outputs Searching with flops constraint (600): 100%|██████████| 500/500 [00:12\u0026lt;00:00, 39.55it/s] Searching with flops constraint (400): 100%|██████████| 500/500 [00:12\u0026lt;00:00, 39.34it/s] Searching with flops constraint (350): 100%|██████████| 500/500 [00:12\u0026lt;00:00, 38.94it/s] Let\u0026rsquo;s evaluate the searched models on ImageNet if GPU is available:\nif cuda_available: # test the searched model on the test dataset (ImageNet val) top1s = [] flops_lis = [] for result in result_lis: _, net_config, flops = result print(\u0026#39;Evaluating the sub-network with FLOPs = %.1fM\u0026#39; % flops) top1 = evaluate_ofa_subnet( ofa_network, imagenet_data_path, net_config, data_loader, batch_size=250, device=\u0026#39;cuda:0\u0026#39; if cuda_available else \u0026#39;cpu\u0026#39;) print(\u0026#39;-\u0026#39; * 45) top1s.append(top1) flops_lis.append(flops) plt.figure(figsize=(8,4)) plt.subplot(1, 2, 1) plt.plot([x[-1] for x in result_lis], [x[0] * 100 for x in result_lis], \u0026#39;x-\u0026#39;, marker=\u0026#39;*\u0026#39;, color=\u0026#39;darkred\u0026#39;, linewidth=2, markersize=8, label=\u0026#39;OFA\u0026#39;) plt.xlabel(\u0026#39;FLOPs (M)\u0026#39;, size=12) plt.ylabel(\u0026#39;Predicted Holdout Top-1 Accuracy (%)\u0026#39;, size=12) plt.legend([\u0026#39;OFA\u0026#39;], loc=\u0026#39;lower right\u0026#39;) plt.grid(True) plt.subplot(1, 2, 2) plt.plot(flops_lis, top1s, \u0026#39;x-\u0026#39;, marker=\u0026#39;*\u0026#39;, color=\u0026#39;darkred\u0026#39;, linewidth=2, markersize=8, label=\u0026#39;OFA\u0026#39;) plt.plot([320, 581], [74.6, 76.7], \u0026#39;--\u0026#39;, marker=\u0026#39;+\u0026#39;, linewidth=2, markersize=8, label=\u0026#39;ProxylessNAS\u0026#39;) plt.plot([219, 343], [75.2, 76.6], \u0026#39;--\u0026#39;, marker=\u0026#39;^\u0026#39;, linewidth=2, markersize=8, label=\u0026#39;MobileNetV3\u0026#39;) plt.plot([390, 700], [76.3, 78.8], \u0026#39;--\u0026#39;, marker=\u0026#39;\u0026gt;\u0026#39;, linewidth=2, markersize=8, label=\u0026#39;EfficientNet\u0026#39;) plt.xlabel(\u0026#39;FLOPs (M)\u0026#39;, size=12) plt.ylabel(\u0026#39;ImageNet Top-1 Accuracy (%)\u0026#39;, size=12) plt.legend([\u0026#39;OFA\u0026#39;, \u0026#39;ProxylessNAS\u0026#39;, \u0026#39;MobileNetV3\u0026#39;, \u0026#39;EfficientNet\u0026#39;], loc=\u0026#39;lower right\u0026#39;) plt.grid(True) plt.show() ## outputs Evaluating the sub-network with FLOPs = 599.1M Validate: 100%|██████████| 200/200 [01:48\u0026lt;00:00, 1.85it/s, loss=0.906, top1=79.1, top5=94.5, img_size=224] Results: loss=0.90586,\ttop1=79.1,\ttop5=94.5 --------------------------------------------- Evaluating the sub-network with FLOPs = 399.5M Validate: 100%|██████████| 200/200 [01:41\u0026lt;00:00, 1.96it/s, loss=0.945, top1=78.3, top5=94.1, img_size=208] Results: loss=0.94540,\ttop1=78.3,\ttop5=94.1 --------------------------------------------- Evaluating the sub-network with FLOPs = 349.9M Validate: 100%|██████████| 200/200 [01:39\u0026lt;00:00, 2.00it/s, loss=0.954, top1=78.1, top5=94, img_size=208] Results: loss=0.95356,\ttop1=78.1,\ttop5=94.0 --------------------------------------------- Notice: Again, you can further improve the accuracy of the search sub-net by fine-tuning it on ImageNet. The final accuracy is much better than training the same architecture from scratch. Our results are as follows: Congratulations! You\u0026rsquo;ve finished all the content of this tutorial! Hope you enjoy playing with the OFA Networks. If you are interested, please refer to our paper and GitHub Repo for further details.\nReference [1] CVPR\u0026rsquo;20 tutorial: AutoML for TinyML with Once-for-All Network. [talk].\n[1] Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang and Song Han. Once for All: Train One Network and Specialize It for Efficient Deployment. In ICLR 2020. [paper], [code], [talk].\n[2] Han Cai, Ligeng Zhu and Song Han. ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware. In ICLR 2019. [paper], [code].\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/lane/2020-spinn/",
	"title": "2020 SPINN",
	"tags": [],
	"description": "",
	"content": " References:\n reference  Evaluation Server: 2x Intel Xeon Gold 6130, 128GB Memory, with GPU GTX 1080Ti\nClient: Nvidia Jetson Xavier AGX, 16GB Memory, with GPU 512-core Volta\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/deep/distributed/2018-horovod/",
	"title": "2018 Horovod",
	"tags": [],
	"description": "",
	"content": " References:\n Horovod: fast and easy distributed deep learning in TensorFlow. code  Overview Uber: deep learning for self-driving, trip forecasting, fraud prevention.\nMichelangelo[c3], an internal ML-as-a-service platform, deploying ML systems at scale.\nHorovod, an open-source component of Michelangelo\u0026rsquo;s deep learning toolkit which makes it easier to start \u0026ndash; and speed up \u0026ndash; distributed deep learning projects with TensorFlow.\nMotivation As datasets grew, so did the training times, which sometimes took a week or longer to complete. Need a way to train using a lot of data while maintaining short training times.\nNo related work???\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/deep/distributed/",
	"title": "Distributed",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  2018 Horovod  References: Horovod: fast and easy distributed deep learning in TensorFlow. code Overview Uber: deep learning for self-driving, trip forecasting, fraud prevention. Michelangelo[c3], an internal ML-as-a-service platform, deploying ML systems at scale. Horovod, an open-source component of Michelangelo\u0026rsquo;s deep learning toolkit which makes it easier to start \u0026ndash; and speed up \u0026ndash; distributed deep learning projects with TensorFlow. Motivation As datasets grew, so did the training times, which sometimes took a week or longer to complete.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/songhan/2019-proxyless-nas/",
	"title": "2019 Proxyless Nas",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A   \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;  References:\n ICLR\u0026rsquo;19: ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware. By Han Cai, Ligeng Zhu, and Song Han. NeurIPS\u0026rsquo;20: MCUNet: Tiny Deep Learning on IoT Devices. By Ji Lin, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, Song Han.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/nas/2017-nas/",
	"title": "2017 ICLR Neural Architecture Search with Reinforcement Learning",
	"tags": [],
	"description": "",
	"content": " References:\n Neural Architecture Search with Reinforcement Learning. By Barret Zoph, Quoc V.Le. ICLR 2017.  Overview Nerual networks are hard to design.\nIn this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/songhan/2020-mcunet/",
	"title": "2020 MCUNet",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  What is the search space? What is mobile search space?  ? c42 Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, and Quoc V Le. MnasNet: Platform-Aware Neural Architecture Search for Mobile. In CVPR, 2019  What is a model? What is the system part and model part in the system-model codesign? What is one-shot architecture search?\n ? [c4] Gabriel Bender, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, and Quoc Le. Understanding and simplifying one-shot architecture search. In ICML, 2018 ? [c17] Zichao Guo, Xiangyu Zhang, Haoyuan Mu, Wen Heng, Zechun Liu, Yichen Wei, and Jian Sun. Single Path One-Shot Neural Architecture Search with Uniform Sampling. arXiv, 2019.  Neural Architecture Search (NAS).\n What is the position of NAS in the entire ML system? How many categories of Search mehtods in general?  Interpreter-based inference libraries (TF-Lite Micro, CMSIS-NN)\n How this is executed in practice?  Evolution search?\n Memory Scheduling?\n Who is doing the scheduling?  What is operation fusion?\n Int8 linear quantization?\n Hard-swish activation (in MobileNetV3[c23])\n  References:\n NeurIPS\u0026rsquo;20: MCUNet: Tiny Deep Learning on IoT Devices. By Ji Lin, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, Song Han. [c6] ICLR\u0026rsquo;19: ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware. By Han Cai, Ligeng Zhu, and Song Han. [c4] Gabriel Bender, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, and Quoc Le. Understanding and simplifying one-shot architecture search. In ICML, 2018 [c17] Zichao Guo, Xiangyu Zhang, Haoyuan Mu, Wen Heng, Zechun Liu, Yichen Wei, and Jian Sun. Single Path One-Shot Neural Architecture Search with Uniform Sampling. arXiv, 2019. c42 Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, and Quoc V Le. MnasNet: Platform-Aware Neural Architecture Search for Mobile. In CVPR, 2019  Motivation ARM Cortext-M7 MCU: 320KB SRAM, 1MB flash storage.\n ResNet-50 exceeds the storage limit by 100x MobileNetV2 exceeds the peak memory limit by 22x int8 quantized version of MobileNetV2 still exceeds the memory limit by 5.3x  MCUs are bare-metal devices that do not have an operating system.\n Need to jointly design the deep learning model and inference library;  Limited literatures:\n Mobile GPU or smartphones have abundant memory and storage.  They only optimize to reduce FLOPs or latency Resulting models cannot fit microcontrollers.  Machine learning on microcontrollers  either study tiny-scale dataset (e.g., CIFAR or sub-CIFAR level), which is far from real-life use case, or use weak neural networks that cannot achieve decent performance. Examples: [c15] [c30] [c40] [c28]  Deep learning inference on microcontrollers.  Most framework rely on an interpreter to interpret the network graph at runtime, which will consume a lot of SRAM and Flash (up to 65% of peak memory) and increase latency by 22%. The optimization is performed at layer-level, which fails to utilize the overall network architecture information to further reduce memory usage. Examples: TensorFlow Lite Micro[c3], CMSIS-NN[c27], CMix-NN[c8], MicroTVM[c9]   Efficient Neural Network Design\n Two ways to improve the performance of deep learning system:\n One is to compress the off-the-shelf networks Pruning Quantization Tensor decomposition Another is to design a new network suitable for mobile scenarios Neural Architecture Search (NAS) dominates efficient neural network design  Performance of NAS highly depends on the quality of the search space[^c38]\n Traditionally, need to follow manual design heuristics for NAS search space design. E.g. Mobile-setting search space 1 [^c6] [^c45]  Originates from MobileNetV2[^c41]; Use 224 input resolution and a similar base channel number configurations; Searching for kernel sizes, block depths, and expansion ratios;   For MCUs: no standard model designs nor search space designs for MCUs with limited memory\n It is possible to manually tweak the search space for each MCU, but labor-intensive; Need to automatically optimize the search space for tiny and diverse deployment scenarios.   Overview MCUNet, a system-model co-design framework that enables ImageNet-scale deep learning on microcontrollers.\n Efficient neural architecture \u0026ndash; TinyNAS, with\n automated search space optimization resource constrained model specification.  Lightweight inference engine \u0026ndash; TinyEngine\n Enabling ImageNet-scale inference on microcontrollers.\n  SRAM (Read/Write) constrains the activation size; Flash (read only) constrains the model size;\n Jointly optimize the deep learning model design (TinyNAS) and the inference library (TinyEngine) to reduce the memory usage; TinyNAS: two-stage neural architecture search (NAS) method that can handle the tiny and diverse memory constraints on various microcontrollers;  Performance depends on search space[^c38], and TinyNAS explores the design heuristic at the tiny scale First optimize the search space to fit the resource constraints;  Generate different search spaces by scaling the input resolution and the model width Collect the computation FLOPs distribution of satisfying networks within the search space to evaluate its priority; Insight: a search space that can accommodate higher FLOPs under memory constraint can produce better model Experiments verfied.  Then perform the search in optmized space;  TinyEngine:  code generator-based compilation method to eliminate memory overhead.  reduce overhead by 2.7x, improves inference by 22%  model adaptive memory scheduling:  not layer-wise optimization Optimize memory scheduling according to the overall network topology to get a better strategy.  Perform specialized computation kernel optimization (e.g, loop tiling, loop unrolling, op fusion, etc.) for different layers;   Pushes the limit of deep network performance on microcontrollers.\n TinyEngine  reduces 2.7x memory usage (??? 1-2.7 = -1.7x negitive usage???); accelerates the inference by 1.7-3.3x compared to TF-Lite and CMSIS-NN  System-algorithm codesign: TinyNAS + TinyEngine  ImageNet top-1 accurary 70.2% on microcontroller. visual audio wake words: 2.4-3.4x faster; 2.2.-2.6x smaller peak SRAM; interactive applications: 10FPS with 91% top-1 accuracy on Speech Commands dataset.   TinyNAS Two stage neural architecture search approach:\n Optimize the search space to fit the resource constraints  Analyze the computation distribution Scale the input resolution and the width multiplier of the mobile search space 1. Select the best search space by analyzing the FLOPs CDF of different search spaces. Insight: the design space that is more likely to produce high FLOPs models under the memory constraint gives higher model capacity, thus more likely to achieve high accuracy.   Specialize the network architecture in the optimized search space  TinyEngine  Model adaptive compilation.  interpreter-based -\u0026gt; generator-based compilation only compiles the operations that are used by a given model into the binary.  Memory Scheduling.  One layer on buffer -\u0026gt; multiple layers on buffer Tile the computation loop nests, so that as many columns can fit in that memory as possible.  Specialized kernel optimization. Loops tiling, inner loop unrolling, operation fusion.  Major Techniques In TinyNAS\n Sampling + FLOPs CDF One-shot neural arch search [c4, c17] Super network training with weight sharing among sub-networks Evolution search  In TinyEngine\n Code generator-based compilation Memory scheduling Loops tiling Inner loop unrolling Operation fusion  Evaluation  Datasets: ImageNet, Visual Wake Words(VWW), Speech Commands. Devices: STM32F746 MCU (320kB SRAM/1MB Flash), STM32H743 (512kB SRAM/2MB Flash). 216MHz CPU. Youtube Demo 70.2% accuracy, record high, ImageNet recognition on microcontrollers.  More   Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, and Quoc V Le. MnasNet: Platform-Aware Neural Architecture Search for Mobile. In CVPR, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/nas/2019-survey/",
	"title": "2019 Survey",
	"tags": [],
	"description": "",
	"content": " References:\n Neural Architecture Search: A Survey. Thomas Elsken, Jan Hendrik Metzen, Frank Hutter. Journal of Machine Learning Research, 2019.   Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.\nAlready by now, NAS methods have outperformed manually designed architectures on some tasks such as image classification (1; 2, object detection (1), or semantic segmentation (3)\n  Search Space $\\mathcal{A}$. Defines with architecture can be represented in principle.  Incorporating prior knowledge about typical properties of architectures well-suited for a task can reduce the size of the search space and simplify the search; But will introduce human bias, which may prevent finding novel architectural building that go beyond current human knowledge.  Search Strategy. Details how to explore the search space (which is often exponentially large or even unbounded).  It encompasses the classical exploration-explitation trade-off find well-performing architectures quickly premature convergence to a region of suboptimal architectures should be avoided.  Performance Estimation Strategy.  Simplest form is to perform a standard training. But computationally expensive. Method that reduce the cost of these performance estimations.   $A \\in \\mathcal{A}$\nMore   Learning transferable architectures for scalable image recognition. In Conference on Computer Vision and Pattern Recognition, 2018. ↩ Large-scale evolution of image classifiers. by Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu,Quoc V. Le, and Alex Kurakin. ICML, 2017. ↩ Searching for efficient multi-scale architecturesfor dense image prediction. By Liang-Chieh Chen, Maxwell Collins, Yukun Zhu, George Papandreou, Barret Zoph, FlorianSchroff, Hartwig Adam, and Jon Shlens. IN S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors,Advances in Neural Information Processing Systems31, pages 8713–8724. Curran Associates, Inc 2018. pdf ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/nas/",
	"title": "NAS",
	"tags": [],
	"description": "",
	"content": "  Neural Architecture Search (NAS) [49, 50, 32, 6, 42, 45] dominates efficient network design. From \u0026ldquo;MCUNet: Tiny Deep Learning on IoT Devices\u0026rdquo; by Lin, Ji, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, and Song Han;\n References:\nCitations of NAS from \u0026ldquo;NeurIPS\u0026rsquo;20: MCUNet: Tiny Deep Learning on IoT Devices\u0026rdquo; by Lin, Ji, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, and Song Han\n ICLR\u0026rsquo;17: Neural Architecture Search with Reinforcement Learning. Barret Zoph and Quoc V Le. CVPR\u0026rsquo;18: Learning Transferable Architectures for Scalable Image Recognition. Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V. Le. ICLR\u0026rsquo;19: DARTS: Differentiable Architecture Search. Haoxiao Liu, Karen Simonyan, and Yiming Yang. ICLR\u0026rsquo;19: ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware. Han Cai, Ligeng Zhu, and Song Han. CVPR\u0026rsquo;19: MnasNet: Platform-Aware Neural Architecture Search for Mobile. Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, and Quoc V Le. CVPR\u0026rsquo;19: FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search. Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing Jia, and Kurt Keutzer. Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr Dollár. Designing network design spaces. arXiv preprint arXiv:2003.13678, 2020. Neural Arch Search \u0026ndash; Lil\u0026rsquo;Log Neural Architecture Search: A Survey. Thomas Elsken, Jan Hendrik Metzen, Frank Hutter. Journal of Machine Learning Research, 2019. Blog: What’s the deal with Neural Architecture Search?  NAS overview Reference:\n Neural Arch Search \u0026ndash; Lil\u0026rsquo;Log Neural Architecture Search: A Survey. Thomas Elsken, Jan Hendrik Metzen, Frank Hutter. Journal of Machine Learning Research, 2019. Blog: What’s the deal with Neural Architecture Search?  Neural networks are hard to design.\nObservation: The structure and connectivity of a neural network can be typically specified by a variable-length string. Therefore, it is possible to use a recurrent network \u0026ndash; the controller \u0026ndash; to generate such string.\nNAS: a gradient-based method for finding good architectures.\nNAS with reinforcement learning (ICLR\u0026rsquo;17): use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set.\nNAS a subproblem of Hperparameter optimization Reference: Blog: What’s the deal with Neural Architecture Search?\n AutoML focuses on automating every aspect of the machine learning workflow to increase efficiency and democratize machine learning so that non-experts can apply machine learning to their problems with ease. While AutoML encompasses the automation of a wide range of problems associated with ETL, model training, and model deployment, the problem of Hyperparameter Optimization is a core focus of AutoML. This problem involves configuring the internal settings that goven the behavior of an ML model/algorithm in order to return a high quality predictive model.\nFor example, ridge regression models require setting the value of a regularization term; random forest models require the user to set the maximum tree depth and minimum number of samples per leaf; and training any model with stochastic gradient descent requires setting an appropriate step size. Neural networks also require setting a multitude of hyperparameters including (1) Selecting an optimization method along with its associated set of hyperparameters, (2) setting the dropout rate and other regularization hyperparameters, and, if desired, (3) tuning parameters that control the architecture of the network (e.g., number of hidden layers, number of convolutional filters).\nAlthough the exposition on Neural Architecture Search (NAS) might suggest that it is a completely new problem, our final example above hints at a close relationship between hyperparameter optimization and NAS. While search space used for NAS are generally larger and control different aspects of the neural network architecture, the underlying problem is the same as that addressed by hyperparameter optimization: find a configuration within the search space that performs well on the target task. Hence, we view NAS to be a subproblem within hyperparameter optmization.\n NAS components Reference: Blog: What’s the deal with Neural Architecture Search?, December 18, 2018\n The first NAS, Zoph et. al. 2016, requires a tremendous amount of computational power  hundreds of GPUs running for thousands of GPU days in aggregate.  Recent approaches exploit various methods of reuse to drastically reduce the computational cost.  Three main components of most NAS methods (more on survey paper)\n Search space. This component describes the set of possible neural network architectures to consider. These search spaces are designed specific to the application, e.g., a space of convolutional networks for computer vision tasks or a space of recurrent networks for language modeling tasks.  NAS methods are not fully automated, as the design of these search spaces fundamentally relies on human-designed architectures as starting points. The number of possible architectures considered in these search spaces are often over 10^10.  Optimization method. This component determines how to explore the search space in order to find a good architecture.  The most basic approach here is random search, while various adaptive methods have also been introduced, e.g., reinforcement learning, evolutionary search, gradient-based optimization, and Bayesian optimization. While these adaptive approaches differ in how they determine which architectures to evaluate, they all attempt to bias the search towards architectures that are more likely to perform well. Unsurprisingly, all of these methods have counterparts that have been introduced in the context of traditional hyperparameter optimization tasks.  Evaluation method. Measures the quality of each architecture considered by the optimization method.  Simplest, but most computationally expensive choice is to fully train an architecture. One can alternatively exploit partial training, similar in spirit to early-stopping methods commonly used in hyperparameter optimization like ASHA.  an order-of-magnitude cheapter than full training.  NAS-specific evaluation methods have also been introduced to exploit the structure of neural network to provide cheaper, heuristic estimates of quality.  network morphsim weight-sharing hypernetworks 2-3 orders of magnitude cheaper than full training    NAS models vs human designed models Public NAS Impelementations  A collection of NAS papers and codes:\n https://github.com/D-X-Y/Awesome-AutoDL https://github.com/D-X-Y/AutoDL-Projects  NASBench\n paper  ENAS: Efficient Neural Architecture Search via Parameter Sharing and Language Model Implementation of ENAS (google)\n PyTorch implemenatation of ENAS  Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search.\n LA-MCTS code (Facebook) From one-shot NAS to few-shot NAS From LaNAS to a generic solver LA-MCTS From AlphaX to LaNAS MCTS based NAS agent old AlphaX: AlphaX-NASBench101;  TF-NAS: Rethinking Three Search Freedoms of Latency-Constrained Differentiable Neural Architecture Search\n Pytorch code paper  Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture Search\n Python implementation (xiaomi) paper  Darts: Differentiable architecture search.\n PyTorch paper  UNAS: Differentiable Architecture Search Meets Reinforcement Learning, CVPR 2020 Oral\n PyTorch Impl paper  Rethinking Performance Estimation in Neural Architecture Search\n code   More  2017 ICLR Neural Architecture Search with Reinforcement Learning   References: Neural Architecture Search with Reinforcement Learning. By Barret Zoph, Quoc V.Le. ICLR 2017. Overview Nerual networks are hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. More  2019 Survey  References: Neural Architecture Search: A Survey. Thomas Elsken, Jan Hendrik Metzen, Frank Hutter. Journal of Machine Learning Research, 2019. Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/lane/",
	"title": "Lane",
	"tags": [],
	"description": "",
	"content": " ICLR\u0026rsquo;19: An Empirical study of Binary Neural Networks\u0026rsquo; Optimization.\nECCV\u0026rsquo;20: Journey towards tiny perceptual super-resolution\nMobiCom\u0026rsquo;20: SPINN: Synergistic Progressive Inference of Neural Networks over Device and Cloud\nInterSpeech\u0026rsquo;20: Iterative Compression of End-to-End ASR Model using AutoML\nDAC\u0026rsquo;20: Best of Both Worlds: AutoML Codesign of a CNN and its Hardware Accelerator\nMore  2020 SPINN   References: reference Evaluation Server: 2x Intel Xeon Gold 6130, 128GB Memory, with GPU GTX 1080Ti Client: Nvidia Jetson Xavier AGX, 16GB Memory, with GPU 512-core Volta More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/songhan/",
	"title": "Songhan",
	"tags": [],
	"description": "",
	"content": " TinyTL NeurIPS\u0026rsquo;20: Tiny Transfer Learning: Towards Memory-Efficient On-Device Learning\n Three benchmark datasets: Cars, Flowers, Aircraft\n Using ImageNet as the pre-training dataset. Neural network architecture: MobileNetV2 (lightweight), ResNet-50.  Devices: Raspberry Pi 1. 256MB of memory.\n  Once for all ICLR\u0026rsquo;20: Once-for-all: Train one network and specialize it for efficient deployment.\n ImageNet; Samsung S7 Edge, Note10, Google Pixel1, Pixel2, LG G8, NVIDIA 1080 Ti, V100 GPUs, Jetson TX2, Intel Xeon CPU, Xilinx ZU8EG, and ZU3EG FPGAs. Cloud Devices:  GPU NVIDIA 1080Ti and V100 with Pytorch 1.0+cuDNN. CPU batch size 1 on Intel Xeon E5-2690 v4 + MKL-DNN.  Edge Devices:  Mobile phones: Samsung, Google and LG phones with TF-Lite, batch size 1; Mobile GPU: Jetson TX2 with Pytorch 1.0 + cuDNN, batch size of 16; Embedded FPGA: Xilinx ZU9EG and ZU3EG FPGAs with Vitis AI, batch size 1. (Inference accelaration) Xilinx ZU9EG (ZCU102, $2495) Xilinx ZU3EG ()   Deep Leakage NeurIPS\u0026rsquo;19: Deep Leakage from Gradients.\nDiff Aug GAN NeurIPS\u0026rsquo;20: Differentiable Augmentation for Data-Efficient GAN Training\n Model: BigGAN, CR-BigGAN, StyleGAN2 Datasets: ImageNet (128x128 resolution), FFHQ portait dataset (256x256), image generated by few-shot learning. Devices: Not in paper. (General platform?) Code: Data-efficient-gans  More  2019 Proxyless Nas   Q\u0026amp;A \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; References: ICLR\u0026rsquo;19: ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware. By Han Cai, Ligeng Zhu, and Song Han. NeurIPS\u0026rsquo;20: MCUNet: Tiny Deep Learning on IoT Devices. By Ji Lin, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, Song Han. More  2020 MCUNet  Q\u0026amp;A What is the search space? What is mobile search space? ? c42 Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, and Quoc V Le. MnasNet: Platform-Aware Neural Architecture Search for Mobile. In CVPR, 2019 What is a model? What is the system part and model part in the system-model codesign? What is one-shot architecture search? ? [c4] Gabriel Bender, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, and Quoc Le.\n Once-for-all: Train one network and specialize it for efficient deployment  Q\u0026amp;A What is MACs? Resolution? Kernel? Depth? Width? Channel? L1 norm of channel\u0026rsquo;s weight? Problem formalization ${min_{W_o}{\\sum}{_a{_i}}}L_v(C(W_o, a_i))$ References: Once-for-all: Qualcomm News The future will be populated with many IoT devices that are AI-capable. AI will surround our lives at much lower cost, lower latency, and higher accuracy. There will be more powerful AI applications running on tiny edge devices, which requires extremely compact models and efficient chips.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/songhan/2020-ofa/",
	"title": "Once-for-all: Train one network and specialize it for efficient deployment",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  What is MACs?\n Resolution?\n Kernel?\n Depth?\n Width? Channel?\n L1 norm of channel\u0026rsquo;s weight?  Problem formalization\n ${min_{W_o}{\\sum}{_a{_i}}}L_v(C(W_o, a_i))$   References:\n Once-for-all: Qualcomm News   The future will be populated with many IoT devices that are AI-capable. AI will surround our lives at much lower cost, lower latency, and higher accuracy. There will be more powerful AI applications running on tiny edge devices, which requires extremely compact models and efficient chips. At the same time, privacy will become increasingly important. On-device AI will be popular thanks to the privacy and latency advantages. Model compression and efficient architecture design techniques will enable on-device AI, making it more capable.\n ICLR\u0026rsquo;20: Once-for-all: Train one network and specialize it for efficient deployment.\n Decouples model training from neural architectural search.  Traing once: train a super network Search multiple targets: each targets are progressively shrinked sub-network of the trained super network. opportunity for algorithm and hardware co-design.   Key Techniques Progressive Shrinking\n 4 dimension shrink instead of one-dimension Kernel Size: introduce kernel transformation matrices.  sharing kernel weights; separate transformation matrices for different layers;  Depth: Original N layer, Keep first D layers, skip the N-D layers; Width: Original num of Channels. Channel sorting by importance.  Importance of the channel: L1 norm of a channel\u0026rsquo;s weight Large L1 norm means more important Smaller subnetworks are initialized with the most important channles.   Evaluation  ImageNet; Samsung S7 Edge, Note10, Google Pixel1, Pixel2, LG G8, NVIDIA 1080 Ti, V100 GPUs, Jetson TX2, Intel Xeon CPU, Xilinx ZU8EG, and ZU3EG FPGAs. Cloud Devices:  GPU NVIDIA 1080Ti and V100 with Pytorch 1.0+cuDNN. CPU batch size 1 on Intel Xeon E5-2690 v4 + MKL-DNN.  Edge Devices:  Mobile phones: Samsung, Google and LG phones with TF-Lite, batch size 1; Mobile GPU: Jetson TX2 with Pytorch 1.0 + cuDNN, batch size of 16; Embedded FPGA: Xilinx ZU9EG and ZU3EG FPGAs with Vitis AI, batch size 1. (Inference accelaration)   More  Training  Q\u0026amp;A ofa_net is always called with pretrained=True, which means it will works without training. But how to train the super network ? References: reference # file: # ofa/model_zoo.py def ofa_net(net_id, pretrained=True): if net_id == \u0026#39;ofa_proxyless_d234_e346_k357_w1.3\u0026#39;: net = OFAProxylessNASNets( dropout_rate=0, width_mult=1.3, ks_list=[3, 5, 7], expand_ratio_list=[3, 4, 6], depth_list=[2, 3, 4], ) elif net_id == \u0026#39;ofa_mbv3_d234_e346_k357_w1.0\u0026#39;: net = OFAMobileNetV3( dropout_rate=0, width_mult=1.0, ks_list=[3, 5, 7], expand_ratio_list=[3, 4, 6], depth_list=[2, 3, 4], ) elif net_id == \u0026#39;ofa_mbv3_d234_e346_k357_w1.\n Tutorial  References: Hands-on Tutorial of Once-for-All Network, See tutorial/ofa.ipynb How to Get Your Specialized Neural Networks on ImageNet in Minutes With OFA Networks In this notebook, we will demonstrate - how to use pretrained specialized OFA sub-networks for efficient inference on diverse hardware platforms - how to get new specialized neural networks on ImageNet with the OFA network within minutes. Once-for-All (OFA) is an efficient AutoML technique that decouples training from search.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/iot/ai/",
	"title": "Efficient AI with Tiny Resources",
	"tags": [],
	"description": "",
	"content": " References:\n Song Han from MIT  Evaluations NeurIPS\u0026rsquo;20: MCUNet: Tiny Deep Learning on IoT Devices\n Datasets: ImageNet, Visual Wake Words(VWW), Speech Commands. Devices: STM32F746 MCU (320kB SRAM/1MB Flash), STM32H743 (512kB SRAM/2MB Flash). 216MHz CPU. Youtube Demo 70.2% accuracy, record high, ImageNet recognition on microcontrollers.  NeurIPS\u0026rsquo;20: Tiny Transfer Learning: Towards Memory-Efficient On-Device Learning\n Three benchmark datasets: Cars, Flowers, Aircraft\n Using ImageNet as the pre-training dataset. Neural network architecture: MobileNetV2 (lightweight), ResNet-50.  Devices: Raspberry Pi 1. 256MB of memory.\n  NeurIPS\u0026rsquo;20: Differentiable Augmentation for Data-Efficient GAN Training\n Model: BigGAN, CR-BigGAN, StyleGAN2 Datasets: ImageNet (128x128 resolution), FFHQ portait dataset (256x256), image generated by few-shot learning. Devices: Not in paper. (General platform?) Code: Data-efficient-gans  ICLR\u0026rsquo;20: Once-for-all: Train one network and specialize it for efficient deployment.\n ImageNet; Samsung S7 Edge, Note10, Google Pixel1, Pixel2, LG G8, NVIDIA 1080 Ti, V100 GPUs, Jetson TX2, Intel Xeon CPU, Xilinx ZU8EG, and ZU3EG FPGAs. Cloud Devices:  GPU NVIDIA 1080Ti and V100 with Pytorch 1.0+cuDNN. CPU batch size 1 on Intel Xeon E5-2690 v4 + MKL-DNN.  Edge Devices:  Mobile phones: Samsung, Google and LG phones with TF-Lite, batch size 1; Mobile GPU: Jetson TX2 with Pytorch 1.0 + cuDNN, batch size of 16; Embedded FPGA: Xilinx ZU9EG and ZU3EG FPGAs with Vitis AI, batch size 1. (Inference accelaration) Xilinx ZU9EG (ZCU102, $2495) Xilinx ZU3EG ()   ECCV\u0026rsquo;20: Searching Efficient 3D Architectures with Sparse Point-Voxel Convolution.\nECCV\u0026rsquo;20: DataMix: Efficient Privacy-Preserving Edge-Cloud Inference.\nACL\u0026rsquo;20: HAT: Hardware-Aware Transformers for Efficient Natural Language Processing.\nCVPR\u0026rsquo;20: GAN Compression: Efficient Architectures for Interactive Conditional GANs\n Three GAN (Generative Adversarial Network) Models  CycleGAN Pix2pix GauGAN  Four datasets:\n Edges-\u0026gt;shoes. Used in pix2pix. Cityscapes. Used in pix2pix and GauGAN. Horse \u0026lt;-\u0026gt; zebra. Used in CycleGAN. Map \u0026lt;-\u0026gt; aerial photo. Used in pix2pix.  CPU or NVIDIA GPU + CUDA CuDNN\n Mobile device (NVIDIA Jetson Nano GPU). Youtube Demo github: https://github.com/mit-han-lab/gan-compression   CVPR\u0026rsquo;20: APQ: Joint Search for Network Architecture, Pruning and Quantization Policy.\nDAC\u0026rsquo;20: GCN-RL Circuit Designer: Transferable Transistor Sizing with Graph Neural Networks and Reinforcement Learning.\nHPCA\u0026rsquo;20: SpArch: Efficient Architecture for Sparse Matrix Multiplication.\nICLR\u0026rsquo;20: Lite Transformer with Long Short Term Attention.\nNeurIPS\u0026rsquo;19: Point Voxel CNN for Efficient 3D Deep Learning.\nNeurIPS\u0026rsquo;19: Deep Leakage from Gradients.\nICCV\u0026rsquo;19: TSM: Temporal Shift Module for Efficient Video Understanding.\nCVPR\u0026rsquo;19: HAQ: Hardware-Aware Automated Quantization with Mixed Precision.\nICLR\u0026rsquo;19: ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware.\nICLR\u0026rsquo;19: Defensive Quantization: When Efficiency Meets Robustness.\nECCV\u0026rsquo;18: AMC: AutoML for Model Compression and Acceleration on Mobile Devices.\nICLR\u0026rsquo;18: Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training.\nICLR\u0026rsquo;18: Efficient Sparse-winograd Convolutional Neural Networks.\nICLR\u0026rsquo;17: DSD: Dense-Sparse-Dense Training for Deep Neural Networks.\nICLR\u0026rsquo;17: Trained Tenary Quantization.\nHotChips at MICRO\u0026rsquo;17: Software-Hardware Co-Design for Efficient Neural Network Acceleration.\n Devices: FPGA  Xilinx XCKU060, 200MHz CPU: Intel Core i7-5930K GPU: Pascal TitanX GPU.   EMDNN\u0026rsquo;16 FPGA\u0026rsquo;17: ESE: Efficient Speech Recognition Engine for Sparse LSTM on FPGA.\n Devices: FPGA  Xilinx XCKU060, 200MHz Intel Core i7 5930K Pascal Titan X GPU   O\u0026rsquo;Reilly, 2016: Compressing and Regularizing Deep Neural Networks, Improving Prediction Accuracy Using Deep Compression and DSD Training.\nISCA\u0026rsquo;16: EIE: Efficient Inference Engine on Compressed Deep Neural Network.\n Model: Caffe, NerualTalk, AlexNet, VGGNet, ImageNet Devices:  Simulator, implemented in C++, cycle accurate Also implemented in RTL in Verilog for area, power, and critical path delay. Use Synopsys Design Compiler (DC) under TSMC 45nm GP standard VT lib. Use Cacti to get SRAM area and energy numbers. Baseline: CPU, GPU and mobile GPU. Intel Core i7 5930K Nvidia GeForce GTX Titan X GPU Nvidia Tegra K1 mobile GPU. 192 CUDA cores.   ICLR\u0026rsquo;16: Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding.\n Model/Platform: Caffe framework;  Lenet-300-100, Lenet-5 on MNIST AlexNet, VGG-16 on ImageNet  Devices: CPU, GPU, mobile GPU.  Nvidia GeForce GTX Titan X Intel Core i7 5930K as desktop processor. Nvidia Tegra K1 as mobile processor.   NIPS\u0026rsquo;15: Learning both Weights and Connections for Efficient\n Model/Platform: Caffe; Four networks:  Lenet-300-100, Lenet-5 on MNIST AlexNext and VGG on ImageNet.  Devices:  Nvidia TitanX GTX980 GPUs.   ArXiv\u0026rsquo;16: SqueezeNet: AlexNet-Level Accuracy with 50x Fewer Parameters and \u0026lt;0.5MB Model Size.\n Devices: general? Code at github  ISVLSI\u0026rsquo;16: Angel-Eye: A Complete Design Flow for Mapping CNN onto Customized Hardware.\n Model: face detection Devices: FPGA, power \u0026amp; performance  Xilinx XC7Z045 (16-bit data bitwidth) Xilinx XC7Z020 (8-bit data bidwidth) For comparison: N   ICLR Workshop\u0026rsquo;16: Hardware-friendly Convolutional Neural Network with Even-number Filter Size., 4 pages, with Tsinghua Brain.\n MXnet (Chen et al. 2015) Devices:  Intel Xeon E5-2690 CPUs@2.9GHz, 2 Nvidia TITAN X GPUs.   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/english/",
	"title": "English",
	"tags": [],
	"description": "",
	"content": " stab at:\n Sealed pointers come about in a few ways; from userspace on CheriBSD, tho\u0026rsquo;, calling sysarch(CHERI_GET_SEALCAP, \u0026amp;sealer) will set sealer to be a capability capable of sealing and unsealing at all otypes the kernel permits userspace to use. (This is not, obviously, the envisioned future mechanism, but it\u0026rsquo;s what we\u0026rsquo;ve got at the moment. Also I think it\u0026rsquo;s only the case that we have it on MIPS right now.) Anyway, once you\u0026rsquo;ve got such a thing, use pointer math or offset adjustment instructions to adjust the sealing type and then sealed = cheri_seal(input, sealer) to make a sealed cap. Sorry for the delay in answering, but there\u0026rsquo;s my stab at it.\n More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/cpi/2014-osdi/",
	"title": "Code-Pointer Integrity",
	"tags": [],
	"description": "",
	"content": " References:\n Code-Pointer Integrity  Goal Guarantees the integrity of all code pointers in a program, e.g. function pointers, saved return addresses), and thereby prevents all control-flow hijack attacks, including return-oriented programming.\nChallenges  Hard to make Low level languages safe (C/C++) while preserving their benefits including performance and flexible programming patterns.  Data execution prevention(DEP): return-to-libc [^c37] attack, ROP[^c44] [^c8], Turning-complete computations. Address Space Layout Randomization (ASLR): defeated by pointer leaks, side channel attacks [^c22], and just-in-time code reuse attacks [^c45]. Stack Cookies [^c14]. Only against continuous buffer overflows. CFI. Above impose overheads and are bypassable as shown in survey 1 Some require changes to how the programmers should write code.   In order to render control-flow hijack impossible, it is sufficient to guarantee the integrity of code pointers, i.e., those that are used to determine the targets of indirect control-flow transfers (indirect calls, indirect jumps, or returns).\nSolution Overview A partial memory safety solution aiming to protect code pointers only:\n Split process memory into a safe region and a regular region. Use static analysis to identify the set of memory objects that must be protected in order to guarantee memory safety for code pointers.  All memory objects that contain code pointers and all data pointers used to access code pointers indirectly. Store them in safe region.  Safe region use static analysis and runtime check to ensure full memory safety for this region. Unsafe region behaves the same as before, no runtime overhead.  Design Definitions:\n A pointer dereference is safe iff the memory it accesses lies within the target object on which the dereferenced pointer is based. Execution of a program is memory-safe iff all pointer dereferences in the execution are safe. A pointer is based on a target object X iff the pointer is obtained at runtime by (stricter than C99\u0026rsquo;s based on definition)  i) allocating X on the heap; ii) explicitly taking the address of X, if allocated statically, such as local or global variable, or is a control flow target (including return locations, whose addresses are implicitly taken and stored on the stack when calling a function.) iii) taking the address of a sub-object y of X (e.g., a field in the X struct), or iv) computing a pointer expression involving operands that are either themselves based on object X, or are not pointers. (e.g., pointer arithmetic, array indexing, or simply copying a pointer)   Code-Pointer Integrity Property:\nA program execution satisfies the code-pointer integrity property iff all its dereferences that either dereference or access sensitive pointers are safe.\n Sensitive pointers are code pointers and pointers that may later be used to access sensitive pointers. (Recursive definition)  The integrity of the based-on metadata associated with sensitive pointers requires that pointers used to update sensitive pointers be sensitive as well. (Fig.1) two pointers: *p=\u0026amp;q The notion of a sensitive pointer is dynamic. void *pointer can be sensitive when it points at a sensitive pointer at runtime, but not sensitive when it points to an integer.   Determining precisely the set of pointers that are sensitive can only be done at run time. However, the CPI property can still be enforced using any over-approximation of this set, and such over-approximations can be obtained at compile time, using static analysis.\nCPI enforcement mechanism: A combination of static instrumentation and runtime support.\n Static analysis pass: identify all sensitive pointers in P and all instructions that operate on them.  type-based static analysis: a pointer is sensitive if its type is sensitive. Sensitive types: Pointers to functions, pointers to sensitive types, pointers to composite types that contains one or more members of sensitive types, universal pointers (i.e., void * and opaque pointers to forward-declared structs or classes.) A programmer could additionally indicate, if desired, other types to be considered sensitive struct ucred used in FreeBSD kernel to store process UIDs and jail information. All pointers that a compiler or runtime creates implicitly (such as return addresses, C++ virtual table pointers, and setjmp buffers) are sensitive as well. To identify all instructions manipulate sensitive pointers: Pointer dereferences; Pointer arithmetic; Memory (de-)allocation operations that calls:  standard libarary functions; C++ new/delete operators; manually annotated custom allocators;  Notes on over approximation of sensitive pointer set: It may include universal pointers that never end up pointing to sensitive values at runtime. e.g. char * pointers in C/C++ standard are allowed to point to object of any type. As heuristic, we assume not universal on these char * pointers that  are passed to the standard libc string manipulation functions or that are assigned to point to string manipulation functions or that are assigned to point to string constants  Neither the over-approximation nor the char * heuristic affect the security guarantees provided by CPI:  Over-approximation merely introduces extra overhead heuristic errors may result in false violation reports (though we never observed any in practice).  Notes on optimization of performance: the void * arguments in memset memcpy: CPI will instrument all accesses inside the functions, regardless whether they are operating on sensitive pointers or not. To optimize:  Use static analysis to detect the real types of the arguments prior to being cast to void *. Subsequent instrumentation pass handles them separately using type-specific versions of the corresponding memory manipulation functions.  Note on the soundness: Type-based static analysis with a data-flow analysis that handles most practical cases of unsafe pointer casts and casts between pointers and integers.   Instrumentation pass: rewrite P to \u0026ldquo;protect\u0026rdquo; all sensitive pointers, i.e. store them in a separate, safe memory region, and associate, propagate, and check their based-on metadata. Instruction level isolation mechanism that prevents non-protected memory operations from accessing the safe region. For performance reasons, return addresses are stored on the stack separately from the rest of the code pointers using a safe stack mechanism.  Evaluation Open problems More   L. Szekeres, M. Payer, T. Wei, and D. Song. SoK: Eternal war in memory. IEEE Symp. on Security and Privacy, 2013. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/cpi/",
	"title": "Code Pointer Integrity",
	"tags": [],
	"description": "",
	"content": " References:\n Code Pointer Integrity  Motivation CFI 1 2 3 4 5 is shown to be ineffective 6 7 8.\nTransactions on Information Forensics and Security, 6(4):1404–1417, Dec. 2011.\nMore  Code-Pointer Integrity  References: Code-Pointer Integrity Goal Guarantees the integrity of all code pointers in a program, e.g. function pointers, saved return addresses), and thereby prevents all control-flow hijack attacks, including return-oriented programming. Challenges Hard to make Low level languages safe (C/C++) while preserving their benefits including performance and flexible programming patterns. Data execution prevention(DEP): return-to-libc [^c37] attack, ROP[^c44] [^c8], Turning-complete computations. Address Space Layout Randomization (ASLR): defeated by pointer leaks, side channel attacks [^c22], and just-in-time code reuse attacks [^c45].\n  M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-flow integrity. In ACM Conf. on Computer and Communication Security, 2005 ↩ J. Li, Z. Wang, T. K. Bletsch, D. Srinivasan, M. C. Grace, and X. Jiang. Comprehensive and efficient protection of kernel control data. IEEE ↩ C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant, D. Song, and W. Zou. Practical Control Flow Integrity \u0026amp; Randomization for Binary Executables. In IEEE Symp. on Security and Privacy, 2013. ↩ M. Zhang and R. Sekar. Control flow integrity for COTS binaries. In USENIX Security Symposium, 2013. ↩ B. Niu and G. Tan. Modular control-flow integrity. In ACM Conf. on Programming Language Design and Implementation, 2014. ↩ E. Göktaş, E. Athanasopoulosy, H. Bos, and G. Portokalidis. Out of control: Overcoming control-flow integrity. In IEEE Symp. on Security and Privacy, 2014. ↩ L. Davi, A.-R. Sadeghi, D. Lehmann, and F. Monrose. Stitching the gadgets: On the ineffectiveness of coarse-grained control-flow integrity protection. In USENIX Security Symposium, 2014. ↩ N. Carlini and D. Wagner. Rop is still dangerous: Breaking modern defenses. In USENIX Security Symposium, 2014. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/bios/margo-seltzer/",
	"title": "Margo Seltzer",
	"tags": [],
	"description": "",
	"content": " References:\n People of Systems \u0026amp; Architecture: Margo I. Seltzer  Career jouney  It\u0026rsquo;s a circuitous journey that had no pre-planning. One of the things that I always tell my graduating students, particularly undergrads, is don\u0026rsquo;t try to plan out the rest of your life; figure out what you\u0026rsquo;re doing next. In large part, that\u0026rsquo;s because I never could have predicted where I ended up.\n\u0026hellip; Grad school was great [thinks]. Um, no, grad school was not that great. I like to tell my students who start their PhD that there will be times in grad school when it\u0026rsquo;s really, really hard. I tell them \u0026ldquo;Just don\u0026rsquo;t hide if you have a problem. I am here for you. We\u0026rsquo;ll get you through this\u0026rdquo;. Nobody told me that.\n\u0026hellip; [Being a professor] It was the best job in the world for me because, it turns out I don\u0026rsquo;t do really well with a boss. Academia is one of very few jobs in life where you don\u0026rsquo;t really have a boss. So, it actually turned out to be a great fit. It brought together the various aspects of me that I was really good at. I\u0026rsquo;m a people person, I\u0026rsquo;m an extrovert. But, I\u0026rsquo;m also a geek. I really enjoy programming and I like technology. Being a professor lets me do those two things.\n\u0026hellip; I\u0026rsquo;ve never seen a research problem I didn\u0026rsquo;t like. I talk to people and they\u0026rsquo;ll mention things that are interesting. Collaboration is really fun. I\u0026rsquo;ve got a couple of visualization projects going on, because systems people are often really good at producing interesting data and not very good at helping people use it. I am not somebody who knows how to solve visualization problems, but I can often identify things like, \u0026ldquo;Ooh, this is really interesting data! I wonder if there\u0026rsquo;s a way we could make it accessible to people\u0026rdquo;.\nI\u0026rsquo;m really excited about being able to visualize the data that we use to make intrusion detection systems, because in many cases, you get an alarm that says, \u0026ldquo;Oh, we think there\u0026rsquo;s intrusion\u0026rdquo;. And it\u0026rsquo;s like, \u0026ldquo;Why?!\u0026rdquo; um well because some piece of the software says so. I think it would be really great to give people the mechanism to dig down into it and get a sense of what\u0026rsquo;s going on. So, that\u0026rsquo;s been a whole fun area.\n\u0026hellip; My secret desire is that I want to spend the rest of my career trying to publish in as many different areas of computer science as possible. I\u0026rsquo;ve got my first PL paper under submission at the moment, but I\u0026rsquo;ve never published a theory paper. My ML papers have a lot of math in them though. I haven\u0026rsquo;t published in scientific computing either. So yeah, that\u0026rsquo;s my new fantasy.\n\u0026hellip; \u0026ldquo;Oh, I understand it at this higher level and I actually don\u0026rsquo;t understand low-level details\u0026rdquo;. I think that\u0026rsquo;s a really uncomfortable position for a lot of people, but if you\u0026rsquo;re going to work across areas, there are going to be some areas where you\u0026rsquo;re going to have to draw a line and say, \u0026ldquo;Okay, I can stop here\u0026rdquo;. I don\u0026rsquo;t know if this is a skill or a failure of a skill. Often with graduate students, one of the challenges, particularly when I\u0026rsquo;m encouraging them to do these bold, stupid, audacious (pick your right word) projects is helping them figure out that they don\u0026rsquo;t need to go all the way down to the bottom on every topic. You need to understand that this is the technology we are going to use. So, you do not need to understand how to develop it from scratch.\n More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/bios/",
	"title": "Bios",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Margo Seltzer  References: People of Systems \u0026amp; Architecture: Margo I. Seltzer Career jouney It\u0026rsquo;s a circuitous journey that had no pre-planning. One of the things that I always tell my graduating students, particularly undergrads, is don\u0026rsquo;t try to plan out the rest of your life; figure out what you\u0026rsquo;re doing next. In large part, that\u0026rsquo;s because I never could have predicted where I ended up. \u0026hellip; Grad school was great [thinks].\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/exceptions/",
	"title": "Exceptions",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Landingpad   References: LLVM Exception Handling A landing pad corresponds roughly to the code found in the catch portion of a try/catch sequence. When execution resumes at a landing pad, it receives an exception structure and a selector value corresponding to the type of exception thrown. The selector is then used to determine which catch should actually process the exception. More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/exceptions/landingpad/",
	"title": "Landingpad",
	"tags": [],
	"description": "",
	"content": " References:\n LLVM Exception Handling   A landing pad corresponds roughly to the code found in the catch portion of a try/catch sequence. When execution resumes at a landing pad, it receives an exception structure and a selector value corresponding to the type of exception thrown. The selector is then used to determine which catch should actually process the exception.\n More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-c-model/provenance/",
	"title": "Exploring C Semantics and Pointer Provenance",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  What is pointer provenance?  Pointer Provenance: the \u0026ldquo;origin\u0026rdquo; of pointer values Problem:  About the distinctions between integer values and pointer values: wheter they can be casted to each other; and how they should be casted properly in a \u0026lsquo;standard\u0026rsquo; way About what the standard meaning or requirements for being \u0026ldquo;provenance tracking\u0026rdquo;   How to determine provenance of a given pointer?  References:\n Exploring C Semantics and Pointer Provenance  Overview Explore the possible source-language semantics for memory objects and pointers, in ISO C and in C as it is used and implemented in practice, focusing especially on pointer provenance.\nTwo proposals: Tracking provenance via integers and not.\nHighlight some pros and cons and open questions, and illustrate the discussion with a library of test cases.\nIntegrate the provenance semantic with the Cerberus semantics for much of the rest of C.\nAnalyse the changes required and the resulting behaviour for a port of FreeBSD to CHERI.\nA new instrumentation tool to detect possible provenance violations in normal C code, and apply it to some of the SPEC benchmarks.\nCompared with a source-language variant of the twin-allocation LLVM semantics proposal of Lee et al.\nDescribe ongoing interactions with WG14, exploring how the proposals could be incorporated into the ISO standard.\nProblem Memory semantics of C pointers and objects: neither extreme concrete nor extreme abstract model.\n Concrete exterme: exposes the memory semantics of underlying hardware, with memory being simply a finite partial map from machine-word addresses to bytes. Abstract extreme: the language types enforces hard distinctions, e.g. between numberic types that support arithmetic and pointer types that support dereferencing.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/new-pass/",
	"title": "Add New Pass to LLVM pipeline",
	"tags": [],
	"description": "",
	"content": " References:\n Writing LLVM Pass in 2018 \u0026ndash; Part III  Steps  createXXXPass function initializeXXXPass function INITIALIZE_PASS_BEGIN/END/DEPENDENCY code. Put initializeXXXPass in the right place. update LinkAllPasses.h Put createXXXPass in the right place.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-llvm/passes/bound-allocas/",
	"title": "Bound Allocas",
	"tags": [],
	"description": "",
	"content": " References:\n llvm/lib/CodeGen/CheriBoundAllocas.cpp  Overview A Module pass with instruction visitor: class CheriBoundAllocas : public ModulePass, public InstVisitor\u0026lt;CheriBoundAllocas\u0026gt;\nInitialization: initializeCheriBoundAllocaPass()\n declared in llvm/include/llvm/InitializePasses.h impl in llvm/lib/CodeGen/CheriBoundAllocas.cpp: INITIALIZE_PASS(\u0026hellip;) called in:  llvm/lib/CodeGen/CheriBoundAllocas.cpp: CheriBoundAllocas() llvm/lib/CodeGen/CodeGen.cpp: initializeCodeGen() llvm/tools/opt/opt.cpp: main()   Pass Creation: createCheriBoundAllocasPass()\n declared in llvm/include/llvm/CodeGen/Passes.h called in  Mips: llvm/lib/Target/Mips/MipsTargetMachine.cpp: MipsPassConfig::addIRPasses() RISCV: llvm/lib/Target/RISCV/RISCVTargetMachine.cpp: RISCVPassConfig::addIRPasses()   Adding bound instruction:\n Get intrinsic: Intrinsic::getDeclaration(M, Intrinsic::cheri_cap_bounds_set, SizeTy);\n// llvm/lib/CodeGen/CheriBoundAllocas.cpp  // Intrinsic handle as function Function *SetBoundsIntrin = Intrinsic::getDeclaration(M, Intrinsic::cheri_cap_bounds_set, SizeTy); Intrinsic::ID BoundedStackCap = UseRematerializableIntrinsic ? Intrinsic::cheri_bounded_stack_cap : Intrinsic::cheri_cap_bounds_set; Function *BoundedStackFn = Intrinsic::getDeclaration(M, BoundedStackCap, SizeTy); // Use intrinsic to create IR instruction LLVMContext \u0026amp;C = M-\u0026gt;getContext(); IRBuilder\u0026lt;\u0026gt; B(C); // one version // convert to i8 for the intrinsic Instruction *AllocaI8 = cast\u0026lt;Instruction\u0026gt;(B.CreateBitCast(AI, I8CapTy)); Value *SingleBoundedAlloc = B.CreateCall(SetBoundsIntrin, {AllocaI8, Size}); SingleBoundedAlloc = B.CreateBitCast(SingleBoundedAlloc, AllocaTy); // another version auto WithBounds = B.CreateCall(SetBoundsIntrin, {AllocaI8, Size}); const_cast\u0026lt;Use *\u0026gt;(U)-\u0026gt;set(B.CreateBitCast(WithBounds, AllocaTy));   Functions/Steps:\n runOnModule: Iterate over all functions and call runOnFunction runOnFunction:  visit(F) -\u0026gt; visitAllocaInst(): Store All AllocaInst in this function in vector Allocas For every AllocaInst in the function: Set the (AllocaInst + 1) as insertion point, so will be inserted immediately after the alloca. Check the type of AllocaInst, i.e. the type of data being allocated. Check if CHERI has precise bounds (TLI: TargetLowering), and determine the final bounds of the alloca object. Collect a set of Uses of the AllocaInst that needs to be inserted with a Bound instruction.  enum StackBoundsMethod has different modes: Never/AllUses/IfNeeded... class CheriNeedBoundsChecker finds the uses that needs bound check.  If alloca is dynamic alloca (!AI-\u0026gt;isStaticAlloca()): use single intrinsic cheri_cap_bounds_set. If static, use cheri_bounded_stack_cap or cher_cap_bounds_set. For every uses of AllocaInst (I = cast\u0026lt;Instruction\u0026gt;(U-\u0026gt;getUser())):  Check if reuse the result of a single csetbounds intrinsic Reuse only when we are at -O0 or there are more than N users of this bounded stack capability. If reuse the result of a single csetbounds intrinsic:  const_cast\u0026lt;Use *\u0026gt;(U)-\u0026gt;set(SingleBoundedAlloc): Update the user as the user of the SingleBoundedAlloc instruction instead of the AllocaInst.  If not reusing the single intrinsic call: Locate the Insertion point:  If the user instruction is is a PHINode, insert point is the terminator of the incoming basic block corresponding to the User instruction. Otherwise, the insert point is the current user instruction.  Do Insertion of bounding instruction:  Create BitCast Instruction B.CreateBitCast(AI, I8CapTy) Create Call Instruction B.CreateCall(SetBoundsIntrin, {AllocaI8, Size}) Create BitCast Instruction and set the AllocaInst as the user of this BitCast Inst: const_cast\u0026lt;User *\u0026gt;(U)-\u0026gt;set(B.CreateBitCast(WithBounds, AllocaTy))     Summary Check all alloca instructions in a function, insert cheri_cap_bounds_set or cheri_bounded_stack_cap instruction to proper location to set/check the bound of alloca\u0026rsquo;d object.\nIf alloca\u0026rsquo;d object is non-pointer type, convert it to a pointer type, set the bounds, so that it can be checked in CHERI, and convert it back for normal use.\n  CheriBoundAllocas   #include \u0026#34;llvm/ADT/Statistic.h\u0026#34;#include \u0026#34;llvm/ADT/StringSwitch.h\u0026#34;#include \u0026#34;llvm/Analysis/CheriBounds.h\u0026#34;#include \u0026#34;llvm/Analysis/Utils/Local.h\u0026#34;#include \u0026#34;llvm/CodeGen/TargetLowering.h\u0026#34;#include \u0026#34;llvm/CodeGen/TargetPassConfig.h\u0026#34;#include \u0026#34;llvm/CodeGen/TargetSubtargetInfo.h\u0026#34;#include \u0026#34;llvm/InitializePasses.h\u0026#34;#include \u0026#34;llvm/IR/CallSite.h\u0026#34;#include \u0026#34;llvm/IR/Cheri.h\u0026#34;#include \u0026#34;llvm/IR/Constants.h\u0026#34;#include \u0026#34;llvm/IR/DataLayout.h\u0026#34;#include \u0026#34;llvm/IR/DebugInfoMetadata.h\u0026#34;#include \u0026#34;llvm/IR/Function.h\u0026#34;#include \u0026#34;llvm/IR/GlobalVariable.h\u0026#34;#include \u0026#34;llvm/IR/IRBuilder.h\u0026#34;#include \u0026#34;llvm/IR/InstVisitor.h\u0026#34;#include \u0026#34;llvm/IR/Instructions.h\u0026#34;#include \u0026#34;llvm/IR/Intrinsics.h\u0026#34;#include \u0026#34;llvm/IR/LLVMContext.h\u0026#34;#include \u0026#34;llvm/IR/Module.h\u0026#34;#include \u0026#34;llvm/Pass.h\u0026#34;#include \u0026#34;llvm/Target/TargetMachine.h\u0026#34;#include \u0026#34;llvm/Transforms/Utils/CheriSetBounds.h\u0026#34;#include \u0026#34;llvm/Transforms/Utils/Local.h\u0026#34; #include \u0026lt;string\u0026gt;#include \u0026lt;utility\u0026gt;#include \u0026lt;unordered_map\u0026gt; #include \u0026#34;llvm/IR/Verifier.h\u0026#34; #define DEBUG_TYPE \u0026#34;cheri-bound-allocas\u0026#34; using namespace llvm; #define DBG_MESSAGE(...) LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; DEBUG_TYPE \u0026#34;: \u0026#34; \u0026lt;\u0026lt; __VA_ARGS__)  namespace { // TODO: remove this option after eval static cl::opt\u0026lt;bool\u0026gt; UseRematerializableIntrinsic( \u0026#34;cheri-stack-bounds-allow-remat\u0026#34;, cl::init(true), cl::desc(\u0026#34;Use bounded.stack.cap() instead of bounds.set() for stack \u0026#34; \u0026#34;allocations (allows rematerialization)\u0026#34;), cl::Hidden); // Loading/storing from constant stack indices does not need to use a small // tightly bounded capability and can use $csp instead // TODO: remove these options once we know what the best stragegy is? // TODO: change this to an integer threshold (more than N uses -\u0026gt; reuse the same one) static cl::opt\u0026lt;unsigned\u0026gt; SingleIntrinsicThreshold( \u0026#34;cheri-stack-bounds-single-intrinsic-threshold\u0026#34;, cl::init(5), cl::desc(\u0026#34;Reuse the result of a single CHERI bounds intrinsic if there are \u0026#34; \u0026#34;more than N uses (default=5). A value of 0 means always.\u0026#34;), cl::Hidden); // single option instead of the booleans? enum classStackBoundsMethod { Never, ForAllUsesIfOneNeedsBounds, // This is not particularly useful, just for  // comparison  IfNeeded, AllUses, }; static cl::opt\u0026lt;StackBoundsMethod\u0026gt; BoundsSettingMode( \u0026#34;cheri-stack-bounds\u0026#34;, cl::desc(\u0026#34;Strategy for setting bounds on stack capabilities:\u0026#34;), cl::init(StackBoundsMethod::IfNeeded), cl::values(clEnumValN(StackBoundsMethod::Never, \u0026#34;never\u0026#34;, \u0026#34;Do not add bounds on stack allocations (UNSAFE!)\u0026#34;), clEnumValN(StackBoundsMethod::ForAllUsesIfOneNeedsBounds, \u0026#34;all-or-none\u0026#34;, \u0026#34;Set stack allocation bounds for all uses if at \u0026#34; \u0026#34;least one use neededs bounds, otherwise omit\u0026#34;), clEnumValN(StackBoundsMethod::IfNeeded, \u0026#34;if-needed\u0026#34;, \u0026#34;Set stack allocation bounds for all uses except for \u0026#34; \u0026#34;loads/stores to statically known in-bounds offsets\u0026#34;), clEnumValN(StackBoundsMethod::AllUses, \u0026#34;all-uses\u0026#34;, \u0026#34;Set stack allocation bounds even for loads/stores \u0026#34; \u0026#34;to statically known in-bounds offset\u0026#34;))); STATISTIC(NumProcessed, \u0026#34;Number of allocas that were analyzed for CHERI bounds\u0026#34;); STATISTIC(NumDynamicAllocas, \u0026#34;Number of dyanmic allocas that were analyzed\u0026#34;); // TODO: skip them STATISTIC(NumUsesProcessed, \u0026#34;Total number of alloca uses that were analyzed\u0026#34;); STATISTIC(NumCompletelyUnboundedAllocas, \u0026#34;Number of allocas where CHERI bounds were completely unncessary\u0026#34;); STATISTIC(NumUsesWithBounds, \u0026#34;Number of alloca uses that had CHERI bounds added\u0026#34;); STATISTIC(NumUsesWithoutBounds, \u0026#34;Number of alloca uses that did not needed CHERI bounds\u0026#34;); STATISTIC(NumSingleIntrin, \u0026#34;Number of times that a single intrinisic was used instead of per-use\u0026#34;); classCheriBoundAllocas : public ModulePass, public InstVisitor\u0026lt;CheriBoundAllocas\u0026gt; { Module *M; llvm::SmallVector\u0026lt;AllocaInst *, 16\u0026gt; Allocas; Type *I8CapTy; Type *SizeTy; public: static char ID; CheriBoundAllocas() : ModulePass(ID) { initializeCheriBoundAllocasPass(*PassRegistry::getPassRegistry()); } StringRef getPassName() const override { return \u0026#34;CHERI bound stack allocations\u0026#34;; } void visitAllocaInst(AllocaInst \u0026amp;AI) { Allocas.push_back(\u0026amp;AI); } bool runOnModule(Module \u0026amp;Mod) override { M = \u0026amp;Mod; const DataLayout \u0026amp;DL = Mod.getDataLayout(); unsigned AllocaAS = DL.getAllocaAddrSpace(); // Early abort if we aren\u0026#39;t using capabilities on the stack  if (!DL.isFatPointer(AllocaAS)) return false; LLVMContext \u0026amp;C = M-\u0026gt;getContext(); I8CapTy = Type::getInt8PtrTy(C, AllocaAS); SizeTy = Type::getIntNTy(C, DL.getIndexSizeInBits(AllocaAS)); bool Modified = false; for (Function \u0026amp;F : Mod) Modified |= runOnFunction(F); return Modified; } bool runOnFunction(Function \u0026amp;F) { // always set bounds with optnone  bool IsOptNone = F.hasFnAttribute(Attribute::OptimizeNone); // FIXME: should still ignore lifetime-start + lifetime-end intrinsics even at -O0  const TargetPassConfig \u0026amp;TPC = getAnalysis\u0026lt;TargetPassConfig\u0026gt;(); const TargetMachine \u0026amp;TM = TPC.getTM\u0026lt;TargetMachine\u0026gt;(); const TargetLowering *TLI = TM.getSubtargetImpl(F)-\u0026gt;getTargetLowering(); LLVMContext \u0026amp;C = M-\u0026gt;getContext(); Allocas.clear(); visit(F); // Give up if this function has no allocas  if (Allocas.empty()) return false; LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;\\nChecking function \u0026#34; \u0026lt;\u0026lt; F.getName() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;); // TODO: csetboundsexact and round up sizes  // Keep around the non-rematerializable cheri_cap_bounds_set code path to  // compare how much rematerialization can help  Intrinsic::ID BoundedStackCap = UseRematerializableIntrinsic ? Intrinsic::cheri_bounded_stack_cap : Intrinsic::cheri_cap_bounds_set; const DataLayout \u0026amp;DL = M-\u0026gt;getDataLayout(); Function *BoundedStackFn = Intrinsic::getDeclaration(M, BoundedStackCap, SizeTy); StackBoundsMethod BoundsMode = BoundsSettingMode; IRBuilder\u0026lt;\u0026gt; B(C); for (AllocaInst *AI : Allocas) { const uint64_t TotalUses = AI-\u0026gt;getNumUses(); NumProcessed++; Function *SetBoundsIntrin = BoundedStackFn; // Insert immediately after the alloca  B.SetInsertPoint(AI); B.SetInsertPoint(\u0026amp;*++B.GetInsertPoint()); Align ForcedAlignment; PointerType *AllocaTy = AI-\u0026gt;getType(); assert(isCheriPointer(AllocaTy, \u0026amp;DL)); Type *AllocationTy = AllocaTy-\u0026gt;getElementType(); Value *ArraySize = AI-\u0026gt;getArraySize(); // Create a new (AS 0) alloca  // For imprecise capabilities, we need to increase the alignment for  // on-stack allocations to ensure that we can create precise bounds.  if (!TLI-\u0026gt;cheriCapabilityTypeHasPreciseBounds()) { // If not a constant then definitely a DYNAMIC_STACKALLOC; alignment  // requirements will be added later during legalisation.  if (ConstantInt *CI = dyn_cast\u0026lt;ConstantInt\u0026gt;(ArraySize)) { uint64_t AllocaSize = DL.getTypeAllocSize(AllocationTy); AllocaSize *= CI-\u0026gt;getValue().getLimitedValue(); ForcedAlignment = TLI-\u0026gt;getAlignmentForPreciseBounds(AllocaSize); } } AI-\u0026gt;setAlignment(max(MaybeAlign(AI-\u0026gt;getAlignment()), ForcedAlignment)); // Only set bounds for allocas that escape this function  bool NeedBounds = true; // Always set bounds if the function has the optnone attribute  SmallVector\u0026lt;const Use *, 32\u0026gt; UsesThatNeedBounds; // If one of the bounded alloca users is a PHI we must reuse the single  // intrinsic since PHIs must be the first instruction in the basic block  // and we can\u0026#39;t insert anything before. Theoretically we could still  // use separate intrinsics for the other users but if we are already  // saving a bounded stack slot we might as well reuse it.  bool MustUseSingleIntrinsic = false; if (BoundsMode == StackBoundsMethod::Never) { NeedBounds = false; } else { CheriNeedBoundsChecker BoundsChecker(AI, DL); // With -O0 or =always we set bounds on every stack allocation even  // if it is not necessary  bool BoundAll = IsOptNone || BoundsMode == StackBoundsMethod::AllUses; BoundsChecker.findUsesThatNeedBounds(\u0026amp;UsesThatNeedBounds, BoundAll, \u0026amp;MustUseSingleIntrinsic); NeedBounds = !UsesThatNeedBounds.empty(); NumUsesProcessed += TotalUses; DBG_MESSAGE(F.getName() \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; UsesThatNeedBounds.size() \u0026lt;\u0026lt; \u0026#34; of \u0026#34; \u0026lt;\u0026lt; TotalUses \u0026lt;\u0026lt; \u0026#34; users need bounds for \u0026#34;; AI-\u0026gt;dump()); // TODO: remove the all-or-nothing case  if (NeedBounds \u0026amp;\u0026amp; BoundsMode == StackBoundsMethod::ForAllUsesIfOneNeedsBounds) { // We are compiling with the all-or-nothing case and found at least  // one use that needs bounds -\u0026gt; set bounds on all uses  UsesThatNeedBounds.clear(); LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;Checking if alloca needs bounds: \u0026#34;; AI-\u0026gt;dump()); BoundsChecker.findUsesThatNeedBounds(\u0026amp;UsesThatNeedBounds, /*BoundAllUses=*/true, \u0026amp;MustUseSingleIntrinsic); } } if (!NeedBounds) { NumCompletelyUnboundedAllocas++; DBG_MESSAGE(\u0026#34;No need to set bounds on stack alloca\u0026#34;; AI-\u0026gt;dump()); continue; } if (!AI-\u0026gt;isStaticAlloca()) { NumDynamicAllocas++; // TODO: skip bounds on dynamic allocas (maybe add a TLI hook to check  // whether the backend already adds bounds to the dynamic_stackalloc)  DBG_MESSAGE(\u0026#34;Found dynamic alloca: must use single intrinisic and \u0026#34; \u0026#34;bounds.set intrinisic\u0026#34;); MustUseSingleIntrinsic = true; SetBoundsIntrin = Intrinsic::getDeclaration(M, Intrinsic::cheri_cap_bounds_set, SizeTy); } // Reuse the result of a single csetbounds intrinisic if we are at -O0 or  // there are more than N users of this bounded stack capability.  const bool ReuseSingleIntrinsicCall = MustUseSingleIntrinsic || IsOptNone || UsesThatNeedBounds.size() \u0026gt;= SingleIntrinsicThreshold; NumUsesWithBounds += UsesThatNeedBounds.size(); NumUsesWithoutBounds += TotalUses - UsesThatNeedBounds.size(); // Get the size of the alloca  unsigned ElementSize = DL.getTypeAllocSize(AllocationTy); Value *Size = ConstantInt::get(SizeTy, ElementSize); if (AI-\u0026gt;isArrayAllocation()) Size = B.CreateMul(Size, AI-\u0026gt;getArraySize()); if (AI-\u0026gt;isStaticAlloca() \u0026amp;\u0026amp; ForcedAlignment != Align()) { // Pad to ensure bounds don\u0026#39;t overlap adjacent objects  uint64_t AllocaSize = cast\u0026lt;ConstantInt\u0026gt;(Size)-\u0026gt;getValue().getLimitedValue(); TailPaddingAmount TailPadding = TLI-\u0026gt;getTailPaddingForPreciseBounds(AllocaSize); if (TailPadding != TailPaddingAmount::None) { Type *AllocatedType = AI-\u0026gt;isArrayAllocation() ? ArrayType::get( AI-\u0026gt;getAllocatedType(), cast\u0026lt;ConstantInt\u0026gt;(AI-\u0026gt;getArraySize())-\u0026gt;getZExtValue()) : AI-\u0026gt;getAllocatedType(); Type *PaddingType = ArrayType::get(Type::getInt8Ty(F.getContext()), static_cast\u0026lt;uint64_t\u0026gt;(TailPadding)); Type *TypeWithPadding = StructType::get(AllocatedType, PaddingType); auto *NewAI = new AllocaInst(TypeWithPadding, AI-\u0026gt;getType()-\u0026gt;getAddressSpace(), nullptr, \u0026#34;\u0026#34;, AI); NewAI-\u0026gt;takeName(AI); NewAI-\u0026gt;setAlignment(MaybeAlign(AI-\u0026gt;getAlignment())); NewAI-\u0026gt;setUsedWithInAlloca(AI-\u0026gt;isUsedWithInAlloca()); NewAI-\u0026gt;setSwiftError(AI-\u0026gt;isSwiftError()); NewAI-\u0026gt;copyMetadata(*AI); auto *NewPtr = new BitCastInst(NewAI, AI-\u0026gt;getType(), \u0026#34;\u0026#34;, AI); AI-\u0026gt;replaceAllUsesWith(NewPtr); AI-\u0026gt;eraseFromParent(); AI = NewAI; Size = ConstantInt::get(SizeTy, AllocaSize + static_cast\u0026lt;uint64_t\u0026gt;(TailPadding)); } } if (cheri::ShouldCollectCSetBoundsStats) { cheri::addSetBoundsStats( AI-\u0026gt;getAlign().valueOrOne(), Size, getPassName(), cheri::SetBoundsPointerSource::Stack, \u0026#34;set bounds on \u0026#34; + cheri::inferLocalVariableName(AI), cheri::inferSourceLocation(AI)); } LLVM_DEBUG(auto S = cheri::inferConstantValue(Size); dbgs() \u0026lt;\u0026lt; AI-\u0026gt;getFunction()-\u0026gt;getName() \u0026lt;\u0026lt; \u0026#34;: setting bounds on stack alloca to \u0026#34; \u0026lt;\u0026lt; (S ? Twine(*S) : Twine(\u0026#34;\u0026lt;unknown\u0026gt;\u0026#34;)); AI-\u0026gt;dump()); Value *SingleBoundedAlloc = nullptr; if (ReuseSingleIntrinsicCall) { NumSingleIntrin++; // We need to convert it to an i8* for the intrinisic:  Instruction *AllocaI8 = cast\u0026lt;Instruction\u0026gt;(B.CreateBitCast(AI, I8CapTy)); SingleBoundedAlloc = B.CreateCall(SetBoundsIntrin, {AllocaI8, Size}); SingleBoundedAlloc = B.CreateBitCast(SingleBoundedAlloc, AllocaTy); } for (const Use *U : UsesThatNeedBounds) { Instruction *I = cast\u0026lt;Instruction\u0026gt;(U-\u0026gt;getUser()); if (ReuseSingleIntrinsicCall) { const_cast\u0026lt;Use *\u0026gt;(U)-\u0026gt;set(SingleBoundedAlloc); } else { if (auto PHI = dyn_cast\u0026lt;PHINode\u0026gt;(I)) { // For PHI nodes we can\u0026#39;t insert just before the PHI, instead we  // must insert it just before  auto BB = PHI-\u0026gt;getIncomingBlock(*U); // LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;PHI use coming from\u0026#34;; BB-\u0026gt;dump());  B.SetInsertPoint(BB-\u0026gt;getTerminator()); } else { // insert a new intrinsic call before every use. This can avoid  // stack spills but will result in additional instructions.  // This should avoid spilling registers when using an alloca in a  // different basic block.  // TODO: there should be a MIR pass to merge unncessary calls  B.SetInsertPoint(I); } // We need to convert it to an i8* for the intrinisic. Note: we must  // not reuse a bitcast since otherwise that results in spilling the  // register that was incremented and doing a setbounds in a different  // basic block. This is stupid and we should be either using the  // bounded capability everywhere or be doing inc+setoffset in the  // other block.  Instruction *AllocaI8 = cast\u0026lt;Instruction\u0026gt;(B.CreateBitCast(AI, I8CapTy)); auto WithBounds = B.CreateCall(SetBoundsIntrin, {AllocaI8, Size}); const_cast\u0026lt;Use *\u0026gt;(U)-\u0026gt;set(B.CreateBitCast(WithBounds, AllocaTy)); } } } return true; } void getAnalysisUsage(AnalysisUsage \u0026amp;AU) const override { AU.addRequired\u0026lt;TargetPassConfig\u0026gt;(); AU.setPreservesCFG(); } }; } // anonymous namespace  char CheriBoundAllocas::ID; INITIALIZE_PASS(CheriBoundAllocas, DEBUG_TYPE, \u0026#34;CHERI add bounds to alloca instructions\u0026#34;, false, false) ModulePass *llvm::createCheriBoundAllocasPass(void) { return new CheriBoundAllocas(); }    More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/table-gen/",
	"title": "Table Gen",
	"tags": [],
	"description": "",
	"content": " References:\n TableGen Overview TableGen Programmer\u0026rsquo;s Reference TableGen Backend Developer\u0026rsquo;s Guide  ####\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/control-flow/ucfi/",
	"title": "uCFI",
	"tags": [],
	"description": "",
	"content": " References:\n Enforcing Unique Code Target Property for Control-Flow Integrity, CCS\u0026rsquo;18  UCT: Unique Code Target\nICT: Indirect Control-flow Transfer\nKey: collecting the necessary runtime information and using it to augment the points-to analysis on control data.\nContraining data: the data helps to determine the target of indirect calls.\n How to identify the constraining data? How to collect this data efficiently? How to perform the points-to analysis efficiently and accurately?  Identify constraining data  Static data-flow analysis to accurately identify contraining daa from the program source code.  Starts from code pointers Recursively identifies variables that are involved in calculating known constraining data.  A novel arbitrary data collection technique to record all constraining data as indirect control-flow transfers, and rely on a hardware feature for efficient recording. A monitor runs in parallel with the program execution.  Algorithms    More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/control-flow/",
	"title": "Control Flow",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  uCFI  References: Enforcing Unique Code Target Property for Control-Flow Integrity, CCS\u0026rsquo;18 UCT: Unique Code Target ICT: Indirect Control-flow Transfer Key: collecting the necessary runtime information and using it to augment the points-to analysis on control data. Contraining data: the data helps to determine the target of indirect calls. How to identify the constraining data? How to collect this data efficiently? How to perform the points-to analysis efficiently and accurately?\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/translate/ccall/",
	"title": "CCall",
	"tags": [],
	"description": "",
	"content": " References:\n target/mips/translate.c\n// target/mips/translate.c mips_tr_translate_insn() --\u0026gt; gen_branch() // is_slot  decode_opc() --\u0026gt; gen_compute_compact_branch() --\u0026gt; gen_branch() // bcond_compute == 0  --\u0026gt; gen_helper_copy_cap_btarget_to_pcc(cpu_env) // MIPS_HFLAG_BRCCALL/MIPS_HFLAG_BRC  --\u0026gt; CHERI_HELPER_IMPL(copy_cap_btarget_to_pcc(CPUArchState *env))   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/translate/",
	"title": "Translate",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  CCall   References: target/mips/translate.c // target/mips/translate.c mips_tr_translate_insn() --\u0026gt; gen_branch() // is_slot decode_opc() --\u0026gt; gen_compute_compact_branch() --\u0026gt; gen_branch() // bcond_compute == 0 --\u0026gt; gen_helper_copy_cap_btarget_to_pcc(cpu_env) // MIPS_HFLAG_BRCCALL/MIPS_HFLAG_BRC --\u0026gt; CHERI_HELPER_IMPL(copy_cap_btarget_to_pcc(CPUArchState *env)) More  Syscall   References: target/mips/translate.c mips_tr_translate_insn() --\u0026gt; decode_opc() // !(ctx-\u0026gt;hflags \u0026amp; MIPS_HFLAG_M16) --\u0026gt; decode_opc_special() --\u0026gt; generate_exception_end(ctx, EXCP_SYSCALL) generate_exception_end() -\u0026gt; generate_exception_err() // target/mips/translate.c // generate_exception_end(ctx, EXCP_SYSCALL) --\u0026gt; generate_exception_err(ctx, excp, 0) static inline void generate_exception_err(DisasContext *ctx, MipsExcp excp, int err) { TCGv_i32 texcp = tcg_const_i32(excp); TCGv_i32 terr = tcg_const_i32(err); save_cpu_state(ctx, 1); gen_helper_raise_exception_err(cpu_env, texcp, terr); tcg_temp_free_i32(terr); tcg_temp_free_i32(texcp); ctx-\u0026gt;base.is_jmp = DISAS_NORETURN; } More  Branch Insts  Tracking the implementation of branch instructions in MIPS target. References: target/mips/translate.c Branches is translated in function gen_compute_branch: gen_compute_branch // target/mips/translate.c /* Branches (before delay slot) */ static void gen_compute_branch(DisasContext *ctx, uint32_t opc, int insn_bytes, int rs, int rt, int32_t offset, int delayslot_size) { target_ulong btgt = -1; int blink = 0; int bcond_compute = 0; TCGv t0 = tcg_temp_new(); TCGv t1 = tcg_temp_new(); // Note: For CHERI btgt is an absolute address not an offset relative // to PCC.\n QEMU impl for Legacy Load and Store Inst  Q\u0026amp;A Where is the DDC check during legacy ld/st? Reference reference check_cap Who call it? target_ulong check_ddc(CPUArchState *env, uint32_t perm, uint64_t ddc_offset, uint32_t len, uintptr_t retpc) void CHERI_HELPER_IMPL(ddc_check_bounds(CPUArchState *env, target_ulong addr, target_ulong num_bytes)) target_ulong CHERI_HELPER_IMPL(pcc_check_load(CPUArchState *env, target_ulong pcc_offset, MemOp op)) void CHERI_HELPER_IMPL(raise_exception_ddc_perms(CPUArchState *env, uint32_t required_perms)) void CHERI_HELPER_IMPL(raise_exception_ddc_bounds(CPUArchState *env, target_ulong addr, uint32_t num_bytes)) void CHERI_HELPER_IMPL(ccheck_load_pcrel(CPUArchState *env, target_ulong addr, uint32_t len)) ddc_check_bounds ddc_check_bounds caller _generate_ddc_checked_ptr, and upper callers:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/translate/syscall/",
	"title": "Syscall",
	"tags": [],
	"description": "",
	"content": " References:\n target/mips/translate.c\nmips_tr_translate_insn() --\u0026gt; decode_opc() // !(ctx-\u0026gt;hflags \u0026amp; MIPS_HFLAG_M16) --\u0026gt; decode_opc_special() --\u0026gt; generate_exception_end(ctx, EXCP_SYSCALL)   generate_exception_end() -\u0026gt; generate_exception_err()\n// target/mips/translate.c  // generate_exception_end(ctx, EXCP_SYSCALL) --\u0026gt; generate_exception_err(ctx, excp, 0)  static inline void generate_exception_err(DisasContext *ctx, MipsExcp excp, int err) { TCGv_i32 texcp = tcg_const_i32(excp); TCGv_i32 terr = tcg_const_i32(err); save_cpu_state(ctx, 1); gen_helper_raise_exception_err(cpu_env, texcp, terr); tcg_temp_free_i32(terr); tcg_temp_free_i32(texcp); ctx-\u0026gt;base.is_jmp = DISAS_NORETURN; }  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/translate/branch-insts/",
	"title": "Branch Insts",
	"tags": [],
	"description": "",
	"content": " Tracking the implementation of branch instructions in MIPS target.\nReferences:\n target/mips/translate.c  Branches is translated in function gen_compute_branch:\n  gen_compute_branch   // target/mips/translate.c  /* Branches (before delay slot) */ static void gen_compute_branch(DisasContext *ctx, uint32_t opc, int insn_bytes, int rs, int rt, int32_t offset, int delayslot_size) { target_ulong btgt = -1; int blink = 0; int bcond_compute = 0; TCGv t0 = tcg_temp_new(); TCGv t1 = tcg_temp_new(); // Note: For CHERI btgt is an absolute address not an offset relative  // to PCC.base. #if defined(TARGET_CHERI)  bool btarget_checked = false; // Some debug assertions to ensure all branch cases are bounds checked #define SET_BTARGET_CHECKED(value) \\ do { tcg_debug_assert(!btarget_checked); btarget_checked = value; } while (false) #else #define SET_BTARGET_CHECKED(value) #endif // defined(TARGET_CHERI)  if (ctx-\u0026gt;hflags \u0026amp; MIPS_HFLAG_BMASK) { #ifdef MIPS_DEBUG_DISAS  LOG_DISAS(\u0026#34;Branch in delay / forbidden slot at PC 0x\u0026#34; TARGET_FMT_lx \u0026#34;\\n\u0026#34;, ctx-\u0026gt;base.pc_next); #endif  generate_exception_end(ctx, EXCP_RI); SET_BTARGET_CHECKED(true); // exception raised -\u0026gt; no need to check  goto out; } /* Load needed operands */ switch (opc) { case OPC_BEQ: case OPC_BEQL: case OPC_BNE: case OPC_BNEL: /* Compare two registers */ if (rs != rt) { gen_load_gpr(t0, rs); gen_load_gpr(t1, rt); bcond_compute = 1; } btgt = ctx-\u0026gt;base.pc_next + insn_bytes + offset; break; case OPC_BGEZ: case OPC_BGEZAL: case OPC_BGEZALL: case OPC_BGEZL: case OPC_BGTZ: case OPC_BGTZL: case OPC_BLEZ: case OPC_BLEZL: case OPC_BLTZ: case OPC_BLTZAL: case OPC_BLTZALL: case OPC_BLTZL: /* Compare to zero */ if (rs != 0) { gen_load_gpr(t0, rs); bcond_compute = 1; } btgt = ctx-\u0026gt;base.pc_next + insn_bytes + offset; break; case OPC_BPOSGE32: #if defined(TARGET_MIPS64)  case OPC_BPOSGE64: tcg_gen_andi_tl(t0, cpu_dspctrl, 0x7F); #else  tcg_gen_andi_tl(t0, cpu_dspctrl, 0x3F); #endif  bcond_compute = 1; btgt = ctx-\u0026gt;base.pc_next + insn_bytes + offset; break; case OPC_J: case OPC_JAL: #ifndef TARGET_CHERI  case OPC_JALX: #endif  /* Jump to immediate (taking PCC.base into account) */ btgt = (((ctx-\u0026gt;base.pc_next + insn_bytes - pcc_base(ctx)) \u0026amp; (int32_t)0xF0000000) | (uint32_t)offset) + pcc_base(ctx); break; case OPC_JR: case OPC_JALR: /* Jump to register */ if (offset != 0 \u0026amp;\u0026amp; offset != 16) { /* * Hint = 0 is JR/JALR, hint 16 is JR.HB/JALR.HB, the * others are reserved. */ MIPS_INVAL(\u0026#34;jump hint\u0026#34;); generate_exception_end(ctx, EXCP_RI); SET_BTARGET_CHECKED(true); // exception raised -\u0026gt; no need to check  goto out; } gen_load_gpr(btarget, rs); #ifdef TARGET_CHERI  /* Add PCC.base to rs (jr/jalr is relative to PCC) */ tcg_gen_addi_tl(btarget, btarget, ctx-\u0026gt;base.pcc_base); #endif /* TARGET_CHERI */ gen_check_branch_target_dynamic(ctx, btarget); SET_BTARGET_CHECKED(true); break; default: MIPS_INVAL(\u0026#34;branch/jump\u0026#34;); generate_exception_end(ctx, EXCP_RI); SET_BTARGET_CHECKED(true); // exception raised -\u0026gt; no need to check  goto out; } if (bcond_compute == 0) { /* No condition to be computed */ switch (opc) { case OPC_BEQ: /* rx == rx */ case OPC_BEQL: /* rx == rx likely */ case OPC_BGEZ: /* 0 \u0026gt;= 0 */ case OPC_BGEZL: /* 0 \u0026gt;= 0 likely */ case OPC_BLEZ: /* 0 \u0026lt;= 0 */ case OPC_BLEZL: /* 0 \u0026lt;= 0 likely */ /* Always take */ ctx-\u0026gt;hflags |= MIPS_HFLAG_B; break; case OPC_BGEZAL: /* 0 \u0026gt;= 0 */ case OPC_BGEZALL: /* 0 \u0026gt;= 0 likely */ /* Always take and link */ blink = 31; ctx-\u0026gt;hflags |= MIPS_HFLAG_B; break; case OPC_BNE: /* rx != rx */ case OPC_BGTZ: /* 0 \u0026gt; 0 */ case OPC_BLTZ: /* 0 \u0026lt; 0 */ /* Treat as NOP. */ SET_BTARGET_CHECKED(true); // not taken -\u0026gt; no need to check  goto out; case OPC_BLTZAL: /* 0 \u0026lt; 0 */ /* * Handle as an unconditional branch to get correct delay * slot checking. */ blink = 31; btgt = ctx-\u0026gt;base.pc_next + insn_bytes + delayslot_size; ctx-\u0026gt;hflags |= MIPS_HFLAG_B; break; case OPC_BLTZALL: /* 0 \u0026lt; 0 likely */ /* For CHERI, we have to subtract PCC.base from r31 */ tcg_gen_movi_tl(cpu_gpr[31], ctx-\u0026gt;base.pc_next + 8 - pcc_base(ctx)); gen_log_instr_gpr_update(ctx, 31); /* Skip the instruction in the delay slot */ ctx-\u0026gt;base.pc_next += 4; SET_BTARGET_CHECKED(true); // not taken -\u0026gt; no need to check  goto out; case OPC_BNEL: /* rx != rx likely */ case OPC_BGTZL: /* 0 \u0026gt; 0 likely */ case OPC_BLTZL: /* 0 \u0026lt; 0 likely */ /* Skip the instruction in the delay slot */ ctx-\u0026gt;base.pc_next += 4; SET_BTARGET_CHECKED(true); // not taken -\u0026gt; no need to check  goto out; case OPC_J: ctx-\u0026gt;hflags |= MIPS_HFLAG_B; break; #ifndef TARGET_CHERI  case OPC_JALX: ctx-\u0026gt;hflags |= MIPS_HFLAG_BX; /* Fallthrough */ #endif  case OPC_JAL: blink = 31; ctx-\u0026gt;hflags |= MIPS_HFLAG_B; break; case OPC_JR: ctx-\u0026gt;hflags |= MIPS_HFLAG_BR; break; case OPC_JALR: blink = rt; ctx-\u0026gt;hflags |= MIPS_HFLAG_BR; break; default: MIPS_INVAL(\u0026#34;branch/jump\u0026#34;); generate_exception_end(ctx, EXCP_RI); SET_BTARGET_CHECKED(true); // exception raised -\u0026gt; no need to check  goto out; } } else { switch (opc) { case OPC_BEQ: tcg_gen_setcond_tl(TCG_COND_EQ, bcond, t0, t1); goto not_likely; case OPC_BEQL: tcg_gen_setcond_tl(TCG_COND_EQ, bcond, t0, t1); goto likely; case OPC_BNE: tcg_gen_setcond_tl(TCG_COND_NE, bcond, t0, t1); goto not_likely; case OPC_BNEL: tcg_gen_setcond_tl(TCG_COND_NE, bcond, t0, t1); goto likely; case OPC_BGEZ: tcg_gen_setcondi_tl(TCG_COND_GE, bcond, t0, 0); goto not_likely; case OPC_BGEZL: tcg_gen_setcondi_tl(TCG_COND_GE, bcond, t0, 0); goto likely; case OPC_BGEZAL: tcg_gen_setcondi_tl(TCG_COND_GE, bcond, t0, 0); blink = 31; goto not_likely; case OPC_BGEZALL: tcg_gen_setcondi_tl(TCG_COND_GE, bcond, t0, 0); blink = 31; goto likely; case OPC_BGTZ: tcg_gen_setcondi_tl(TCG_COND_GT, bcond, t0, 0); goto not_likely; case OPC_BGTZL: tcg_gen_setcondi_tl(TCG_COND_GT, bcond, t0, 0); goto likely; case OPC_BLEZ: tcg_gen_setcondi_tl(TCG_COND_LE, bcond, t0, 0); goto not_likely; case OPC_BLEZL: tcg_gen_setcondi_tl(TCG_COND_LE, bcond, t0, 0); goto likely; case OPC_BLTZ: tcg_gen_setcondi_tl(TCG_COND_LT, bcond, t0, 0); goto not_likely; case OPC_BLTZL: tcg_gen_setcondi_tl(TCG_COND_LT, bcond, t0, 0); goto likely; case OPC_BPOSGE32: tcg_gen_setcondi_tl(TCG_COND_GE, bcond, t0, 32); goto not_likely; #if defined(TARGET_MIPS64)  case OPC_BPOSGE64: tcg_gen_setcondi_tl(TCG_COND_GE, bcond, t0, 64); goto not_likely; #endif  case OPC_BLTZAL: tcg_gen_setcondi_tl(TCG_COND_LT, bcond, t0, 0); blink = 31; not_likely: ctx-\u0026gt;hflags |= MIPS_HFLAG_BC; break; case OPC_BLTZALL: tcg_gen_setcondi_tl(TCG_COND_LT, bcond, t0, 0); blink = 31; likely: ctx-\u0026gt;hflags |= MIPS_HFLAG_BL; break; default: MIPS_INVAL(\u0026#34;conditional branch/jump\u0026#34;); generate_exception_end(ctx, EXCP_RI); SET_BTARGET_CHECKED(true); // not taken -\u0026gt; no need to check  goto out; } } ctx-\u0026gt;btarget = btgt; #ifdef TARGET_CHERI  if (bcond_compute) { // Check that the conditional branch target is in range (but only if the branch is taken)  tcg_debug_assert(btgt != -1 \u0026amp;\u0026amp; \u0026#34;btgt should have been set!\u0026#34;); gen_check_cond_branch_target(ctx, bcond, btgt); SET_BTARGET_CHECKED(true); } else if (!btarget_checked) { tcg_debug_assert(btgt != -1 \u0026amp;\u0026amp; \u0026#34;btgt should have been set!\u0026#34;); gen_check_branch_target(ctx, btgt); SET_BTARGET_CHECKED(true); } #endif  switch (delayslot_size) { case 2: ctx-\u0026gt;hflags |= MIPS_HFLAG_BDS16; break; case 4: ctx-\u0026gt;hflags |= MIPS_HFLAG_BDS32; break; } if (blink \u0026gt; 0) { int post_delay = insn_bytes + delayslot_size; int lowbit = !!(ctx-\u0026gt;hflags \u0026amp; MIPS_HFLAG_M16); tcg_gen_movi_tl(cpu_gpr[blink], /* Subtract PCC.base from r[blink] */ ctx-\u0026gt;base.pc_next + post_delay + lowbit - pcc_base(ctx)); gen_log_instr_gpr_update(ctx, blink); } out: if (insn_bytes == 2) { ctx-\u0026gt;hflags |= MIPS_HFLAG_B16; } tcg_temp_free(t0); tcg_temp_free(t1); #ifdef TARGET_CHERI  tcg_debug_assert(btarget_checked); #endif  }    Call path:\n// target/mips/translate.c  mips_tr_translate_insn() --\u0026gt; decode_opc() // !(ctx-\u0026gt;hflags \u0026amp; MIPS_HFLAG_M16)  --\u0026gt; gen_compute_branch() // OPC_{BGEZ, BLTZAL, BGEZAL, BPOSGE64, JAL, BLEZC, BGTZC, BLEZALC, BGTZALC, BEQ, BNE, BC1EQZ, BC1NEZ, BC1, ...}  --\u0026gt; decode_opc_special() --\u0026gt; gen_compute_branch() // OPC_JALR  --\u0026gt; decode_opc_special_tx79() // default: INSN_R5900  --\u0026gt; gen_compute_branch() --\u0026gt; decode_opc_special_legacy() // default: else  --\u0026gt; gen_compute_branch() --\u0026gt; decode_micromips_opc() // ctx-\u0026gt;insn_flags \u0026amp; ASE_MICROMIPS  --\u0026gt; decode_micromips32_opc() --\u0026gt; gen_compute_branch() // POOL32I -\u0026gt; BLTZ/BLTZAL/BLTZALS/BGEZ/BGEZAL/...  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/debug-info/diexpr/",
	"title": "DIExpression",
	"tags": [],
	"description": "",
	"content": " References:\n LLVM langRef \u0026ndash; DIExpression  DIExpression nodes: expressions that are inspired by the DWARF expression language. Used to describe how the referenced LLVM variable relates to the source language variable.\nDebug intrinsics are interpreted left-to-right: start by pushing the value/address operand of the intrinsic onto a stack, then repeatedly push and evaluate opcodes from the DIExpression until the final variable description is produced.\nExample opcodes:\n DW_OP_deref: deferences the top of the expression stack; DW_OP_plus: pops the last two entries from the expression stack, adds them together and appends the result to the expression stack. \u0026hellip;  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/debug-info/",
	"title": "Debug Info",
	"tags": [],
	"description": "",
	"content": " References:\n Source Level Debugging with LLVM  Debugger Intrinsic Functions LLVM uses several intrinsic functions (name prefixed with \u0026ldquo;llvm.dbg\u0026rdquo;) to track source local variables through optimization and code generation.\n void @llvm.dbg.addr(metadata, metadata, metadata). Information about a local element (e.g., variable)  first argument is metadata holding the address of the variable, typically a static alloca in the function entry block. Second argument is a local variable containing a description of the variable. Third argument is an expression DIExpression.  void @llvm.dbg.declare(metadata, metadata, metadata). identical to llvm.dbg.addr, except that there can only be one call to llvm.dbg.declare for a given concrete local variable.  The debug location is not control-dependent. That means that if a call to llvm.dbg.declare exists and has a valid location argument, that address is considered to be the true home of the variable across the entire lifetime.  void @llvm.dbg.value(metadata, metadata, metadata). Provides information when a user source variable is set to a new value. Describes the value of a source variable directly, not its address.  First argument is the new value (Wrapped as metadata). Second argument is a local variable containing a description of the variable. Third argument is a DIExpression.   Object lifetimes and scoping Reference:\n Source Level Debugging - Object Lifetimes and Scoping  More  DIExpression  References: LLVM langRef \u0026ndash; DIExpression DIExpression nodes: expressions that are inspired by the DWARF expression language. Used to describe how the referenced LLVM variable relates to the source language variable. Debug intrinsics are interpreted left-to-right: start by pushing the value/address operand of the intrinsic onto a stack, then repeatedly push and evaluate opcodes from the DIExpression until the final variable description is produced. Example opcodes: DW_OP_deref: deferences the top of the expression stack; DW_OP_plus: pops the last two entries from the expression stack, adds them together and appends the result to the expression stack.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/call-conv/syscall/",
	"title": "Syscall",
	"tags": [],
	"description": "",
	"content": " References:\n The Definitive Guide to Linux System Calls FreeBSD - System Calls FreeBSD - Alternate Calling Convention  X86-32 (i386)\n %eax for syscall number %ebx, %ecx, %edx, %esi, %edi, %ebp are used for passing 6 parameters to system calls. if there are more than six arguments, %ebx must contain the memory location where the list of arguments is stored.  FreeBSD System Calls By default, FreeBSD kernel uses the C calling convention.\nIt is assumed the program will call a function that issues int 80h, rather than issuing int80h directly.\nkernel: int\t80h\t; Call kernel \tret open: push\tdword mode push\tdword flags push\tdword path mov\teax, 5 call\tkernel add\tesp, byte 12 retopen: push\tdword mode push\tdword flags push\tdword path mov\teax, 5 push\teax\t; Or any other dword \tint\t80h add\tesp, byte 16 More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/call-conv/riscv-call/",
	"title": "Riscv Call",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/call-conv/mips-call/",
	"title": "Mips Call",
	"tags": [],
	"description": "",
	"content": " References:\n [llvm/lib/Target/Mips/Mips16ISelLowering.h] [llvm/lib/Target/Mips/Mips16ISelLowering.cpp] [llvm/lib/Target/Mips/MipsCallingConv.td] [llvm/lib/Target/Mips/MipsCallLowering.cpp] [llvm/lib/Target/Mips/MipsCCState.h] [llvm/lib/Target/Mips/MipsCCState.cpp] [llvm/lib/Target/Mips/MipsISelLowering.h] [llvm/lib/Target/Mips/MipsISelLowering.cpp]  MipsCallingConv.td More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/pointer-ana/undecidability/",
	"title": "Undecidability",
	"tags": [],
	"description": "",
	"content": " References:\n Pointer Analysis The undecidability of aliasing  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/basics/escape-capture/",
	"title": "Escape Capture",
	"tags": [],
	"description": "",
	"content": " References:\n Escape Analysis \u0026amp; Capture Tracking in LLVM  Pointer Capture: A pointer value is captured if the function makes a copy of any part of the pointer that outlives the call.\nPinter Escape: A pointer value escapes if it is accessible from outside the current function or thread. The latter case is sometimes considered separate and called thread-escape.\nCapture and Escape are not opposites: Informally, escaping is concerned with the contents of the pointer, while capturing is concerned with the pointer itself 1.\nExamples:\nint f(void* p) { return ((unsigned long)p \u0026amp; 15) == 0; }  Function f returns whether a given pointer p is aligned on a 16-byte boundary. This function captures pointer p but does not cause its value to escape.\n\u0026ldquo;The goal of knowing whether a pointer is captured or escaped, is providing the compiler to correctly change the address or content respectively of a pointer\u0026rdquo;.\nCapture tracking in LLVM More   ?? ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/tools/regression-tests/cheri/",
	"title": "Cheri",
	"tags": [],
	"description": "",
	"content": " References:\n reference\n# llvm/utils/lit/lit/llvm/config.py tool_substitutions = [ # CHERI substitutions (order is important due to repeated substitutions!) ToolSubst(\u0026#39;%cheri_purecap_cc1\u0026#39;, command=\u0026#39;%cheri_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%cheri128_purecap_cc1\u0026#39;, command=\u0026#39;%cheri128_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%cheri256_purecap_cc1\u0026#39;, command=\u0026#39;%cheri256_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%cheri_cc1\u0026#39;, command=self.config.clang, extra_args=cheri_cc1_args+additional_flags), ToolSubst(\u0026#39;%cheri128_cc1\u0026#39;, command=self.config.clang, extra_args=cheri128_cc1_args+additional_flags), ToolSubst(\u0026#39;%cheri256_cc1\u0026#39;, command=self.config.clang, extra_args=cheri256_cc1_args+additional_flags), ToolSubst(\u0026#39;%cheri_clang\u0026#39;, command=self.config.clang, extra_args=cheri_clang_args+additional_flags), ToolSubst(\u0026#39;%cheri_purecap_clang\u0026#39;, command=self.config.clang, extra_args=cheri_clang_args + [\u0026#39;-mabi=purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_purecap_cc1\u0026#39;, command=\u0026#39;%riscv32_cheri_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;il32pc64\u0026#39;, \u0026#39;-target-feature\u0026#39;, \u0026#39;+cap-mode\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv64_cheri_purecap_cc1\u0026#39;, command=\u0026#39;%riscv64_cheri_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;l64pc128\u0026#39;, \u0026#39;-target-feature\u0026#39;, \u0026#39;+cap-mode\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_purecap_clang\u0026#39;, command=\u0026#39;%riscv32_cheri_clang\u0026#39;, extra_args=[\u0026#39;-mabi=il32pc64\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv64_cheri_purecap_clang\u0026#39;, command=\u0026#39;%riscv64_cheri_clang\u0026#39;, extra_args=[\u0026#39;-mabi=l64pc128\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_cc1\u0026#39;, command=self.config.clang, extra_args=riscv32_cheri_cc1_args+additional_flags), ToolSubst(\u0026#39;%riscv64_cheri_cc1\u0026#39;, command=self.config.clang, extra_args=riscv64_cheri_cc1_args+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_clang\u0026#39;, command=self.config.clang, extra_args=riscv32_cheri_clang_args+additional_flags), ToolSubst(\u0026#39;%riscv64_cheri_clang\u0026#39;, command=self.config.clang, extra_args=riscv64_cheri_clang_args+additional_flags), # For the tests in Driver that don\u0026#39;t depend on the capability size ToolSubst(\u0026#39;%plain_clang_cheri_triple_allowed\u0026#39;, command=self.config.clang, extra_args=additional_flags), ToolSubst(\u0026#39;%clang\u0026#39;, command=self.config.clang, extra_args=additional_flags), ToolSubst(\u0026#39;%clang_analyze_cc1\u0026#39;, command=\u0026#39;%clang_cc1\u0026#39;, extra_args=[\u0026#39;-analyze\u0026#39;, \u0026#39;%analyze\u0026#39;, \u0026#39;-setup-static-analyzer\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%clang_cc1\u0026#39;, command=self.config.clang, extra_args=clang_cc1_args+additional_flags), ToolSubst(\u0026#39;%clang_cpp\u0026#39;, command=self.config.clang, extra_args=[\u0026#39;--driver-mode=cpp\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%clang_cl\u0026#39;, command=self.config.clang, extra_args=[\u0026#39;--driver-mode=cl\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%clangxx\u0026#39;, command=self.config.clang, extra_args=[\u0026#39;--driver-mode=g++\u0026#39;]+additional_flags), ] self.add_tool_substitutions(tool_substitutions)  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/tools/regression-tests/",
	"title": "Regression Tests",
	"tags": [],
	"description": "",
	"content": " References:\n LLVM doc: Writing new regression tests Lit documentation  More  Cheri  References: reference # llvm/utils/lit/lit/llvm/config.py tool_substitutions = [ # CHERI substitutions (order is important due to repeated substitutions!) ToolSubst(\u0026#39;%cheri_purecap_cc1\u0026#39;, command=\u0026#39;%cheri_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%cheri128_purecap_cc1\u0026#39;, command=\u0026#39;%cheri128_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%cheri256_purecap_cc1\u0026#39;, command=\u0026#39;%cheri256_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%cheri_cc1\u0026#39;, command=self.config.clang, extra_args=cheri_cc1_args+additional_flags), ToolSubst(\u0026#39;%cheri128_cc1\u0026#39;, command=self.config.clang, extra_args=cheri128_cc1_args+additional_flags), ToolSubst(\u0026#39;%cheri256_cc1\u0026#39;, command=self.config.clang, extra_args=cheri256_cc1_args+additional_flags), ToolSubst(\u0026#39;%cheri_clang\u0026#39;, command=self.config.clang, extra_args=cheri_clang_args+additional_flags), ToolSubst(\u0026#39;%cheri_purecap_clang\u0026#39;, command=self.config.clang, extra_args=cheri_clang_args + [\u0026#39;-mabi=purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_purecap_cc1\u0026#39;, command=\u0026#39;%riscv32_cheri_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;il32pc64\u0026#39;, \u0026#39;-target-feature\u0026#39;, \u0026#39;+cap-mode\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv64_cheri_purecap_cc1\u0026#39;, command=\u0026#39;%riscv64_cheri_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;l64pc128\u0026#39;, \u0026#39;-target-feature\u0026#39;, \u0026#39;+cap-mode\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_purecap_clang\u0026#39;, command=\u0026#39;%riscv32_cheri_clang\u0026#39;, extra_args=[\u0026#39;-mabi=il32pc64\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv64_cheri_purecap_clang\u0026#39;, command=\u0026#39;%riscv64_cheri_clang\u0026#39;, extra_args=[\u0026#39;-mabi=l64pc128\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_cc1\u0026#39;, command=self.config.clang, extra_args=riscv32_cheri_cc1_args+additional_flags), ToolSubst(\u0026#39;%riscv64_cheri_cc1\u0026#39;, command=self.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/naming/",
	"title": "Unique Naming Mechanisms in LLVM",
	"tags": [],
	"description": "",
	"content": " References:\n llvm/include/llvm/IR/ValueSymbolTable.h  ValueSymbolTable ValueSymbolTable: provides a symbol table of name/value pairs. It is essentially a std::map, but has a controlled interface provided by LLVM as well as ensuring uniqueness of names.\nclassValueSymbolTable { ... private: ValueName *makeUniqueName(Value *V, SmallString\u0026lt;256\u0026gt; \u0026amp;UniqueName); /// This method adds the provided value \\p N to the symbol table. The Value  /// must have a name which is used to place the value in the symbol table.  /// If the inserted name conflicts, this renames the value.  /// Add a named value to the symbol table  void reinsertValue(Value *V); /// createValueName - This method attempts to create a value name and insert  /// it into the symbol table with the specified name. If it conflicts, it  /// auto-renames the name and returns that instead.  ValueName *createValueName(StringRef Name, Value *V); /// This method removes a value from the symbol table. It leaves the  /// ValueName attached to the value, but it is no longer inserted in the  /// symtab.  void removeValueName(ValueName *V); /// @}  /// @name Internal Data  /// @{  ValueMap vmap; ///\u0026lt; The map that holds the symbol table.  mutable uint32_t LastUnique = 0; ///\u0026lt; Counter for tracking unique names  }; // makeUniqueName(..) in llvm/lib/IR/ValueSymbolTable.cpp  ValueName *ValueSymbolTable::makeUniqueName(Value *V, SmallString\u0026lt;256\u0026gt; \u0026amp;UniqueName) { unsigned BaseSize = UniqueName.size(); while (true) { // Trim any suffix off and append the next number.  UniqueName.resize(BaseSize); raw_svector_ostream S(UniqueName); if (auto *GV = dyn_cast\u0026lt;GlobalValue\u0026gt;(V)) { // A dot is appended to mark it as clone during ABI demangling so that  // for example \u0026#34;_Z1fv\u0026#34; and \u0026#34;_Z1fv.1\u0026#34; both demangle to \u0026#34;f()\u0026#34;, the second  // one being a clone.  // On NVPTX we cannot use a dot because PTX only allows [A-Za-z0-9_$] for  // identifiers. This breaks ABI demangling but at least ptxas accepts and  // compiles the program.  const Module *M = GV-\u0026gt;getParent(); if (!(M \u0026amp;\u0026amp; Triple(M-\u0026gt;getTargetTriple()).isNVPTX())) S \u0026lt;\u0026lt; \u0026#34;.\u0026#34;; } S \u0026lt;\u0026lt; ++LastUnique; // Try insert the vmap entry with this suffix.  auto IterBool = vmap.insert(std::make_pair(UniqueName, V)); if (IterBool.second) return \u0026amp;*IterBool.first; } }  This table is created in multiple places:\n Function (include/llvm/IR/Function.h): std::unique_ptr\u0026lt;ValueSymbolTable\u0026gt; SymTab;  symbol table of args/instructions  Module (include/llvm/IR/Module.h): std::unique_ptr\u0026lt;ValueSymbolTable\u0026gt; ValSymTab;  symbol table of global variable and function identifiers   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mir/machine-function-pass/",
	"title": "MachineFunctionPass",
	"tags": [],
	"description": "",
	"content": " References:\n llvm/lib/CodeGen/MachineFunctionPass.cpp llvm/include/llvm/CodeGen/MachineFunctionPass.h  Pass definition and creation /// MachineFunctionPass - This class adapts the FunctionPass interface to /// allow convenient creation of passes that operate on the MachineFunction /// representation. Instead of overriding runOnFunction, subclasses /// override runOnMachineFunction. classMachineFunctionPass : public FunctionPass { public: bool doInitialization(Module\u0026amp;) override { // Cache the properties info at module-init time so we don\u0026#39;t have to  // construct them for every function.  RequiredProperties = getRequiredProperties(); SetProperties = getSetProperties(); ClearedProperties = getClearedProperties(); return false; } ... protected: /// runOnMachineFunction - This method must be overloaded to perform the  /// desired machine code transformation or analysis.  ///  virtual bool runOnMachineFunction(MachineFunction \u0026amp;MF) = 0; private: /// createPrinterPass - Get a machine function printer pass.  Pass *createPrinterPass(raw_ostream \u0026amp;O, const std::string \u0026amp;Banner) const override; bool runOnFunction(Function \u0026amp;F) override; };  runOnFunction is defined as private function which will finally calls the runOnMachineFunction method (that will be implemented by machine function passes).\nbool MachineFunctionPass::runOnFunction(Function \u0026amp;F) { // Do not codegen any \u0026#39;available_externally\u0026#39; functions at all, they have  // definitions outside the translation unit.  if (F.hasAvailableExternallyLinkage()) return false; MachineModuleInfo \u0026amp;MMI = getAnalysis\u0026lt;MachineModuleInfoWrapperPass\u0026gt;().getMMI(); MachineFunction \u0026amp;MF = MMI.getOrCreateMachineFunction(F); MachineFunctionProperties \u0026amp;MFProps = MF.getProperties(); #ifndef NDEBUG  if (!MFProps.verifyRequiredProperties(RequiredProperties)) { errs() \u0026lt;\u0026lt; \u0026#34;MachineFunctionProperties required by \u0026#34; \u0026lt;\u0026lt; getPassName() \u0026lt;\u0026lt; \u0026#34; pass are not met by function \u0026#34; \u0026lt;\u0026lt; F.getName() \u0026lt;\u0026lt; \u0026#34;.\\n\u0026#34; \u0026lt;\u0026lt; \u0026#34;Required properties: \u0026#34;; RequiredProperties.print(errs()); errs() \u0026lt;\u0026lt; \u0026#34;\\nCurrent properties: \u0026#34;; MFProps.print(errs()); errs() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; llvm_unreachable(\u0026#34;MachineFunctionProperties check failed\u0026#34;); } #endif  // Collect the MI count of the function before the pass.  unsigned CountBefore, CountAfter; // Check if the user asked for size remarks.  bool ShouldEmitSizeRemarks = F.getParent()-\u0026gt;shouldEmitInstrCountChangedRemark(); // If we want size remarks, collect the number of MachineInstrs in our  // MachineFunction before the pass runs.  if (ShouldEmitSizeRemarks) CountBefore = MF.getInstructionCount(); bool RV = runOnMachineFunction(MF); if (ShouldEmitSizeRemarks) { // We wanted size remarks. Check if there was a change to the number of  // MachineInstrs in the module. Emit a remark if there was a change.  CountAfter = MF.getInstructionCount(); if (CountBefore != CountAfter) { MachineOptimizationRemarkEmitter MORE(MF, nullptr); MORE.emit([\u0026amp;]() { int64_t Delta = static_cast\u0026lt;int64_t\u0026gt;(CountAfter) - static_cast\u0026lt;int64_t\u0026gt;(CountBefore); MachineOptimizationRemarkAnalysis R(\u0026#34;size-info\u0026#34;, \u0026#34;FunctionMISizeChange\u0026#34;, MF.getFunction().getSubprogram(), \u0026amp;MF.front()); R \u0026lt;\u0026lt; NV(\u0026#34;Pass\u0026#34;, getPassName()) \u0026lt;\u0026lt; \u0026#34;: Function: \u0026#34; \u0026lt;\u0026lt; NV(\u0026#34;Function\u0026#34;, F.getName()) \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; \u0026#34;MI Instruction count changed from \u0026#34; \u0026lt;\u0026lt; NV(\u0026#34;MIInstrsBefore\u0026#34;, CountBefore) \u0026lt;\u0026lt; \u0026#34; to \u0026#34; \u0026lt;\u0026lt; NV(\u0026#34;MIInstrsAfter\u0026#34;, CountAfter) \u0026lt;\u0026lt; \u0026#34;; Delta: \u0026#34; \u0026lt;\u0026lt; NV(\u0026#34;Delta\u0026#34;, Delta); return R; }); } } MFProps.set(SetProperties); MFProps.reset(ClearedProperties); return RV; }  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/lto/",
	"title": "LTO",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How does the LTO help the optimizer to avoid relying on conservative escape analysis?  References:\n LLVM Link Time Optimization  A tight integration between the linker and LLVM optimizer.\nThe linker treats LLVM bitcode files like native object files and allows mixing and matching among them.\nThe linker use libLTO, a shared object, to handle LLVM bitcode files.\nThe linker input allows the optmizer to avoid relying on conservative escape analysis. (???)\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-c-model/into-c/undef/",
	"title": "Undef",
	"tags": [],
	"description": "",
	"content": " References:\n X. Wang, H. Chen, A. Cheung, Z. Jia, N. Zeldovich, and M. F. Kaashoek. Undefined behavior: what happened to my code? In Proc. APSYS, 2012. pdf X. Wang, N. Zeldovich, M. F. Kaashoek, and A. SolarLezama. Towards optimization-safe systems: Analyzing the impact of undefined behavior. In Proc. SOSP, 2013. pdf  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-c-model/into-c/",
	"title": "Into the Depths of C: Elaborating the De Facto Standards",
	"tags": [],
	"description": "",
	"content": " References:\n Memarian, K., Matthiesen, J., Lingard, J., Nienhuis, K., Chisnall, D., Watson, R.N. and Sewell, P., 2016. Into the depths of C: elaborating the de facto standards. ACM SIGPLAN Notices, 51(6), pp.1-15. pdf Cerberus   C remains central to our computing infrastructure. It is notionally defined by ISO standards, but in reality the properties of C assumed by systems code and those implemented by compilers have diverged, both from the ISO standards and from each other, and none of these are clearly understood.\n \u0026ldquo;We articulate many specific questions, build a suite of semantic test cases, gather experimental data from multiple implementations, and survey what C experts believe about the de facto standards.\u0026rdquo;\n\u0026ldquo;We identify questions where there is a consensus (either following ISO or differing) and where there are conflicts.\u0026rdquo;\n\u0026ldquo;We describe a formal model, Cerberus, for large parts of C. Cerberus is parameterised on its memory model; it is linkable either with a candidate de facto memory object model, under construction, or with an operational C11 concurrency model; it is defined by elaboration to a much simpler Core language for accessibility, and it is executable as a test oracle on small examples.\u0026rdquo;\n\u0026ldquo;This should provide a solid basis for discussion of what mainstream C is now: what programmers and analysis tools can assume and what compilers aim to implement. Ultimately we hope it will be a step towards clear, consistent, and accepted semantics for the various use-cases of C.\u0026rdquo;\nProblems of Current C C is notionally defined by\n ANSI/ISO standards, C80/C90, C99 and C11  And a numer of research projects have worked to formalise aspects of these [c3,c16,c18,c25-29,c38-40].\nBut the question of what C is in reality is much more complex, and more problematic, than the existence of an established standard would suggest; formalisation alone is not enough.\nProblem 1: de facto vs ISO In practice, the de facto standards in:\n behaviours of the various mainstream compilers; assumptions that system programmers make about the behaviour they rely on; assumptions implicit in the corpus of existing C code; assumptions implicit in C analysis tools.  They all differ from each other, and from the ISO standard, despite the latter\u0026rsquo;s stated intent to \u0026ldquo;codify the common, existing definition of C\u0026rdquo;.\nOvertime, C implementations have tended to become more aggressively optimising, exploiting situations which the standards now regard as undefined behaviour. This can break code that used to work correctly in practise, sometimes with security implications 12.\nCritical infrastructure code, including Linux and FreeBSD kernels, depends on idioms that current compilers do not in general support, or that ISO standards does not permit. Compiler flags -fno-strict-aliasing and -fno-strict-overflow, that turn off particular analyses.\nDevelopers of static and dynamic analysis tools must make ad hoc semantic choices to avoid too many \u0026ldquo;false\u0026rdquo; positives that are contrary to their customers\u0026rsquo; expectations, even where these are real violations of the ISO standards 3. This knowledge of the de facto standards is often left implicit in the tool implementations, and making it precise requires an articulation of the possible choices.\nThe space of mainstream C implementation has become simpler than the one that the C standard was originally written to cope with. For example, mainstream hardware can now reasonably be assumed to have 8-bit bytes, twos-complement arithmetic, and (often) non-segmented memory, but the ISO standard does not take any of this into account.\nProblem 2: no precise and accessible specification The ISO standard is hard to be interpreted precisely.\n C tries to solve a challenging problem: to simultaneously enable programmers to write high-performance hand-crafted low-level code, provide portability between widely varying target machine architectures, and support sophisticated compiler optimizations.\nIt does so by providing operations both on abstract values and on their underlying concrete representations. The interactioins between these is delicate, as are the dynamic propoerties relating to memory and type safety, aliasing, concurrency, and so on; they have, unsurprisingly, proved difficult to characterise precisely in the prose specification style of the standards.\nEven those few who are very familiar with the standard often struggle with the subtleties of C, as witnessed by the committee\u0026rsquo;s internal mailing list discussion of what the correct interpretation of the standard should be, the number of the requests for clarification made in the form of defect reports4, and the inconclusive discussions of whether compiler anomalies are bugs w.r.t. the standard.\nThe prose standard is not executable as a test oracle, which would let one simply compute the set of all allowed behaviours of any small test case, so such discussions have to rely on exegesis of the standard text.\nThe goal of ANSI C89, to \u0026ldquo;develop a clear, consistent, and unambiguous Standard for the C programming language\u0026rdquo;, thus remains an open problem.\n Problem 3: integrating C11 concurrent and sequential semantics A technical challenge of dealing with concurrency.\nFollowing C++, the C standard finally addressed concurrency in C11.\nBatty, et al., worked to ensure that the standard text of the concurrency model is written in close correspondence to a formalisation.\nBut the concurrency model is in an axiomatic style, while the rest of C11 is more naturally expressed in an operational semantics; it is hard to integrate the two.\nSummary Current C, a mess: Divergence among the de facto and ISO standards, the prose form, ambiguities, and xomplexities of the ISO standards, lack of an integrated treatment of concurrency.\nContributions of this paper  detailed investigation into the possible semantics for pointers and memory in C (its memory object model)\n formal semantics, Cerberus, for large parts of C.\n  C pointers and memory C pointers and memory model, where there seems to be the most divergence and variation among the multiple de facto and ISO standards.\n design space: 85 questions, 196 hand-written semantic test cases;  80+ page document 56  de facto standards: what system programmers and compiler writers believe about compiler behaviour and extant code; data collected for test suite. for GCC/Clang/TrustInSoft/KCC \u0026ldquo;In ongoing work, we are building a candidate formal model capturing one plausible view of the de facto standards, as a reference for discussion.\u0026rdquo;  Proved useful in practice: \u0026ldquo;we applied our analysis and test suite to the C dialect supported by Watson et al\u0026rsquo;s experimental CHERI processor 78, which implements unforgeable, bounds-checked C pointers (capabilities)\u0026ldquo;.\nFormal Semantics for C Cerberus: Capture ISO text for large parts of C as clearly as possible.\n Parameterised memory model: can be instantiated with the candidate formal model that we are developing or, in future, other alternative memory object models.\n Can also be instantiated with an operational C/C++11 concurrency model, though not yet combined with a full memory object model.  Executable as a test oracle, to explore all behaviours or single paths of test programs;\n   Cerberus aims to cover essentially all the material of Section 5 Environment and 6 Language of the ISO C11 standard, both syntax and semantics, except: preprocessor features, C11 character-set features, floating-point and complex types (beyond simple float constants), user-defined variadic functions (we do cover printf), bitfields, volatile, restrict, generic selection, register, flexible array members, some exotic initialisation forms, signals, longjmp, multiple translation units, and aspects where our candidate de facto memory object model intentionally differs from the standard.\nIt supports only a small parts of the standard libraries. Threads, atomic types, and atomic operations are supported only with a more restricted memory object model.\n Cerberus computation semantics:\n expressed by an elaboration from a fully type-annotated C AST to a carefully defined Core: a typed call-by-value calculus with constructs to model certain aspects of the C dynamic semantics. handle subtleties such as C evaluation order, integer promotions (???), and the associated impl defined and undefined behaviour. closely follow ISO standard text  Cerberus front-end:\n C parser desugaring phase type checker re-implement to avoid the building in semantic choices about C that are implicit in the transformations from C source to AST done by compiler or CIL front-ends. preliminary experiment in translation validation (in Coq) for the front-end of Clang, for very simple programs.  Key Disagreements Of the 85 questions:\n for 39 the ISO standard is unclear; for 27 the de facto standards are unclear, in some cases with significant differences between usage and implementation; for 27 there are significant differences between the ISO and the de facto standards.  Pointer Provenance  From ISO WG14 Defect Report DR260 Committee Response [^c53]: \u0026ldquo;The implementation is entitled to take account of the provenance of a pointer value when determining what actions are and are not defined.\u0026rdquo;\n // example provenance_basic_global_yx.c #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;string.h\u0026gt;int y=2, x=1; int main() { int *p = \u0026amp;x + 1; int *q = \u0026amp;y; printf(\u0026#34;Addresses: p=%p q=%p\\n\u0026#34;,(void*)p,(void*)q); if (memcmp(\u0026amp;p, \u0026amp;q, sizeof(p)) == 0) { *p = 11; // does this have undefined behaviour?  printf(\u0026#34;x=%d y=%d *p=%d *q=%d\\n\u0026#34;,x,y,*p,*q); } return 0; } Above code will result in different behaviors if the compiler treat pointer provenance differently:\n If x and y happen to be allocated in adjacent memory, \u0026amp;x+1 and \u0026amp;y will have bitwise-identical runtime representation values, the memcmp will succeed, and p (derived from a pointer to x) will have the same representation value as the pointer to y (a different object) at the pointer of the update *p=11.\nIn a concrete semantics we would expect to see x=1 y=11 *p=11 *q=11, but GCC produces x=1 y=2 *p=11 *q=2, ICC produces x=1 y=2 *p=11 *q=11. This suggests that GCC is reasoning, from provenance information, that *p does not alias with y or *q, and hence that the initial value of y=2 can be propagated to the final printf. Note that this is not a type-based aliasing issue: the pointers are of the same type, and the GCC result is not affected by -fno-strict-aliasing.\n D260 suggests a semantic in which pointer values include not just a concrete address but also provenance information, erased at runtime in conventional implementations, including a unique ID from the original allocation. This can be used in the semantics for memory accesses to check that the address used is consistent with the original allocation, which here lets the *p=11 access be regarded as undefined behavior.\nUndefined behavior: program is erroneous and compilers are notionally entirely unconstrained in how they treat it. This makes the above compiler analysis and optimizations (vacuously) corrent in this case.\n==\u0026gt; \u0026ldquo;This general pattern is typical for C: regarding situations as undefined behaviour puts an obligation on programmers to avoid them, but permits compilers to make strong assumptions when optimising.\u0026rdquo;\nThe (block-ID, offset) semantics model for pointers in C, leads to many more vexed questions. e.g.:\nQ25: Can we do relational comparison (with \u0026lt;, \u0026gt;, \u0026lt;=, or \u0026gt;= ) of two pointers to separately allocated objects (of compatible object types)?\n ISO clearly prohibits this, but surveys show that it is widely used, e.g. for global lock orderings and for collection-implementation orderings.  For mainstream C semantics, it seems more useful to permit it than to take the strict-ISO view that all occurrences are bugs. In our model, we can easily regard these relational comparisons as ignoring the provenance information.  Ways a concrete address values are exposed to programs:  Relational comparison of two pointers from different allocated objects, as above. Explicit cast to integer types; IO of pointers; Examination of pointer representation bytes.  Therefore, abstract pointer values must also contain concrete addresses, in contrast to those earlier C semantics that only had block IDs, and the semantics must let those be nondeterministically chosen in any way that a reasonable implementation might.  Q9: Can one make a usable offset between two separately allocated objects by inter-object integer or pointer subtraction, make a usable pointer to the second by adding the offset to a pointer to the first?\n conflicts between C usage one one side and compilers and ISO on the other. In practice, not common, but  Linux, FreeBSD kernel implementation: per-CPU variables. Current compilers sometimes do optimise based on an assumption, in a point-to analysis, that inter-object pointer arithmetic does not occur.  How to resolve?  The usage is buggy, should be rewritten: But it will lose performance. Globally disable the optimizations, eg -fno-tree-pta for GCC: But too a blunt instrument. Adapt the compiler analyses to treat inter-object pointer subtractions as giving integer offsets that have the power to move between objects. a multiple-provenance semantics, not just a singleton provenance, but  compiler would have to be conservative where they could not determine that pionter subtractions are intra-object; might also too costly.  require such usages to be explicitly annotated, e.g. with an attribute on the resulting pionter that declares that it might alias with anything.  None of these are wholly satisfactory.  (we suspect) the last is the most achievable (for the moment) our candidate formal model forbids this idiom.   Q5: Must provenance information be tracked via casts to integer types and integer arithmetic?\n It is common to cast pointers to integer types and back to do arithmetic on them, e.g. to store information in unused bits. To get a coherent model, two possible options:  regard the result of casting from an integer to a pointer as of a wildcard provenance or track provenance through integer operations;  Our formal model associates provenances with all integer values, following the same at-most-one provenance model we use for pointers.   GCC documentation states: \u0026ldquo;When casting from pointer to integer and back again, the resulting pointer must reference the same object as the original pointer, otherwise the behavior is undefined\u0026rdquo;.\n Q2: Can equality testing on pointers be affected by pointer provenance information?\n ISO allows equality testing between pointers to different objects of compatible types; but leaves open whether the result might depend on provenance. GCC with our test suite:  Two pointers with same runtime representation but different provenances are regarded as different by GCC. ==\u0026gt; compilers do take advantage of the provenance information if it is statically available.  This can be soundly modelled by making a nondeterministic choice at each such comparison whether to take provenance into account or not.  Out-of-Bounds Pointers Very limited pointer arithmentic is permitted in ISO standard.\n within an array among the members of a struct access representation bytes one-past an object  However, in practice, \u0026ldquo;it seems to be common to transiently construct out-of-bounds pointers\u0026rdquo;. See Beyond PDP11 paper, Table 1 [^c11]. On the other side, the textual comments reveal that some compiler developers believe that compilers may optimise assuming that this does not occur, and there can be issues with overflow in pointer arithmetic and with large allocations.\nSo long as they are brought back in-bounds before being used to access memory, many experts believe this will work.\n\u0026ldquo;For our formal model, as in CHERI, we tentatively choose to permit arbitrary pointer arithmetic: out-of-bounds pointers can be constructed, with undefined behaviour occurring if an access-time check w.r.t. the bounds associated to their provenance fails.\u0026rdquo;\nPointer Copying  preserve the provenance when copy the entire pointer? How about copying only bits of pointers?   \u0026ldquo;Windows /GS stack cookies do this all the time to protect the return address. The return address is encrypted on the stack, and decrypted as part of the function epilogue\u0026rdquo; and a \u0026ldquo;JIT that stores 64-bit virtual ptrs as their hardware based 48-bits\u0026rdquo;.\n Our candidate formal model:\n should permit copying pointer values via indirect dataflow, as the representation bytes or bits carry the original provenance,  combining values with the same provenance preserves that provenance the access-time check compares the recalculated address with that of the original allocation.  should not permit copying via indirect control flow (e.g. making a branch based on each bit of a pointer value) does not require all of the original bits to flow to the result.   We view this (our formal model) as a plausible de facto semantics, but more work is needed to see if it is really compatible with current compiler analysis implementations.\n Unspecified Values C does not require variables and memory to be initialised.\n(In the text responses) the only real use cases seem to be copying a partially initialised struct and (more rarely) comparing against one.\nSurvey on the semantics of reading an uninitialized variable or struct member (either due to a bug or intentionally, to copy, output, hash, or set some bits of a partially initialised value):\n undefined behaviour (meaning that the compiler is free to arbitrarily miscompile the program, with or without a warning); 139 (43%) going to make the result of any expression involving that value unpredictable; 42(13%) going to give an arbitrary and unstable value (maybe with a different value if you read again); 21 (6%) going to give an arbitrary but stable value (with the same value if you read again); 112 (35%)  GCC and Clang do perform SSA transformation that make uninitialised values unstable (2).\nClang is moving towards (1).\nISO \u0026hellip;\n indeterminate values  unspecified value, a valid value [where ISO] imposes no requirements on which value is chosen in any instance. trap representation   Unspecified Padding Values Pading values.\nPossible semantics:\n regarded as always holding unspecified values, irrespective of any byte writes to them, so the compiler could arbitrarily write to padding at any point; structure member writes are deemed to also write unspecified values over subsequent padding; .. or to nondeterministically either write zeros over subsequent padding or leave it unchanged. Structure copies might copy padding, but structure member writes never touch padding.  MSVC \u0026ndash; 4.\nClang \u0026ndash; Not 1, not 2.\nGCC \u0026ndash; 1 or 2.\nIBM mainfram compiler \u0026ndash; 1 or 2.\nEffective Types  C99 introduced effective types to permit compilers to do optimisations driven by type-based alias analysis (TBAA), ruling out programs involving unannotated aliasing of references to different types by regarding them as having undefined behaviour.\nThis is one of the less clear, less well-understood, and more controversial aspects of C.\n Example conflict:\nQ75: Can an unsigned character array with static or automatic storage duration be used (in the same way as a malloc\u0026rsquo;d region) to hold values of other types?\n 201(65%) know of real code that relies on it. ISO: disallows it GCC: \u0026ldquo;No, this is not safe　(if it\u0026rsquo;s visible to the compiler that the memory in question has unsigned char as its declared type) Our candidate formal model: focuses on the C used by system code, often compiled with -fno-strict-aliasing to turn TBAA off, and so should permit this and related idioms.  Memory Semantics of C Analysis Tools Run test with three groups of tools:\n Clang\u0026rsquo;s memory, address, and undefined-behavior sanitisers (MSan, ASan, UBSan),  intended to identify uses of uninitializd memory values, invlid memory accesses, and other undefined behaviors  TrustInSoft tis-interpreter  based on Frama-C value analysis  Hathhorn et al.\u0026rsquo;s KCC.  The result from these tools ara radically different.\nClang Sanitizers Only few of tests triggered warnings.\n All 13 of structure-padding test and 9 of other unspecified-value tests ran without any sanitiser warnings.  \u0026hellip;\nTrustInSoft  TrustInSoft aims for a tight semantics, to detect enough cases to ensure \u0026ldquo;that any program that executes correctly in tis-interpreter behaves deterministically when compiled and produces the same results\u0026rdquo;.\n  In many places it follows a much stricter notion of C than our candidate de facto model  e.g. flagging most of the unspecified-value tests, and not permitting comparison of pointer representations;  In some others it coincides with our candidate de facto model but differs from ISO.  e.g. assuming null pointer representations are zero.   KCC KCC detected two potential alignment erros in earlier versions of our tests.\nBut it gave\n \u0026ldquo;execution failed\u0026rdquo;, with no futher details for the test of 20 of our questions. \u0026ldquo;Translation failed\u0026rdquo; for one; segfaulted at runtime for one; results contrary to our reading of the ISO standard for at least 6;  KCC exhibited a very strict semantics for reading uninitialised values (but not for padding bytes), and permitted some test that ISO effective types forbid.\nMemory Semantics of CHERI C Researches that focused on memory safe implementation of C:\n [^c14] [^c15] [^c22] [^c34] [^c35] Intel MPX [^c21]  But to date, no wrok in this area has clearly defined the interpretation of C that it aims to implement.\nCerberus Validation More  Beyond PDP-11, various idoms in C   Undef   References: X. Wang, H. Chen, A. Cheung, Z. Jia, N. Zeldovich, and M. F. Kaashoek. Undefined behavior: what happened to my code? In Proc. APSYS, 2012. pdf X. Wang, N. Zeldovich, M. F. Kaashoek, and A. SolarLezama. Towards optimization-safe systems: Analyzing the impact of undefined behavior. In Proc. SOSP, 2013. pdf More   X. Wang, H. Chen, A. Cheung, Z. Jia, N. Zeldovich, and M. F. Kaashoek. Undefined behavior: what happened to my code? In Proc. APSYS, 2012 ↩ X. Wang, N. Zeldovich, M. F. Kaashoek, and A. SolarLezama. Towards optimization-safe systems: Analyzing the impact of undefined behavior. In Proc. SOSP, 2013. ↩ A. Bessey, K. Block, B. Chelf, A. Chou, B. Fulton, S. Hallem, C. Henri-Gros, A. Kamsky, S. McPeak, and D. Engler. A few billion lines of code later: using static analysis to find bugs in the real world. Commun. ACM, 53(2), 2010. ↩ WG14. Defect report summary for ISO/IEC 9899:1999. ↩ K. Memarian, J. Matthiesen, K. Nienhuis, V. B. F. Gomes, J. Lingard, D. Chisnall, R. N. M. Watson, and P. Sewell. Cerberus, 2016. www.cl.cam.ac.uk/~pes20/cerberus, www.repository.cam.ac.uk/handle/1810/255730 ↩ D. Chisnall, J. Matthiesen, K. Memarian, K. Nienhuis, P., and R.N.M. Watson. C memory object and value semantics: the space of de facto and ISO standards, 2016. http://www.cl.cam.ac.uk/~pes20/cerberus/. ↩ R. N. M. Watson, P. G. Neumann, J. Woodruff, M. Roe, J. Anderson, D. Chisnall, B. Davis, A. Joannou, B. Laurie, S. W. Moore, S. J. Murdoch, and R. Norton. Capability hardware enhanced RISC instructions: CHERI instruction-set architecture. Technical Report UCAM-CL-TR-864, University of Cambridge, Computer Laboratory, November 2015. ↩ R. N. M. Watson, J. Woodruff, P. G. Neumann, S. W. Moore, J. Anderson, D. Chisnall, N. H. Dave, B. Davis, K. Gudka, B. Laurie, S. J. Murdoch, R. Norton, M. Roe, S. Son, and M. Vadera. CHERI: A hybrid capability-system architecture for scalable software compartmentalization. In IEEE Symposium on Security and Privacy, SP, 2015. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/extending/add-dag/",
	"title": "Add a new SelectionDAG node",
	"tags": [],
	"description": "",
	"content": " References:\n Extending LLVM: Adding instructions, intrinsics, types, etc  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/extending/add-instr/",
	"title": "Add a new Instruction to LLVM",
	"tags": [],
	"description": "",
	"content": " References:\n Extending LLVM: Adding instructions, intrinsics, types  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/extending/",
	"title": "Extending",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Add a new SelectionDAG node   References: Extending LLVM: Adding instructions, intrinsics, types, etc More  Add a new Instruction to LLVM   References: Extending LLVM: Adding instructions, intrinsics, types More  Cheri CSetBounds Intrinsics  References: Extending LLVM: Adding instructions, intrinsics, types Mips::CSetBounds new instruction support in LLVM IR intrinsics td file llvm/include/IR/IntrinsicsCHERICap.td def int_cheri_cap_bounds_set : Intrinsic\u0026lt;[llvm_fatptr_ty], [llvm_fatptr_ty, llvm_anyint_ty], [IntrNoMem, IntrWillReturn]\u0026gt;; def int_cheri_cap_bounds_set_exact : Intrinsic\u0026lt;[llvm_fatptr_ty], [llvm_fatptr_ty, llvm_anyint_ty], [IntrNoMem, IntrWillReturn]\u0026gt;; target td file llvm/lib/Target/Mips/MipsInstrCheri.td // Accept CIncOffsetImm as an assembler mnemonic because ancient binutils is too stupid to have an opcode // with differing encoding depending on the parameters def : InstAlias\u0026lt;\u0026#34;csetboundsimm $dst, $src, $imm\u0026#34;, (CSetBoundsImm CheriOpnd:$dst, CheriOpnd:$src, uimm11s0:$imm), 0\u0026gt;; def : InstAlias\u0026lt;\u0026#34;cincoffsetimm $dst, $src, $imm\u0026#34;, (CIncOffsetImm CheriOpnd:$dst, CheriOpnd:$src, simm11s0:$imm), 0\u0026gt;; def : InstAlias\u0026lt;\u0026#34;csetboundsimm $dst, $imm\u0026#34;, (CSetBoundsImm CheriOpnd:$dst, CheriOpnd:$dst, uimm11s0:$imm), 0\u0026gt;; def : InstAlias\u0026lt;\u0026#34;cincoffsetimm $dst, $imm\u0026#34;, (CIncOffsetImm CheriOpnd:$dst, CheriOpnd:$dst, simm11s0:$imm), 0\u0026gt;; // CAssertInBounds pseudo def : InstAlias\u0026lt;\u0026#34;cassertinbounds $dst, $imm\u0026#34;, (CSetBoundsImm CNULL, CheriOpnd:$dst, uimm11s0:$imm), 1\u0026gt;; def : InstAlias\u0026lt;\u0026#34;cassertinbounds $dst\u0026#34;, (CSetBoundsImm CNULL, CheriOpnd:$dst, 1), 0\u0026gt;; // Property setters let isReMaterializable = 1, isAsCheapAsAMove = 1 in { def CAndPerms : CheriFmtCSet\u0026lt;0xd, \u0026#34;perm\u0026#34;, \u0026#34;perms\u0026#34;, \u0026#34;and\u0026#34;\u0026gt;; def CSetFlags : CheriFmtCSet\u0026lt;0xe, \u0026#34;flags\u0026#34;\u0026gt;; def CSetOffset : CheriFmtCSet\u0026lt;0xf, \u0026#34;offset\u0026#34;\u0026gt;; def CSetBounds : CheriFmtCSet\u0026lt;0x8, \u0026#34;bounds\u0026#34;\u0026gt;; def CSetBoundsExact : CheriFmtCSet\u0026lt;0x9, \u0026#34;boundsexact\u0026#34;, \u0026#34;bounds\u0026#34;, \u0026#34;set\u0026#34;, \u0026#34;set_exact\u0026#34;\u0026gt;; def CIncOffset : CheriFmt3Op\u0026lt;0x11, (outs CheriOpnd:$r1), (ins CheriOpnd:$r2, GPR64Opnd:$r3), \u0026#34;cincoffset\\t$r1, $r2, $r3\u0026#34;, [(set CheriOpnd:$r1, (ptradd CheriOpnd:$r2, GPR64Opnd:$r3))]\u0026gt;; def CClearTag : CheriFmt2Op\u0026lt;0xb, (outs CheriOpnd:$r1), (ins CheriOpnd:$r2), \u0026#34;ccleartag\\t$r1, $r2\u0026#34;, [(set CheriOpnd:$r1, (int_cheri_cap_tag_clear CheriOpnd:$r2))]\u0026gt;; def CSetAddr : CheriFmtCSet\u0026lt;0x22, \u0026#34;addr\u0026#34;, \u0026#34;address\u0026#34;\u0026gt;; // Add a pseudo instruction to pretend this is only one instruction to avoid register spills def CheriBoundedStackPseudoImm : CheriBoundedStackPseudo\u0026lt;(ins CheriOpnd:$fi, simm11s0:$frameoffs, uimm11s0:$size)\u0026gt;; // FIXME: duplicated to avoid machine verified errors def CheriBoundedStackPseudoReg : CheriBoundedStackPseudo\u0026lt;(ins CheriOpnd:$fi, simm11s0:$frameoffs, GPR64Opnd:$size)\u0026gt;; llvm/lib/Target/RISCV/RISCVInstrinfoXCheri.\n Intrinsics  Reference: Extending LLVM: Adding instructions, intrinsics, types, etc. \u0026ldquo;Adding a new intrinsic function to LLVM is much easier than adding a new instruction. Almost all extensions to LLVM should start as an intrinsic function and then be turned into an instruction if warranted.\u0026rdquo; llvm/docs/LangRef.html: Document the intrinsic. Decide whether it is code generator specific and what the restrictions are. Talk to other people about it so that you are sure it’s a good idea.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/extending/cheri-csetbounds/",
	"title": "Cheri CSetBounds Intrinsics",
	"tags": [],
	"description": "",
	"content": " References:\n Extending LLVM: Adding instructions, intrinsics, types  Mips::CSetBounds new instruction support in LLVM\nIR intrinsics td file llvm/include/IR/IntrinsicsCHERICap.td\ndef int_cheri_cap_bounds_set : Intrinsic\u0026lt;[llvm_fatptr_ty], [llvm_fatptr_ty, llvm_anyint_ty], [IntrNoMem, IntrWillReturn]\u0026gt;; def int_cheri_cap_bounds_set_exact : Intrinsic\u0026lt;[llvm_fatptr_ty], [llvm_fatptr_ty, llvm_anyint_ty], [IntrNoMem, IntrWillReturn]\u0026gt;;  target td file llvm/lib/Target/Mips/MipsInstrCheri.td\n// Accept CIncOffsetImm as an assembler mnemonic because ancient binutils is too stupid to have an opcode // with differing encoding depending on the parameters def : InstAlias\u0026lt;\u0026#34;csetboundsimm $dst, $src, $imm\u0026#34;, (CSetBoundsImm CheriOpnd:$dst, CheriOpnd:$src, uimm11s0:$imm), 0\u0026gt;; def : InstAlias\u0026lt;\u0026#34;cincoffsetimm $dst, $src, $imm\u0026#34;, (CIncOffsetImm CheriOpnd:$dst, CheriOpnd:$src, simm11s0:$imm), 0\u0026gt;; def : InstAlias\u0026lt;\u0026#34;csetboundsimm $dst, $imm\u0026#34;, (CSetBoundsImm CheriOpnd:$dst, CheriOpnd:$dst, uimm11s0:$imm), 0\u0026gt;; def : InstAlias\u0026lt;\u0026#34;cincoffsetimm $dst, $imm\u0026#34;, (CIncOffsetImm CheriOpnd:$dst, CheriOpnd:$dst, simm11s0:$imm), 0\u0026gt;; // CAssertInBounds pseudo def : InstAlias\u0026lt;\u0026#34;cassertinbounds $dst, $imm\u0026#34;, (CSetBoundsImm CNULL, CheriOpnd:$dst, uimm11s0:$imm), 1\u0026gt;; def : InstAlias\u0026lt;\u0026#34;cassertinbounds $dst\u0026#34;, (CSetBoundsImm CNULL, CheriOpnd:$dst, 1), 0\u0026gt;; // Property setters let isReMaterializable = 1, isAsCheapAsAMove = 1 in { def CAndPerms : CheriFmtCSet\u0026lt;0xd, \u0026#34;perm\u0026#34;, \u0026#34;perms\u0026#34;, \u0026#34;and\u0026#34;\u0026gt;; def CSetFlags : CheriFmtCSet\u0026lt;0xe, \u0026#34;flags\u0026#34;\u0026gt;; def CSetOffset : CheriFmtCSet\u0026lt;0xf, \u0026#34;offset\u0026#34;\u0026gt;; def CSetBounds : CheriFmtCSet\u0026lt;0x8, \u0026#34;bounds\u0026#34;\u0026gt;; def CSetBoundsExact : CheriFmtCSet\u0026lt;0x9, \u0026#34;boundsexact\u0026#34;, \u0026#34;bounds\u0026#34;, \u0026#34;set\u0026#34;, \u0026#34;set_exact\u0026#34;\u0026gt;; def CIncOffset : CheriFmt3Op\u0026lt;0x11, (outs CheriOpnd:$r1), (ins CheriOpnd:$r2, GPR64Opnd:$r3), \u0026#34;cincoffset\\t$r1, $r2, $r3\u0026#34;, [(set CheriOpnd:$r1, (ptradd CheriOpnd:$r2, GPR64Opnd:$r3))]\u0026gt;; def CClearTag : CheriFmt2Op\u0026lt;0xb, (outs CheriOpnd:$r1), (ins CheriOpnd:$r2), \u0026#34;ccleartag\\t$r1, $r2\u0026#34;, [(set CheriOpnd:$r1, (int_cheri_cap_tag_clear CheriOpnd:$r2))]\u0026gt;; def CSetAddr : CheriFmtCSet\u0026lt;0x22, \u0026#34;addr\u0026#34;, \u0026#34;address\u0026#34;\u0026gt;; // Add a pseudo instruction to pretend this is only one instruction to avoid register spills def CheriBoundedStackPseudoImm : CheriBoundedStackPseudo\u0026lt;(ins CheriOpnd:$fi, simm11s0:$frameoffs, uimm11s0:$size)\u0026gt;; // FIXME: duplicated to avoid machine verified errors def CheriBoundedStackPseudoReg : CheriBoundedStackPseudo\u0026lt;(ins CheriOpnd:$fi, simm11s0:$frameoffs, GPR64Opnd:$size)\u0026gt;; llvm/lib/Target/RISCV/RISCVInstrinfoXCheri.td\ndef CSetBounds : Cheri_rr\u0026lt;0x8, \u0026#34;csetbounds\u0026#34;\u0026gt;; def CSetBoundsExact : Cheri_rr\u0026lt;0x9, \u0026#34;csetboundsexact\u0026#34;\u0026gt;; def CSetBoundsImm : Cheri_ri\u0026lt;0x2, \u0026#34;csetbounds\u0026#34;, 0\u0026gt;; //... def : InstAlias\u0026lt;\u0026#34;csetboundsimm $cd, $cs1, $imm\u0026#34;, (CSetBoundsImm GPCR:$cd, GPCR:$cs1, uimm12:$imm), 0\u0026gt;; } //... def : PatGpcrGpr\u0026lt;int_cheri_cap_bounds_set, CSetBounds\u0026gt;; def : PatGpcrGpr\u0026lt;int_cheri_cap_bounds_set_exact, CSetBoundsExact\u0026gt;; def : PatGpcrUimm12\u0026lt;int_cheri_cap_bounds_set, CSetBoundsImm\u0026gt;; //... // TODO: Make this rematerialisable like MIPS def : PatGpcrGpr\u0026lt;int_cheri_bounded_stack_cap, CSetBounds\u0026gt;; Mips::CJR llvm/lib/Target/Mips/MipsInstrCheri.td\ndef CJR : CheriFmt1Op\u0026lt;0x3, (outs), (ins CheriOpnd:$r1), \u0026#34;cjr\\t${r1}\u0026#34;, []\u0026gt;; } llvm/lib/Target/RISCV/RISCVInstrinfoXCheri.td\ndef : InstAlias\u0026lt;\u0026#34;cjr $cs1\u0026#34;, (CJALR C0, GPCR:$cs1), 1\u0026gt;; More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/prolog-epilog/mips/",
	"title": "Mips",
	"tags": [],
	"description": "",
	"content": " References:\n reference  Target dependent implementation of prologue/epilogue emission.\nSee [../] for callers.\nMipsSEFrameLowering::emitPrologue Adjust stack pointer:\nMipsSEFrameLowering::emitPrologue() =\u0026gt; TII.adjustStackPtr(SP, -StackSize, MBB, MBBI) MipsSEInstrInfo::adjustStackPtr() =\u0026gt; BuildMI // addi sp, sp, amount  MipsSEFrameLowering::spillCalleeSavedRegisters The instruction to spill return address $ra register is built here.\n// search Mips::RA_64, spill RA as callee saved reg MipsSEFrameLowering::spillCalleeSavedRegisters(){ //...  DebugLL(\u0026#34;before spill callee save: block: \u0026#34;; MBB.dump();); for (unsigned i = 0, e = CSI.size(); i != e; ++i) { // ...  // Insert the spill to the stack frame.  bool IsKill = !IsRAAndRetAddrIsTaken \u0026amp;\u0026amp; KillRAOnSpill; const TargetRegisterClass *RC = TRI-\u0026gt;getMinimalPhysRegClass(Reg); TII.storeRegToStackSlot(MBB, MI, Reg, IsKill, CSI[i].getFrameIdx(), RC, TRI); } DebugLL(\u0026#34;done spill callee save: block: \u0026#34;; MBB.dump();); } // // in file llvm/lib/Target/Mips/MipsISelLowering.cpp // MipsTargetLowering::lowerRETURNADDR() =\u0026gt; unsigned Reg = MF.addLiveIn(RA, getRegClassFor(VT)); // add live-in for RA.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/jemalloc/",
	"title": "jemalloc",
	"tags": [],
	"description": "",
	"content": " References:\n contrib/jemalloc/  FreeBSD use je_malloc for malloc by default:\n/* * Name mangling for public symbols is controlled by --with-mangling and * --with-jemalloc-prefix. With default settings the je_ prefix is stripped by * these macro definitions. */ #ifndef JEMALLOC_NO_RENAME # define je_aligned_alloc aligned_alloc # define je_calloc calloc # define je_dallocx dallocx # define je_free free # define je_mallctl mallctl # define je_mallctlbymib mallctlbymib # define je_mallctlnametomib mallctlnametomib # define je_malloc malloc # define je_malloc_conf malloc_conf # define je_malloc_message malloc_message # define je_malloc_stats_print malloc_stats_print # define je_malloc_usable_size malloc_usable_size # define je_mallocx mallocx # define je_smallocx_ea6b3e973b477b8061e0076bb257dbd7f3faa756 smallocx_ea6b3e973b477b8061e0076bb257dbd7f3faa756 # define je_nallocx nallocx # define je_posix_memalign posix_memalign # define je_rallocx rallocx # define je_realloc realloc # define je_sallocx sallocx # define je_sdallocx sdallocx # define je_xallocx xallocx # define je_valloc valloc #endif  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/elf-writer/",
	"title": "Elf Writer",
	"tags": [],
	"description": "",
	"content": " References:\n reference\n// class .member struct ELFWriter{ ELFObjectWriter \u0026amp;OWriter; } // parent --\u0026gt; child MCObjectWriter -\u0026gt; ELFObjectWriter   States:\n ELFObjectWriter \u0026amp;OWriter support::endian::Writer W. An adapter to write values to a stream in a particular byte order. unsigned LastLocalSymbolIndex. This holds the symbol table index of the last local symbol. unsigned StringTableIndex. This holds the .strtab section index. unsigned SymbolTableIndex. This holds the .symtabl section index. std::vector\u0026lt;const MCSectionELF *\u0026gt; SectionTable. All the sections in order. They are to be output in the section table.  Interfaces:\n// llvm/lib/MC/ELFObjectWriter.cpp  void writeHeader(const MCAssembler \u0026amp;Asm); void writeSymbol(SymbolTableWriter \u0026amp;Writer, uint32_t StringIndex, ELFSymbolData \u0026amp;MSD, const MCAsmLayout \u0026amp;Layout); /// Compute the symbol table data  ///  /// \\param Asm - The assembler.  /// \\param SectionIndexMap - Maps a section to its index.  /// \\param RevGroupMap - Maps a signature symbol to the group section.  void computeSymbolTable(MCAssembler \u0026amp;Asm, const MCAsmLayout \u0026amp;Layout, const SectionIndexMapTy \u0026amp;SectionIndexMap, const RevGroupMapTy \u0026amp;RevGroupMap, SectionOffsetsTy \u0026amp;SectionOffsets); MCSectionELF *createRelocationSection(MCContext \u0026amp;Ctx, const MCSectionELF \u0026amp;Sec); const MCSectionELF *createStringTable(MCContext \u0026amp;Ctx); void writeSectionHeader(const MCAsmLayout \u0026amp;Layout, const SectionIndexMapTy \u0026amp;SectionIndexMap, const SectionOffsetsTy \u0026amp;SectionOffsets); void writeSectionData(const MCAssembler \u0026amp;Asm, MCSection \u0026amp;Sec, const MCAsmLayout \u0026amp;Layout); void WriteSecHdrEntry(uint32_t Name, uint32_t Type, uint64_t Flags, uint64_t Address, uint64_t Offset, uint64_t Size, uint32_t Link, uint32_t Info, uint64_t Alignment, uint64_t EntrySize); void writeRelocations(const MCAssembler \u0026amp;Asm, const MCSectionELF \u0026amp;Sec); uint64_t writeObject(MCAssembler \u0026amp;Asm, const MCAsmLayout \u0026amp;Layout); void writeSection(const SectionIndexMapTy \u0026amp;SectionIndexMap, uint32_t GroupSymbolIndex, uint64_t Offset, uint64_t Size, const MCSectionELF \u0026amp;Section);  More  Elf Object Writer  References: [LLVM source code (version 11)] Inheritance/Member relation // parent --\u0026gt; child MCObjectWriter -\u0026gt; ELFObjectWriter // class .member struct ELFWriter{ ELFObjectWriter \u0026amp;OWriter; } States: // llvm/lib/MC/ELFObjectWriter.cpp classELFObjectWriter : public MCObjectWriter { /// The target specific ELF writer instance. std::unique_ptr\u0026lt;MCELFObjectTargetWriter\u0026gt; TargetObjectWriter; DenseMap\u0026lt;const MCSectionELF *, std::vector\u0026lt;ELFRelocationEntry\u0026gt;\u0026gt; Relocations; DenseMap\u0026lt;const MCSymbolELF *, const MCSymbolELF *\u0026gt; Renames; bool EmitAddrsigSection = false; std::vector\u0026lt;const MCSymbol *\u0026gt; AddrsigSyms; // ... friend struct ELFWriter; }; Interfaces:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/elf-writer/elf-object-writer/",
	"title": "Elf Object Writer",
	"tags": [],
	"description": "",
	"content": " References:\n [LLVM source code (version 11)]  Inheritance/Member relation\n// parent --\u0026gt; child MCObjectWriter -\u0026gt; ELFObjectWriter // class .member struct ELFWriter{ ELFObjectWriter \u0026amp;OWriter; }  States:\n// llvm/lib/MC/ELFObjectWriter.cpp  classELFObjectWriter : public MCObjectWriter { /// The target specific ELF writer instance.  std::unique_ptr\u0026lt;MCELFObjectTargetWriter\u0026gt; TargetObjectWriter; DenseMap\u0026lt;const MCSectionELF *, std::vector\u0026lt;ELFRelocationEntry\u0026gt;\u0026gt; Relocations; DenseMap\u0026lt;const MCSymbolELF *, const MCSymbolELF *\u0026gt; Renames; bool EmitAddrsigSection = false; std::vector\u0026lt;const MCSymbol *\u0026gt; AddrsigSyms; // ...  friend struct ELFWriter; };  Interfaces:\n// llvm/lib/MC/ELFObjectWriter.cpp  classELFObjectWriter : public MCObjectWriter { // ... private: bool hasRelocationAddend() const; bool shouldRelocateWithSymbol(const MCAssembler \u0026amp;Asm, const MCSymbolRefExpr *RefA, const MCSymbolELF *Sym, uint64_t C, unsigned Type) const; public: void reset() override; bool isSymbolRefDifferenceFullyResolvedImpl(const MCAssembler \u0026amp;Asm, const MCSymbol \u0026amp;SymA, const MCFragment \u0026amp;FB, bool InSet, bool IsPCRel) const override; virtual bool checkRelocation(MCContext \u0026amp;Ctx, SMLoc Loc, const MCSectionELF *From, const MCSectionELF *To) { return true; } void recordRelocation(MCAssembler \u0026amp;Asm, const MCAsmLayout \u0026amp;Layout, const MCFragment *Fragment, const MCFixup \u0026amp;Fixup, MCValue Target, uint64_t \u0026amp;FixedValue) override; };  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/relocations/",
	"title": "Relocations in CodeGen",
	"tags": [],
	"description": "",
	"content": " References:\n [](#)  Relocation basics  Relocation Sections in ELF Relocation during Linking in LLD  ELFRelocationEntry // llvm/include/llvm/MC/MCELFObjectWriter.h  struct ELFRelocationEntry { uint64_t Offset; // Where is the relocation.  const MCSymbolELF *Symbol; // The symbol to relocate with.  unsigned Type; // The type of the relocation.  uint64_t Addend; // The addend to use.  const MCSymbolELF *OriginalSymbol; // The original value of Symbol if we changed it.  uint64_t OriginalAddend; // The original value of addend.  ELFRelocationEntry(uint64_t Offset, const MCSymbolELF *Symbol, unsigned Type, uint64_t Addend, const MCSymbolELF *OriginalSymbol, uint64_t OriginalAddend) : Offset(Offset), Symbol(Symbol), Type(Type), Addend(Addend), OriginalSymbol(OriginalSymbol), OriginalAddend(OriginalAddend) {} void print(raw_ostream \u0026amp;Out) const { Out \u0026lt;\u0026lt; \u0026#34;Off=\u0026#34; \u0026lt;\u0026lt; Offset \u0026lt;\u0026lt; \u0026#34;, Sym=\u0026#34; \u0026lt;\u0026lt; Symbol \u0026lt;\u0026lt; \u0026#34;, Type=\u0026#34; \u0026lt;\u0026lt; Type \u0026lt;\u0026lt; \u0026#34;, Addend=\u0026#34; \u0026lt;\u0026lt; Addend \u0026lt;\u0026lt; \u0026#34;, OriginalSymbol=\u0026#34; \u0026lt;\u0026lt; OriginalSymbol \u0026lt;\u0026lt; \u0026#34;, OriginalAddend=\u0026#34; \u0026lt;\u0026lt; OriginalAddend; } void dump() const { print(errs()); } };  ELFObjectWriter and Relocations // llvm/lib/MC/ELFObjectWriter.cpp  classELFObjectWriter : public MCObjectWriter { // ...  DenseMap\u0026lt;const MCSectionELF *, std::vector\u0026lt;ELFRelocationEntry\u0026gt;\u0026gt; Relocations; // ...  bool hasRelocationAddend() const; // yes for MIPS64  bool shouldRelocateWithSymbol(const MCAssembler \u0026amp;Asm, const MCSymbolRefExpr *RefA, const MCSymbolELF *Sym, uint64_t C, unsigned Type) const; public: ELFObjectWriter(std::unique_ptr\u0026lt;MCELFObjectTargetWriter\u0026gt; MOTW) : TargetObjectWriter(std::move(MOTW)) {} void reset() override { Relocations.clear(); Renames.clear(); MCObjectWriter::reset(); } bool isSymbolRefDifferenceFullyResolvedImpl(const MCAssembler \u0026amp;Asm, const MCSymbol \u0026amp;SymA, const MCFragment \u0026amp;FB, bool InSet, bool IsPCRel) const override; virtual bool checkRelocation(MCContext \u0026amp;Ctx, SMLoc Loc, const MCSectionELF *From, const MCSectionELF *To) { return true; } void recordRelocation(MCAssembler \u0026amp;Asm, const MCAsmLayout \u0026amp;Layout, const MCFragment *Fragment, const MCFixup \u0026amp;Fixup, MCValue Target, uint64_t \u0026amp;FixedValue) override; void executePostLayoutBinding(MCAssembler \u0026amp;Asm, const MCAsmLayout \u0026amp;Layout) override; // ... }  Relocations is used in\n ELFObjectWriter::reset() ELFWriter::createRelocationSection(). If OWriter.Relocations[\u0026amp;Sec] is not empty, then a relocation section will be created, with section name xxx.rela or xxx.rel. ELFWriter::writeRelocations(), this is how the relocation section being finally written tothe ELF file??  ELFWriter::writeRelocations().\nvoid ELFWriter::writeRelocations(const MCAssembler \u0026amp;Asm, const MCSectionELF \u0026amp;Sec) { std::vector\u0026lt;ELFRelocationEntry\u0026gt; \u0026amp;Relocs = OWriter.Relocations[\u0026amp;Sec]; // We record relocations by pushing to the end of a vector. Reverse the vector  // to get the relocations in the order they were created.  // In most cases that is not important, but it can be for special sections  // (.eh_frame) or specific relocations (TLS optimizations on SystemZ).  std::reverse(Relocs.begin(), Relocs.end()); // Sort the relocation entries. MIPS needs this.  OWriter.TargetObjectWriter-\u0026gt;sortRelocs(Asm, Relocs); for (unsigned i = 0, e = Relocs.size(); i != e; ++i) { const ELFRelocationEntry \u0026amp;Entry = Relocs[e - i - 1]; unsigned Index = Entry.Symbol ? Entry.Symbol-\u0026gt;getIndex() : 0; if (is64Bit()) { write(Entry.Offset); if (OWriter.TargetObjectWriter-\u0026gt;getEMachine() == ELF::EM_MIPS) { write(uint32_t(Index)); write(OWriter.TargetObjectWriter-\u0026gt;getRSsym(Entry.Type)); write(OWriter.TargetObjectWriter-\u0026gt;getRType3(Entry.Type)); write(OWriter.TargetObjectWriter-\u0026gt;getRType2(Entry.Type)); write(OWriter.TargetObjectWriter-\u0026gt;getRType(Entry.Type)); } else { struct ELF::Elf64_Rela ERE64; ERE64.setSymbolAndType(Index, Entry.Type); write(ERE64.r_info); } if (hasRelocationAddend()) write(Entry.Addend); } else { write(uint32_t(Entry.Offset)); struct ELF::Elf32_Rela ERE32; ERE32.setSymbolAndType(Index, Entry.Type); write(ERE32.r_info); if (hasRelocationAddend()) write(uint32_t(Entry.Addend)); if (OWriter.TargetObjectWriter-\u0026gt;getEMachine() == ELF::EM_MIPS) { if (uint32_t RType = OWriter.TargetObjectWriter-\u0026gt;getRType2(Entry.Type)) { write(uint32_t(Entry.Offset)); ERE32.setSymbolAndType(0, RType); write(ERE32.r_info); write(uint32_t(0)); } if (uint32_t RType = OWriter.TargetObjectWriter-\u0026gt;getRType3(Entry.Type)) { write(uint32_t(Entry.Offset)); ERE32.setSymbolAndType(0, RType); write(ERE32.r_info); write(uint32_t(0)); } } } } }  Relocations creation/insertion Relocation section creation created in ELFWriter::createRelocationSection. If an section Sec contains relocatable entries, it will be stored in a vector OWriter.Relocations[\u0026amp;Sec]. If this vector is not empty(), a new section xxx.rela or xxx.rel will be created.\n// llvm/lib/MC/ELFObjectWriter.cpp  MCSectionELF *ELFWriter::createRelocationSection(MCContext \u0026amp;Ctx, const MCSectionELF \u0026amp;Sec) { if (OWriter.Relocations[\u0026amp;Sec].empty()) return nullptr; const StringRef SectionName = Sec.getSectionName(); std::string RelaSectionName = hasRelocationAddend() ? \u0026#34;.rela\u0026#34; : \u0026#34;.rel\u0026#34;; RelaSectionName += SectionName; unsigned EntrySize; if (hasRelocationAddend()) EntrySize = is64Bit() ? sizeof(ELF::Elf64_Rela) : sizeof(ELF::Elf32_Rela); else EntrySize = is64Bit() ? sizeof(ELF::Elf64_Rel) : sizeof(ELF::Elf32_Rel); unsigned Flags = 0; if (Sec.getFlags() \u0026amp; ELF::SHF_GROUP) Flags = ELF::SHF_GROUP; MCSectionELF *RelaSection = Ctx.createELFRelSection( RelaSectionName, hasRelocationAddend() ? ELF::SHT_RELA : ELF::SHT_REL, Flags, EntrySize, Sec.getGroup(), \u0026amp;Sec); RelaSection-\u0026gt;setAlignment(is64Bit() ? Align(8) : Align(4)); return RelaSection; }  The above function creates a relocation section, by invoking Ctx.createELFRelSection(). It will setting up with section name, entry size, flags, alignment, and a pointer to the original section.\n// llvm/lib/MC/MCContext.cpp  MCSectionELF *MCContext::createELFRelSection(const Twine \u0026amp;Name, unsigned Type, unsigned Flags, unsigned EntrySize, const MCSymbolELF *Group, const MCSectionELF *RelInfoSection) { StringMap\u0026lt;bool\u0026gt;::iterator I; bool Inserted; std::tie(I, Inserted) = RelSecNames.insert(std::make_pair(Name.str(), true)); return createELFSectionImpl( I-\u0026gt;getKey(), Type, Flags, SectionKind::getReadOnly(), EntrySize, Group, true, cast\u0026lt;MCSymbolELF\u0026gt;(RelInfoSection-\u0026gt;getBeginSymbol())); }  Then in ELFWriter::writeObject(), this relocation section is first pushed back to a vector containing all relocation sections Reclocations and then the relocation entries will be written to the object file by scanning of all relocation sections.\n// llvm/lib/MC/ELFObjectWriter.cpp  uint64_t ELFWriter::writeObject(MCAssembler \u0026amp;Asm, const MCAsmLayout \u0026amp;Layout) { std::vector\u0026lt;MCSectionELF *\u0026gt; Relocations; for (MCSection \u0026amp;Sec : Asm) { // ... create relocation section .xxx.rela for .xxx  MCSectionELF *RelSection = createRelocationSection(Ctx, Section); // ...  if (RelSection) { SectionIndexMap[RelSection] = addToSectionTable(RelSection); Relocations.push_back(RelSection); } } // ... scan all relocation sections and write them to object file  // by calling writeRelocations()  for (MCSectionELF *RelSection : Relocations) { align(RelSection-\u0026gt;getAlignment()); // Remember the offset into the file for this section.  uint64_t SecStart = W.OS.tell(); writeRelocations(Asm, cast\u0026lt;MCSectionELF\u0026gt;(*RelSection-\u0026gt;getLinkedToSection())); uint64_t SecEnd = W.OS.tell(); SectionOffsets[RelSection] = std::make_pair(SecStart, SecEnd); } }  Write relocation section to object file writeRelocations() is where the .xxx.rel section being filled up based on the vector of relocation entries stored in OWriter.Relocations[\u0026amp;Sec]:\nvoid ELFWriter::writeRelocations(const MCAssembler \u0026amp;Asm, const MCSectionELF \u0026amp;Sec) { std::vector\u0026lt;ELFRelocationEntry\u0026gt; \u0026amp;Relocs = OWriter.Relocations[\u0026amp;Sec]; // We record relocations by pushing to the end of a vector. Reverse the vector  // to get the relocations in the order they were created.  // In most cases that is not important, but it can be for special sections  // (.eh_frame) or specific relocations (TLS optimizations on SystemZ).  std::reverse(Relocs.begin(), Relocs.end()); // Sort the relocation entries. MIPS needs this.  OWriter.TargetObjectWriter-\u0026gt;sortRelocs(Asm, Relocs); for (unsigned i = 0, e = Relocs.size(); i != e; ++i) { const ELFRelocationEntry \u0026amp;Entry = Relocs[e - i - 1]; unsigned Index = Entry.Symbol ? Entry.Symbol-\u0026gt;getIndex() : 0; if (is64Bit()) { write(Entry.Offset); if (OWriter.TargetObjectWriter-\u0026gt;getEMachine() == ELF::EM_MIPS) { write(uint32_t(Index)); write(OWriter.TargetObjectWriter-\u0026gt;getRSsym(Entry.Type)); write(OWriter.TargetObjectWriter-\u0026gt;getRType3(Entry.Type)); write(OWriter.TargetObjectWriter-\u0026gt;getRType2(Entry.Type)); write(OWriter.TargetObjectWriter-\u0026gt;getRType(Entry.Type)); } else { struct ELF::Elf64_Rela ERE64; ERE64.setSymbolAndType(Index, Entry.Type); write(ERE64.r_info); } if (hasRelocationAddend()) write(Entry.Addend); } else { write(uint32_t(Entry.Offset)); struct ELF::Elf32_Rela ERE32; ERE32.setSymbolAndType(Index, Entry.Type); write(ERE32.r_info); if (hasRelocationAddend()) write(uint32_t(Entry.Addend)); if (OWriter.TargetObjectWriter-\u0026gt;getEMachine() == ELF::EM_MIPS) { if (uint32_t RType = OWriter.TargetObjectWriter-\u0026gt;getRType2(Entry.Type)) { write(uint32_t(Entry.Offset)); ERE32.setSymbolAndType(0, RType); write(ERE32.r_info); write(uint32_t(0)); } if (uint32_t RType = OWriter.TargetObjectWriter-\u0026gt;getRType3(Entry.Type)) { write(uint32_t(Entry.Offset)); ERE32.setSymbolAndType(0, RType); write(ERE32.r_info); write(uint32_t(0)); } } } } }  Relocation for .text All relocations for TextSection is stored in OWriter.Relocations[\u0026amp;TextSection].\nEach relocation entry is created by ELFObjectWriter. See memo on ELFObjectWriter class\nshouldRelocationWithSymbol MCAssembler::layout ==\u0026gt; MCAssembler::handleFixup() ==\u0026gt; ELFObjectWriter::recordRelocation() ==\u0026gt; ELFObjectWriter::shouldRelocateWithSymbol() ==\u0026gt;  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/inst-fetch/find_tb/",
	"title": "Find_tb",
	"tags": [],
	"description": "",
	"content": " Reference reference\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/inst-fetch/tb-invalidate/",
	"title": "Translation Block Invalidate",
	"tags": [],
	"description": "",
	"content": " References:\n Translator Internals  The target CPUs have many internal states which change the way it evaluates instructions. In order to achieve a good speed, the translation phase considers that some state information of the virtual CPU cannot change in it. The state is recorded in the Translation Block (TB). If the state changes (e.g. privilege level), a new TB will be generated and the previous TB won’t be used anymore until the state matches the state recorded in the previous TB. The same idea can be applied to other aspects of the CPU state. For example, on x86, if the SS, DS and ES segments have a zero base, then the translator does not even generate an addition for the segment base.\nSelf modifying code and translated code invalidation To simulate a self modified code, previous translated block must be invalidated after the original code is modified.\nCorrect translated code invalidation is done efficiently by maintaining a linked list of every translated block contained in a given page. (How this is related to a page??? == MMU emulation)\nMMU emulation and translation blocks In soft MMU mode, the MMU virtual to physical address translation is done at every memory access.\nQEMU soft MMU uses an address translation cache (TLB) to speed up the translation.\nIn order to avoid flushing the translated code each time the MMU mappings change, all caches in QEMU are physically indexed. This means that each basic block is indexed with its physical address.\nIn order to avoid invalidating the basic block chain when MMU mappings change, chaining is only performed within a page, i.e. when the destination of the jump shares a page with the basic block that is performing the jump.\nMMU can also distinguish RAM and ROM memory areas from MMIO memory areas.\nAccess to RAM/ROM is faster than MMIO because the translation cache also hosts the offset between guest address and host memory. But access MMIO memory areas instead calls out to C code for device emulation.\nMMU helps tracking dirty pages and pages pointed to by translation blocks.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/addr-trans/",
	"title": "Addr Trans",
	"tags": [],
	"description": "",
	"content": " Reference reference\nAll memory translation requests finally invokes a callback func env-\u0026gt;tlb-\u0026gt;map_address\nExample code:\n// target/mips/helper.c static int get_seg_physical_address(CPUMIPSState *env, hwaddr *physical, int *prot, target_ulong real_address, int rw, int access_type, int mmu_idx, unsigned int am, bool eu, target_ulong segmask, hwaddr physical_base) { int ret; int mapped = is_seg_am_mapped(am, eu, mmu_idx); if (mapped \u0026lt; 0) { /* is_seg_am_mapped can report TLBRET_BADADDR */ return mapped; } else if (mapped) { /* The segment is TLB mapped */ ret = env-\u0026gt;tlb-\u0026gt;map_address(env, physical, prot, real_address, rw, access_type); } else { /* The segment is unmapped */ *physical = physical_base | (real_address \u0026amp; segmask); *prot = PAGE_READ | PAGE_WRITE | PAGE_EXEC; ret = TLBRET_MATCH; } return ret; }  env-\u0026gt;tlb-\u0026gt;map_address is assigned in translate_init.inc.c:\n// target/mips/translate_init.inc.c static void r4k_mmu_init (CPUMIPSState *env, const mips_def_t *def) { env-\u0026gt;tlb-\u0026gt;nb_tlb = 1 + ((def-\u0026gt;CP0_Config1 \u0026gt;\u0026gt; CP0C1_MMU) \u0026amp; 63); env-\u0026gt;tlb-\u0026gt;map_address = \u0026amp;r4k_map_address; env-\u0026gt;tlb-\u0026gt;helper_tlbwi = r4k_helper_tlbwi; env-\u0026gt;tlb-\u0026gt;helper_tlbwr = r4k_helper_tlbwr; env-\u0026gt;tlb-\u0026gt;helper_tlbp = r4k_helper_tlbp; env-\u0026gt;tlb-\u0026gt;helper_tlbr = r4k_helper_tlbr; env-\u0026gt;tlb-\u0026gt;helper_tlbinv = r4k_helper_tlbinv; env-\u0026gt;tlb-\u0026gt;helper_tlbinvf = r4k_helper_tlbinvf; qemu_printf(\u0026#34;env-\u0026gt;tlb-\u0026gt;map_address = \u0026amp;r4k_map_address;\\n\u0026#34;); }  definition of r4k_map_address in MIPS helper.c:\n// target/mips/helper.c  /* MIPS32/MIPS64 R4000-style MMU emulation */ int r4k_map_address(CPUMIPSState *env, hwaddr *physical, int *prot, target_ulong address, int rw, int access_type) { uint16_t ASID = env-\u0026gt;CP0_EntryHi \u0026amp; env-\u0026gt;CP0_EntryHi_ASID_mask; uint32_t MMID = env-\u0026gt;CP0_MemoryMapID; bool mi = !!((env-\u0026gt;CP0_Config5 \u0026gt;\u0026gt; CP0C5_MI) \u0026amp; 1); uint32_t tlb_mmid; int i; MMID = mi ? MMID : (uint32_t) ASID; #if defined(TARGET_CHERI)  unsigned gclg_bit; if (address \u0026lt; 0x4000000000000000) { /* useg, xuseg */ gclg_bit = CP0EnHi_CLGU; } else if (address \u0026lt; 0x8000000000000000) { /* xsseg */ gclg_bit = CP0EnHi_CLGS; } else if (address \u0026lt; 0xFFFFFFFFC0000000) { /* xkphys (won\u0026#39;t be called), xkseg, kseg0, kseg1 */ gclg_bit = CP0EnHi_CLGK; } else if (address \u0026lt; 0xFFFFFFFFE0000000) { /* sseg */ gclg_bit = CP0EnHi_CLGS; } else { /* kseg3 */ gclg_bit = CP0EnHi_CLGK; } bool gclg = !!(env-\u0026gt;CP0_EntryHi \u0026amp; (1UL \u0026lt;\u0026lt; gclg_bit)); #endif  for (i = 0; i \u0026lt; env-\u0026gt;tlb-\u0026gt;tlb_in_use; i++) { r4k_tlb_t *tlb = \u0026amp;env-\u0026gt;tlb-\u0026gt;mmu.r4k.tlb[i]; /* 1k pages are not supported. */ target_ulong mask = tlb-\u0026gt;PageMask | ~(TARGET_PAGE_MASK \u0026lt;\u0026lt; 1); target_ulong tag = address \u0026amp; ~mask; target_ulong VPN = tlb-\u0026gt;VPN \u0026amp; ~mask; #if defined(TARGET_MIPS64)  tag \u0026amp;= env-\u0026gt;SEGMask; #endif  /* Check ASID/MMID, virtual page number \u0026amp; size */ tlb_mmid = mi ? tlb-\u0026gt;MMID : (uint32_t) tlb-\u0026gt;ASID; if ((tlb-\u0026gt;G == 1 || tlb_mmid == MMID) \u0026amp;\u0026amp; VPN == tag \u0026amp;\u0026amp; !tlb-\u0026gt;EHINV) { /* TLB match */ int n = !!(address \u0026amp; mask \u0026amp; ~(mask \u0026gt;\u0026gt; 1)); /* Check access rights */ if (!(n ? tlb-\u0026gt;V1 : tlb-\u0026gt;V0)) { return TLBRET_INVALID; } #if defined(TARGET_CHERI)  if (rw == MMU_DATA_CAP_STORE) { /* * If we\u0026#39;re trying to do a cap-store, first check for the * dirty/store-permitted bit before looking at the the * store-capability inhibit. */ if (!(n ? tlb-\u0026gt;D1 : tlb-\u0026gt;D0)) { // printf(\u0026#34;failed checking the dirty/store-permitted bit in TLB\\n\u0026#34;);  return TLBRET_DIRTY; } if (n ? tlb-\u0026gt;S1 : tlb-\u0026gt;S0) { // printf(\u0026#34;failed checking the dirty/store-permitted bit in TLB\\n\u0026#34;);  return TLBRET_S; } } #else  if (rw == MMU_INST_FETCH \u0026amp;\u0026amp; (n ? tlb-\u0026gt;XI1 : tlb-\u0026gt;XI0)) { return TLBRET_XI; } if (rw == MMU_DATA_LOAD \u0026amp;\u0026amp; (n ? tlb-\u0026gt;RI1 : tlb-\u0026gt;RI0)) { return TLBRET_RI; } #endif /* TARGET_CHERI */ if (( (rw != MMU_DATA_STORE) #if defined(TARGET_CHERI)  \u0026amp;\u0026amp; (rw != MMU_DATA_CAP_STORE) #endif  ) || (n ? tlb-\u0026gt;D1 : tlb-\u0026gt;D0)) { *physical = tlb-\u0026gt;PFN[n] | (address \u0026amp; (mask \u0026gt;\u0026gt; 1)); *prot = PAGE_READ; if (n ? tlb-\u0026gt;D1 : tlb-\u0026gt;D0) { *prot |= PAGE_WRITE; } #if !defined(TARGET_CHERI)  if (!(n ? tlb-\u0026gt;XI1 : tlb-\u0026gt;XI0)) { #else  if (true) { #endif  *prot |= PAGE_EXEC; } #if defined(TARGET_CHERI)  if (n ? tlb-\u0026gt;L1 : tlb-\u0026gt;L0) { *prot |= PAGE_LC_CLEAR; } bool pclg = n ? tlb-\u0026gt;CLG1 : tlb-\u0026gt;CLG0; if (pclg != gclg) { *prot |= PAGE_LC_TRAP; } #endif  return TLBRET_MATCH; } return TLBRET_DIRTY; } } return TLBRET_NOMATCH; }  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/inst-fetch/inst-trans/",
	"title": "Inst Trans",
	"tags": [],
	"description": "",
	"content": " References:\n QEMU source ~4.2.93 QEMU Detailed Study Translator Internals  decode_opc Call path:\n// cpu_exec ---\u0026gt; translator_loop cpu_exec =\u0026gt; tb_find =\u0026gt; if (not found): tb_gen_code // accel/tcg/translate-all.c  =\u0026gt; gen_intermediate_code // target/mips/translate.c  =\u0026gt; translator_loop // translator_loop calling callbacks translator_loop // accel/tcg/translator.c =\u0026gt; ops-\u0026gt;translate_insn =\u0026gt; mips_tr_translate_insn // target/mips/translate.c  =\u0026gt; riscv_tr_translate_insn // target/mips/translate.c  // impl of translate_insn  mips_tr_ops.translate_insn = mips_tr_translate_insn // registered call back // target/mips/translate.c  =\u0026gt; decode_opc // target/mips/translate.c  =\u0026gt; decode_micromips_opc // target/mips/translate.c  Steps:\n check instruction address is on word boundary: ctx-\u0026gt;base.pc_next   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/inst-fetch/",
	"title": "Instruction Fetch and PCC checks",
	"tags": [],
	"description": "",
	"content": " References:\n QEMU source ~4.2.93\n QEMU Detailed Study\n Translator Internals\n  QEMU start to instruction fetch Some call paths for instruction fetch and decoding:\n// cpu_exec callers cpu_loop // linux-user/mips/cpu_loop.c =\u0026gt; cpu_exec qemu_tcg_init_vcpu // thread creation using fn pointer, cpus.c =\u0026gt; qemu_tcg_rr_cpu_thread_fn =\u0026gt; tcg_cpu_exec =\u0026gt; cpu_exec qemu_tcg_init_vcpu // thread creation using fn pointer, cpus.c =\u0026gt; qemu_tcg_cpu_thread_fn =\u0026gt; tcg_cpu_exec =\u0026gt; cpu_exec // cpu_exec ---\u0026gt; translator_loop cpu_exec =\u0026gt; tb_find =\u0026gt; if (not found): tb_gen_code // accel/tcg/translate-all.c  =\u0026gt; gen_intermediate_code // target/mips/translate.c  =\u0026gt; translator_loop // translator_loop calling callbacks translator_loop // accel/tcg/translator.c =\u0026gt; ops-\u0026gt;translate_insn =\u0026gt; mips_tr_translate_insn // target/mips/translate.c  =\u0026gt; riscv_tr_translate_insn // target/mips/translate.c  // impl of translate_insn  mips_tr_ops.translate_insn = mips_tr_translate_insn // registered call back // target/mips/translate.c  =\u0026gt; decode_opc // target/mips/translate.c  =\u0026gt; decode_micromips_opc // target/mips/translate.c  Instruction fetch and translation mips_tr_translate_insn calls gen_check_pcc_bounds_next_inst() to generate instruction on checking the PCC bounds, simulating a PCC check in CHERI.\nstatic void mips_tr_translate_insn(DisasContextBase *dcbase, CPUState *cs) { // XXX: we don\u0026#39;t support micromips, etc. so we can hardcode 4 bytes as the  // instruction size (see assert below).  gen_check_pcc_bounds_next_inst(ctx, 4); ... else if (!(ctx-\u0026gt;hflags \u0026amp; MIPS_HFLAG_M16)) { ctx-\u0026gt;opcode = cpu_ldl_code(env, ctx-\u0026gt;base.pc_next); insn_bytes = 4; gen_mips_log_instr32(ctx); decode_opc(env, ctx); } else if (ctx-\u0026gt;insn_flags \u0026amp; ASE_MICROMIPS) { gen_mips_log_instr_unsupported(ctx, \u0026#34;micromips\u0026#34;); ctx-\u0026gt;opcode = cpu_lduw_code(env, ctx-\u0026gt;base.pc_next); insn_bytes = decode_micromips_opc(env, ctx); } else ... }  gen_check_pcc_bounds_next_inst is implemented as below. The PCC check is done based on the base and bound information stored in the current context DisasContext *ctx. So when does the ctx.base.pc_first and ctx.base.pcc_top is updated with new base and bounds information?\nstatic inline void gen_check_pcc_bounds_next_inst(DisasContext *ctx, uint32_t num_bytes) { #ifdef TARGET_CHERI  if (have_cheri_tb_flags(ctx, TB_FLAG_PCC_FULL_AS)) { return; // PCC spans the full address space, no need to check  } // Note: PC can only be incremented since a branch exits the TB, so checking  // for pc_next \u0026lt; pcc.base should not be needed. Add a debug assertion in  // case this assumption no longer holds in the future.  // Note: we don\u0026#39;t have to check for wraparound here since this case is  // already handled by the TB_FLAG_PCC_FULL_AS check above. Wraparound is  // permitted to avoid any differences with non-CHERI enabled CPUs.  tcg_debug_assert(ctx-\u0026gt;base.pc_next \u0026gt;= ctx-\u0026gt;base.pc_first); if (unlikely(ctx-\u0026gt;base.pc_next + num_bytes \u0026gt; ctx-\u0026gt;base.pcc_top)) { cheri_tcg_prepare_for_unconditional_exception(\u0026amp;ctx-\u0026gt;base); gen_raise_pcc_violation(\u0026amp;ctx-\u0026gt;base, ctx-\u0026gt;base.pc_next, num_bytes); } #endif }  Instruction translation cache tb_find will search a translated basic block and avoid re-translation.\nstatic inline TranslationBlock *tb_find(CPUState *cpu, TranslationBlock *last_tb, int tb_exit, uint32_t cf_mask) { TranslationBlock *tb; target_ulong cs_base, cs_top = 0, pc; uint32_t cheri_flags = 0; uint32_t flags; tb = tb_lookup__cpu_state(cpu, \u0026amp;pc, \u0026amp;cs_base, \u0026amp;cs_top, \u0026amp;cheri_flags, \u0026amp;flags, cf_mask); if (tb == NULL) { mmap_lock(); tb = tb_gen_code(cpu, pc, cs_base, cs_top, cheri_flags, flags, cf_mask); mmap_unlock(); /* We add the TB in the virtual pc hash table for the fast lookup */ atomic_set(\u0026amp;cpu-\u0026gt;tb_jmp_cache[tb_jmp_cache_hash_func(pc)], tb); } ... }  Instruction execution After a basic block is translated. It will start execution in cpu_loop_exec_tb\n// accel/tcg/cpu-exec.c  /* main execution loop */ int cpu_exec(CPUState *cpu) { ... /* if an exception is pending, we execute it here */ while (!cpu_handle_exception(cpu, \u0026amp;ret)) { TranslationBlock *last_tb = NULL; int tb_exit = 0; while (!cpu_handle_interrupt(cpu, \u0026amp;last_tb)) { uint32_t cflags = cpu-\u0026gt;cflags_next_tb; TranslationBlock *tb; ... tb = tb_find(cpu, last_tb, tb_exit, cflags); cpu_loop_exec_tb(cpu, tb, \u0026amp;last_tb, \u0026amp;tb_exit); ... } } ... }  cpu_loop_exec_tb\n// call path: cpu_loop_exec_tb =\u0026gt; cpu_tb_exec =\u0026gt; tcg_qemu_tb_exec =\u0026gt; // accel/tcg/cpu-exec.c cpu_tb_exec // tcg/tci.c tcg_qemu_tb_exec  tcg_qemu_tb_exec can have two definitions:\n// include/tcg/tcg.h #ifdef HAVE_TCG_QEMU_TB_EXEC uintptr_t tcg_qemu_tb_exec(CPUArchState *env, uint8_t *tb_ptr); #else # define tcg_qemu_tb_exec(env, tb_ptr) \\ ((uintptr_t (*)(void *, void *))tcg_ctx-\u0026gt;code_gen_prologue)(env, tb_ptr) #endif  In this CHERI based version, the second version is used, where a code pointer(callback) is used: tcg_ctx-\u0026gt;code_gen_prologue. It can be initialized with different functions under differnt qemu modes, system mode, linux user, and bsd user mode.\nAll above code pointers are initialized using tcg_prologue_init:\n// tcg/tcg.c  void tcg_prologue_init(TCGContext *s) { size_t prologue_size, total_size; void *buf0, *buf1; /* Put the prologue at the beginning of code_gen_buffer. */ buf0 = s-\u0026gt;code_gen_buffer; total_size = s-\u0026gt;code_gen_buffer_size; s-\u0026gt;code_ptr = buf0; s-\u0026gt;code_buf = buf0; s-\u0026gt;data_gen_ptr = NULL; s-\u0026gt;code_gen_prologue = buf0; ... /* Generate the prologue. */ tcg_target_qemu_prologue(s); ... /* Deduct the prologue from the buffer. */ prologue_size = tcg_current_code_size(s); s-\u0026gt;code_gen_ptr = buf1; s-\u0026gt;code_gen_buffer = buf1; s-\u0026gt;code_buf = buf1; total_size -= prologue_size; s-\u0026gt;code_gen_buffer_size = total_size; tcg_register_jit(s-\u0026gt;code_gen_buffer, total_size); #ifdef DEBUG_DISAS  if (qemu_loglevel_mask(CPU_LOG_TB_OUT_ASM)) { FILE *logfile = qemu_log_lock(); qemu_log(\u0026#34;PROLOGUE: [size=%zu]\\n\u0026#34;, prologue_size); if (s-\u0026gt;data_gen_ptr) { size_t code_size = s-\u0026gt;data_gen_ptr - buf0; size_t data_size = prologue_size - code_size; size_t i; log_disas(buf0, code_size); for (i = 0; i \u0026lt; data_size; i += sizeof(tcg_target_ulong)) { if (sizeof(tcg_target_ulong) == 8) { qemu_log(\u0026#34;0x%08\u0026#34; PRIxPTR \u0026#34;: .quad 0x%016\u0026#34; PRIx64 \u0026#34;\\n\u0026#34;, (uintptr_t)s-\u0026gt;data_gen_ptr + i, *(uint64_t *)(s-\u0026gt;data_gen_ptr + i)); } else { qemu_log(\u0026#34;0x%08\u0026#34; PRIxPTR \u0026#34;: .long 0x%08x\\n\u0026#34;, (uintptr_t)s-\u0026gt;data_gen_ptr + i, *(uint32_t *)(s-\u0026gt;data_gen_ptr + i)); } } } else { log_disas(buf0, prologue_size); } qemu_log(\u0026#34;\\n\u0026#34;); qemu_log_flush(); qemu_log_unlock(logfile); } #endif  /* Assert that goto_ptr is implemented completely. */ if (TCG_TARGET_HAS_goto_ptr) { tcg_debug_assert(s-\u0026gt;code_gen_epilogue != NULL); } }  We can see that TCGContext.code_gen_buffer is assigned to tcg_ctx-\u0026gt;code_gen_prologue. So we need to find out where TCGContext.code_gen_buffer is pointing to.\ntcg_prologue_init is called in three places with different func pointers assigned to tcg_ctx, see code below:\n system mode init in accel/tcg/translate-all.c: linux user mode in linux-user/main.c: bsd user mode in bsd-user/main.c:  Now we focus on the system mode version:\n// accel/tcg/translate-all.c  /* Must be called before using the QEMU cpus. \u0026#39;tb_size\u0026#39; is the size (in bytes) allocated to the translation buffer. Zero means default size. */ void tcg_exec_init(unsigned long tb_size) { tcg_allowed = true; cpu_gen_init(); page_init(); tb_htable_init(); code_gen_alloc(tb_size); #if defined(CONFIG_SOFTMMU)  /* There\u0026#39;s no guest base to take into account, so go ahead and initialize the prologue now. */ tcg_prologue_init(tcg_ctx); #endif }  The tcg_ctx is a thread-local variable:\n__thread TCGContext *tcg_ctx; // accel/tcg/translate-all.c  Its TCGContext.code_gen_buffer is initialized in code_gen_alloc where a dynamic translator buffer is allocated using mmap().\n// accel/tcg/translate-all.c static inline void code_gen_alloc(size_t tb_size) { tcg_ctx-\u0026gt;code_gen_buffer_size = size_code_gen_buffer(tb_size); tcg_ctx-\u0026gt;code_gen_buffer = alloc_code_gen_buffer(); if (tcg_ctx-\u0026gt;code_gen_buffer == NULL) { fprintf(stderr, \u0026#34;Could not allocate dynamic translator buffer\\n\u0026#34;); exit(1); } }  tcg_prologue_init assigns this buffer to TCGContext.code_gen_prologue and also generates the prologue code in it by calling tcg_target_qemu_prologue(s);\ntcg_target_qemu_prologue() is a target dependent function implemented in tcg/arch/tcg-target.inc.c. It will generate a system wide prologue code. This piece of code is generated only once each QEMU running instance, generated upon QEMU starts.\nQEMU will generate different prologue when it run on different architectures. For example, if QEMU is runnign on x86 arch (32\u0026frasl;64), the prologue generating code is defined in tcg/i386/tcg-target.inc.c:\n// tcg/i386/tcg-target.inc.c  /* Generate global QEMU prologue and epilogue code */ static void tcg_target_qemu_prologue(TCGContext *s) { int i, stack_addend; /* TB prologue */ // we get here when the qemu is running on x86 hardware.  printf(\u0026#34;i386 tcg_target_qemu_prologue\\n\u0026#34;); /* Reserve some stack space, also for TCG temps. */ stack_addend = FRAME_SIZE - PUSH_SIZE; tcg_set_frame(s, TCG_REG_CALL_STACK, TCG_STATIC_CALL_ARGS_SIZE, CPU_TEMP_BUF_NLONGS * sizeof(long)); /* Save all callee saved registers. */ for (i = 0; i \u0026lt; ARRAY_SIZE(tcg_target_callee_save_regs); i++) { tcg_out_push(s, tcg_target_callee_save_regs[i]); } #if TCG_TARGET_REG_BITS == 32  tcg_out_ld(s, TCG_TYPE_PTR, TCG_AREG0, TCG_REG_ESP, (ARRAY_SIZE(tcg_target_callee_save_regs) + 1) * 4); tcg_out_addi(s, TCG_REG_ESP, -stack_addend); /* jmp *tb. */ tcg_out_modrm_offset(s, OPC_GRP5, EXT5_JMPN_Ev, TCG_REG_ESP, (ARRAY_SIZE(tcg_target_callee_save_regs) + 2) * 4 + stack_addend); #else # if !defined(CONFIG_SOFTMMU) \u0026amp;\u0026amp; TCG_TARGET_REG_BITS == 64  if (guest_base) { int seg = setup_guest_base_seg(); if (seg != 0) { x86_guest_base_seg = seg; } else if (guest_base == (int32_t)guest_base) { x86_guest_base_offset = guest_base; } else { /* Choose R12 because, as a base, it requires a SIB byte. */ x86_guest_base_index = TCG_REG_R12; tcg_out_movi(s, TCG_TYPE_PTR, x86_guest_base_index, guest_base); tcg_regset_set_reg(s-\u0026gt;reserved_regs, x86_guest_base_index); } } # endif  tcg_out_mov(s, TCG_TYPE_PTR, TCG_AREG0, tcg_target_call_iarg_regs[0]); tcg_out_addi(s, TCG_REG_ESP, -stack_addend); /* jmp *tb. */ tcg_out_modrm(s, OPC_GRP5, EXT5_JMPN_Ev, tcg_target_call_iarg_regs[1]); #endif  /* * Return path for goto_ptr. Set return value to 0, a-la exit_tb, * and fall through to the rest of the epilogue. */ s-\u0026gt;code_gen_epilogue = s-\u0026gt;code_ptr; tcg_out_movi(s, TCG_TYPE_REG, TCG_REG_EAX, 0); /* TB epilogue */ tb_ret_addr = s-\u0026gt;code_ptr; tcg_out_addi(s, TCG_REG_CALL_STACK, stack_addend); if (have_avx2) { tcg_out_vex_opc(s, OPC_VZEROUPPER, 0, 0, 0, 0); } for (i = ARRAY_SIZE(tcg_target_callee_save_regs) - 1; i \u0026gt;= 0; i--) { tcg_out_pop(s, tcg_target_callee_save_regs[i]); } tcg_out_opc(s, OPC_RET, 0, 0, 0); }  Every tcg_out_xxx function will compose an instruction that can run on the target x86 architecture. For example, a 4 byte size instruction can be emitted via tcg_out32(TCGContext *s, uint32_t v):\n#if TCG_TARGET_INSN_UNIT_SIZE \u0026lt;= 4 static __attribute__((unused)) inline void tcg_out32(TCGContext *s, uint32_t v) { if (TCG_TARGET_INSN_UNIT_SIZE == 4) { *s-\u0026gt;code_ptr++ = v; } else { tcg_insn_unit *p = s-\u0026gt;code_ptr; memcpy(p, \u0026amp;v, sizeof(v)); s-\u0026gt;code_ptr = p + (4 / TCG_TARGET_INSN_UNIT_SIZE); } }  Translation block chaining After each translated basic block is executed, QEMU uses the simulated Program Counter (PC) and other cpu state information such as CS segment based value, to find the next basic block.\nDirect block chaining. In order to accelerate the most common cases where the new simulated PC is known, QEMU can patch a basic block so that it jumps directly to the next one.\nMore  Find_tb   Reference reference More  Translation Block Invalidate  References: Translator Internals The target CPUs have many internal states which change the way it evaluates instructions. In order to achieve a good speed, the translation phase considers that some state information of the virtual CPU cannot change in it. The state is recorded in the Translation Block (TB). If the state changes (e.g. privilege level), a new TB will be generated and the previous TB won’t be used anymore until the state matches the state recorded in the previous TB.\n Inst Trans  References: QEMU source ~4.2.93 QEMU Detailed Study Translator Internals decode_opc Call path: // cpu_exec ---\u0026gt; translator_loop cpu_exec =\u0026gt; tb_find =\u0026gt; if (not found): tb_gen_code // accel/tcg/translate-all.c =\u0026gt; gen_intermediate_code // target/mips/translate.c =\u0026gt; translator_loop // translator_loop calling callbacks translator_loop // accel/tcg/translator.c =\u0026gt; ops-\u0026gt;translate_insn =\u0026gt; mips_tr_translate_insn // target/mips/translate.c =\u0026gt; riscv_tr_translate_insn // target/mips/translate.c // impl of translate_insn mips_tr_ops.translate_insn = mips_tr_translate_insn // registered call back // target/mips/translate.c =\u0026gt; decode_opc // target/mips/translate.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/translate/legacy-ldst/",
	"title": "QEMU impl for Legacy Load and Store Inst",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Where is the DDC check during legacy ld/st?  Reference reference\ncheck_cap Who call it?\ntarget_ulong check_ddc(CPUArchState *env, uint32_t perm, uint64_t ddc_offset, uint32_t len, uintptr_t retpc) void CHERI_HELPER_IMPL(ddc_check_bounds(CPUArchState *env, target_ulong addr, target_ulong num_bytes)) target_ulong CHERI_HELPER_IMPL(pcc_check_load(CPUArchState *env, target_ulong pcc_offset, MemOp op)) void CHERI_HELPER_IMPL(raise_exception_ddc_perms(CPUArchState *env, uint32_t required_perms)) void CHERI_HELPER_IMPL(raise_exception_ddc_bounds(CPUArchState *env, target_ulong addr, uint32_t num_bytes)) void CHERI_HELPER_IMPL(ccheck_load_pcrel(CPUArchState *env, target_ulong addr, uint32_t len))  ddc_check_bounds ddc_check_bounds caller _generate_ddc_checked_ptr, and upper callers:\ndecode_i64_mips16 decode_extended_mips16_opc decode_mips16_opc decode_micromips32_opc decode_micromips_opc decode_nanomips_32_48_opc decode_opc_special3_r6 // target/mips/translate.c:28026 decode_opc_special3 // target/mips/translate.c:28936 decode_opc // target/mips/translate.c:30893  =\u0026gt; gen_ld // target/mips/translate.c  =\u0026gt; generate_ddc_checked_load_ptr =\u0026gt; _generate_ddc_checked_ptr() =\u0026gt; ddc_check_bounds // relations between decode_xxx  mips_tr_ops.translate_insn = mips_tr_translate_insn // a member  =\u0026gt; decode_opc =\u0026gt; // todo  =\u0026gt; decode_micromips_opc =\u0026gt; decode_mips16_opc (not CHERI compatible) =\u0026gt; decode_i64_mips16 =\u0026gt; decode_extended_mips16_opc =\u0026gt; decode_i64_mips16 // todo gen_ldst_pair // target/mips/translate.c =\u0026gt; generate_ddc_checked_load_ptr =\u0026gt; _generate_ddc_checked_ptr() =\u0026gt; ddc_check_bounds // todo gen_ddc_interposed_ld_i64 // target/cheri-common/cheri-translate-util.h gen_ddc_interposed_ld_i32 // target/cheri-common/cheri-translate-util.h =\u0026gt; generate_ddc_checked_load_ptr =\u0026gt; _generate_ddc_checked_ptr() =\u0026gt; ddc_check_bounds // todo generate_ddc_checked_store_ptr =\u0026gt; _generate_ddc_checked_ptr() =\u0026gt; ddc_check_bounds // todo generate_ddc_checked_rmw_ptr =\u0026gt; _generate_ddc_checked_ptr() =\u0026gt; ddc_check_bounds  check_ddc Who calls check_ddc?\ntarget_ulong CHERI_HELPER_IMPL(ccheck_load_right(CPUArchState *env, target_ulong offset, uint32_t len)) target_ulong CHERI_HELPER_IMPL(ccheck_store(CPUArchState *env, target_ulong offset, uint32_t len)) target_ulong CHERI_HELPER_IMPL(ccheck_load(CPUArchState *env, target_ulong offset, uint32_t len)) static inline target_ulong ccheck_store_right(CPUMIPSState *env, target_ulong offset, uint32_t len, uintptr_t retpc) void helper_swl(CPUMIPSState *env, target_ulong arg1, target_ulong arg2, int mem_idx) void helper_sdl(CPUMIPSState *env, target_ulong arg1, target_ulong arg2, int mem_idx)  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/vm/",
	"title": "Vm",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  When/Where does a .text page being mapped?  References:\n 2.5 Memory Management Chapter 7 Virtual Memory System   Overview Reference: 2.5 Memory Management\na process can change the size of its text segment only when the segment\u0026rsquo;s contents are overlaid with data from the filesystem, or when debugging takes place.\nThe entire contents of a process address space do not need to be resident for a process to execute. If a process references a part of its address space that is not resident in main memory, the system pages the necessary information into memory. (Where?)\nWhen system resources are scarce, the system uses a two-level approach to maintain available resources. If a modest amount of memory is available, the system will take memory resources away from processes if these resources have not been used recently. Should there be a severe resource shortage, the system will resort to swapping the entire context of a process to secondary storage. The demand paging and swapping done by the system are effectively transparent to processes. A process may, however, advise the system about expected future memory utilization as a performance aid.\nInside the kernel both stack and heap in kernel.\nThe kernel often does allocations of memory that are needed for only the duration of a single system call. In a user process, such short-term memory would be allocated on the [kernel\u0026rsquo;s] run-time stack.\nBecause the kernel has a limited run-time stack, it is not feasible to allocate even moderate-sized blocks of memory on it. Consequently, such memory must be allocated through a more dynamic mechanism. An example is protocol-control blocks that remain throughout the duration of a network connection.\nA generalized memory allocator reduces the complexity of writing code inside the kernel. Thus, the 4.4BSD kernel has a single memory allocator that can be used by any part of the system.\n [Kernel\u0026rsquo;s dynamic memory management] has an interface similar to the C library routines malloc and free that provide memory allocation to application programs. Like the C library interface, the allocation routine takes a parameter specifying the size of memory that is needed.\n[Unlike C\u0026rsquo;s interface,] the range of sizes for memory requests is not constrained; however, physical memory is allocated and is not paged. The free routine takes a pointer to the storage being freed, but does not require the size of the piece of memory being freed.\n Kenrel-user data sharing Another issue with the virtual-memory system is the way that information is passed into the kernel when a system call is made. 4.4BSD always copies data from the process address space into a buffer in the kernel.\nFor read or write operations that are transferring large quantities of data, doing the copy can be time consuming. An alternative to doing the copying is to remap the process memory into the kernel.\nThe biggest incentives for memory mapping are the needs for accessing big files and for passing large quantities of data between processes. The mmap interface provides a way for both of these tasks to be done without copying.\nvm_page_t Reference: Chapter 7 Virtual Memory System \nPhysical memory is managed on a page-by-page basis through the vm_page_t structure.\nPages of physical memory are categorized through the placement of their respective vm_page_t structures on one of several paging queues.\nA page can be in a wired, active, inactive, cache, or free state. Except for the wired state, the page is typically placed in a doubly link list queue representing the state that it is in. Wired pages are not placed on any queue.\nFreeBSD implements a more involved paging queue for cached and free pages in order to implement page coloring. Each of these states involves multiple queues arranged according to the size of the processor\u0026rsquo;s L1 and L2 caches. When a new page needs to be allocated, FreeBSD attempts to obtain one that is reasonably well aligned from the point of view of the L1 and L2 caches relative to the VM object the page is being allocated for.\nAdditionally, a page may be held with a reference count or locked with a busy count. The VM system also implements an “ultimate locked” state for a page using the PG_BUSY bit in the page\u0026rsquo;s flags.\nIn general terms, each of the paging queues operates in a LRU fashion. A page is typically placed in a wired or active state initially. When wired, the page is usually associated with a page table somewhere. The VM system ages the page by scanning pages in a more active paging queue (LRU) in order to move them to a less-active paging queue.\nPages that get moved into the cache are still associated with a VM object but are candidates for immediate reuse. Pages in the free queue are truly free. FreeBSD attempts to minimize the number of pages in the free queue, but a certain minimum number of truly free pages must be maintained in order to accommodate page allocation at interrupt time.\nIf a process attempts to access a page that does not exist in its page table but does exist in one of the paging queues (such as the inactive or cache queues), a relatively inexpensive page reactivation fault occurs which causes the page to be reactivated. If the page does not exist in system memory at all, the process must block while the page is brought in from disk.\nMore  Tracking Page Fault Handlers   References: Chapter 7 Virtual Memory System More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/vm/page_fault/",
	"title": "Tracking Page Fault Handlers",
	"tags": [],
	"description": "",
	"content": " References:\n Chapter 7 Virtual Memory System   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/loading/init/",
	"title": "Init and Fini sections",
	"tags": [],
	"description": "",
	"content": " References:\n Initialization and Termination Sections  Dynamic object can supply code that provides for runtime initialization and termination processing. The initialization code of a dynamic object is executed once each time the dynamic object is loaded in a process. The termination code of a dynamic object is executed once each time the dynamic object is unloaded from a process or at process termination. This code can be encapsulated in one of two section types, either an array of function pointers or a single code block. Each of these section types is built from a concatenation of like sections from the input relocatable objects.\n .pre_initarray, pre-initialization functions. Applicable to dynamic executables only. .init_array, initialization functions .fini_array, termination functions  When creating a dynamic object, the linker-editor identifies these arrays with the .dynamic tag pairs DT_PREINIT_[ARRAY/ARRAYSZ], DT_INIT_[ARRAY/ARRAYSZ], and DT_FINI_[ARRAY/ARRAYSZ] accordingly. These tags identify the associated sections so that the sections can be called by the runtime linker.\nFunctions that are assigned to these arrays must be provided from the object that is being built.\n .init, runtime initialization code block. .fini, runtime termination code block.  The compiler drivers typically supply .init and .fini sections with files they add to the beginning and end of your input file list. These compiler provided files have the effect of encapsulating the .init and .fini code from your relocatable objects into individual functions. These functions are identified by the reserved symbol names _init and _fini respectively.\nWhen creating a dynamic object, the link-editor identifies these symbols with the .dynamic tags DT_INIT and DT_FINI accordingly. These tags identify the associated sections so they can be called by the runtime linker.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/ast/",
	"title": "AST in FreeBSD kernel",
	"tags": [],
	"description": "",
	"content": "Reference reference\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/vnode/",
	"title": "VNODE",
	"tags": [],
	"description": "",
	"content": "References:\n FreeBSD kernel developer\u0026rsquo;s manual \u0026ndash; vnode  vnode \u0026ndash; internal representation of a file or a directory. The vnode is the focus of all file activity in UNIX. A vnode is described by struct vnode. There is a unique vnode allocated for each active file, each current directory, each mounted-on file, text file, and the root.\nThree reference counts:\n v_usecount, the number of clients within the kernel which are using the vnode.  Maintained by vref, vrele, vput  v_holdcnt, num of clients in the kernel who veto the recycling of the vnode.  Maintained by vhold and vdrop.  v_writecount, num of clients which is writing into the file.  Maintained by open and close system calls.   Any call which returns a vnode (e.g., vget, VOP_LOOKUP, etc.) will increase the v_usecount of the vnode by one. When the caller is finished with the vnode, it should release this reference by calling vrele (or vput if the vnode is locked).\nMore members:\n v_id v_mount, points at the file system which owns the vnode. v_type, contains the type of the object the vnode represents. v_data, used by the file system to store file system specific data with the vnode. v_op, used by VOP_* macros to call functions in the file system which implement the vnode\u0026rsquo;s functionality. (Such as ???)   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/lld/relocation/sythetic-relocation-sections/",
	"title": "Sythetic Relocation Sections",
	"tags": [],
	"description": "",
	"content": " Reference reference\nSynthetic Input Sections for relocation .got or .mipsgot are synthetic input sections created before relocation can actually happen on them. They are created before finalizeSections(), so that they can be placed into the finall output; they are updated during finalizeSections(), where they got allocated in the virtual space; After the location of sections are finalized, virtual addresses are mostly available for relocation to happen.\nNow here tracks the first step where synthetic relocation sections such as .got are created and initialized.\n.got as InputSection is created via createSyntheticSections()\n// lld/ELF/Writer.cpp  template \u0026lt;classELFT\u0026gt; void createSyntheticSections() { ... // Add .got. MIPS\u0026#39; .got is so different from the other archs,  // it has its own class.  if (config-\u0026gt;emachine == EM_MIPS) { in.mipsGot = make\u0026lt;MipsGotSection\u0026gt;(); add(in.mipsGot); } else { in.got = make\u0026lt;GotSection\u0026gt;(); add(in.got); } ... } // call path for createSyntheticSections() LinkerDriver::link() -\u0026gt; createSyntheticSections\u0026lt;ELFT\u0026gt;();  Non-Mips .got section entries are created in:\nMips .got section entries are created in\n finalizeContents() Every SyntheticSection in LLD implements function finalizeContents().\nWhat does it do?\nIn (both Mips and Non-Mips) .got: it compute and set the size of the section.\n// lld/ELF/SyntheticSections.cpp void GotSection::finalizeContents() { size = numEntries * config-\u0026gt;wordsize; } void MipsGotSection::finalizeContents() { updateAllocSize(); } bool MipsGotSection::updateAllocSize() { size = headerEntriesNum * config-\u0026gt;wordsize; for (const FileGot \u0026amp;g : gots) size += g.getEntriesNum() * config-\u0026gt;wordsize; return false; }  When/Where it is invoked?\nDuring the execution of finalizeSections(), where each section is \u0026ldquo;finalized\u0026rdquo; with a certain virtual address. Call path:\n// lld/ELF/Writer.cpp Writer::finalizeSections(){ ... finalizeSynthetic(in.bss); finalizeSynthetic(in.bssRelRo); finalizeSynthetic(in.symTabShndx); finalizeSynthetic(in.shStrTab); finalizeSynthetic(in.strTab); finalizeSynthetic(in.got); finalizeSynthetic(in.mipsGot); finalizeSynthetic(in.igotPlt); finalizeSynthetic(in.gotPlt); finalizeSynthetic(in.relaIplt); finalizeSynthetic(in.relaPlt); finalizeSynthetic(in.plt); finalizeSynthetic(in.iplt); finalizeSynthetic(in.ppc32Got2); finalizeSynthetic(in.partIndex); ... } // lld/ELF/Writer.cpp static void finalizeSynthetic(SyntheticSection *sec){ if (sec \u0026amp;\u0026amp; sec-\u0026gt;isNeeded() \u0026amp;\u0026amp; sec-\u0026gt;getParent()) sec-\u0026gt;finalizeContents(); }  Output Sections for synthetic relocation section  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/lld/thunk/",
	"title": "Thunk",
	"tags": [],
	"description": "",
	"content": "Reference reference\nA thunk is a code-sequence inserted by the linker in between a caller and the callee.\nA relocation to the callee is redirected to the Thunk.\n// lld/ELF/Thunks.h  // Class to describe an instance of a Thunk. // A Thunk is a code-sequence inserted by the linker in between a caller and // the callee. The relocation to the callee is redirected to the Thunk, which // after executing transfers control to the callee. Typical uses of Thunks // include transferring control from non-pi to pi and changing state on // targets like ARM. // // Thunks can be created for Defined, Shared and Undefined Symbols. // Thunks are assigned to synthetic ThunkSections   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/lld/relocation/",
	"title": "Relocation in LLD",
	"tags": [],
	"description": "",
	"content": " Reference reference\nRelocation after Address Assignment Each section has a relocate method that can relocate itself. It happens after the dot address resolution, phdrs creation.\nRelocation per Section Relocation for each relocatable section:\n// lld/ELF/InputSection.h  // class InputSectionBase  // Each section knows how to relocate itself. These functions apply  // relocations, assuming that Buf points to this section\u0026#39;s copy in  // the mmap\u0026#39;ed output buffer.  template \u0026lt;classELFT\u0026gt; void relocate(uint8_t *buf, uint8_t *bufEnd); void relocateAlloc(uint8_t *buf, uint8_t *bufEnd); static uint64_t getRelocTargetVA(const InputFile *File, RelType Type, relocateNoSym int64_t A, uint64_t P, const Symbol \u0026amp;Sym, RelExpr Expr, InputSectionBase *isec, uint64_t offset);  Call path for relocate, relocateAlloc and getRelocTargetVA:\nvoid InputSection::writeTo(uint8_t *buf) =\u0026gt; relocate\u0026lt;ELFT\u0026gt;(buf, bufEnd); =\u0026gt; adjustSplitStackFunctionPrologues\u0026lt;ELFT\u0026gt;(buf, bufEnd); // if (flags \u0026amp; SHF_EXECINSTR)  =\u0026gt; relocateAlloc(buf, bufEnd); // if (flags \u0026amp; SHF_ALLOC)  =\u0026gt; targetVA = getRelocTargetVA(file, type, rel.addend, addrLoc, *rel.sym, expr, this, rel.offset); =\u0026gt; target-\u0026gt;relocate(bufLoc, rel, targetVA); =\u0026gt; relocateNonAllocForRelocatable(sec, buf); // if (config-\u0026gt;relocatable)  =\u0026gt; sec-\u0026gt;relocateNonAlloc\u0026lt;ELFT\u0026gt;(buf, sec-\u0026gt;template relas\u0026lt;ELFT\u0026gt;()); // if (sec-\u0026gt;areRelocsRela)  =\u0026gt; sec-\u0026gt;relocateNonAlloc\u0026lt;ELFT\u0026gt;(buf, sec-\u0026gt;template rels\u0026lt;ELFT\u0026gt;()); // call path to InputSection::writeTo  Target Specific Relocation impl Relocation per target:\n// lld/ELF/Target.h  // class TargetInfo  classTargetInfo{ ... virtual void relocate(uint8_t *loc, const Relocation \u0026amp;rel, uint64_t val) const = 0; void relocateNoSym(uint8_t *loc, RelType type, uint64_t val) const { relocate(loc, Relocation{R_NONE, type, 0, 0, nullptr}, val); } } // lld/ELF/Arch/Mips.cpp classMIPS final: public TargetInfo{ ... void relocate(uint8_t *loc, const Relocation \u0026amp;rel, uint64_t val) const override; }  Call path for target relocate\n// lld/ELF/InputSection.cpp void InputSectionBase::relocate(uint8_t *buf, uint8_t *bufEnd) =\u0026gt; static void relocateNonAllocForRelocatable(InputSection *sec, uint8_t *buf) =\u0026gt; target-\u0026gt;relocate(..) void InputSectionBase::relocateAlloc(uint8_t *buf, uint8_t *bufEnd) =\u0026gt; target-\u0026gt;relocate(..)  call path for target relocateNoSym:\nvoid InputSection::relocateNonAlloc(uint8_t *buf, ArrayRef\u0026lt;RelTy\u0026gt; rels) =\u0026gt; void TargetInfo::relocateNoSym(uint8_t *loc, RelType type, uint64_t val) const =\u0026gt; this-\u0026gt;relocate(...) void ARMExidxSyntheticSection::writeTo(uint8_t *buf) // lld/ELF/SyntheticSections.cpp =\u0026gt; void TargetInfo::relocateNoSym(uint8_t *loc, RelType type, uint64_t val) const =\u0026gt; this-\u0026gt;relocate(...) // lld/ELF/Thunks.cpp void ARMThunk::writeTo(uint8_t *buf) void ThumbThunk::writeTo(uint8_t *buf) void MipsThunk::writeTo(uint8_t *buf) =\u0026gt; void TargetInfo::relocateNoSym(uint8_t *loc, RelType type, uint64_t val) const =\u0026gt; this-\u0026gt;relocate(...) // lld/ELF/Arch/Mips.cpp void MIPS\u0026lt;ELFT\u0026gt;::writePltHeader(uint8_t *buf) const void MIPS\u0026lt;ELFT\u0026gt;::writePlt(uint8_t *buf, const Symbol \u0026amp;sym, uint64_t pltEntryAddr) const =\u0026gt; void TargetInfo::relocateNoSym(uint8_t *loc, RelType type, uint64_t val) const =\u0026gt; this-\u0026gt;relocate(...) // lld/ELF/Arch/RISCV.cpp (recursive???) void RISCV::relocate(uint8_t *loc, const Relocation \u0026amp;rel, uint64_t val) const =\u0026gt; void TargetInfo::relocateNoSym(uint8_t *loc, RelType type, uint64_t val) const =\u0026gt; this-\u0026gt;relocate(...)  Ending  Sythetic Relocation Sections  Reference reference Synthetic Input Sections for relocation .got or .mipsgot are synthetic input sections created before relocation can actually happen on them. They are created before finalizeSections(), so that they can be placed into the finall output; they are updated during finalizeSections(), where they got allocated in the virtual space; After the location of sections are finalized, virtual addresses are mostly available for relocation to happen. Now here tracks the first step where synthetic relocation sections such as .\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-linkers-loaders/linker-scripts/",
	"title": "Linker Scripts",
	"tags": [],
	"description": "",
	"content": " Reference\n SECTIONS Command  Output Section description:\nsection [address] [(type)] : [AT(lma)] [ALIGN(section_align) | ALIGN_WITH_INPUT] [SUBALIGN(subsection_align)] [constraint] { output-section-command output-section-command ... } [\u0026gt;region] [AT\u0026gt;lma_region] [:phdr :phdr ...] [=fillexp] [,] VMA and LMA Every section has a virtual memory address (VMA) and a load memory address (LMA), see baseic script concepts.\n The address in a linker script is virtual address (VMA). This address is optional, but if it is provided then the output address will be set exactly as specified. If the output address is not specified, a virtual address will be choosen. The heuristic below will be used to choose the VMA:  If an output memory region is set for the section then it is added to this region and its address will be the next free address in that region. If the MEMORY command has been used to create a list of memory regions then the first region which has attributes compatible with the section is selected to contain it. The section\u0026rsquo;s output address will be the next free address in that region; If no memory regions were specified, or none match the section then the output address will be based on the current value of the location counter.  The load address (LMA) is specified by the AT or AT\u0026gt; keywords. Specifying a load address is optional.  This feature is designed to make it easy to build a ROM image. LMA can point to a ROM address, and when the program is loaded and running, the system will first load the contents from LMA to VMA and starting execution. Heuristic to choose the LMA without AT or AT\u0026gt;: If the section has a specific VMA address, then this is used as the LMA address as well. If the section is not allocatable then its LMA is sect to its VMA. Otherwise, if a memory region can be found that is compatible with the curent section, and this region contains at least one section, then the LMA is set so the difference between the VMA and LMA is the same as the difference between the VMA and LMA of the last section in the located region. If no memory regions have been declared then a default region that covers the entire address space is used in the previous step. If no suitable region could be found, or there was no previous section then the LMA is set equal to the VMA.    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/lld/linking/phdrs_cmds/",
	"title": "Phdrs_cmds",
	"tags": [],
	"description": "",
	"content": " Reference reference\nphdrsCommands (empty for most binary) In LinkerScript:\n// lld/ELF/LinkerScript.h  classLinkerScript final{ // PHDRS command list.  std::vector\u0026lt;PhdrsCommand\u0026gt; phdrsCommands; };  In LLD Code updated in two ways;\n based on the linker script if exists; by the linker itself if no linker script is given (true for binary and relocatable outputs);  The driven function to update the program header commands, in void Writer\u0026lt;ELFT\u0026gt;::finalizeSections()\n// lld/ELF/Writer.cpp  // Create output section objects and add them to OutputSections. template \u0026lt;classELFT\u0026gt; void Writer\u0026lt;ELFT\u0026gt;::finalizeSections() { ... if (!config-\u0026gt;relocatable \u0026amp;\u0026amp; !config-\u0026gt;oFormatBinary) { for (Partition \u0026amp;part : partitions) { part.phdrs = script-\u0026gt;hasPhdrsCommands() ? script-\u0026gt;createPhdrs() : createPhdrs(part); if (config-\u0026gt;emachine == EM_ARM) { // PT_ARM_EXIDX is the ARM EHABI equivalent of PT_GNU_EH_FRAME  addPhdrForSection(part, SHT_ARM_EXIDX, PT_ARM_EXIDX, PF_R); } ... } ...  Update based on scripts:\n// lld/ELF/ScriptParser.cpp void ScriptParser::readPhdrs() { expect(\u0026#34;{\u0026#34;); while (!errorCount() \u0026amp;\u0026amp; !consume(\u0026#34;}\u0026#34;)) { PhdrsCommand cmd; cmd.name = next(); cmd.type = readPhdrType(); while (!errorCount() \u0026amp;\u0026amp; !consume(\u0026#34;;\u0026#34;)) { if (consume(\u0026#34;FILEHDR\u0026#34;)) cmd.hasFilehdr = true; else if (consume(\u0026#34;PHDRS\u0026#34;)) cmd.hasPhdrs = true; else if (consume(\u0026#34;AT\u0026#34;)) cmd.lmaExpr = readParenExpr(); else if (consume(\u0026#34;FLAGS\u0026#34;)) cmd.flags = readParenExpr()().getValue(); else setError(\u0026#34;unexpected header attribute: \u0026#34; + next()); } script-\u0026gt;phdrsCommands.push_back(cmd); } }  Update by linker itself:\nUsed here:\n To adjust sections after sorting\n// lld/ELF/LinkerScript.cpp  void LinkerScript::adjustSectionsAfterSorting() { // Try and find an appropriate memory region to assign offsets in. for (BaseCommand *base : sectionCommands) { if (auto *sec = dyn_cast\u0026lt;OutputSection\u0026gt;(base)) { if (!sec-\u0026gt;lmaRegionName.empty()) { if (MemoryRegion *m = memoryRegions.lookup(sec-\u0026gt;lmaRegionName)) sec-\u0026gt;lmaRegion = m; else error(\u0026#34;memory region \u0026#39;\u0026#34; + sec-\u0026gt;lmaRegionName + \u0026#34;\u0026#39; not declared\u0026#34;); } sec-\u0026gt;memRegion = findMemoryRegion(sec); } } // If output section command doesn\u0026#39;t specify any segments, // and we haven\u0026#39;t previously assigned any section to segment, // then we simply assign section to the very first load segment. // Below is an example of such linker script: // PHDRS { seg PT_LOAD; } // SECTIONS { .aaa : { *(.aaa) } } std::vector\u0026lt;StringRef\u0026gt; defPhdrs; auto firstPtLoad = llvm::find_if(phdrsCommands, [](const PhdrsCommand \u0026amp;cmd) { return cmd.type == PT_LOAD; }); if (firstPtLoad != phdrsCommands.end()) defPhdrs.push_back(firstPtLoad-\u0026gt;name); // Walk the commands and propagate the program headers to commands that don\u0026#39;t // explicitly specify them. for (BaseCommand *base : sectionCommands) { auto *sec = dyn_cast\u0026lt;OutputSection\u0026gt;(base); if (!sec) continue; if (sec-\u0026gt;phdrs.empty()) { // To match the bfd linker script behaviour, only propagate program  // headers to sections that are allocated.  if (sec-\u0026gt;flags \u0026amp; SHF_ALLOC) sec-\u0026gt;phdrs = defPhdrs; } else { defPhdrs = sec-\u0026gt;phdrs; } } }  To allocate headers???\n// lld/ELF/LinkerScrpt.cpp  // When the SECTIONS command is used, try to find an address for the file and // program headers output sections, which can be added to the first PT_LOAD // segment when program headers are created. // // We check if the headers fit below the first allocated section. If there isn\u0026#39;t // enough space for these sections, we\u0026#39;ll remove them from the PT_LOAD segment, // and we\u0026#39;ll also remove the PT_PHDR segment. void LinkerScript::allocateHeaders(std::vector\u0026lt;PhdrEntry *\u0026gt; \u0026amp;phdrs) { uint64_t min = std::numeric_limits\u0026lt;uint64_t\u0026gt;::max(); for (OutputSection *sec : outputSections) if (sec-\u0026gt;flags \u0026amp; SHF_ALLOC) min = std::min\u0026lt;uint64_t\u0026gt;(min, sec-\u0026gt;addr); auto it = llvm::find_if( phdrs, [](const PhdrEntry *e) { return e-\u0026gt;p_type == PT_LOAD; }); if (it == phdrs.end()) return; PhdrEntry *firstPTLoad = *it; bool hasExplicitHeaders = llvm::any_of(phdrsCommands, [](const PhdrsCommand \u0026amp;cmd) { return cmd.hasPhdrs || cmd.hasFilehdr; }); bool paged = !config-\u0026gt;omagic \u0026amp;\u0026amp; !config-\u0026gt;nmagic; uint64_t headerSize = getHeaderSize(); if ((paged || hasExplicitHeaders) \u0026amp;\u0026amp; headerSize \u0026lt;= min - computeBase(min, hasExplicitHeaders)) { min = alignDown(min - headerSize, config-\u0026gt;maxPageSize); Out::elfHeader-\u0026gt;addr = min; Out::programHeaders-\u0026gt;addr = min + Out::elfHeader-\u0026gt;size; return; } // Error if we were explicitly asked to allocate headers. if (hasExplicitHeaders) error(\u0026#34;could not allocate headers\u0026#34;); Out::elfHeader-\u0026gt;ptLoad = nullptr; Out::programHeaders-\u0026gt;ptLoad = nullptr; firstPTLoad-\u0026gt;firstSec = findFirstSection(firstPTLoad); llvm::erase_if(phdrs, [](const PhdrEntry *e) { return e-\u0026gt;p_type == PT_PHDR; }); }  To create program header entries:\n// lld/ELF/LinkerScript.cpp  // Creates program headers as instructed by PHDRS linker script command. std::vector\u0026lt;PhdrEntry *\u0026gt; LinkerScript::createPhdrs() { std::vector\u0026lt;PhdrEntry *\u0026gt; ret; // Process PHDRS and FILEHDR keywords because they are not // real output sections and cannot be added in the following loop. for (const PhdrsCommand \u0026amp;cmd : phdrsCommands) { PhdrEntry *phdr = make\u0026lt;PhdrEntry\u0026gt;(cmd.type, cmd.flags ? *cmd.flags : PF_R); if (cmd.hasFilehdr) phdr-\u0026gt;add(Out::elfHeader); if (cmd.hasPhdrs) phdr-\u0026gt;add(Out::programHeaders); if (cmd.lmaExpr) { phdr-\u0026gt;p_paddr = cmd.lmaExpr().getValue(); phdr-\u0026gt;hasLMA = true; } ret.push_back(phdr); } // Add output sections to program headers. for (OutputSection *sec : outputSections) { // Assign headers specified by linker script for (size_t id : getPhdrIndices(sec)) { ret[id]-\u0026gt;add(sec); if (!phdrsCommands[id].flags.hasValue()) ret[id]-\u0026gt;p_flags |= sec-\u0026gt;getPhdrFlags(); } } return ret; }  To check whether have .interp section\n// lld/ELF/LinkerScript.cpp  // Returns true if we should emit an .interp section. // // We usually do. But if PHDRS commands are given, and // no PT_INTERP is there, there\u0026#39;s no place to emit an // .interp, so we don\u0026#39;t do that in that case. bool LinkerScript::needsInterpSection() { if (phdrsCommands.empty()) return true; for (PhdrsCommand \u0026amp;cmd : phdrsCommands) if (cmd.type == PT_INTERP) return true; return false; }  To get the indices of ELF headers containing specific section:\n// lld/ELF/LinkerScript.cpp  // Returns indices of ELF headers containing specific section. Each index is a // zero based number of ELF header listed within PHDRS {} script block. std::vector\u0026lt;size_t\u0026gt; LinkerScript::getPhdrIndices(OutputSection *cmd) { std::vector\u0026lt;size_t\u0026gt; ret; for (StringRef s : cmd-\u0026gt;phdrs) { if (Optional\u0026lt;size_t\u0026gt; idx = getPhdrIndex(phdrsCommands, s)) ret.push_back(*idx); else if (s != \u0026#34;NONE\u0026#34;) error(cmd-\u0026gt;location + \u0026#34;: program header \u0026#39;\u0026#34; + s + \u0026#34;\u0026#39; is not listed in PHDRS\u0026#34;); } return ret; } //  // Returns the index of the segment named Name. static Optional\u0026lt;size_t\u0026gt; getPhdrIndex(ArrayRef\u0026lt;PhdrsCommand\u0026gt; vec, StringRef name) { for (size_t i = 0; i \u0026lt; vec.size(); ++i) if (vec[i].name == name) return i; return None; }  To check whether the phdr command exists\n// lld/ELF/LinkerScript.h // class LinkerScript bool hasPhdrsCommands() { return !phdrsCommands.empty(); }    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/loading/freebsd/",
	"title": "Freebsd",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to load a section from file and read its contents?  see example code parse_notes() in sys/kern/imgact_elf.c \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;   References:\n sys/kern/kern_exec.c sys/sys/elf_generic.h sys/kern/imgact_elf.c  The overview of how a execve system call loads a binary and start executing a binary file is discussed based on the Linux previously. Here this post aims to track more details on the source code about how the ELF file is parsed and mapped into the address space in the FreeBSD.\ndo_execve Implementation is similar.\nFreeBSD has a struct image_params imgp; store similar info as the struct linux_binprm in Linux.\n do_execve() handles the syscall  Prepare the struct image_params imgp the credentials: -\u0026gt;newcred the full path to the image file, set field -\u0026gt;freepath, -\u0026gt;execpath, etc. Loop through a list of image activators, calling each one; call interpreter if image is interpreted.   Calling ELF Image Activator   calling image activators   // sys/kern/kern_exec.c  /* * In-kernel implementation of execve(). All arguments are assumed to be * userspace pointers from the passed thread. */ static int do_execve(struct thread *td, struct image_args *args, void * __capability umac){ ... /* *\tLoop through the list of image activators, calling each one. *\tAn activator returns -1 if there is no match, 0 on success, *\tand an error otherwise. */ for (i = 0; error == -1 \u0026amp;\u0026amp; execsw[i]; ++i) { if (execsw[i]-\u0026gt;ex_imgact == NULL || execsw[i]-\u0026gt;ex_imgact == img_first) { continue; } error = (*execsw[i]-\u0026gt;ex_imgact)(imgp); } ... }  The definition of struct execsw for elf files:\n// in file: sys/kern/imgact_elf.c /* * Tell kern_execve.c about it, with a little help from the linker. */ static struct execsw __elfN(execsw) = { .ex_imgact = __CONCAT(exec_, __elfN(imgact)), // -\u0026gt; e.g. `exec_elf64_imgact`  .ex_name = __XSTRING(__CONCAT(ELF, __ELF_WORD_SIZE)) }; EXEC_SET(__CONCAT(elf, __ELF_WORD_SIZE), __elfN(execsw)); // __elfN is defined as a macro: // in file: sys/sys/elf_generic.h #define __elfN(x) __CONCAT(__CONCAT(__CONCAT(elf,__ELF_WORD_SIZE),_),x)  // function __CONCAT(exec_, __elfN(imgact)) is defined as // in file sys/kern/imgact_elf.c static int __CONCAT(exec_, __elfN(imgact))(struct image_params *imgp) { }    Loading ELF file References:\n sys/kern/imgact_elf.c  ELF binary is loaded using function _CONCAT(exec, __elfN(imgact))(struct image_params *imgp). This is a macro based function name definition, can be compiled to exec_elf64_imgact() for example.\n Check three types of sections: PT_LOAD, PT_INTERP, PT_GNU_STACK, and PT_PHDR. Update image_params accordingly. Detect ELF binary (sub)type. __elfN(get_branchinfo). Dynamic or not. (dso) Decide whether to enable randomization of user mappings.  update imgp-\u0026gt;map_flags accordingly;  call exec_new_vmspace(imgp, sv): clear old virtual address space, and set up new stack. call __elfN(load_sections): loading the contents of sections. call __elfN(enforce_limits):  Reading program headers // sys/kern/imgact_elf.c // http://fxr.watson.org/fxr/source/kern/imgact_elf.c?v=FREEBSD-12-STABLE#L1106  static int __CONCAT(exec_, __elfN(imgact))(struct image_params *imgp) { /// ... \tfor (i = 0; i \u0026lt; hdr-\u0026gt;e_phnum; i++) { switch (phdr[i].p_type) { case PT_LOAD: if (n == 0) baddr = phdr[i].p_vaddr; if (phdr[i].p_align \u0026gt; maxalign) maxalign = phdr[i].p_align; mapsz += phdr[i].p_memsz; n++; /* * If this segment contains the program headers, * remember their virtual address for the AT_PHDR * aux entry. Static binaries don\u0026#39;t usually include * a PT_PHDR entry. */ if (phdr[i].p_offset == 0 \u0026amp;\u0026amp; hdr-\u0026gt;e_phoff + hdr-\u0026gt;e_phnum * hdr-\u0026gt;e_phentsize \u0026lt;= phdr[i].p_filesz) proghdr = phdr[i].p_vaddr + hdr-\u0026gt;e_phoff; break; case PT_INTERP: /* Path to interpreter */ if (interp != NULL) { uprintf(\u0026#34;Multiple PT_INTERP headers\\n\u0026#34;); error = ENOEXEC; goto ret; } error = __elfN(get_interp)(imgp, \u0026amp;phdr[i], \u0026amp;interp, \u0026amp;free_interp); if (error != 0) goto ret; break; case PT_GNU_STACK: if (__elfN(nxstack)) imgp-\u0026gt;stack_prot = __elfN(trans_prot)(phdr[i].p_flags); imgp-\u0026gt;stack_sz = phdr[i].p_memsz; break; case PT_PHDR: /* Program header table info */ proghdr = phdr[i].p_vaddr; break; } } /// ... } Reading brandinfo from ELF binary get_branchinfo \u0026mdash;\u0026gt; parse_notes():\nCall path:\n__CONCAT(exec_, __elfN(imgact))(struct image_params *imgp) =\u0026gt; brand_info = __elfN(get_brandinfo)(imgp, interp, \u0026amp;osrel, \u0026amp;fctl0); static Elf_Brandinfo * __elfN(get_brandinfo)(struct image_params *imgp, const char *interp, int32_t *osrel, uint32_t *fctl0) =\u0026gt; ret = __elfN(check_note)(imgp, bi-\u0026gt;brand_note, osrel, fctl0); =\u0026gt; static boolean_t __elfN(check_note)(struct image_params *imgp, Elf_Brandnote *brandnote, int32_t *osrel, uint32_t *fctl0){ for (i = 0; i \u0026lt; hdr-\u0026gt;e_phnum; i++) { if (phdr[i].p_type == PT_NOTE \u0026amp;\u0026amp; __elfN(parse_notes)(imgp, \u0026amp;brandnote-\u0026gt;hdr, brandnote-\u0026gt;vendor, \u0026amp;phdr[i], brandnote_cb, \u0026amp;b_arg)) { for (j = 0; j \u0026lt; hdr-\u0026gt;e_phnum; j++) { if (phdr[j].p_type == PT_NOTE \u0026amp;\u0026amp; __elfN(parse_notes)(imgp, \u0026amp;fctl_note, FREEBSD_ABI_VENDOR, \u0026amp;phdr[j], note_fctl_cb, \u0026amp;f_arg)) break; } return (TRUE); } } } =\u0026gt; __elfN(parse_notes)(imgp, \u0026amp;fctl_note, FREEBSD_ABI_VENDOR, \u0026amp;phdr[j], note_fctl_cb, \u0026amp;f_arg));  parse_notes():\n// sys/kern/imgact_elf.c  static boolean_t __elfN(parse_notes)(struct image_params *imgp, Elf_Note *checknote, const char *note_vendor, const Elf_Phdr *pnote, boolean_t (*cb)(const Elf_Note *, void *, boolean_t *), void *cb_arg) { const Elf_Note *note, *note0, *note_end; const char *note_name; char *buf; int i, error; boolean_t res; /* We need some limit, might as well use PAGE_SIZE. */ if (pnote == NULL || pnote-\u0026gt;p_filesz \u0026gt; PAGE_SIZE) return (FALSE); ASSERT_VOP_LOCKED(imgp-\u0026gt;vp, \u0026#34;parse_notes\u0026#34;); if (pnote-\u0026gt;p_offset \u0026gt; PAGE_SIZE || pnote-\u0026gt;p_filesz \u0026gt; PAGE_SIZE - pnote-\u0026gt;p_offset) { buf = malloc(pnote-\u0026gt;p_filesz, M_TEMP, M_NOWAIT); if (buf == NULL) { VOP_UNLOCK(imgp-\u0026gt;vp); buf = malloc(pnote-\u0026gt;p_filesz, M_TEMP, M_WAITOK); vn_lock(imgp-\u0026gt;vp, LK_SHARED | LK_RETRY); } error = vn_rdwr(UIO_READ, imgp-\u0026gt;vp, buf, pnote-\u0026gt;p_filesz, pnote-\u0026gt;p_offset, UIO_SYSSPACE, IO_NODELOCKED, curthread-\u0026gt;td_ucred, NOCRED, NULL, curthread); if (error != 0) { uprintf(\u0026#34;i/o error PT_NOTE\\n\u0026#34;); goto retf; } note = note0 = (const Elf_Note *)buf; note_end = (const Elf_Note *)(buf + pnote-\u0026gt;p_filesz); } else { note = note0 = (const Elf_Note *)(imgp-\u0026gt;image_header + pnote-\u0026gt;p_offset); note_end = (const Elf_Note *)(imgp-\u0026gt;image_header + pnote-\u0026gt;p_offset + pnote-\u0026gt;p_filesz); buf = NULL; } for (i = 0; i \u0026lt; 100 \u0026amp;\u0026amp; note \u0026gt;= note0 \u0026amp;\u0026amp; note \u0026lt; note_end; i++) { if (!aligned(note, Elf32_Addr) || (const char *)note_end - (const char *)note \u0026lt; sizeof(Elf_Note)) { goto retf; } if (note-\u0026gt;n_namesz != checknote-\u0026gt;n_namesz || note-\u0026gt;n_descsz != checknote-\u0026gt;n_descsz || note-\u0026gt;n_type != checknote-\u0026gt;n_type) goto nextnote; note_name = (const char *)(note + 1); if (note_name + checknote-\u0026gt;n_namesz \u0026gt;= (const char *)note_end || strncmp(note_vendor, note_name, checknote-\u0026gt;n_namesz) != 0) goto nextnote; if (cb(note, cb_arg, \u0026amp;res)) goto ret; nextnote: note = (const Elf_Note *)((const char *)(note + 1) + roundup2(note-\u0026gt;n_namesz, ELF_NOTE_ROUNDSIZE) + roundup2(note-\u0026gt;n_descsz, ELF_NOTE_ROUNDSIZE)); } retf: res = FALSE; ret: free(buf, M_TEMP); return (res); }  Set up stack exec_new_vmspace(): clear old address space, and set up a new stack.\nCall path:\ndo_execve() =\u0026gt; __CONCAT(exec_,(imgact)) // sys/kern/imgact_elf.c  =\u0026gt; exec_new_vmspace(imgp, sv) // sys/kern/kern_exec.c Input is imgp and struct sysentvec *sv. struct sysentvec contains a pointer to system call table, a function translating trap-to-signal mapping, \u0026hellip;\nsteps in exec_new_vmspace():\n Blow away entire process VM.  if shared, create new VM space.  Map shared page if any; Allocate stack.\n// sys/kern/kern_exec.c  /* * Destroy old address space, and allocate a new stack. *\tThe new stack is only sgrowsiz large because it is grown *\tautomatically on a page fault. */ int exec_new_vmspace(struct image_params *imgp, struct sysentvec *sv) { .. }   Loading sections Call path:\nload_sections =\u0026gt; load_section =\u0026gt; map_insert// sys/kern/imgact_elf.c  // load_sections =\u0026gt; load_section static int __elfN(load_sections)(struct image_params *imgp, const Elf_Ehdr *hdr, const Elf_Phdr *phdr, u_long rbase, u_long *base_addrp, u_long *max_addrp) { for (i = 0; i \u0026lt; hdr-\u0026gt;e_phnum; i++) { if (phdr[i].p_type != PT_LOAD || phdr[i].p_memsz == 0) continue; /* Loadable segment */ prot = __elfN(trans_prot)(phdr[i].p_flags); error = __elfN(load_section)(imgp, phdr[i].p_offset, (caddr_t)(uintptr_t)phdr[i].p_vaddr + rbase, phdr[i].p_memsz, phdr[i].p_filesz, prot); if (error != 0) return (error); ... }  load_section =\u0026gt; map_insert\n Preparing the page address (keep aligned) for the mapped addr, file addr, and map length. \u0026hellip;\nstatic int __elfN(load_section)(struct image_params *imgp, vm_ooffset_t offset, caddr_t vmaddr, size_t memsz, size_t filsz, vm_prot_t prot) { object = imgp-\u0026gt;object; map = \u0026amp;imgp-\u0026gt;proc-\u0026gt;p_vmspace-\u0026gt;vm_map; map_addr = trunc_page((vm_offset_t)vmaddr); file_addr = trunc_page(offset); /* * We have two choices. We can either clear the data in the last page * of an oversized mapping, or we can start the anon mapping a page * early and copy the initialized data into that first page. We * choose the second. */ if (filsz == 0) map_len = 0; else if (memsz \u0026gt; filsz) map_len = trunc_page(offset + filsz) - file_addr; else map_len = round_page(offset + filsz) - file_addr; ... if (map_len != 0) { ... rv = __elfN(map_insert)(imgp, map, object, file_addr, map_addr, map_addr + map_len, prot, cow); ... } ... }   map_insert =\u0026gt; { map_partial; vm_map_fixed; copyout_implicit_cap; vm_imgact_map_page; vm_imgact_unmap_page; }\nstatic int __elfN(map_insert)(struct image_params *imgp, vm_map_t map, vm_object_t object, vm_ooffset_t offset, vm_offset_t start, vm_offset_t end, vm_prot_t prot, int cow) { rv = __elfN(map_partial)(map, object, offset, start, round_page(start), prot); ... if ((offset \u0026amp; PAGE_MASK) != 0) { /* * The mapping is not page aligned. This means that we have * to copy the data. */ rv = vm_map_fixed(map, NULL, 0, start, end - start, prot | VM_PROT_WRITE, VM_PROT_ALL, MAP_CHECK_EXCL); if (rv != KERN_SUCCESS) return (rv); if (object == NULL) return (KERN_SUCCESS); for (; start \u0026lt; end; start += sz) { sf = vm_imgact_map_page(object, offset); if (sf == NULL) return (KERN_FAILURE); off = offset - trunc_page(offset); sz = end - start; if (sz \u0026gt; PAGE_SIZE - off) sz = PAGE_SIZE - off; error = copyout_implicit_cap((caddr_t)sf_buf_kva(sf) + off, (caddr_t)start, sz); vm_imgact_unmap_page(sf); if (error != 0) return (KERN_FAILURE); offset += sz; } } else { vm_object_reference(object); rv = vm_map_fixed(map, object, offset, start, end - start, prot, VM_PROT_ALL, cow | MAP_CHECK_EXCL | (object != NULL ? MAP_VN_EXEC : 0)); if (rv != KERN_SUCCESS) { locked = VOP_ISLOCKED(imgp-\u0026gt;vp); VOP_UNLOCK(imgp-\u0026gt;vp); vm_object_deallocate(object); vn_lock(imgp-\u0026gt;vp, locked | LK_RETRY); return (rv); } else if (object != NULL) { MPASS(imgp-\u0026gt;vp-\u0026gt;v_object == object); VOP_SET_TEXT_CHECKED(imgp-\u0026gt;vp); } } return (KERN_SUCCESS); }  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/loading/",
	"title": "Loading",
	"tags": [],
	"description": "",
	"content": " Reference\n How programs get run: ELF binaries How programs get run: execve() system calls\n Linux src: fs/binfmt_elf.c\n load_elf_binary() load_elf_phdrs(), load the program headers load_elf_interp(), load_elf_library(), ? elf_core_dump()  ELF文件的加载过程(load_elf_binary函数详解)\u0026ndash;Linux进程的管理与调度（十三）\n  Program Header Table An ELF file for an executable program (rather than a shared library or an object file), must always contain a program header table near the start of the file, after the ELF header; each entry in this table provides information that is needed to run the program. elf The kernel only really cares about three types of program header entries:\n Entry with PT_LOAD type. This type of entry describes areas of the new program\u0026rsquo;s running memory. This includes code and data sections that come from the executable file, together with the size of a BSS section. Entry with PT_INTERP type. This type of entry identifies the run-time linker needed to assemble the complete program during dynamic linking process. Entry with GNU_STACK type. This type of entry stores a one-bit value flagging whether the program\u0026rsquo;s stack should be made executable or not.  Initial Load: struct linux_binprm do_execve() in fs/exec.c. The main purpose of this function is to build a new struct linux_binprm instance that describes the current program invocation operation.\n char buf[BINPRM_BUF_SIZE]; is filled with the first chunk (128 bytes) of data from the program file. This data will be used later to detect the binary format so it can be processed appropriately. struct file *file. const char * filename; name of the binary as seen by procps const char * interp; name the the binary really executed. Most of the time the same as filename, but could be differnt for binfmt_{misc,script} */ bprm_mm_init() function. (not found in latest Linux) p is set to point at the end of memory space. The value of p will be updated (downward) as more information is added to the new program\u0026rsquo;s stack. cred is a separately allocated object of type struct cred.  Next, the information about the program invocation is copied into the top of new program\u0026rsquo;s stack, using the local copy_strings() and copy_strings_kernel() utility functions. The stack will contain: file name,\n  struct linux_binprm   // include/linux/binfmts.h  /* * This structure is used to hold the arguments that are used when loading binaries. */ struct linux_binprm { #ifdef CONFIG_MMU \tstruct vm_area_struct *vma; unsigned long vma_pages; #else # define MAX_ARG_PAGES\t32 \tstruct page *page[MAX_ARG_PAGES]; #endif \tstruct mm_struct *mm; unsigned long p; /* current top of mem */ unsigned long argmin; /* rlimit marker for copy_strings() */ unsigned int /* * True after the bprm_set_creds hook has been called once * (multiple calls can be made via prepare_binprm() for * binfmt_script/misc). */ called_set_creds:1, /* * True if most recent call to the commoncaps bprm_set_creds * hook (due to multiple prepare_binprm() calls from the * binfmt_script/misc handlers) resulted in elevated * privileges. */ cap_elevated:1, /* * Set by bprm_set_creds hook to indicate a privilege-gaining * exec has happened. Used to sanitize execution environment * and to set AT_SECURE auxv for glibc. */ secureexec:1, /* * Set by flush_old_exec, when exec_mmap has been called. * This is past the point of no return, when the * exec_update_mutex has been taken. */ called_exec_mmap:1; #ifdef __alpha__ \tunsigned int taso:1; #endif \tunsigned int recursion_depth; /* only for search_binary_handler() */ struct file * file; struct cred *cred;\t/* new credentials */ int unsafe;\t/* how unsafe this exec is (mask of LSM_UNSAFE_*) */ unsigned int per_clear;\t/* bits to clear in current-\u0026gt;personality */ int argc, envc; const char * filename;\t/* Name of binary as seen by procps */ const char * interp;\t/* Name of the binary really executed. Most of the time same as filename, but could be different for binfmt_{misc,script} */ unsigned interp_flags; unsigned interp_data; unsigned long loader, exec; struct rlimit rlim_stack; /* Saved RLIMIT_STACK used during exec. */ char buf[BINPRM_BUF_SIZE]; } __randomize_layout;    do_execve definition:   do_execve()   // fs/exec.c // https://elixir.bootlin.com/linux/latest/source/fs/exec.c  do_execve() -\u0026gt; do_execveat_common() -\u0026gt; __do_execve_file() /* * sys_execve() executes a new program. */ static int __do_execve_file(int fd, struct filename *filename, struct user_arg_ptr argv, struct user_arg_ptr envp, int flags, struct file *file) { char *pathbuf = NULL; struct linux_binprm *bprm; struct files_struct *displaced; int retval; if (IS_ERR(filename)) return PTR_ERR(filename); /* * We move the actual failure in case of RLIMIT_NPROC excess from * set*uid() to execve() because too many poorly written programs * don\u0026#39;t check setuid() return code. Here we additionally recheck * whether NPROC limit is still exceeded. */ if ((current-\u0026gt;flags \u0026amp; PF_NPROC_EXCEEDED) \u0026amp;\u0026amp; atomic_read(\u0026amp;current_user()-\u0026gt;processes) \u0026gt; rlimit(RLIMIT_NPROC)) { retval = -EAGAIN; goto out_ret; } /* We\u0026#39;re below the limit (still or again), so we don\u0026#39;t want to make * further execve() calls fail. */ current-\u0026gt;flags \u0026amp;= ~PF_NPROC_EXCEEDED; retval = unshare_files(\u0026amp;displaced); if (retval) goto out_ret; retval = -ENOMEM; bprm = kzalloc(sizeof(*bprm), GFP_KERNEL); if (!bprm) goto out_files; retval = prepare_bprm_creds(bprm); if (retval) goto out_free; check_unsafe_exec(bprm); current-\u0026gt;in_execve = 1; if (!file) file = do_open_execat(fd, filename, flags); retval = PTR_ERR(file); if (IS_ERR(file)) goto out_unmark; sched_exec(); bprm-\u0026gt;file = file; if (!filename) { bprm-\u0026gt;filename = \u0026#34;none\u0026#34;; } else if (fd == AT_FDCWD || filename-\u0026gt;name[0] == \u0026#39;/\u0026#39;) { bprm-\u0026gt;filename = filename-\u0026gt;name; } else { if (filename-\u0026gt;name[0] == \u0026#39;\\0\u0026#39;) pathbuf = kasprintf(GFP_KERNEL, \u0026#34;/dev/fd/%d\u0026#34;, fd); else pathbuf = kasprintf(GFP_KERNEL, \u0026#34;/dev/fd/%d/%s\u0026#34;, fd, filename-\u0026gt;name); if (!pathbuf) { retval = -ENOMEM; goto out_unmark; } /* * Record that a name derived from an O_CLOEXEC fd will be * inaccessible after exec. Relies on having exclusive access to * current-\u0026gt;files (due to unshare_files above). */ if (close_on_exec(fd, rcu_dereference_raw(current-\u0026gt;files-\u0026gt;fdt))) bprm-\u0026gt;interp_flags |= BINPRM_FLAGS_PATH_INACCESSIBLE; bprm-\u0026gt;filename = pathbuf; } bprm-\u0026gt;interp = bprm-\u0026gt;filename; retval = bprm_mm_init(bprm); if (retval) goto out_unmark; retval = prepare_arg_pages(bprm, argv, envp); if (retval \u0026lt; 0) goto out; retval = prepare_binprm(bprm); if (retval \u0026lt; 0) goto out; retval = copy_strings_kernel(1, \u0026amp;bprm-\u0026gt;filename, bprm); if (retval \u0026lt; 0) goto out; bprm-\u0026gt;exec = bprm-\u0026gt;p; retval = copy_strings(bprm-\u0026gt;envc, envp, bprm); if (retval \u0026lt; 0) goto out; retval = copy_strings(bprm-\u0026gt;argc, argv, bprm); if (retval \u0026lt; 0) goto out; retval = exec_binprm(bprm); if (retval \u0026lt; 0) goto out; /* execve succeeded */ current-\u0026gt;fs-\u0026gt;in_exec = 0; current-\u0026gt;in_execve = 0; rseq_execve(current); acct_update_integrals(current); task_numa_free(current, false); free_bprm(bprm); kfree(pathbuf); if (filename) putname(filename); if (displaced) put_files_struct(displaced); return retval; out: if (bprm-\u0026gt;mm) { acct_arg_size(bprm, 0); mmput(bprm-\u0026gt;mm); } out_unmark: current-\u0026gt;fs-\u0026gt;in_exec = 0; current-\u0026gt;in_execve = 0; out_free: free_bprm(bprm); kfree(pathbuf); out_files: if (displaced) reset_files_struct(displaced); out_ret: if (filename) putname(filename); return retval; }   \nDetermine Binary Handler: struct linux_binfmt With a completed struct linux_binprm, program exection is performed in exec_binprm() and (more importantly) search_binary_handler(). search_binary_handler() iterates over a list of struct linux_binfmt objects, each of which provides a handler for a particular format of binary programs.\nFor each struct linux_binfmt handler object, the load_binary() function pointer is called, passing in the linux_binprm object. If the handler code supports the binary format, it does whatever is needed to prepare the program for execution and return success (\u0026gt;=0). Otherwise, the handler returns a failure code (\u0026lt;0) and iteration continues with the next handler.\nIf no format that can handle the program have been found (and the program appears to be binary rather than text, at least according to the first four bytes), then the code will also attempt to load a module named \u0026ldquo;binfmt-XXXX\u0026rdquo;, where XXXX is the hex value of bytes three and four in the program file. This an old mechanism (added in 1996 for Linux 1.3.57) to allow for a more dynamic way of associating binary format handlers with formats; the more recent binfmt_misc mechanism allows a mroe flexible way of doing something similar.\nLoading ELF binary Handled by load_elf_binary() function.\n check ELF header follows ELF format. read the full ELF program header into some scratch space. Preparing attributes of the new program  loop over the program header entries, checking for an PT_INTERP and whether the program\u0026rsquo;s stack should be executable from PT_GUN_STACK entry. Initialize the new program with these attributes that are not inherited from the old programs; more info about the attribute behaviors from the exec specification in Single Unix Specification see a summary of attributes involved from table 28-4 of The linux programing interface  call flush_old_exec(): clears up the state in the kernel that refers to the previous program.  previous threads, signal-handling info, timers, location of the exe file (visible at /proc/pid/exe) virtual memory mappings, I/O operations, uprobes. personality  call setup_new_exec(): set up a kernel\u0026rsquo;s internal state for the program.  call __set_task_comm(): set the task\u0026rsquo;s comm field, the basename of the invoked file name, used as the thread name, accessible to user space via PR_GET_NAME PR_SET_NAME prctl() operations. call flush_singal_handlers(): set up singal handlers for the new program. call do_close_on_exec(): close all of the old program\u0026rsquo;s file descriptors that have the O_CLOEXEC flag set; other file descriptors will be inherited by the new program.  Set up virtual memory.\n determine highest address of the stack. call setup_arg_pages(): set up the kernel\u0026rsquo;s memory tracking structures and update new location of the stack. Loop through all the PT_LOAD segments in the program file maps them into the process\u0026rsquo;s address space. sets up zero-filled pages that corresponding to the program\u0026rsquo;s BSS segment. additional special pages, such as vDSO, the virtual dynamic shared object pages.  set up credentials: install_exec_creds(). This function let any Linux Security Module(LSM) know about the change in credentials(through the bprm_committing_creds and bprm_committed_creds LSM hooks), and the inner commit_creds() function performs the assignment.\n launch the program.\n the saved user-space CPU registers are overwritten with suitable values for the start of the new program. call start_thread() sets the saved instruction pointer to the entry point of the program (or dynamic linker), and sets the saved stack pointer to the entry point of the top of the stack (from the p field in linux_binprm). execve() returns to the user space. user space process start execution with a new memory space, with the new program being loaded in.    Init and Fini sections  References: Initialization and Termination Sections Dynamic object can supply code that provides for runtime initialization and termination processing. The initialization code of a dynamic object is executed once each time the dynamic object is loaded in a process. The termination code of a dynamic object is executed once each time the dynamic object is unloaded from a process or at process termination. This code can be encapsulated in one of two section types, either an array of function pointers or a single code block.\n Freebsd  Q\u0026amp;A How to load a section from file and read its contents? see example code parse_notes() in sys/kern/imgact_elf.c \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; References: sys/kern/kern_exec.c sys/sys/elf_generic.h sys/kern/imgact_elf.c The overview of how a execve system call loads a binary and start executing a binary file is discussed based on the Linux previously. Here this post aims to track more details on the source code about how the ELF file is parsed and mapped into the address space in the FreeBSD.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/lld/linking/",
	"title": "Linking",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to merge the .text sections from two object (relocatable) files into one executable binary?  How/When to determine the virtual address of each .text segment?  scan and parse each output section commands, update .dot according to each section. see LinkerScript::assignAddresses() called in Writer\u0026lt;ELFT\u0026gt;::finalizeSections() =\u0026gt; Writer\u0026lt;ELFT\u0026gt;::finalizeAddressDependentContent() =\u0026gt; LinkerScript::assignAddresses();  How/When to update the other sections that related to the relocated .text sections?   References:\n lld/ELF/Driver.cpp lld/ELF/LinkerScript.cpp  Handling In/Out Sections Mapping between an InputSection and an OutputSection: N to 1 Mapping.\n// lld/ELF/InputSection.h  // This is a section that is added directly to an output section // instead of needing special combination via a synthetic section. This // includes all input sections with the exceptions of SHF_MERGE and // .eh_frame. It also includes the synthetic sections themselves. classInputSection : public InputSectionBase { public: ... };  Each input section is assigned to at most one output section. One output section contain one or more input sections.\nThe function that get the output section that holds the input section is getOutputSection(), or getParent().\n// lld/ELF/InputSection.cpp  OutputSection *SectionBase::getOutputSection() { InputSection *sec; if (auto *isec = dyn_cast\u0026lt;InputSection\u0026gt;(this)) sec = isec; else if (auto *ms = dyn_cast\u0026lt;MergeInputSection\u0026gt;(this)) sec = ms-\u0026gt;getParent(); else if (auto *eh = dyn_cast\u0026lt;EhInputSection\u0026gt;(this)) sec = eh-\u0026gt;getParent(); else return cast\u0026lt;OutputSection\u0026gt;(this); return sec ? sec-\u0026gt;getParent() : nullptr; } //  OutputSection *InputSection::getParent() const { return cast_or_null\u0026lt;OutputSection\u0026gt;(parent); }  Tracking the parent of an InputSection (InputSectionBase):\n// This corresponds to a section of an input file. classInputSectionBase : public SectionBase { // Input sections are part of an output section. Special sections  // like .eh_frame and merge sections are first combined into a  // synthetic section that is then added to an output section. In all  // cases this points one level up.  SectionBase *parent = nullptr; OutputSection *getParent() const; };  OutputSection // lld/ELF/OutputSection.h  // This represents a section in an output file. // It is composed of multiple InputSections. // The writer creates multiple OutputSections and assign them unique, // non-overlapping file offsets and VAs. classOutputSection final : public BaseCommand, public SectionBase { public: OutputSection(StringRef name, uint32_t type, uint64_t flags); static bool classof(const SectionBase *s) { return s-\u0026gt;kind() == SectionBase::Output; } ... };  In LinkerScript, the sectionCommands vector stores all the output sections as BaseCommand *. Another vector, outputSections, also stores the output sections.\nWhat is the difference here?\n Creation/Filling time:  sectionCommands is filled in during addOrphanSections. It: scans all the input sections, and maps the input section to a proper output section. will also create the output section if it does not exits and this output section as a member of sectionCommands. outputSections ??  Before finalizeSections()  sectionCommands contain 49 sections. Each section addr is 0x0, same as input file. Contain synthesized sections .got. outputSections contain 0 sections.  During finalizeSections()  After sortSections();, the sectionCommands is scanned and added to outputSections if the section is of type OutputSection. See code below. Before createPhdrs(): outputSections has 39 sections.  After finalizeSections(),  sectionCommands contain 39 sections. outputSections contain 39 sections.   Code picking an output section from sectionCommands to put it in outputSections:\n// Create output section objects and add them to OutputSections. template \u0026lt;classELFT\u0026gt; void Writer\u0026lt;ELFT\u0026gt;::finalizeSections() { ... sortSections(); // Now that we have the final list, create a list of all the  // OutputSections for convenience.  for (BaseCommand *base : script-\u0026gt;sectionCommands) if (auto *sec = dyn_cast\u0026lt;OutputSection\u0026gt;(base)) outputSections.push_back(sec); } // lld/ELF/LinkerScript.h  classLinkerScript final{ // SECTIONS command list.  std::vector\u0026lt;BaseCommand *\u0026gt; sectionCommands; };  Sections have the same name from different object files (input sections) will me merged into one output section. A list of input sections can be retrieved from each output section. For example, the following code in LLVM LLD iterates each output section and list all the input sections it holds:   iterating output sections   // lld/ELF/Writer.cpp  // check ownership section  // refer code from checkExecuteOnly for iteration through all sections  for (OutputSection *os : outputSections){ DebugLL(\u0026#34;Output Section \u0026#34; + os-\u0026gt;name + \u0026#34; has the following input sections:\\n\u0026#34;); for (InputSection *isec : getInputSections(os)){ DebugLLS(\u0026#34;\\t\\tInput Section:\u0026#34; + toString(isec) + \u0026#34;\\n\u0026#34;); } }   \nSyntheticSection Program Header Generation Program Header Entry class In LLD, defined as PhdrEntry\n// lld/ELF/Writer.h  // This describes a program header entry. // Each contains type, access flags and range of output sections that will be // placed in it. struct PhdrEntry { PhdrEntry(unsigned type, unsigned flags) : p_align(type == llvm::ELF::PT_LOAD ? config-\u0026gt;maxPageSize : 0), p_type(type), p_flags(flags) {} void add(OutputSection *sec); uint64_t p_paddr = 0; uint64_t p_vaddr = 0; uint64_t p_memsz = 0; uint64_t p_filesz = 0; uint64_t p_offset = 0; uint32_t p_align = 0; uint32_t p_type = 0; uint32_t p_flags = 0; OutputSection *firstSec = nullptr; OutputSection *lastSec = nullptr; bool hasLMA = false; uint64_t lmaOffset = 0; };  The method add(OutputSection *sec), will put one output section to the segment this entry describes. The class only tracks:\n lastSec, the last section being added to this segment; firstSec, the first section being added to this segment; p_align, the alignment of this segment, it is a largest alignment required by any output section it holds; update the output section\u0026rsquo;s ptLoad field. The ptLoad field in the output section is used to compute the section offset for the sections in PT_LOAD segment. Formula: Off = Off_first + VA - VA_first, where Off_first and VA_first is file offset and VA of the first section in PT_LOAD. Questions:\n When does the section\u0026rsquo;s offset being determined using the above formula? Why not use section header to determine the section offset? Where does this section offset is used and stored to? Can the OS access it?\n// lld/ELF/Writer.cpp  void PhdrEntry::add(OutputSection *sec) { lastSec = sec; if (!firstSec) firstSec = sec; p_align = std::max(p_align, sec-\u0026gt;alignment); if (p_type == PT_LOAD) sec-\u0026gt;ptLoad = this; }    Create Program Header Entries Program header entries are grouped into partitions in LLD, but there is only one paritition as seen in the testing code. See LLD Partitions below.\nCall Path:\n// lld/ELF/{Driver|Writer}.cpp LinkerDriver::link\u0026lt;ELFT\u0026gt;() // lld/ELF/Driver.cpp  =\u0026gt; writeResult\u0026lt;ELFT\u0026gt;() // lld/ELF/Driver.cpp  =\u0026gt; Writer\u0026lt;ELFT\u0026gt;().run() // lld/ELF/Writer.cpp  =\u0026gt; Writer\u0026lt;ELFT\u0026gt;::finalizeSections() // lld/ELF/Writer.cpp  =\u0026gt; ... =\u0026gt; for (Partition \u0026amp;part: partitions) part.phdrs = script-\u0026gt;hasPhdrsCommands()? script-\u0026gt;createPhdrs() : createPhdrs(part) =\u0026gt; createPhdrs(part) { // lld/ELF/Writer.cpp: Writer\u0026lt;ELFT\u0026gt;::createPhdrs(Partition \u0026amp;part)  addHdr(PT_PHDR, PF_R); .. addHdr(PT_INTERP, flags); .. addHdr(PT_LOAD, flags); .. // create a new PT_LOAD segment when a section has new flags.  uint64_t newFlags = computeFlags(sec-\u0026gt;getPhdrFlags()); load = addHdr(PT_LOAD, newFlags); load-\u0026gt;add(sec); .. addHdr(PT_GNU_EH_FRAME, ...); .. addHdr(PT_GNU_STACK, perm)-\u0026gt;p_memsz = config-\u0026gt;zStackSize; .. note = addHdr(PT_NOTE, PF_R); note-\u0026gt;add(sec); .. // here we add program header entry for capsule ownership  addHdr(PT_CAPSULE_OWNERSHIP, own_flag)-\u0026gt;add(own_text); addHdr(PT_CAPSULE_OWNERSHIP, own_flag)-\u0026gt;add(own_data); }  If the linker script does not give program header commands (which is the usual case), then the writer will create program headers according to the default policies. This is implemented in Writer\u0026lt;ELFT\u0026gt;::createPhdrs(Partition \u0026amp;part).\nSteps in the code to determine which section goes to which program header entry:\n (To add an header entry, use lambda func addHdr.)     code Writer::createPhdrs()   // lld/ELF/Writer.cpp  // Decide which program headers to create and which sections to include in each // one. template \u0026lt;classELFT\u0026gt; std::vector\u0026lt;PhdrEntry *\u0026gt; Writer\u0026lt;ELFT\u0026gt;::createPhdrs(Partition \u0026amp;part) { std::vector\u0026lt;PhdrEntry *\u0026gt; ret; auto addHdr = [\u0026amp;](unsigned type, unsigned flags) -\u0026gt; PhdrEntry * { ret.push_back(make\u0026lt;PhdrEntry\u0026gt;(type, flags)); return ret.back(); }; unsigned partNo = part.getNumber(); bool isMain = partNo == 1; // Add the first PT_LOAD segment for regular output sections.  uint64_t flags = computeFlags(PF_R); PhdrEntry *load = nullptr; // nmagic or omagic output does not have PT_PHDR, PT_INTERP, or the readonly  // PT_LOAD.  if (!config-\u0026gt;nmagic \u0026amp;\u0026amp; !config-\u0026gt;omagic) { // The first phdr entry is PT_PHDR which describes the program header  // itself.  if (isMain) addHdr(PT_PHDR, PF_R)-\u0026gt;add(Out::programHeaders); else addHdr(PT_PHDR, PF_R)-\u0026gt;add(part.programHeaders-\u0026gt;getParent()); // PT_INTERP must be the second entry if exists.  if (OutputSection *cmd = findSection(\u0026#34;.interp\u0026#34;, partNo)) addHdr(PT_INTERP, cmd-\u0026gt;getPhdrFlags())-\u0026gt;add(cmd); // Add the headers. We will remove them if they don\u0026#39;t fit.  // In the other partitions the headers are ordinary sections, so they don\u0026#39;t  // need to be added here.  if (isMain) { load = addHdr(PT_LOAD, flags); load-\u0026gt;add(Out::elfHeader); load-\u0026gt;add(Out::programHeaders); } } // PT_GNU_RELRO includes all sections that should be marked as  // read-only by dynamic linker after processing relocations.  // Current dynamic loaders only support one PT_GNU_RELRO PHDR, give  // an error message if more than one PT_GNU_RELRO PHDR is required.  PhdrEntry *relRo = make\u0026lt;PhdrEntry\u0026gt;(PT_GNU_RELRO, PF_R); bool inRelroPhdr = false; OutputSection *relroEnd = nullptr; for (OutputSection *sec : outputSections) { if (sec-\u0026gt;partition != partNo || !needsPtLoad(sec)) continue; if (isRelroSection(sec)) { inRelroPhdr = true; if (!relroEnd) relRo-\u0026gt;add(sec); else error(\u0026#34;section: \u0026#34; + sec-\u0026gt;name + \u0026#34; is not contiguous with other relro\u0026#34; + \u0026#34; sections\u0026#34;); } else if (inRelroPhdr) { inRelroPhdr = false; relroEnd = sec; } } for (OutputSection *sec : outputSections) { if (!(sec-\u0026gt;flags \u0026amp; SHF_ALLOC)) break; if (!needsPtLoad(sec)) continue; // Normally, sections in partitions other than the current partition are  // ignored. But partition number 255 is a special case: it contains the  // partition end marker (.part.end). It needs to be added to the main  // partition so that a segment is created for it in the main partition,  // which will cause the dynamic loader to reserve space for the other  // partitions.  if (sec-\u0026gt;partition != partNo) { if (isMain \u0026amp;\u0026amp; sec-\u0026gt;partition == 255) addHdr(PT_LOAD, computeFlags(sec-\u0026gt;getPhdrFlags()))-\u0026gt;add(sec); continue; } // Segments are contiguous memory regions that has the same attributes  // (e.g. executable or writable). There is one phdr for each segment.  // Therefore, we need to create a new phdr when the next section has  // different flags or is loaded at a discontiguous address or memory  // region using AT or AT\u0026gt; linker script command, respectively. At the same  // time, we don\u0026#39;t want to create a separate load segment for the headers,  // even if the first output section has an AT or AT\u0026gt; attribute.  uint64_t newFlags = computeFlags(sec-\u0026gt;getPhdrFlags()); bool sameLMARegion = load \u0026amp;\u0026amp; !sec-\u0026gt;lmaExpr \u0026amp;\u0026amp; sec-\u0026gt;lmaRegion == load-\u0026gt;firstSec-\u0026gt;lmaRegion; if (!(load \u0026amp;\u0026amp; newFlags == flags \u0026amp;\u0026amp; sec != relroEnd \u0026amp;\u0026amp; sec-\u0026gt;memRegion == load-\u0026gt;firstSec-\u0026gt;memRegion \u0026amp;\u0026amp; (sameLMARegion || load-\u0026gt;lastSec == Out::programHeaders))) { load = addHdr(PT_LOAD, newFlags); flags = newFlags; } load-\u0026gt;add(sec); } // Add a TLS segment if any.  PhdrEntry *tlsHdr = make\u0026lt;PhdrEntry\u0026gt;(PT_TLS, PF_R); for (OutputSection *sec : outputSections) if (sec-\u0026gt;partition == partNo \u0026amp;\u0026amp; sec-\u0026gt;flags \u0026amp; SHF_TLS) tlsHdr-\u0026gt;add(sec); if (tlsHdr-\u0026gt;firstSec) ret.push_back(tlsHdr); // Add an entry for .dynamic.  if (OutputSection *sec = part.dynamic-\u0026gt;getParent()) addHdr(PT_DYNAMIC, sec-\u0026gt;getPhdrFlags())-\u0026gt;add(sec); if (relRo-\u0026gt;firstSec) ret.push_back(relRo); // PT_GNU_EH_FRAME is a special section pointing on .eh_frame_hdr.  if (part.ehFrame-\u0026gt;isNeeded() \u0026amp;\u0026amp; part.ehFrameHdr \u0026amp;\u0026amp; part.ehFrame-\u0026gt;getParent() \u0026amp;\u0026amp; part.ehFrameHdr-\u0026gt;getParent()) addHdr(PT_GNU_EH_FRAME, part.ehFrameHdr-\u0026gt;getParent()-\u0026gt;getPhdrFlags()) -\u0026gt;add(part.ehFrameHdr-\u0026gt;getParent()); // PT_OPENBSD_RANDOMIZE is an OpenBSD-specific feature. That makes  // the dynamic linker fill the segment with random data.  if (OutputSection *cmd = findSection(\u0026#34;.openbsd.randomdata\u0026#34;, partNo)) addHdr(PT_OPENBSD_RANDOMIZE, cmd-\u0026gt;getPhdrFlags())-\u0026gt;add(cmd); if (config-\u0026gt;zGnustack != GnuStackKind::None) { // PT_GNU_STACK is a special section to tell the loader to make the  // pages for the stack non-executable. If you really want an executable  // stack, you can pass -z execstack, but that\u0026#39;s not recommended for  // security reasons.  unsigned perm = PF_R | PF_W; if (config-\u0026gt;zGnustack == GnuStackKind::Exec) perm |= PF_X; addHdr(PT_GNU_STACK, perm)-\u0026gt;p_memsz = config-\u0026gt;zStackSize; } // PT_OPENBSD_WXNEEDED is a OpenBSD-specific header to mark the executable  // is expected to perform W^X violations, such as calling mprotect(2) or  // mmap(2) with PROT_WRITE | PROT_EXEC, which is prohibited by default on  // OpenBSD.  if (config-\u0026gt;zWxneeded) addHdr(PT_OPENBSD_WXNEEDED, PF_X); if (OutputSection *cmd = findSection(\u0026#34;.note.gnu.property\u0026#34;, partNo)) addHdr(PT_GNU_PROPERTY, PF_R)-\u0026gt;add(cmd); // Create one PT_NOTE per a group of contiguous SHT_NOTE sections with the  // same alignment.  PhdrEntry *note = nullptr; for (OutputSection *sec : outputSections) { if (sec-\u0026gt;partition != partNo) continue; if (sec-\u0026gt;type == SHT_NOTE \u0026amp;\u0026amp; (sec-\u0026gt;flags \u0026amp; SHF_ALLOC)) { if (!note || sec-\u0026gt;lmaExpr || note-\u0026gt;lastSec-\u0026gt;alignment != sec-\u0026gt;alignment) note = addHdr(PT_NOTE, PF_R); note-\u0026gt;add(sec); } else { note = nullptr; } } return ret; }    LLD Partitions Refrences:\n LLD Partitions  LLD\u0026rsquo;s partition feature allows a program (which may be an executable or a shared library) to be split inptu multiple pieces, or partitions. A partitioned program consists of a main partitin together with a number of loadable partions. The loadable partitions depend on the main partition in a similar way to a regular ELF shared object dependency, but unlike a shared object, the main partition and the loadable partitions share a virtual address space at link time, and each loadable partition is assigned a fixed offset from the main partition. This allows the loadable partitions to refer to code and data in the main parition directly withtout the binary size and performance overhead of PLTs, GOTs or symbol table entries.\nAddress Resolution  GOT/PLT table: linker will redirect all external references to a dynamic library to an entry in these tables. For capsule ownership section, a similar approach will be used: recreate each entry with an address pointing to the txt/data section, and with ownership values. Now to understand how does these work, the questions seek to answer:  How/Where does the linker create these GOT/PLT entries? How/Where does the linker update the corresponding sections\u0026rsquo; references to the global variables/function ptrs?   Call Path:\n// lld/ELF/{Driver|Writer}.cpp LinkerDriver::link\u0026lt;ELFT\u0026gt;() // lld/ELF/Driver.cpp  =\u0026gt; writeResult\u0026lt;ELFT\u0026gt;() // lld/ELF/Driver.cpp  =\u0026gt; Writer\u0026lt;ELFT\u0026gt;().run() // lld/ELF/Writer.cpp  =\u0026gt; Writer\u0026lt;ELFT\u0026gt;::finalizeSections() // lld/ELF/Writer.cpp  =\u0026gt; ... // Some symbols are defined in term of program headers. Now that we  // have the headers, we can find out which sections they point to.  setReservedSymbolSections(); finalizeSynthetic(in.bss); finalizeSynthetic(in.bssRelRo); finalizeSynthetic(in.symTabShndx); finalizeSynthetic(in.shStrTab); finalizeSynthetic(in.strTab); finalizeSynthetic(in.got); finalizeSynthetic(in.mipsGot); finalizeSynthetic(in.igotPlt); finalizeSynthetic(in.gotPlt); finalizeSynthetic(in.relaIplt); finalizeSynthetic(in.relaPlt); finalizeSynthetic(in.plt); finalizeSynthetic(in.iplt); finalizeSynthetic(in.ppc32Got2); finalizeSynthetic(in.partIndex);  assignAddresses() \u0026ldquo;This function assign address as instructed by linker script SECTIONS sub-commands. Doing that allows us to use final VA values.\u0026rdquo;\nAfter this, all output sections have their addr field being set to be the virtual address which is the address referred by the loader when they are being loaded.\n scan and parse each output section commands, update .dot according to each section. see LinkerScript::assignAddresses() called in Writer\u0026lt;ELFT\u0026gt;::finalizeSections() =\u0026gt; Writer\u0026lt;ELFT\u0026gt;::finalizeAddressDependentContent() =\u0026gt; LinkerScript::assignAddresses();  Call Path:\nWriter::finalizeSections() =\u0026gt; Writer\u0026lt;ELFT\u0026gt;::finalizeAddressDependentContent() =\u0026gt; script-\u0026gt;assignAddresses(); // multiple places  Writer::finalizeSections() =\u0026gt; Writer\u0026lt;ELFT\u0026gt;::optimizeBasicBlockJumps() // if (config-\u0026gt;optmizeBBJumps)  =\u0026gt; script-\u0026gt;assignAddresses(); const Defined *LinkerScript::assignAddresses() // lld/ELF/LinkerScript.cpp =\u0026gt; // lld/ELF/LinkerScript.cpp  // Here we assign addresses as instructed by linker script SECTIONS // sub-commands. Doing that allows us to use final VA values, so here // we also handle rest commands like symbol assignments and ASSERTs. // Returns a symbol that has changed its section or value, or nullptr if no // symbol has changed. const Defined *LinkerScript::assignAddresses() { if (script-\u0026gt;hasSectionsCommand) { // With a linker script, assignment of addresses to headers is covered by  // allocateHeaders().  dot = config-\u0026gt;imageBase.getlaterValueOr(0); } else { // Assign addresses to headers right now.  dot = target-\u0026gt;getImageBase(); Out::elfHeader-\u0026gt;addr = dot; Out::programHeaders-\u0026gt;addr = dot + Out::elfHeader-\u0026gt;size; dot += getHeaderSize(); } auto deleter = std::make_unique\u0026lt;AddressState\u0026gt;(); ctx = deleter.get(); errorOnMissingSection = true; switchTo(aether); SymbolAssignmentMap oldValues = getSymbolAssignmentValues(sectionCommands); for (BaseCommand *base : sectionCommands) { if (auto *cmd = dyn_cast\u0026lt;SymbolAssignment\u0026gt;(base)) { cmd-\u0026gt;addr = dot; assignSymbol(cmd, false); cmd-\u0026gt;size = dot - cmd-\u0026gt;addr; continue; } assignOffsets(cast\u0026lt;OutputSection\u0026gt;(base)); } ctx = nullptr; return getChangedSymbolAssignment(oldValues); }  AddressState // lld/ELF/LinkerScript.h  // Temporary state used in processSectionCommands() and assignAddresses()  // that must be reinitialized for each call to the above functions, and must  // not be used outside of the scope of a call to the above functions.  struct AddressState { AddressState(); uint64_t threadBssOffset = 0; OutputSection *outSec = nullptr; MemoryRegion *memRegion = nullptr; MemoryRegion *lmaRegion = nullptr; uint64_t lmaOffset = 0; };  finalizeInputSections() Ending  Phdrs_cmds  Reference reference phdrsCommands (empty for most binary) In LinkerScript: // lld/ELF/LinkerScript.h classLinkerScript final{ // PHDRS command list. std::vector\u0026lt;PhdrsCommand\u0026gt; phdrsCommands; }; In LLD Code updated in two ways; based on the linker script if exists; by the linker itself if no linker script is given (true for binary and relocatable outputs); The driven function to update the program header commands, in void Writer\u0026lt;ELFT\u0026gt;::finalizeSections() // lld/ELF/Writer.cpp // Create output section objects and add them to OutputSections.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/relocation/",
	"title": "Relocation Section",
	"tags": [],
	"description": "",
	"content": " References:\n ELF specification Computer Systems: A Programmer\u0026rsquo;s Perspective, Chapter 7.7 PLT and GOT - the key to code sharing and dynamic libraries GOT and PLT for pwning  Relocation is the process of connecting symbolic references with symbolic definitions. For example, when a program calls a function, the associated call instruction must transfer control to the proper destination address at execution. In other words, relocatable files must have information that describes how to modify their section contents, thus allowing executable and shared object files to hold the right information for a process\u0026rsquo;s program image. Relocation entries are the data designed for this task.\nRelocation Entries typedef struct { Elf32_Addr r_offset; Elf32_Word r_info; } Elf32_Rel; typedef struct { Elf32_Addr r_offset; Elf32_Word r_info; Elf32_Sword r_addend; } Elf32_Rela;   r_offset: gives the location at which to apply the relocation action. For a relocatable file, the value is the byte offset from the beginning of the section to the storage unit affected by the relocation. For an executable file or a shared object, the value is the virtual address of the storage unit affected by the relocation. (LLM: What is the storage unit here???). Relocation entries for different object files have slightly differnet interpretations for the r_offset.\n In relocatable files, r_offset holds a section offset. That is, the relocation section itself describes how to modify another section in the same file; relocation offsets designate a storage unit within the second section. In executable and shared object file, r_offset holds a virtual address. To make these file\u0026rsquo;s relocation entries more useful for the dynamic linker, the section offset (file interpretation) gives way to a virtual address (memory interpretation). Although the different file and memory interpretations exist for r_offset, the goal is solely to make relocation access more efficient, and the underlying meaning of r_offset stays the same.  r_info: gives both the symbol table index with respect to which the relocation must be made, and the type of the relocation to apply.\n For example, a call instruction\u0026rsquo;s relocation entry would hold the symbol table index of the function being called. If the index is STN_UNDEF, the undefined symbol index, the relocation uses 0 as the symbol value. Relocation types are processor-specific, descriptions of their behavior appear in the processor supplement. When the text in the processor supplement refers to a relocation entry\u0026rsquo;s relocation type or symbol table index, it means the result of applying ELF32_R_TYPE or ELF32_R_SYM, respectively, to the entry\u0026rsquo;s r_info member.  r_addend: a constant addend used to compute the value to be stored into the relocatable field.\n  A relocation section references two other sections: a symbol table and a section to modify. The section header\u0026rsquo;s sh_info and sh_link members, specify these relationships.\n$ readelf -r global_array.exe There are no relocations in this file. $ readelf -r global_array.o Relocation section \u0026#39;.rela.text\u0026#39; at offset 0xcd8 contains 28 entries: Offset Info Type Symbol\u0026#39;s Value Symbol\u0026#39;s Name + Addend 0000000000000010 0000000e00051807 R_MIPS_GPREL16/R_MIPS_SUB/R_MIPS_HI16 0000000000000000 set_global_int + 0 0000000000000018 0000000e00061807 R_MIPS_GPREL16/R_MIPS_SUB/R_MIPS_LO16 0000000000000000 set_global_int + 0 0000000000000058 0000000a00000013 R_MIPS_GOT_DISP/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 global_int + 0 00000000000000b4 0000000f00051807 R_MIPS_GPREL16/R_MIPS_SUB/R_MIPS_HI16 00000000000000a0 use_global_int + 0 00000000000000bc 0000000f00061807 R_MIPS_GPREL16/R_MIPS_SUB/R_MIPS_LO16 00000000000000a0 use_global_int + 0 00000000000000c4 0000000600000014 R_MIPS_GOT_PAGE/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .rodata.str1.1 + 0 00000000000000c8 0000000600000015 R_MIPS_GOT_OFST/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .rodata.str1.1 + 0 00000000000000cc 0000000d0000000b R_MIPS_CALL16/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 printf + 0 0000000000000110 0000000a00000013 R_MIPS_GOT_DISP/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 global_int + 0 0000000000000144 0000000600000014 R_MIPS_GOT_PAGE/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .rodata.str1.1 + 2 0000000000000148 0000000600000015 R_MIPS_GOT_OFST/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .rodata.str1.1 + 2 000000000000014c 0000000d0000000b R_MIPS_CALL16/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 printf + 0 00000000000000d8 0000000d00000025 R_MIPS_JALR/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 printf + 0 000000000000016c 0000000600000014 R_MIPS_GOT_PAGE/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .rodata.str1.1 + 7 0000000000000170 0000000600000015 R_MIPS_GOT_OFST/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .rodata.str1.1 + 7 0000000000000174 0000000d0000000b R_MIPS_CALL16/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 printf + 0 0000000000000154 0000000d00000025 R_MIPS_JALR/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 printf + 0 00000000000001ac 0000000600000014 R_MIPS_GOT_PAGE/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .rodata.str1.1 + e 00000000000001b0 0000000600000015 R_MIPS_GOT_OFST/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .rodata.str1.1 + e 00000000000001b4 0000000d0000000b R_MIPS_CALL16/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 printf + 0 000000000000017c 0000000d00000025 R_MIPS_JALR/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 printf + 0 00000000000001bc 0000000d00000025 R_MIPS_JALR/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 printf + 0 00000000000001f4 0000000c00051807 R_MIPS_GPREL16/R_MIPS_SUB/R_MIPS_HI16 00000000000001e0 main + 0 00000000000001fc 0000000c00061807 R_MIPS_GPREL16/R_MIPS_SUB/R_MIPS_LO16 00000000000001e0 main + 0 0000000000000200 0000000f0000000b R_MIPS_CALL16/R_MIPS_NONE/R_MIPS_NONE 00000000000000a0 use_global_int + 0 0000000000000224 0000000f0000000b R_MIPS_CALL16/R_MIPS_NONE/R_MIPS_NONE 00000000000000a0 use_global_int + 0 0000000000000218 0000000f00000025 R_MIPS_JALR/R_MIPS_NONE/R_MIPS_NONE 00000000000000a0 use_global_int + 0 0000000000000230 0000000f00000025 R_MIPS_JALR/R_MIPS_NONE/R_MIPS_NONE 00000000000000a0 use_global_int + 0 ... Relocation section \u0026#39;.rela.stack_sizes\u0026#39; at offset 0xfc0 contains 3 entries: Offset Info Type Symbol\u0026#39;s Value Symbol\u0026#39;s Name + Addend 0000000000000000 0000000500000012 R_MIPS_64/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .text + 0 0000000000000009 0000000500000012 R_MIPS_64/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .text + a0 0000000000000012 0000000500000012 R_MIPS_64/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .text + 1e0 Relocation section \u0026#39;.rela.debug_info\u0026#39; at offset 0x1008 contains 29 entries: Offset Info Type Symbol\u0026#39;s Value Symbol\u0026#39;s Name + Addend 0000000000000006 0000000700000002 R_MIPS_32/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .debug_abbrev + 0 000000000000000c 0000000800000002 R_MIPS_32/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .debug_str + 0 0000000000000012 0000000800000002 R_MIPS_32/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .debug_str + 67 0000000000000016 0000000900000002 R_MIPS_32/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .debug_line + 0 000000000000001a 0000000800000002 R_MIPS_32/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .debug_str + 76 000000000000001e 0000000500000012 R_MIPS_64/R_MIPS_NONE/R_MIPS_NONE 0000000000000000 .text + 0 PLT and GOT Refrences:\n PLT and GOT - the key to code sharing and dynamic libraries GOT and PLT for pwning  PLT (.plt) and GOT (.got) are for dynamic linking.\nRelocation entry: A relocation entry in a binary is a descriptor which essentially says \u0026ldquo;determine the value of X, and put that value into the binary at offset Y\u0026rdquo; \u0026ndash; each relocation has a specific type, defined in the ABI documentation, which describes exactly how to \u0026ldquo;determine the value of X\u0026rdquo;.\nThese relocation entries in binaries are left to be filled in later \u0026ndash; at link time by the toolchain linker or at runtime by the dynamic linker.\n$ cat a.c extern int foo; int function(void){ return foo; } $ gcc -c test.c -o test.o $ readelf --relocs ./test.o Relocation section \u0026#39;.rela.text\u0026#39; at offset 0x1b8 contains 1 entry: Offset Info Type Sym. Value Sym. Name + Addend 000000000006 000900000002 R_X86_64_PC32 0000000000000000 foo - 4 The value of foo is not known during compilation, so the compiler leaves behind a relocation entry (of type R_X86_64_PC32) which is saying \u0026ldquo;in the final binary, patch the value at offset 0x6 in this object file with the address of symbol foo\u0026rdquo;. If you take a look at the output file, you can see at offset 0x6 there are 4 bytes of zeroes just waiting for a real address:\nobjdump --disassemble ./test.o test.o: file format elf64-x86-64 Disassembly of section .text: 0000000000000000 \u0026lt;function\u0026gt;: 0:\t55 push %rbp 1:\t48 89 e5 mov %rsp,%rbp 4:\t8b 05 00 00 00 00 mov 0x0(%rip),%eax # a \u0026lt;function+0xa\u0026gt; a:\t5d pop %rbp b:\tc3 retq  This will be resolved at link time.\nFor unresolved data or code in a dynamic libraries, or code using dynamic libraries, how to access the data or call the function which is unknown at compilation or linking time yet?\nGOT and PLT provides a layer of indirection where dynamic lib loader can query the two to compute the right location:\n GOT (Global Offset Table). The table has the place holders for unresolved data, where a dynamic loader can fill in the actual data or address to this table during the loading of the library. PLT (Procedure Linkage Table). The dynamic loaders will indirect all the unresolved functions in the dynamic library to a PLT stub function. The PLT stub.  Only go through the PLT stub for the fist time (when target func is unresolved yet, the got.plt entry store the address of PLT stub);  PLT stub will call the ld.so functions to resolve the address; When the function address is resolved for the first time by the dynamic loader ld.so, the loader will also save the address to the GOT (.got.plt), which replaces the PLT stub address.  Next time the function is called, func addr is called over GOT (.got.plt) without going through PLT stub.   More at\n PLT and GOT - the key to code sharing and dynamic libraries\n GOT and PLT for pwning\n  Relocation support in LLD see more on Relocation in LLD.\n// lld/ELF/Relocations.cpp  //===- Relocations.cpp ----------------------------------------------------===// // // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions. // See https://llvm.org/LICENSE.txt for license information. // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception // //===----------------------------------------------------------------------===// // // This file contains platform-independent functions to process relocations. // I\u0026#39;ll describe the overview of this file here. // // Simple relocations are easy to handle for the linker. For example, // for R_X86_64_PC64 relocs, the linker just has to fix up locations // with the relative offsets to the target symbols. It would just be // reading records from relocation sections and applying them to output. // // But not all relocations are that easy to handle. For example, for // R_386_GOTOFF relocs, the linker has to create new GOT entries for // symbols if they don\u0026#39;t exist, and fix up locations with GOT entry // offsets from the beginning of GOT section. So there is more than // fixing addresses in relocation processing. // // ELF defines a large number of complex relocations. // // The functions in this file analyze relocations and do whatever needs // to be done. It includes, but not limited to, the following. // // - create GOT/PLT entries // - create new relocations in .dynsym to let the dynamic linker resolve // them at runtime (since ELF supports dynamic linking, not all // relocations can be resolved at link-time) // - create COPY relocs and reserve space in .bss // - replace expensive relocs (in terms of runtime cost) with cheap ones // - error out infeasible combinations such as PIC and non-relative relocs // // Note that the functions in this file don\u0026#39;t actually apply relocations // because it doesn\u0026#39;t know about the output file nor the output file buffer. // It instead stores Relocation objects to InputSection\u0026#39;s Relocations // vector to let it apply later in InputSection::writeTo. // //===----------------------------------------------------------------------===//  COPY relocations reference: Copy Relocations\n RELRO  References: Hardening ELF binaries using Relocation Read-Only(RELRO) RELRO ELF: Executable and Linkable Format. PIE: Position Independent Executables. RELRO: Relocation Read-Only. In dynamic linked ELF: GOT: Global Offset Table. A look-up table, contains pointers that points to the actual location of dynamically resolved functions. Lives in .got.plt section. Located at a static address. Needs to be writable. \u0026mdash;\u0026gt; can be overflowed by attackers. dynamically populcated as the program is running: first time GOT points back to PLT(inside a dynamic linker procedure), the dynamic linker finds the actual location, then written to GOT.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/lld/",
	"title": "lld",
	"tags": [],
	"description": "",
	"content": " Reference\n [lld/ELF/Driver.cpp] lld/ELF/LinkerScript.cpp  lld xxx.o -o xxx.exe\nlld \u0026ndash;verbose\nHow to determine which sections to write to exe LinkerDriver::link\u0026lt;ELFT\u0026gt; is the driving entry for the link to prepare different sections needed for the final executable.\ninputSecions hold a list of all sections from all object files.\noutputSections   tracking sections in/out   // lld/ELF/Driver.cpp  // Do actual linking. Note that when this function is called, // all linker scripts have already been parsed. template \u0026lt;classELFT\u0026gt; void LinkerDriver::link(opt::InputArgList \u0026amp;args) { ... // Now that we have a complete list of input files.  // Beyond this point, no new files are added.  // Aggregate all input sections into one place.  for (InputFile *f : objectFiles) for (InputSectionBase *s : f-\u0026gt;getSections()){ if (s \u0026amp;\u0026amp; s != \u0026amp;InputSection::discarded){ inputSections.push_back(s); MSGLL(\u0026#34;input section added: \u0026#39;\u0026#34; + s-\u0026gt;name + \u0026#34;\u0026#39;, size: \u0026#34; + std::to_string(s-\u0026gt;getSize()) + \u0026#34;\\n\u0026#34;); }else{ if (s) MSGLL(\u0026#34;empty section disgarded: \u0026#39;\u0026#34; + s-\u0026gt;name + \u0026#34;\u0026#39;\\n\u0026#34;); } } for (BinaryFile *f : binaryFiles) for (InputSectionBase *s : f-\u0026gt;getSections()) inputSections.push_back(cast\u0026lt;InputSection\u0026gt;(s)); llvm::erase_if(inputSections, [](InputSectionBase *s) { if (s-\u0026gt;type == SHT_LLVM_SYMPART) { readSymbolPartitionSection\u0026lt;ELFT\u0026gt;(s); MSGLL(\u0026#34;input section \u0026#39;\u0026#34; + s-\u0026gt;name + \u0026#34;\u0026#39; removed\\n\u0026#34;); return true; } // We do not want to emit debug sections if --strip-all  // or -strip-debug are given.  if(config-\u0026gt;strip != StripPolicy::None \u0026amp;\u0026amp; (s-\u0026gt;name.startswith(\u0026#34;.debug\u0026#34;) || s-\u0026gt;name.startswith(\u0026#34;.zdebug\u0026#34;))) { MSGLL(\u0026#34;input section (debug) \u0026#39;\u0026#34; + s-\u0026gt;name + \u0026#34;\u0026#39; removed\\n\u0026#34;); return true; }else{ return false; } }); // Linker scripts control how input sections are assigned to output sections.  // Input sections that were not handled by scripts are called \u0026#34;orphans\u0026#34;, and  // they are assigned to output sections by the default rule. Process that.  script-\u0026gt;addOrphanSections(); ... }  LinkerScript::addOrphanSections() handles sections that are not defined in the LinkerScritps using default rules.\n// Add sections that didn\u0026#39;t match any sections command. void LinkerScript::addOrphanSections() { StringMap\u0026lt;TinyPtrVector\u0026lt;OutputSection *\u0026gt;\u0026gt; map; std::vector\u0026lt;OutputSection *\u0026gt; v; auto add = [\u0026amp;](InputSectionBase *s) { MSGLL(\u0026#34;Handling Orphan Section: \u0026#34; + s-\u0026gt;name + \u0026#34;\\n\u0026#34;); if (!s-\u0026gt;isLive() || s-\u0026gt;parent) return; StringRef name = getOutputSectionName(s); MSGLL(\u0026#34;Orphan section is placed in \u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;\\n\u0026#34;); if (config-\u0026gt;orphanHandling == OrphanHandlingPolicy::Error) error(toString(s) + \u0026#34; is being placed in \u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;\u0026#34;); else if (config-\u0026gt;orphanHandling == OrphanHandlingPolicy::Warn) warn(toString(s) + \u0026#34; is being placed in \u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;\u0026#34;); if (OutputSection *sec = findByName(sectionCommands, name)) { sec-\u0026gt;addSection(cast\u0026lt;InputSection\u0026gt;(s)); return; } if (OutputSection *os = addInputSec(map, s, name)) v.push_back(os); assert(s-\u0026gt;getOutputSection()-\u0026gt;sectionIndex == UINT32_MAX); }; // For futher --emit-reloc handling code we need target output section  // to be created before we create relocation output section, so we want  // to create target sections first. We do not want priority handling  // for synthetic sections because them are special.  for (InputSectionBase *isec : inputSections) { if (auto *sec = dyn_cast\u0026lt;InputSection\u0026gt;(isec)) if (InputSectionBase *rel = sec-\u0026gt;getRelocatedSection()) if (auto *relIS = dyn_cast_or_null\u0026lt;InputSectionBase\u0026gt;(rel-\u0026gt;parent)) add(relIS); add(isec); } // If no SECTIONS command was given, we should insert sections commands  // before others, so that we can handle scripts which refers them,  // for example: \u0026#34;foo = ABSOLUTE(ADDR(.text)));\u0026#34;.  // When SECTIONS command is present we just add all orphans to the end.  if (hasSectionsCommand) sectionCommands.insert(sectionCommands.end(), v.begin(), v.end()); else sectionCommands.insert(sectionCommands.begin(), v.begin(), v.end()); }   Thunk  Reference reference A thunk is a code-sequence inserted by the linker in between a caller and the callee. A relocation to the callee is redirected to the Thunk. // lld/ELF/Thunks.h // Class to describe an instance of a Thunk. // A Thunk is a code-sequence inserted by the linker in between a caller and // the callee. The relocation to the callee is redirected to the Thunk, which // after executing transfers control to the callee.\n Relocation in LLD  Reference reference Relocation after Address Assignment Each section has a relocate method that can relocate itself. It happens after the dot address resolution, phdrs creation. Relocation per Section Relocation for each relocatable section: // lld/ELF/InputSection.h // class InputSectionBase // Each section knows how to relocate itself. These functions apply // relocations, assuming that Buf points to this section\u0026#39;s copy in // the mmap\u0026#39;ed output buffer. template \u0026lt;classELFT\u0026gt; void relocate(uint8_t *buf, uint8_t *bufEnd); void relocateAlloc(uint8_t *buf, uint8_t *bufEnd); static uint64_t getRelocTargetVA(const InputFile *File, RelType Type, relocateNoSym int64_t A, uint64_t P, const Symbol \u0026amp;Sym, RelExpr Expr, InputSectionBase *isec, uint64_t offset); Call path for relocate, relocateAlloc and getRelocTargetVA:\n Linking  Q\u0026amp;A How to merge the .text sections from two object (relocatable) files into one executable binary? How/When to determine the virtual address of each .text segment? scan and parse each output section commands, update .dot according to each section. see LinkerScript::assignAddresses() called in Writer\u0026lt;ELFT\u0026gt;::finalizeSections() =\u0026gt; Writer\u0026lt;ELFT\u0026gt;::finalizeAddressDependentContent() =\u0026gt; LinkerScript::assignAddresses(); How/When to update the other sections that related to the relocated .text sections? References: lld/ELF/Driver.\n  \n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/mc-streamer/mips-elf-streamer/",
	"title": "Mips Elf Streamer",
	"tags": [],
	"description": "",
	"content": " Reference\n llvm/lib/Target/Mips/MCTargetDesc/MipsELFStreamer.h llvm/lib/Target/Mips/MCTargetDesc/MipsELFStreamer.cpp\n// Inheritance relations  MCStreamer (contain an instance of `MCTargetStreamer` as member `TargetStreamer`) -\u0026gt; MCAsmStreamer (final) -\u0026gt; MCObjectStreamer -\u0026gt; MCELFStreamer -\u0026gt; MipsELFStreamer -\u0026gt; MCWasmStreamer // MCTargetStreamer for directives.  // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetAsmStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetELFStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; RISCVTargetStreamer // lib/Target/RISCV/MCTargetDesc/RISCVTargetStreamer.h   MCELFStreamer::EmitInstToData() MCELFStreamer::EmitInstToData() handles how an instruction MCInst is emitted to binary file.\nThe Call path:\nMipsAsmPrinter::EmitInstruction(const MachineInstr *MI) -\u0026gt; MCInstLowering.Lower(\u0026amp;*I, TmpInst0); // here MachineInstr is lowered to MCInst -\u0026gt; EmitToStreamer(*OutStreamer, TmpInst0); // here a streamer is called to emit the MCInst  -\u0026gt; MCObjectStreamer::EmitInstruction(MCInst \u0026amp;, MCSubtargetInfo \u0026amp;) -\u0026gt; MCELFStreamer::EmitInstToData(Inst, STI) // all no-relaxation instructions and some relaxation instructions.  -\u0026gt; MCELFStreamer::EmitInstToFragment(Inst, STI) // for some other relaxiable instructions.  Major steps:\nvoid MCELFStreamer::EmitInstToData(const MCInst \u0026amp;Inst, const MCSubtargetInfo \u0026amp;STI) { MCAssembler \u0026amp;Assembler = getAssembler(); SmallVector\u0026lt;MCFixup, 4\u0026gt; Fixups; SmallString\u0026lt;256\u0026gt; Code; raw_svector_ostream VecOS(Code); Assembler.getEmitter().encodeInstruction(Inst, VecOS, Fixups, STI); // DebugLL(\u0026#34;Done encode Instruction by the target: \u0026#34; \u0026lt;\u0026lt; VecOS.str() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;);  for (unsigned i = 0, e = Fixups.size(); i != e; ++i) fixSymbolsInTLSFixups(Fixups[i].getValue()); // There are several possibilities here:  //  // If bundling is disabled, append the encoded instruction to the current data  // fragment (or create a new such fragment if the current fragment is not a  // data fragment, or the Subtarget has changed).  //  // If bundling is enabled:  // - If we\u0026#39;re not in a bundle-locked group, emit the instruction into a  // fragment of its own. If there are no fixups registered for the  // instruction, emit a MCCompactEncodedInstFragment. Otherwise, emit a  // MCDataFragment.  // - If we\u0026#39;re in a bundle-locked group, append the instruction to the current  // data fragment because we want all the instructions in a group to get into  // the same fragment. Be careful not to do that for the first instruction in  // the group, though.  MCDataFragment *DF; if (Assembler.isBundlingEnabled()) { DebugLL(\u0026#34;Bundling: TODO: check/add support for the ownership emission\\n\u0026#34;); MCSection \u0026amp;Sec = *getCurrentSectionOnly(); if (Assembler.getRelaxAll() \u0026amp;\u0026amp; isBundleLocked()) { // If the -mc-relax-all flag is used and we are bundle-locked, we re-use  // the current bundle group.  DF = BundleGroups.back(); CheckBundleSubtargets(DF-\u0026gt;getSubtargetInfo(), \u0026amp;STI); } else if (Assembler.getRelaxAll() \u0026amp;\u0026amp; !isBundleLocked()) // When not in a bundle-locked group and the -mc-relax-all flag is used,  // we create a new temporary fragment which will be later merged into  // the current fragment.  DF = new MCDataFragment(); else if (isBundleLocked() \u0026amp;\u0026amp; !Sec.isBundleGroupBeforeFirstInst()) { // If we are bundle-locked, we re-use the current fragment.  // The bundle-locking directive ensures this is a new data fragment.  DF = cast\u0026lt;MCDataFragment\u0026gt;(getCurrentFragment()); CheckBundleSubtargets(DF-\u0026gt;getSubtargetInfo(), \u0026amp;STI); } else if (!isBundleLocked() \u0026amp;\u0026amp; Fixups.size() == 0) { // Optimize memory usage by emitting the instruction to a  // MCCompactEncodedInstFragment when not in a bundle-locked group and  // there are no fixups registered.  MCCompactEncodedInstFragment *CEIF = new MCCompactEncodedInstFragment(); insert(CEIF); CEIF-\u0026gt;getContents().append(Code.begin(), Code.end()); CEIF-\u0026gt;setHasInstructions(STI); return; } else { DF = new MCDataFragment(); insert(DF); } if (Sec.getBundleLockState() == MCSection::BundleLockedAlignToEnd) { // If this fragment is for a group marked \u0026#34;align_to_end\u0026#34;, set a flag  // in the fragment. This can happen after the fragment has already been  // created if there are nested bundle_align groups and an inner one  // is the one marked align_to_end.  DF-\u0026gt;setAlignToBundleEnd(true); } // We\u0026#39;re now emitting an instruction in a bundle group, so this flag has  // to be turned off.  Sec.setBundleGroupBeforeFirstInst(false); } else { DF = getOrCreateDataFragment(\u0026amp;STI); } // Add the fixups and data.  for (unsigned i = 0, e = Fixups.size(); i != e; ++i) { Fixups[i].setOffset(Fixups[i].getOffset() + DF-\u0026gt;getContents().size()); DF-\u0026gt;getFixups().push_back(Fixups[i]); } DF-\u0026gt;setHasInstructions(STI); DF-\u0026gt;getContents().append(Code.begin(), Code.end()); if (Assembler.isBundlingEnabled() \u0026amp;\u0026amp; Assembler.getRelaxAll()) { if (!isBundleLocked()) { mergeFragment(getOrCreateDataFragment(\u0026amp;STI), DF); delete DF; } } EmitOwnershipToData(Inst, STI); }  MipsELFStreamer::EmitIntValue MipsELFStreamer, defined in lib/Target/Mips/MCTargetDesc/MipsELFStreamer.h\nEmitIntValue() is defined as:\n// lib/Target/Mips/MCTargetDesc/MipsELFStreamer.cpp void MipsELFStreamer::EmitIntValue(uint64_t Value, unsigned Size) { MCELFStreamer::EmitIntValue(Value, Size); Labels.clear(); }  MCELFStreamer::EmitIntValue() is an inherited methods include/llvm/MC/MCELFStreamer.h -\u0026gt; include/llvm/MC/MCStreamer.h, defined in llvm/lib/MC/MCStreamer.cpp\n// llvm/lib/MC/MCStreamer.cpp  /// emitIntValue - Special case of EmitValue that avoids the client having to /// pass in a MCExpr for constant integers. void MCStreamer::emitIntValue(uint64_t Value, unsigned Size) { assert(1 \u0026lt;= Size \u0026amp;\u0026amp; Size \u0026lt;= 8 \u0026amp;\u0026amp; \u0026#34;Invalid size\u0026#34;); assert((isUIntN(8 * Size, Value) || isIntN(8 * Size, Value)) \u0026amp;\u0026amp; \u0026#34;Invalid size\u0026#34;); char buf[8]; const bool isLittleEndian = Context.getAsmInfo()-\u0026gt;isLittleEndian(); for (unsigned i = 0; i != Size; ++i) { unsigned index = isLittleEndian ? i : (Size - i - 1); buf[i] = uint8_t(Value \u0026gt;\u0026gt; (index * 8)); } emitBytes(StringRef(buf, Size)); }  MCStreamer::emitBytes() is implemented in the children classes, such as MCAsmStreamer, MCObjectStreamer, ARMELFStreamer etc.\nHere is the MCObjectStreamer impl. (Question: will it update the offset of the current section?)\n// llvm/lib/MC/MCObjectStreamer.cpp  void MCObjectStreamer::emitBytes(StringRef Data) { MCDwarfLineEntry::Make(this, getCurrentSectionOnly()); MCDataFragment *DF = getOrCreateDataFragment(); flushPendingLabels(DF, DF-\u0026gt;getContents().size()); DF-\u0026gt;getContents().append(Data.begin(), Data.end()); }   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/asm-printer/global-print/",
	"title": "Emit Globals in AsmPrinter",
	"tags": [],
	"description": "",
	"content": "Reference\n llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp  The call path of emitting a global variable:\nAsmPrinter::doFinalization(Module \u0026amp;) =\u0026gt; emitGlobalVariable(\u0026amp;G); // for (const auto \u0026amp;G : M.globals()) =\u0026gt; emitGlobalGOTEquivs() =\u0026gt; emitGlobalVariable(GV) // for (auto *GV: FailedCandidates)  Function interfaces for global emission in AsmPrinter:\n// llvm/include/llvm/CodeGen/AsmPrinter.h  /// This class is intended to be used as a driving class for all asm writers. classAsmPrinter : public MachineFunctionPass { ... /// Emit the specified global variable to the .s file.  virtual void emitGlobalVariable(const GlobalVariable *GV); /// Check to see if the specified global is a special global used by LLVM. If  /// so, emit it and return true, otherwise do nothing and return false.  bool emitSpecialLLVMGlobal(const GlobalVariable *GV); /// Constant expressions using GOT equivalent globals may not be  /// eligible for PC relative GOT entry conversion, in such cases we need to  /// emit the proxies we previously omitted in EmitGlobalVariable.  void emitGlobalGOTEquivs(); ... } // llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp  static void emitGlobalConstantArray(const DataLayout \u0026amp;DL, const ConstantArray *CA, AsmPrinter \u0026amp;AP, const Constant *BaseCV, uint64_t Offset); static void emitGlobalConstantImpl(const DataLayout \u0026amp;DL, const Constant *C, AsmPrinter \u0026amp;AP, const Constant *BaseCV = nullptr, uint64_t Offset = 0); static void emitGlobalConstantFP(const ConstantFP *CFP, AsmPrinter \u0026amp;AP); static void emitGlobalConstantFP(APFloat APF, Type *ET, AsmPrinter \u0026amp;AP);  The global variable value is finally emitted by EmitGlobalConstant:\n/// EmitGlobalConstant - Print a general LLVM constant to the .s file. void AsmPrinter::EmitGlobalConstant(const DataLayout \u0026amp;DL, const Constant *CV, uint64_t TailPadding) { uint64_t Size = DL.getTypeAllocSize(CV-\u0026gt;getType()); if (Size) emitGlobalConstantImpl(DL, CV, *this); else if (MAI-\u0026gt;hasSubsectionsViaSymbols()) { // If the global has zero size, emit a single byte so that two labels don\u0026#39;t  // look like they are at the same location.  OutStreamer-\u0026gt;EmitIntValue(0, 1); } if (TailPadding != 0) { OutStreamer-\u0026gt;AddComment(\u0026#34;Tail padding to ensure precise bounds\u0026#34;); OutStreamer-\u0026gt;EmitZeros(TailPadding); } }   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/new-section/",
	"title": "New Section",
	"tags": [],
	"description": "",
	"content": " Reference reference\nTo emit a new section, e.g. .newsection, to an object (ELF) file:\n add an option to clang to enable options.\n need to pass option from clang frontend to backend. Option finally goes to TargetOptions::EmitNewSection Option access in different classes:  via TargetMachine instance: TM.Options.EmitNewSection  Can be used in AsmPrinter, etc.  via MachineFunction instance: MF.getTarget().Options.EmitNewSection   update AsmPrinter class in LLVM CodeGen to emit the new section. e.g. AsmPrinter::emitNewSection()\n implement in llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp  add target dependent interface in AsmPrinter for each target to implement the actual emission for the section. e.g. virtual void EmitNewSectionEntry();\n impl for mips in llvm/lib/Target/Mips/MipsAsmPrinter.cpp  add a new MCSection member, say MCSection *NewSection;, to MCObjectFileInfo class.\n Also add the corresponding get methods: e.g. MCSection *getNewSection(){...}  Update initialization code of MCObjectFileInfo to create the new section instance.\n in MCObjectFileInfo::initELFMCObjectFileInfo():   code: initELFMCObjectFileInfo()   void MCObjectFileInfo::initELFMCObjectFileInfo(const Triple \u0026amp;T, bool Large) { ... NewSection = Ctx-\u0026gt;getELFSection(\u0026#34;.newsection\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC); ... }     Register the section to the MCAssembler in MipsTargetELFStreamer::finish():   register section   void MipsTargetELFStreamer::finish() { MCAssembler \u0026amp;MCA = getStreamer().getAssembler(); const MCObjectFileInfo \u0026amp;OFI = *MCA.getContext().getObjectFileInfo(); ... // add new section .newsection.  MCSection \u0026amp;NewSection = *OFI.getNewSection(); MCA.registerSection(NewSection); ... }   \n Update DumpStyle class with new interface to print the new section; and implement it in the children class, such as GNUStyle, LLVMStyle, etc. // currently not used.\n  AsmPrinter::emitNewSection Switch current section to the new section and emit the section entries one by one:\n  emitNewSection()   // llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp  AsmPrinter::emitNewSection(const MachineFunction \u0026amp;MF){ ... MCSection *NewSection = getObjFileLowering().getNewSection(); OutStreamer-\u0026gt;PushSection(); OutStreamer-\u0026gt;SwitchSection(NewSection); for (auto \u0026amp;MBB : MF) { for (auto \u0026amp;MI : MBB) { EmitNewSectionEntry(\u0026amp;MI); } } OutStreamer-\u0026gt;PopSection(); }     "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/selection-dag/legalize/",
	"title": "Legalize",
	"tags": [],
	"description": "",
	"content": "References:\n llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp\n// llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp  /// This is the entry point for the file. void SelectionDAG::Legalize() { AssignTopologicalOrder(); SmallPtrSet\u0026lt;SDNode *, 16\u0026gt; LegalizedNodes; ... SelectionDAGLegalize Legalizer(*this, LegalizedNodes); // Visit all the nodes. We start in topological order, so that we see // nodes with their original operands intact. Legalization can produce // new nodes which may themselves need to be legalized. Iterate until all // nodes have been legalized. while (true) { bool AnyLegalized = false; for (auto NI = allnodes_end(); NI != allnodes_begin();) { --NI; ;delete_node_with_no_use; if (LegalizedNodes.insert(N).second) { AnyLegalized = true; Legalizer.LegalizeOp(N); ;delete_node_with_no_use; } } if (!AnyLegalized) break; } // Remove dead nodes now. RemoveDeadNodes(); }    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/selection-dag/legalize-types/",
	"title": "Legalize Types",
	"tags": [],
	"description": "",
	"content": "Some DAG node will be replaced in this pass over the DAG nodes for a basic block.\nReferences:\n llvm/lib/CodeGen/SelectionDAG/LegalizeTypes.cpp\n/// This is the main entry point for the type legalizer. This does a top-down /// traversal of the dag, legalizing types as it goes. Returns \u0026#34;true\u0026#34; if it made /// any changes. bool DAGTypeLegalizer::run() { bool Changed = false; // Create a dummy node (which is not added to allnodes), that adds a reference // to the root node, preventing it from being deleted, and tracking any // changes of the root. HandleSDNode Dummy(DAG.getRoot()); Dummy.setNodeId(Unanalyzed); // The root of the dag may dangle to deleted nodes until the type legalizer is // done. Set it to null to avoid confusion. DAG.setRoot(SDValue()); // Walk all nodes in the graph, assigning them a NodeId of \u0026#39;ReadyToProcess\u0026#39; // (and remembering them) if they are leaves and assigning \u0026#39;Unanalyzed\u0026#39; if // non-leaves. for (SDNode \u0026amp;Node : DAG.allnodes()) { if (Node.getNumOperands() == 0) { AddToWorklist(\u0026amp;Node); } else { Node.setNodeId(Unanalyzed); } } // Now that we have a set of nodes to process, handle them all. while (!Worklist.empty()) { #ifndef EXPENSIVE_CHECKS if (EnableExpensiveChecks) #endif  PerformExpensiveChecks(); SDNode *N = Worklist.back(); Worklist.pop_back(); assert(N-\u0026gt;getNodeId() == ReadyToProcess \u0026amp;\u0026amp; \u0026#34;Node should be ready if on worklist!\u0026#34;); LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;Legalizing node: \u0026#34;; N-\u0026gt;dump(\u0026amp;DAG)); if (IgnoreNodeResults(N)) { LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;Ignoring node results\\n\u0026#34;); goto ScanOperands; } // Scan the values produced by the node, checking to see if any result // types are illegal. for (unsigned i = 0, NumResults = N-\u0026gt;getNumValues(); i \u0026lt; NumResults; ++i) { EVT ResultVT = N-\u0026gt;getValueType(i); LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;Analyzing result type: \u0026#34; \u0026lt;\u0026lt; ResultVT.getEVTString() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;); switch (getTypeAction(ResultVT)) { case TargetLowering::TypeLegal: LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;Legal result type\\n\u0026#34;); break; // The following calls must take care of *all* of the node\u0026#39;s results,  // not just the illegal result they were passed (this includes results  // with a legal type). Results can be remapped using ReplaceValueWith,  // or their promoted/expanded/etc values registered in PromotedIntegers,  // ExpandedIntegers etc.  case TargetLowering::TypePromoteInteger: PromoteIntegerResult(N, i); Changed = true; goto NodeDone; case TargetLowering::TypeExpandInteger: ExpandIntegerResult(N, i); Changed = true; goto NodeDone; case TargetLowering::TypeSoftenFloat: SoftenFloatResult(N, i); Changed = true; goto NodeDone; case TargetLowering::TypeExpandFloat: ExpandFloatResult(N, i); Changed = true; goto NodeDone; case TargetLowering::TypeScalarizeVector: ScalarizeVectorResult(N, i); Changed = true; goto NodeDone; case TargetLowering::TypeSplitVector: SplitVectorResult(N, i); Changed = true; goto NodeDone; case TargetLowering::TypeWidenVector: WidenVectorResult(N, i); Changed = true; goto NodeDone; case TargetLowering::TypePromoteFloat: PromoteFloatResult(N, i); Changed = true; goto NodeDone; } } ScanOperands: // Scan the operand list for the node, handling any nodes with operands that // are illegal. { unsigned NumOperands = N-\u0026gt;getNumOperands(); bool NeedsReanalyzing = false; unsigned i; for (i = 0; i != NumOperands; ++i) { if (IgnoreNodeResults(N-\u0026gt;getOperand(i).getNode())) continue; const auto Op = N-\u0026gt;getOperand(i); LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;Analyzing operand: \u0026#34;; Op.dump(\u0026amp;DAG)); EVT OpVT = Op.getValueType(); switch (getTypeAction(OpVT)) { case TargetLowering::TypeLegal: LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;Legal operand\\n\u0026#34;); continue; // The following calls must either replace all of the node\u0026#39;s results  // using ReplaceValueWith, and return \u0026#34;false\u0026#34;; or update the node\u0026#39;s  // operands in place, and return \u0026#34;true\u0026#34;.  case TargetLowering::TypePromoteInteger: NeedsReanalyzing = PromoteIntegerOperand(N, i); Changed = true; break; case TargetLowering::TypeExpandInteger: NeedsReanalyzing = ExpandIntegerOperand(N, i); Changed = true; break; case TargetLowering::TypeSoftenFloat: NeedsReanalyzing = SoftenFloatOperand(N, i); Changed = true; break; case TargetLowering::TypeExpandFloat: NeedsReanalyzing = ExpandFloatOperand(N, i); Changed = true; break; case TargetLowering::TypeScalarizeVector: NeedsReanalyzing = ScalarizeVectorOperand(N, i); Changed = true; break; case TargetLowering::TypeSplitVector: NeedsReanalyzing = SplitVectorOperand(N, i); Changed = true; break; case TargetLowering::TypeWidenVector: NeedsReanalyzing = WidenVectorOperand(N, i); Changed = true; break; case TargetLowering::TypePromoteFloat: NeedsReanalyzing = PromoteFloatOperand(N, i); Changed = true; break; } break; } // The sub-method updated N in place. Check to see if any operands are new, // and if so, mark them. If the node needs revisiting, don\u0026#39;t add all users // to the worklist etc. if (NeedsReanalyzing) { assert(N-\u0026gt;getNodeId() == ReadyToProcess \u0026amp;\u0026amp; \u0026#34;Node ID recalculated?\u0026#34;); N-\u0026gt;setNodeId(NewNode); // Recompute the NodeId and correct processed operands, adding the node to  // the worklist if ready.  SDNode *M = AnalyzeNewNode(N); if (M == N) // The node didn\u0026#39;t morph - nothing special to do, it will be revisited.  continue; // The node morphed - this is equivalent to legalizing by replacing every  // value of N with the corresponding value of M. So do that now.  assert(N-\u0026gt;getNumValues() == M-\u0026gt;getNumValues() \u0026amp;\u0026amp; \u0026#34;Node morphing changed the number of results!\u0026#34;); for (unsigned i = 0, e = N-\u0026gt;getNumValues(); i != e; ++i) // Replacing the value takes care of remapping the new value.  ReplaceValueWith(SDValue(N, i), SDValue(M, i)); assert(N-\u0026gt;getNodeId() == NewNode \u0026amp;\u0026amp; \u0026#34;Unexpected node state!\u0026#34;); // The node continues to live on as part of the NewNode fungus that  // grows on top of the useful nodes. Nothing more needs to be done  // with it - move on to the next node.  continue; } if (i == NumOperands) { LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;Legally typed node: \u0026#34;; N-\u0026gt;dump(\u0026amp;DAG); dbgs() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;); } } NodeDone: // If we reach here, the node was processed, potentially creating new nodes. // Mark it as processed and add its users to the worklist as appropriate. assert(N-\u0026gt;getNodeId() == ReadyToProcess \u0026amp;\u0026amp; \u0026#34;Node ID recalculated?\u0026#34;); N-\u0026gt;setNodeId(Processed); for (SDNode::use_iterator UI = N-\u0026gt;use_begin(), E = N-\u0026gt;use_end(); UI != E; ++UI) { SDNode *User = *UI; int NodeId = User-\u0026gt;getNodeId(); // This node has two options: it can either be a new node or its Node ID  // may be a count of the number of operands it has that are not ready.  if (NodeId \u0026gt; 0) { User-\u0026gt;setNodeId(NodeId-1); // If this was the last use it was waiting on, add it to the ready list.  if (NodeId-1 == ReadyToProcess) Worklist.push_back(User); continue; } // If this is an unreachable new node, then ignore it. If it ever becomes  // reachable by being used by a newly created node then it will be handled  // by AnalyzeNewNode.  if (NodeId == NewNode) continue; // Otherwise, this node is new: this is the first operand of it that  // became ready. Its new NodeId is the number of operands it has minus 1  // (as this node is now processed).  assert(NodeId == Unanalyzed \u0026amp;\u0026amp; \u0026#34;Unknown node ID!\u0026#34;); User-\u0026gt;setNodeId(User-\u0026gt;getNumOperands() - 1); // If the node only has a single operand, it is now ready.  if (User-\u0026gt;getNumOperands() == 1) Worklist.push_back(User); } } #ifndef EXPENSIVE_CHECKS if (EnableExpensiveChecks) #endif PerformExpensiveChecks(); // If the root changed (e.g. it was a dead load) update the root. DAG.setRoot(Dummy.getValue()); // Remove dead nodes. This is important to do for cleanliness but also before // the checking loop below. Implicit folding by the DAG.getNode operators and // node morphing can cause unreachable nodes to be around with their flags set // to new. DAG.RemoveDeadNodes(); // In a debug build, scan all the nodes to make sure we found them all. This // ensures that there are no cycles and that everything got processed. #ifndef NDEBUG for (SDNode \u0026amp;Node : DAG.allnodes()) { bool Failed = false; // Check that all result types are legal. if (!IgnoreNodeResults(\u0026amp;Node)) for (unsigned i = 0, NumVals = Node.getNumValues(); i \u0026lt; NumVals; ++i) if (!isTypeLegal(Node.getValueType(i))) { dbgs() \u0026lt;\u0026lt; \u0026#34;Result type \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34; illegal: \u0026#34;; Node.dump(\u0026amp;DAG); Failed = true; } // Check that all operand types are legal. for (unsigned i = 0, NumOps = Node.getNumOperands(); i \u0026lt; NumOps; ++i) if (!IgnoreNodeResults(Node.getOperand(i).getNode()) \u0026amp;\u0026amp; !isTypeLegal(Node.getOperand(i).getValueType())) { dbgs() \u0026lt;\u0026lt; \u0026#34;Operand type \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34; illegal: \u0026#34;; Node.getOperand(i).dump(\u0026amp;DAG); Failed = true; } if (Node.getNodeId() != Processed) { if (Node.getNodeId() == NewNode) dbgs() \u0026lt;\u0026lt; \u0026#34;New node not analyzed?\\n\u0026#34;; else if (Node.getNodeId() == Unanalyzed) dbgs() \u0026lt;\u0026lt; \u0026#34;Unanalyzed node not noticed?\\n\u0026#34;; else if (Node.getNodeId() \u0026gt; 0) dbgs() \u0026lt;\u0026lt; \u0026#34;Operand not processed?\\n\u0026#34;; else if (Node.getNodeId() == ReadyToProcess) dbgs() \u0026lt;\u0026lt; \u0026#34;Not added to worklist?\\n\u0026#34;; Failed = true; } if (Failed) { Node.dump(\u0026amp;DAG); dbgs() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; llvm_unreachable(nullptr); } } #endif  return Changed; }    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/prolog-epilog/",
	"title": "Prolog Epilog",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A/Top  Where is the return address being spilled? Where is the allocated stack frame being \u0026lsquo;destroyed\u0026rsquo;?  Reference reference\n llvm/lib/CodeGen/PrologEpilogInserter.cpp  Pass overview PEI (Prolog Epilog Inserter) pass creation:\n// void TargetPassConfig::addMachinePasses() { //...  // Insert prolog/epilog code. Eliminate abstract frame index references...  if (getOptLevel() != CodeGenOpt::None) { addPass(\u0026amp;PostRAMachineSinkingID); // sink COPY instructions which should be handled after RA.  addPass(\u0026amp;ShrinkWrapID); // determine where the safe point to insert the prologue and epilogue.  } // Prolog/Epilog inserter needs a TargetMachine to instantiate. But only  // do so if it hasn\u0026#39;t been disabled, substituted, or overridden.  if (!isPassSubstitutedOrOverridden(\u0026amp;PrologEpilogCodeInserterID)) addPass(createPrologEpilogInserterPass()); }  Terminologies:\n Register Scavenge. Frame Index Scavenge. Optimization Remark Emitter (ORE). CSR spill/restore. Entry/return block.  Important functions:\n calculateCallFrameInfo(MF). Caculate the MaxCallFrameSize and AdjustsStack variables for the functions fram information. Also eliminates call frame pseudo instructions. calculateSaveRestoreBlocks(MF). determine the placement of CSR spill/restore code and prolog/epilog code: place all spills in the entry block, all restores in return block. spillCalleeSavedRegs(MF). CSR spilling and restoring, for targets that need it. TFI-\u0026gt;processFunctionBeforeFrameFinalized(MF,RS). This allows the target machine to make final modifications to the function before the frame layout is finalized. calculateFrameObjectOffsets(MF). Calculate actual frame offsets for all abstract stack objects. insertPrologEpilogCode(MF). Adding prolog/epilog code to the function. TFI-\u0026gt;processFunctionBeforeFrameIndicesReplaced(MF,RS). This allows target machine to make final modifications to the function before the frame layout is finalized. replaceFrameIndices(MF). Replace all MO_FrameIndex operands with physical register references and actual offsets.  Machine Function pass entry:\n  code runOnMachineFunction   // llvm/lib/CodeGen/PrologEpilogInserter.cpp  /// runOnMachineFunction - Insert prolog/epilog code and replace abstract /// frame indexes with appropriate references. bool PEI::runOnMachineFunction(MachineFunction \u0026amp;MF) { NumFuncSeen++; const Function \u0026amp;F = MF.getFunction(); const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo(); const TargetFrameLowering *TFI = MF.getSubtarget().getFrameLowering(); RS = TRI-\u0026gt;requiresRegisterScavenging(MF) ? new RegScavenger() : nullptr; FrameIndexVirtualScavenging = TRI-\u0026gt;requiresFrameIndexScavenging(MF); ORE = \u0026amp;getAnalysis\u0026lt;MachineOptimizationRemarkEmitterPass\u0026gt;().getORE(); // Calculate the MaxCallFrameSize and AdjustsStack variables for the  // function\u0026#39;s frame information. Also eliminates call frame pseudo  // instructions.  calculateCallFrameInfo(MF); // Determine placement of CSR spill/restore code and prolog/epilog code:  // place all spills in the entry block, all restores in return blocks.  calculateSaveRestoreBlocks(MF); // Stash away DBG_VALUEs that should not be moved by insertion of prolog code.  SavedDbgValuesMap EntryDbgValues; for (MachineBasicBlock *SaveBlock : SaveBlocks) stashEntryDbgValues(*SaveBlock, EntryDbgValues); // Handle CSR spilling and restoring, for targets that need it.  if (MF.getTarget().usesPhysRegsForPEI()) spillCalleeSavedRegs(MF); // Allow the target machine to make final modifications to the function  // before the frame layout is finalized.  TFI-\u0026gt;processFunctionBeforeFrameFinalized(MF, RS); // Calculate actual frame offsets for all abstract stack objects...  calculateFrameObjectOffsets(MF); // Add prolog and epilog code to the function. This function is required  // to align the stack frame as necessary for any stack variables or  // called functions. Because of this, calculateCalleeSavedRegisters()  // must be called before this function in order to set the AdjustsStack  // and MaxCallFrameSize variables.  if (!F.hasFnAttribute(Attribute::Naked)) insertPrologEpilogCode(MF); // Reinsert stashed debug values at the start of the entry blocks.  for (auto \u0026amp;I : EntryDbgValues) I.first-\u0026gt;insert(I.first-\u0026gt;begin(), I.second.begin(), I.second.end()); // Replace all MO_FrameIndex operands with physical register references  // and actual offsets.  //  replaceFrameIndices(MF); // If register scavenging is needed, as we\u0026#39;ve enabled doing it as a  // post-pass, scavenge the virtual registers that frame index elimination  // inserted.  if (TRI-\u0026gt;requiresRegisterScavenging(MF) \u0026amp;\u0026amp; FrameIndexVirtualScavenging) scavengeFrameVirtualRegs(MF, *RS); // Warn on stack size when we exceeds the given limit.  MachineFrameInfo \u0026amp;MFI = MF.getFrameInfo(); uint64_t StackSize = MFI.getStackSize(); if (WarnStackSize.getNumOccurrences() \u0026gt; 0 \u0026amp;\u0026amp; WarnStackSize \u0026lt; StackSize) { DiagnosticInfoStackSize DiagStackSize(F, StackSize); F.getContext().diagnose(DiagStackSize); } ORE-\u0026gt;emit([\u0026amp;]() { return MachineOptimizationRemarkAnalysis(DEBUG_TYPE, \u0026#34;StackSize\u0026#34;, MF.getFunction().getSubprogram(), \u0026amp;MF.front()) \u0026lt;\u0026lt; ore::NV(\u0026#34;NumStackBytes\u0026#34;, StackSize) \u0026lt;\u0026lt; \u0026#34; stack bytes in function\u0026#34;; }); delete RS; SaveBlocks.clear(); RestoreBlocks.clear(); MFI.setSavePoint(nullptr); MFI.setRestorePoint(nullptr); return true; }    PEI::calculateCallFrameInfo TODO.\nPEI::calculateSaveRestoreBlocks Compute the lists of blocks.\n  calculateSaveRestoreBlocks   // llvm/lib/CodeGen/PrologEpilogInserter.cpp // void PEI::calculateSaveRestoreBlocks(MachineFunction \u0026amp;MF) {..  for (MachineBasicBlock \u0026amp;MBB : MF) { if (MBB.isEHFuncletEntry()) SaveBlocks.push_back(\u0026amp;MBB); if (MBB.isReturnBlock()) RestoreBlocks.push_back(\u0026amp;MBB); }    PEI::spillCalleeSavedRegs for (MachineBasicBlock *SaveBlock : SaveBlocks) { insertCSRSaves(*SaveBlock, CSI); // Update the live-in information of all the blocks up to the save  // point.  updateLiveness(MF); } for (MachineBasicBlock *RestoreBlock : RestoreBlocks) insertCSRRestores(*RestoreBlock, CSI);  insertCSRSaves will call target dependent spill function TFI-\u0026gt;spillCalleeSavedRegisters(). See Mips for example.\nMore code tracking:\n  spillCalleeSavedRegs   // llvm/lib/CodeGen/PrologEpilogInserter.cpp  void PEI::spillCalleeSavedRegs(MachineFunction \u0026amp;MF) { // ...  // Determine which of the registers in the callee save list should be saved.  BitVector SavedRegs; TFI-\u0026gt;determineCalleeSaves(MF, SavedRegs, RS); // Assign stack slots for any callee-saved registers that must be spilled.  assignCalleeSavedSpillSlots(MF, SavedRegs, MinCSFrameIndex, MaxCSFrameIndex); // Add the code to save and restore the callee saved registers.  if (!F.hasFnAttribute(Attribute::Naked)) { MFI.setCalleeSavedInfoValid(true); std::vector\u0026lt;CalleeSavedInfo\u0026gt; \u0026amp;CSI = MFI.getCalleeSavedInfo(); if (!CSI.empty()) { if (!MFI.hasCalls()) NumLeafFuncWithSpills++; for (MachineBasicBlock *SaveBlock : SaveBlocks) { insertCSRSaves(*SaveBlock, CSI); // Update the live-in information of all the blocks up to the save  // point.  updateLiveness(MF); } for (MachineBasicBlock *RestoreBlock : RestoreBlocks) insertCSRRestores(*RestoreBlock, CSI); } } } /// insertCSRSaves  /// Insert restore code for the callee-saved registers used in the function. static void insertCSRSaves(MachineBasicBlock \u0026amp;SaveBlock, ArrayRef\u0026lt;CalleeSavedInfo\u0026gt; CSI) { MachineFunction \u0026amp;MF = *SaveBlock.getParent(); const TargetInstrInfo \u0026amp;TII = *MF.getSubtarget().getInstrInfo(); const TargetFrameLowering *TFI = MF.getSubtarget().getFrameLowering(); const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo(); MachineBasicBlock::iterator I = SaveBlock.begin(); if (!TFI-\u0026gt;spillCalleeSavedRegisters(SaveBlock, I, CSI, TRI)) { // only reach here if target impl is not available  for (const CalleeSavedInfo \u0026amp;CS : CSI) { // Insert the spill to the stack frame.  unsigned Reg = CS.getReg(); if (CS.isSpilledToReg()) { BuildMI(SaveBlock, I, DebugLoc(), TII.get(TargetOpcode::COPY), CS.getDstReg()) .addReg(Reg, getKillRegState(true)); } else { const TargetRegisterClass *RC = TRI-\u0026gt;getMinimalPhysRegClass(Reg); TII.storeRegToStackSlot(SaveBlock, I, Reg, true, CS.getFrameIdx(), RC, TRI); } } } } /// insertCSRRestores  /// Insert restore code for the callee-saved registers used in the function. static void insertCSRRestores(MachineBasicBlock \u0026amp;RestoreBlock, std::vector\u0026lt;CalleeSavedInfo\u0026gt; \u0026amp;CSI) { MachineFunction \u0026amp;MF = *RestoreBlock.getParent(); const TargetInstrInfo \u0026amp;TII = *MF.getSubtarget().getInstrInfo(); const TargetFrameLowering *TFI = MF.getSubtarget().getFrameLowering(); const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo(); // Restore all registers immediately before the return and any  // terminators that precede it.  MachineBasicBlock::iterator I = RestoreBlock.getFirstTerminator(); if (!TFI-\u0026gt;restoreCalleeSavedRegisters(RestoreBlock, I, CSI, TRI)) { for (const CalleeSavedInfo \u0026amp;CI : reverse(CSI)) { unsigned Reg = CI.getReg(); if (CI.isSpilledToReg()) { BuildMI(RestoreBlock, I, DebugLoc(), TII.get(TargetOpcode::COPY), Reg) .addReg(CI.getDstReg(), getKillRegState(true)); } else { const TargetRegisterClass *RC = TRI-\u0026gt;getMinimalPhysRegClass(Reg); TII.loadRegFromStackSlot(RestoreBlock, I, Reg, CI.getFrameIdx(), RC, TRI); assert(I != RestoreBlock.begin() \u0026amp;\u0026amp; \u0026#34;loadRegFromStackSlot didn\u0026#39;t insert any code!\u0026#34;); // Insert in reverse order. loadRegFromStackSlot can insert  // multiple instructions.  } } } }    TFI-\u0026gt;processFunctionBeforeFrameFinalized PEI::calculateFrameObjectOffsets Calculate actual frame offsets for all of the abstract stack objects.\nCode snippet:\n// llvm/lib/CodeGen/PrologEpilogInserter.cpp // PEI::calculateFrameObjectOffsets  ... }else if (MaxCSFrameIndex \u0026gt;= MinCSFrameIndex) { // Be careful about underflow in comparisons agains MinCSFrameIndex.  for (unsigned i = MaxCSFrameIndex; i != MinCSFrameIndex - 1; --i) { if (MFI.getStackID(i) != TargetStackID::Default) // Only allocate objects on the default stack.  continue; if (MFI.isDeadObjectIndex(i)) continue; // Adjust to alignment boundary  Offset = alignTo(Offset, MFI.getObjectAlign(i), Skew); LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;alloc FI(\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;) at SP[\u0026#34; \u0026lt;\u0026lt; Offset \u0026lt;\u0026lt; \u0026#34;]\\n\u0026#34;); MFI.setObjectOffset(i, Offset); Offset += MFI.getObjectSize(i); } } ...  PEI::insertPrologEpilogCode  scan the function for modified callee saved registers insert spill code for these callee saved registers then add prolog and epilog code to the function.  Call\n TFI.emitPrologue(MF, *SaveBlock) TFI.emitEpilogue(MF, *RestoreBlock) TFI.inlineStackProbe(MF, *SaveBlock) TFI.adjustForHiPEPrologue(MF, *SaveBlock)  See MIPS for target dependent TargetFrameLowering implementation.\n  insertPrologEpilogCode   // llvm/lib/CodeGen/PrologEpilogInserter.cpp  /// insertPrologEpilogCode - Scan the function for modified callee saved /// registers, insert spill code for these callee saved registers, then add /// prolog and epilog code to the function. void PEI::insertPrologEpilogCode(MachineFunction \u0026amp;MF) { const TargetFrameLowering \u0026amp;TFI = *MF.getSubtarget().getFrameLowering(); // Add prologue to the function...  for (MachineBasicBlock *SaveBlock : SaveBlocks) TFI.emitPrologue(MF, *SaveBlock); // Add epilogue to restore the callee-save registers in each exiting block.  for (MachineBasicBlock *RestoreBlock : RestoreBlocks) TFI.emitEpilogue(MF, *RestoreBlock); for (MachineBasicBlock *SaveBlock : SaveBlocks) TFI.inlineStackProbe(MF, *SaveBlock); // Emit additional code that is required to support segmented stacks, if  // we\u0026#39;ve been asked for it. This, when linked with a runtime with support  // for segmented stacks (libgcc is one), will result in allocating stack  // space in small chunks instead of one large contiguous block.  if (MF.shouldSplitStack()) { for (MachineBasicBlock *SaveBlock : SaveBlocks) TFI.adjustForSegmentedStacks(MF, *SaveBlock); // Record that there are split-stack functions, so we will emit a  // special section to tell the linker.  MF.getMMI().setHasSplitStack(true); } else MF.getMMI().setHasNosplitStack(true); // Emit additional code that is required to explicitly handle the stack in  // HiPE native code (if needed) when loaded in the Erlang/OTP runtime. The  // approach is rather similar to that of Segmented Stacks, but it uses a  // different conditional check and another BIF for allocating more stack  // space.  if (MF.getFunction().getCallingConv() == CallingConv::HiPE) for (MachineBasicBlock *SaveBlock : SaveBlocks) TFI.adjustForHiPEPrologue(MF, *SaveBlock); }    Target independent vs dependent passes  More  Mips  References: reference Target dependent implementation of prologue/epilogue emission. See [../] for callers. MipsSEFrameLowering::emitPrologue Adjust stack pointer: MipsSEFrameLowering::emitPrologue() =\u0026gt; TII.adjustStackPtr(SP, -StackSize, MBB, MBBI) MipsSEInstrInfo::adjustStackPtr() =\u0026gt; BuildMI // addi sp, sp, amount MipsSEFrameLowering::spillCalleeSavedRegisters The instruction to spill return address $ra register is built here. // search Mips::RA_64, spill RA as callee saved reg MipsSEFrameLowering::spillCalleeSavedRegisters(){ //... DebugLL(\u0026#34;before spill callee save: block: \u0026#34;; MBB.dump();); for (unsigned i = 0, e = CSI.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/selection-dag/instr-emission/",
	"title": "Instr Emission",
	"tags": [],
	"description": "",
	"content": " Reference reference\nOverview // llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp void SelectionDAGISel::SelectAllBasicBlocks(const Function \u0026amp;Fn) { ... // No FastIS  // Lower arguments to copyFromReg instruction  LowerArguments(Fn); // For every basic block:  { SelectBasicBlock(); // Block IR -\u0026gt; DAG  -\u0026gt;\u0026gt; SelectionDAGBuilder::visit(const Instruction \u0026amp;I) -\u0026gt;\u0026gt; SelectionDAGBuilder::HandlePHINodesInSuccessorBlocks() // 1-1 correspondence between LLVM PHI nodes and Machine PHI nodes,  -\u0026gt;\u0026gt; vist(I.getOpcode(), I); -\u0026gt;\u0026gt; vistXXX(I); //  // DAG -\u0026gt; Block MIR  -\u0026gt;\u0026gt; CodeGenAndEmitDAG(); -\u0026gt;\u0026gt; Scheduler-\u0026gt;EmitSchedule() -\u0026gt;\u0026gt; CurDAG-\u0026gt;Clear() // Empty the DAG when CodeGenAndEmitDAG() finishes.  FinishBasicBlock(); } } // CodeGenAndEmitDAG()  CodeGenAndEmitDAG() Do instruction selection and scheduling using DAG, and generate MIR.\n  SelectionDAGISel::CodeGenAndEmitDAG()   // DAG -\u0026gt; DAG OPT -\u0026gt; Block MIR void SelectionDAGISel::CodeGenAndEmitDAG() { // Initial selection DAG --\u0026gt;  // Run the DAG combiner in pre-legalize mode.  { NamedRegionTimer T(\u0026#34;combine1\u0026#34;, \u0026#34;DAG Combining 1\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); CurDAG-\u0026gt;Combine(BeforeLegalizeTypes, AA, OptLevel); } // Second step, hack on the DAG until it only uses operations and types that  // the target supports.  bool Changed; { NamedRegionTimer T(\u0026#34;legalize_types\u0026#34;, \u0026#34;Type Legalization\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); Changed = CurDAG-\u0026gt;LegalizeTypes(); } //If Changed: Run the DAG combiner in post-type-legalize mode.  { NamedRegionTimer T(\u0026#34;combine_lt\u0026#34;, \u0026#34;DAG Combining after legalize types\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); CurDAG-\u0026gt;Combine(AfterLegalizeTypes, AA, OptLevel); } { NamedRegionTimer T(\u0026#34;legalize_vec\u0026#34;, \u0026#34;Vector Legalization\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); Changed = CurDAG-\u0026gt;LegalizeVectors(); } { NamedRegionTimer T(\u0026#34;legalize_types2\u0026#34;, \u0026#34;Type Legalization 2\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); CurDAG-\u0026gt;LegalizeTypes(); } // Run the DAG combiner in post-type-legalize mode.  { NamedRegionTimer T(\u0026#34;combine_lv\u0026#34;, \u0026#34;DAG Combining after legalize vectors\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); CurDAG-\u0026gt;Combine(AfterLegalizeVectorOps, AA, OptLevel); } { NamedRegionTimer T(\u0026#34;legalize\u0026#34;, \u0026#34;DAG Legalization\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); CurDAG-\u0026gt;Legalize(); } // Run the DAG combiner in post-legalize mode.  { NamedRegionTimer T(\u0026#34;combine2\u0026#34;, \u0026#34;DAG Combining 2\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); CurDAG-\u0026gt;Combine(AfterLegalizeDAG, AA, OptLevel); } // Third, instruction select all of the operations to machine code, adding the  // code to the MachineBasicBlock.  { NamedRegionTimer T(\u0026#34;isel\u0026#34;, \u0026#34;Instruction Selection\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); DoInstructionSelection(); } // Create scheduler and emit MIR  }    Emission DAG Nodes to MIR Instructions This is the last step of ISelDAG algorithm: convert DAG to MIR instructions. After this, DAG will be cleared.\n// DAG -\u0026gt; Block MIR void SelectionDAGISel::CodeGenAndEmitDAG() { // Instr Selection/Sechduling Optimizations using DAG.  ... // Emit machine code to BB. This can change \u0026#39;BB\u0026#39; to the last block being  // inserted into.  MachineBasicBlock *FirstMBB = FuncInfo-\u0026gt;MBB, *LastMBB; { NamedRegionTimer T(\u0026#34;emit\u0026#34;, \u0026#34;Instruction Creation\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); // FuncInfo-\u0026gt;InsertPt is passed by reference and set to the end of the  // scheduled instructions.  LastMBB = FuncInfo-\u0026gt;MBB = Scheduler-\u0026gt;EmitSchedule(FuncInfo-\u0026gt;InsertPt); } // Free the SelectionDAG state, now that we\u0026#39;re finished with it.  CurDAG-\u0026gt;clear(); }  Scheduler-\u0026gt;EmitSchedule(FuncInfo-\u0026gt;InsertPt) will emit the current basic block\u0026rsquo;s DAG representation into a list of MIR MachineInstruction\u0026rsquo;s.\nScheduleDAGSDNodes::EmitSchedule() /// EmitSchedule - Emit the machine code in scheduled order. Return the new /// InsertPos and MachineBasicBlock that contains this insertion /// point. ScheduleDAGSDNodes holds a BB pointer for convenience, but this does /// not necessarily refer to returned BB. The emitter may split blocks. MachineBasicBlock *ScheduleDAGSDNodes:: EmitSchedule(MachineBasicBlock::iterator \u0026amp;InsertPos) { ... // Emit a node, and determine where its first instruction is for debuginfo.  // Zero, one, or multiple instructions can be created when emitting a node.  auto EmitNode = [\u0026amp;](SDNode *Node, bool IsClone, bool IsCloned, DenseMap\u0026lt;SDValue, unsigned\u0026gt; \u0026amp;VRBaseMap) -\u0026gt; MachineInstr * { // Fetch instruction prior to this, or end() if nonexistant.  auto GetPrevInsn = [\u0026amp;](MachineBasicBlock::iterator I) { if (I == BB-\u0026gt;begin()) return BB-\u0026gt;end(); else return std::prev(Emitter.getInsertPos()); }; MachineBasicBlock::iterator Before = GetPrevInsn(Emitter.getInsertPos()); Emitter.EmitNode(Node, IsClone, IsCloned, VRBaseMap); MachineBasicBlock::iterator After = GetPrevInsn(Emitter.getInsertPos()); // If the iterator did not change, no instructions were inserted.  if (Before == After) return nullptr; MachineInstr *MI; if (Before == BB-\u0026gt;end()) { // There were no prior instructions; the new ones must start at the  // beginning of the block.  MI = \u0026amp;Emitter.getBlock()-\u0026gt;instr_front(); } else { // Return first instruction after the pre-existing instructions.  MI = \u0026amp;*std::next(Before); } if (MI-\u0026gt;isCall() \u0026amp;\u0026amp; DAG-\u0026gt;getTarget().Options.EnableDebugEntryValues) MF.addCallArgsForwardingRegs(MI, DAG-\u0026gt;getSDCallSiteInfo(Node)); // Lele: transfer the ownership from DAG Node to MIR Instruction  if (Node-\u0026gt;hasCapsuleOwnership()){ MI-\u0026gt;setCapsuleOwnership(Node-\u0026gt;getCapsuleOwnership()); DebugLL(\u0026#34;\\n-- CapsuleOwnership transferred from DAG: \u0026#34;; Node-\u0026gt;dump()); DebugLLS(\u0026#34;\\n\\tto MIR Instruction: \u0026#34;; MI-\u0026gt;dump()); } return MI; }; ... }  EmitNode() // llvm/lib/CodeGen/SelectionDAG/InstrEmitter.h  /// EmitNode - Generate machine code for a node and needed dependencies.  ///  void EmitNode(SDNode *Node, bool IsClone, bool IsCloned, DenseMap\u0026lt;SDValue, unsigned\u0026gt; \u0026amp;VRBaseMap) { if (Node-\u0026gt;isMachineOpcode()) EmitMachineNode(Node, IsClone, IsCloned, VRBaseMap); else EmitSpecialNode(Node, IsClone, IsCloned, VRBaseMap); }   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/calling-conv/",
	"title": "Calling Conv",
	"tags": [],
	"description": "",
	"content": "References:\n llvm/include/llvm/CodeGen/CallingConvLower.h llvm/lib/CodeGen/CallingConvLower.cpp\n class CCState. Holds information needed while lowering arguments and return values. It captures which registers are already assigned and which stack slots are used. It provides accessors to allocate these values.\n   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/debugloc/",
	"title": "DebugLoc",
	"tags": [],
	"description": "",
	"content": "References\n llvm/include/llvm/CodeGen/SelectionDAGNodes.h: class SDLoc  Two points where the debug location info is passed from IR to MIR:\n When an SDNode is created from the DAGBuilder, the DebugLoc is extracted from the original Instruction, and IROrder is the ordinal position of the instruction.\n When an SDNode is created after the DAG is being built, both DebugLoc and the IROrder are propagated from the original SDNode.\n   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/selection-dag/",
	"title": "Selection Dag",
	"tags": [],
	"description": "",
	"content": " References:\n llvm/include/llvm/CodeGen/SelectionDAGISel.h llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp LLVM Selection DAG Introduction  Pass registration // llvm/lib/Target/Mips/MipsTargetMachine.cpp  // Install an instruction selector pass using // the ISelDag to gen Mips code. bool MipsPassConfig::addInstSelector() { DebugLL(\u0026#34;adding MipsModuleISelDagPass\\n\u0026#34;); addPass(createMipsModuleISelDagPass()); DebugLL(\u0026#34;adding Mips16ISelDag\\n\u0026#34;); addPass(createMips16ISelDag(getMipsTargetMachine(), getOptLevel())); DebugLL(\u0026#34;adding MipsSEISelDag\\n\u0026#34;); addPass(createMipsSEISelDag(getMipsTargetMachine(), getOptLevel())); DebugLL(\u0026#34;done adding MipsSEISelDag\\n\u0026#34;); return false; }  SelectionDAGISel::runOnMachineFunction() SelectionDAGISel::runOnMachineFunction(MachineFunction \u0026amp;mf)\n  SelectionDAGISel::runOnMachineFunction()   bool SelectionDAGISel::runOnMachineFunction(MachineFunction \u0026amp;mf) { DebugLL(\u0026#34;SelectionDAGISel pass on MF: \u0026#34;\u0026lt;\u0026lt; mf.getName() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;); CurDAG-\u0026gt;init(*MF, *ORE, this, LibInfo, getAnalysisIfAvailable\u0026lt;LegacyDivergenceAnalysis\u0026gt;()); SDB-\u0026gt;init(GFI, AA, LibInfo); // SDB: SelectionDAGBuilder  MachineBasicBlock *EntryMBB = \u0026amp;MF-\u0026gt;front(); ///////////////////////////////////////////  // Do selection for all basic blocks.  //////////////////////////////////////////  SelectAllBasicBlocks(Fn); ///////////////////////////////////////////  // Post-processing the MIR being generated.  ///////////////////////////////////////////  // Replace forward-declared registers with the registers containing  // the desired value.  // Note: it is important that this happens **before** the call to  // EmitLiveInCopies, since implementations can skip copies of unused  // registers. If we don\u0026#39;t apply the reg fixups before, some registers may  // appear as unused and will be skipped, resulting in bad MI.  MachineRegisterInfo \u0026amp;MRI = MF-\u0026gt;getRegInfo(); for (DenseMap\u0026lt;unsigned, unsigned\u0026gt;::iterator I = FuncInfo-\u0026gt;RegFixups.begin(), E = FuncInfo-\u0026gt;RegFixups.end(); I != E; ++I) { unsigned From = I-\u0026gt;first; unsigned To = I-\u0026gt;second; // If To is also scheduled to be replaced, find what its ultimate  // replacement is.  while (true) { DenseMap\u0026lt;unsigned, unsigned\u0026gt;::iterator J = FuncInfo-\u0026gt;RegFixups.find(To); if (J == E) break; To = J-\u0026gt;second; } // Make sure the new register has a sufficiently constrained register class.  if (Register::isVirtualRegister(From) \u0026amp;\u0026amp; Register::isVirtualRegister(To)) MRI.constrainRegClass(To, MRI.getRegClass(From)); // Replace it.  // Replacing one register with another won\u0026#39;t touch the kill flags.  // We need to conservatively clear the kill flags as a kill on the old  // register might dominate existing uses of the new register.  if (!MRI.use_empty(To)) MRI.clearKillFlags(From); MRI.replaceRegWith(From, To); } // If the first basic block in the function has live ins that need to be  // copied into vregs, emit the copies into the top of the block before  // emitting the code for the block.  const TargetRegisterInfo \u0026amp;TRI = *MF-\u0026gt;getSubtarget().getRegisterInfo(); RegInfo-\u0026gt;EmitLiveInCopies(EntryMBB, TRI, *TII); // Insert copies in the entry block and the return blocks.  if (FuncInfo-\u0026gt;SplitCSR) { SmallVector\u0026lt;MachineBasicBlock*, 4\u0026gt; Returns; // Collect all the return blocks.  for (MachineBasicBlock \u0026amp;MBB : mf) { if (!MBB.succ_empty()) continue; MachineBasicBlock::iterator Term = MBB.getFirstTerminator(); if (Term != MBB.end() \u0026amp;\u0026amp; Term-\u0026gt;isReturn()) { Returns.push_back(\u0026amp;MBB); continue; } } TLI-\u0026gt;insertCopiesSplitCSR(EntryMBB, Returns); } for (unsigned i = 0, e = FuncInfo-\u0026gt;ArgDbgValues.size(); i != e; ++i){ // Insert DBG_VALUE instructions for function arguments to the entry block.  // If Reg is live-in then update debug info to track its copy in a vreg.  } // Determine if there are any calls in this machine function.  // Determine if there are any Inline ASM in this machine function.  // Determine if there is a call to setjmp in the machine function.  MF-\u0026gt;setExposesReturnsTwice(Fn.callsFunctionThatReturnsTwice()); // Replace forward-declared registers with the registers containing  // the desired value.  ... TLI-\u0026gt;finalizeLowering(*MF); // Release function-specific state. SDB and CurDAG are already cleared  // at this point.  FuncInfo-\u0026gt;clear(); ////////////////////////////////////////////////////////////////  LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;*** MachineFunction at end of ISel ***\\n\u0026#34;); LLVM_DEBUG(MF-\u0026gt;print(dbgs())); }    SelectionDAGISel::SelectAllBasicBlocks() // llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp  void SelectionDAGISel::SelectAllBasicBlocks(const Function \u0026amp;Fn) { ... // No FastIS  // Lower arguments to copyFromReg instruction  LowerArguments(Fn); // For every basic block:  { SelectBasicBlock(); // Block IR -\u0026gt; DAG  -\u0026gt;\u0026gt; SelectionDAGBuilder::visit(const Instruction \u0026amp;I) -\u0026gt;\u0026gt; SelectionDAGBuilder::HandlePHINodesInSuccessorBlocks() // 1-1 correspondence between LLVM PHI nodes and Machine PHI nodes,  -\u0026gt;\u0026gt; vist(I.getOpcode(), I); -\u0026gt;\u0026gt; vistXXX(I); //  // DAG -\u0026gt; Block MIR  -\u0026gt;\u0026gt; CodeGenAndEmitDAG(); -\u0026gt;\u0026gt; Scheduler-\u0026gt;EmitSchedule() -\u0026gt;\u0026gt; CurDAG-\u0026gt;Clear() // Empty the DAG when CodeGenAndEmitDAG() finishes.  FinishBasicBlock(); } }  vistXXX() // visit() --\u0026gt; visit##OPCODE()  void SelectionDAGBuilder::visit(unsigned Opcode, const User \u0026amp;I) { // Note: this doesn\u0026#39;t use InstVisitor, because it has to work with  // ConstantExpr\u0026#39;s in addition to instructions.  switch (Opcode) { default: llvm_unreachable(\u0026#34;Unknown instruction type encountered!\u0026#34;); // Build the switch statement using the Instruction.def file. #define HANDLE_INST(NUM, OPCODE, CLASS) \\ case Instruction::OPCODE: visit##OPCODE((const CLASS\u0026amp;)I); break; #include \u0026#34;llvm/IR/Instruction.def\u0026#34; } } // visitLoad()  void SelectionDAGBuilder::visitLoad(const LoadInst \u0026amp;I) { if (I.isAtomic()) return visitAtomicLoad(I); ... SDValue DSA = DAG.getNode(ISD::MERGE_VALUES, dl, DAG.getVTList(ValueVTs), Values); setValue(\u0026amp;I, DSA); }  Tracking SDNode Creation In SelectionDAG::SelectionDAG() Entry SDNode is created for the DAG.\nIn SelectionDAGISel::LowerArguments() Call paths:\nSelectionDAGISel::runOnMachineFunction() -\u0026gt; SelectionDAGISel::SelectAllBasicBlocks() -\u0026gt; SelectionDAGISel::LowerArguments() -\u0026gt; (SelectionDAGBuilder.cpp: findArgumentCopyElisionCandidates()) -\u0026gt; MipsTargetLowering::LowerFormalArguments(), create a chain of DAG Nodes as arguments.  Mips Implementation MipsTargetLowering::LowerFormalArguments():\n// llvm/lib/Target/Mips/MipsISelLowering.cpp  //===----------------------------------------------------------------------===// // Formal Arguments Calling Convention Implementation //===----------------------------------------------------------------------===// /// LowerFormalArguments - transform physical registers into virtual registers /// and generate load operations for arguments places on the stack. SDValue MipsTargetLowering::LowerFormalArguments( SDValue Chain, CallingConv::ID CallConv, bool IsVarArg, const SmallVectorImpl\u0026lt;ISD::InputArg\u0026gt; \u0026amp;Ins, const SDLoc \u0026amp;DL, SelectionDAG \u0026amp;DAG, SmallVectorImpl\u0026lt;SDValue\u0026gt; \u0026amp;InVals) const { MachineFunction \u0026amp;MF = DAG.getMachineFunction(); MachineFrameInfo \u0026amp;MFI = MF.getFrameInfo(); MipsFunctionInfo *MipsFI = MF.getInfo\u0026lt;MipsFunctionInfo\u0026gt;(); MipsFI-\u0026gt;setVarArgsFrameIndex(0); CCInfo.AllocateStack(ABI.GetCalleeAllocdArgSizeInBytes(CallConv), 1); // for each (implicit \u0026amp; explict) argument in the function  for (unsigned i = 0, e = ArgLocs.size(); i != e; ++i){ // handling byvalue arguments  copyByValRegs(Chain, DL, OutChains, DAG, Flags, InVals, \u0026amp;*FuncArg, FirstByValReg, LastByValReg, VA, CCInfo); // if argument stored in register...  SDValue ArgValue = DAG.getCopyFromReg(Chain, DL, Reg, RegVT); InVals.push_back(ArgValue); // if argument not stored in register...  ArgValue = DAG.getLoad(LocVT, DL, Chain, Addr, MachinePointerInfo()); InVals.push_back(ArgValue); } }  In SelectionDAGISel::CodeGenAndEmitDAG() Here all the CurDAG nodes are dumped.\nTracking SDNode Replacement SDNode can be replaced during DAG optmization stages for a basic block.\nDAG based optimization is driven by function SelectionDAGISel::CodeGenAndEmitDAG().\nIt includes the following stages:\n Run DAG Combiner in pre-legalize mode   code: DAG Combiner 1   // Run the DAG combiner in pre-legalize mode.  { NamedRegionTimer T(\u0026#34;combine1\u0026#34;, \u0026#34;DAG Combining 1\u0026#34;, GroupName, GroupDescription, TimePassesIsEnabled); CurDAG-\u0026gt;Combine(BeforeLegalizeTypes, AA, OptLevel); }  The CurDAG-\u0026gt;Combine() function is further defined as:\n// llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp  //===----------------------------------------------------------------------===// // Main DAG Combiner implementation //===----------------------------------------------------------------------===//  void DAGCombiner::Run(CombineLevel AtLevel) { ... // Add all the dag nodes to the worklist.  for (SDNode \u0026amp;Node : DAG.allnodes()) AddToWorklist(\u0026amp;Node); ... // While we have a valid worklist entry node, try to combine it.  while (SDNode *N = getNextWorklistEntry()) { // If N has no uses, it is dead. Make sure to revisit all N\u0026#39;s operands once  // N is deleted from the DAG, since they too may now be dead or may have a  // reduced number of uses, allowing other xforms.  if (recursivelyDeleteUnusedNodes(N)) continue; WorklistRemover DeadNodes(*this); // If this combine is running after legalizing the DAG, re-legalize any  // nodes pulled off the worklist.  if (Level == AfterLegalizeDAG) { SmallSetVector\u0026lt;SDNode *, 16\u0026gt; UpdatedNodes; bool NIsValid = DAG.LegalizeOp(N, UpdatedNodes); for (SDNode *LN : UpdatedNodes) { AddUsersToWorklist(LN); AddToWorklist(LN); } if (!NIsValid) continue; } ... LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;\\nCombining: \u0026#34;; N-\u0026gt;dump(\u0026amp;DAG)); } }      Passing info across DAG via DAG node To pass srcloc MetaData across DAG for inline ASM, use MDNodeSDNode.\n// llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp  // If we have a !srcloc metadata node associated with it, we want to attach  // this to the ultimately generated inline asm machineinstr. To do this, we  // pass in the third operand as this (potentially null) inline asm MDNode.  const MDNode *SrcLoc = CS.getInstruction()-\u0026gt;getMetadata(\u0026#34;srcloc\u0026#34;); AsmNodeOperands.push_back(DAG.getMDNode(SrcLoc));  Code Learning  To detect a return block in a Function:\n// see SelectionDAGISel::runOnMachineFunction() // in llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp  // Collect all the return blocks. for (const BasicBlock \u0026amp;BB : Fn) { if (!succ_empty(\u0026amp;BB)) continue; // handle return blocks: }  To scan a DAG (e.g. check for cycles):\n// llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp  void llvm::checkForCycles(const llvm::SDNode *N, const llvm::SelectionDAG *DAG, bool force) { #ifndef NDEBUG bool check = force; #ifdef EXPENSIVE_CHECKS check = true; #endif // EXPENSIVE_CHECKS if (check) { assert(N \u0026amp;\u0026amp; \u0026#34;Checking nonexistent SDNode\u0026#34;); SmallPtrSet\u0026lt;const SDNode*, 32\u0026gt; visited; SmallPtrSet\u0026lt;const SDNode*, 32\u0026gt; checked; checkForCyclesHelper(N, visited, checked, DAG); } #endif // !NDEBUG } static void checkForCyclesHelper(const SDNode *N, SmallPtrSetImpl\u0026lt;const SDNode*\u0026gt; \u0026amp;Visited, SmallPtrSetImpl\u0026lt;const SDNode*\u0026gt; \u0026amp;Checked, const llvm::SelectionDAG *DAG) { // If this node has already been checked, don\u0026#39;t check it again. if (Checked.count(N)) return; // If a node has already been visited on this depth-first walk, reject it as // a cycle. if (!Visited.insert(N).second) { errs() \u0026lt;\u0026lt; \u0026#34;Detected cycle in SelectionDAG\\n\u0026#34;; dbgs() \u0026lt;\u0026lt; \u0026#34;Offending node:\\n\u0026#34;; N-\u0026gt;dumprFull(DAG); dbgs() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; abort(); } for (const SDValue \u0026amp;Op : N-\u0026gt;op_values()) checkForCyclesHelper(Op.getNode(), Visited, Checked, DAG); Checked.insert(N); Visited.erase(N); }    Legalize  References: llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp // llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp /// This is the entry point for the file. void SelectionDAG::Legalize() { AssignTopologicalOrder(); SmallPtrSet\u0026lt;SDNode *, 16\u0026gt; LegalizedNodes; ... SelectionDAGLegalize Legalizer(*this, LegalizedNodes); // Visit all the nodes. We start in topological order, so that we see // nodes with their original operands intact. Legalization can produce // new nodes which may themselves need to be legalized. Iterate until all // nodes have been legalized. while (true) { bool AnyLegalized = false; for (auto NI = allnodes_end(); NI !\n Legalize Types  Some DAG node will be replaced in this pass over the DAG nodes for a basic block. References: llvm/lib/CodeGen/SelectionDAG/LegalizeTypes.cpp /// This is the main entry point for the type legalizer. This does a top-down /// traversal of the dag, legalizing types as it goes. Returns \u0026#34;true\u0026#34; if it made /// any changes. bool DAGTypeLegalizer::run() { bool Changed = false; // Create a dummy node (which is not added to allnodes), that adds a reference // to the root node, preventing it from being deleted, and tracking any // changes of the root.\n Instr Emission  Reference reference Overview // llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp void SelectionDAGISel::SelectAllBasicBlocks(const Function \u0026amp;Fn) { ... // No FastIS // Lower arguments to copyFromReg instruction LowerArguments(Fn); // For every basic block: { SelectBasicBlock(); // Block IR -\u0026gt; DAG -\u0026gt;\u0026gt; SelectionDAGBuilder::visit(const Instruction \u0026amp;I) -\u0026gt;\u0026gt; SelectionDAGBuilder::HandlePHINodesInSuccessorBlocks() // 1-1 correspondence between LLVM PHI nodes and Machine PHI nodes, -\u0026gt;\u0026gt; vist(I.getOpcode(), I); -\u0026gt;\u0026gt; vistXXX(I); // // DAG -\u0026gt; Block MIR -\u0026gt;\u0026gt; CodeGenAndEmitDAG(); -\u0026gt;\u0026gt; Scheduler-\u0026gt;EmitSchedule() -\u0026gt;\u0026gt; CurDAG-\u0026gt;Clear() // Empty the DAG when CodeGenAndEmitDAG() finishes.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/mips-isel/",
	"title": "MIPS ISel Passes",
	"tags": [],
	"description": "",
	"content": " References:\n llvm/lib/Target/Mips/MipsTargetMachine.cpp  3 Passes for Mips ISel  MipsModuleDAGToDAGISel, a pass used to change the subtarget for the Mips Instruction selector. Mips16DAGToDAGISel, Subclass of MipsDAGToDAGISel specialized for mips16. MipsSEDAGToDAGISel, Subclass of MipsDAGToDAGISel specialized for mips32/64.  The core passes are Mips16DAGToDAGISel for 16-bit mips and MipsSEDAGToDAGISel for 32\u0026frasl;64 bit mips. Both of them finally calls the parent pass entry (SelectionDAGISel::runOnMachineFunction) in their implementation. See more impl details on SelectionDAGISel.\nPass registeration:\n  pass creation and registration   // llvm/lib/Target/Mips/MipsTargetMachine.cpp // parent-\u0026gt;child: TargetPassConfig -\u0026gt; MipsPassConfig  // Install an instruction selector pass using // the ISelDag to gen Mips code. bool MipsPassConfig::addInstSelector() { addPass(createMipsModuleISelDagPass()); addPass(createMips16ISelDag(getMipsTargetMachine(), getOptLevel())); addPass(createMipsSEISelDag(getMipsTargetMachine(), getOptLevel())); return false; } // createMipsModuleISelDagPass() // llvm/lib/Target/Mips/MipsModuleISelDAGToDAG.cpp llvm::FunctionPass *llvm::createMipsModuleISelDagPass() { return new MipsModuleDAGToDAGISel(); } // createMips16ISelDag() // llvm/lib/Target/Mips/Mips16ISelDAGToDAG.cpp FunctionPass *llvm::createMips16ISelDag(MipsTargetMachine \u0026amp;TM, CodeGenOpt::Level OptLevel) { return new Mips16DAGToDAGISel(TM, OptLevel); } // createMipsSEISelDag() FunctionPass *llvm::createMipsSEISelDag(MipsTargetMachine \u0026amp;TM, CodeGenOpt::Level OptLevel) { return new MipsSEDAGToDAGISel(TM, OptLevel); }    MipsSEDAGToDAGISel Inheritance: parent-\u0026gt;child\nMachineFunctionPass -\u0026gt; SelectionDAGISel -\u0026gt; MipsDAGToDAGISel -\u0026gt; MipsSEDAGToDAGISel // llvm/lib/Target/Mips/MipsSEISelDAGToDAG.cpp  bool MipsSEDAGToDAGISel::runOnMachineFunction(MachineFunction \u0026amp;MF) { Subtarget = \u0026amp;static_cast\u0026lt;const MipsSubtarget \u0026amp;\u0026gt;(MF.getSubtarget()); if (Subtarget-\u0026gt;inMips16Mode()) return false; return MipsDAGToDAGISel::runOnMachineFunction(MF); } // MipsDAGToDAGISel::runOnMachineFunction // llvm/lib/Target/Mips/MipsISelDAGToDAG.cpp  bool MipsDAGToDAGISel::runOnMachineFunction(MachineFunction \u0026amp;MF) { Subtarget = \u0026amp;static_cast\u0026lt;const MipsSubtarget \u0026amp;\u0026gt;(MF.getSubtarget()); DebugLL(\u0026#34;MipsDAGToDAGISel pass on MF: \u0026#34;\u0026lt;\u0026lt; MF.getName() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;) bool Ret = SelectionDAGISel::runOnMachineFunction(MF); processFunctionAfterISel(MF); return Ret; }  MipsModuleDAGToDAGISel Set the subtarget for MipsTargetMachine\n// llvm/lib/Target/Mips/MipsModuleISelDAGToDAG.cpp  bool MipsModuleDAGToDAGISel::runOnMachineFunction(MachineFunction \u0026amp;MF) { LLVM_DEBUG(errs() \u0026lt;\u0026lt; \u0026#34;In MipsModuleDAGToDAGISel::runMachineFunction\\n\u0026#34;); auto \u0026amp;TPC = getAnalysis\u0026lt;TargetPassConfig\u0026gt;(); auto \u0026amp;TM = TPC.getTM\u0026lt;MipsTargetMachine\u0026gt;(); TM.resetSubtarget(\u0026amp;MF); return false; } // MipsTargetMachine::resetSubTarget() // llvm/lib/Target/Mips/MipsTargetMachine.cpp void MipsTargetMachine::resetSubtarget(MachineFunction *MF) { LLVM_DEBUG(dbgs() \u0026lt;\u0026lt; \u0026#34;resetSubtarget\\n\u0026#34;); Subtarget = \u0026amp;MF-\u0026gt;getSubtarget\u0026lt;MipsSubtarget\u0026gt;(); }  Mips16DAGToDAGISel Inheritance: parent-\u0026gt;child\nMachineFunctionPass -\u0026gt; SelectionDAGISel -\u0026gt; MipsDAGToDAGISel -\u0026gt; Mips16DAGToDAGISel // llvm/lib/Target/Mips/Mips16ISelDAGToDAG.cpp  bool Mips16DAGToDAGISel::runOnMachineFunction(MachineFunction \u0026amp;MF) { Subtarget = \u0026amp;static_cast\u0026lt;const MipsSubtarget \u0026amp;\u0026gt;(MF.getSubtarget()); DebugLL(\u0026#34;Mips16DAGToDAGISel pass on MF: \u0026#34;\u0026lt;\u0026lt; MF.getName() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;); if (!Subtarget-\u0026gt;inMips16Mode()) return false; return MipsDAGToDAGISel::runOnMachineFunction(MF); }   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/",
	"title": "Core ISel",
	"tags": [],
	"description": "",
	"content": "References:\n llvm/lib/CodeGen/TargetPassConfig.cpp  TargetPassConfig::addCoreISelPasses() will create the core passes needed for instruction selection in LLVM. It will\n choose one of three instruction selectors (FastISel, SelectionDAG, or GlobalISel) for the compilation, whichever is available or meets the configuration options. add finalization pass addPass(\u0026amp;FinalizeISelID);  to expand pseudo-instructions emitted by ISel.  print and verify the instructions selected machine code: printAndVerify(\u0026quot;After Instruction Selection\u0026quot;);.    code TargetPassConfig::addCoreISelPasses()   ```C++\nbool TargetPassConfig::addCoreISelPasses() { // Enable FastISel with -fast-isel, but allow that to be overridden. TM-\u0026gt;setO0WantsFastISel(EnableFastISelOption != cl::BOU_FALSE);\n// Determine an instruction selector. enum class SelectorType { SelectionDAG, FastISel, GlobalISel }; SelectorType Selector;\nif (EnableFastISelOption == cl::BOU_TRUE) Selector = SelectorType::FastISel; else if (EnableGlobalISelOption == cl::BOU_TRUE || (TM-\u0026gt;Options.EnableGlobalISel \u0026amp;\u0026amp; EnableGlobalISelOption != cl::BOU_FALSE)) Selector = SelectorType::GlobalISel; else if (TM-\u0026gt;getOptLevel() == CodeGenOpt::None \u0026amp;\u0026amp; TM-\u0026gt;getO0WantsFastISel()) Selector = SelectorType::FastISel; else Selector = SelectorType::SelectionDAG;\n// Set consistently TM-\u0026gt;Options.EnableFastISel and EnableGlobalISel. if (Selector == SelectorType::FastISel) { errs() \u0026lt;\u0026lt; \u0026ldquo;Lele: use FastISel, will have no IRTranslator\u0026hellip;.\\n\u0026rdquo;; TM-\u0026gt;setFastISel(true); TM-\u0026gt;setGlobalISel(false); } else if (Selector == SelectorType::GlobalISel) { errs() \u0026lt;\u0026lt; \u0026ldquo;Lele: use GlobalISel, will add IRTranslator\u0026hellip;.\\n\u0026rdquo;; TM-\u0026gt;setFastISel(false); TM-\u0026gt;setGlobalISel(true); } else { errs() \u0026lt;\u0026lt; \u0026ldquo;Lele: use SelectionDAG, will have no IRTranslator\u0026hellip;.\\n\u0026rdquo;; } // Add instruction selector passes. if (Selector == SelectorType::GlobalISel) { SaveAndRestore SavedAddingMachinePasses(AddingMachinePasses, true); if (addIRTranslator()) return true;\naddPreLegalizeMachineIR(); if (addLegalizeMachineIR()) return true; // Before running the register bank selector, ask the target if it // wants to run some passes. addPreRegBankSelect(); if (addRegBankSelect()) return true; addPreGlobalInstructionSelect(); if (addGlobalInstructionSelect()) return true; // Pass to reset the MachineFunction if the ISel failed. addPass(createResetMachineFunctionPass( reportDiagnosticWhenGlobalISelFallback(), isGlobalISelAbortEnabled())); // Provide a fallback path when we do not want to abort on // not-yet-supported input. if (!isGlobalISelAbortEnabled() \u0026amp;\u0026amp; addInstSelector()) return true;  } else { errs() \u0026lt;\u0026lt; \u0026ldquo;Lele: Not GlobalISel, no IRTranslator, creating target dependent\u0026rdquo; \u0026lt;\u0026lt; \u0026ldquo;passes\u0026hellip;\\n\u0026rdquo;; if (addInstSelector()) return true; }\n// Expand pseudo-instructions emitted by ISel. Don\u0026rsquo;t run the verifier before // FinalizeISel. addPass(\u0026amp;FinalizeISelID);\n// Print the instruction selected machine code\u0026hellip; printAndVerify(\u0026ldquo;After Instruction Selection\u0026rdquo;);\nreturn false; }\n  ```\naddInstSelector() is target specific. For example, see MIPS ISel\n Calling Conv  References: llvm/include/llvm/CodeGen/CallingConvLower.h llvm/lib/CodeGen/CallingConvLower.cpp class CCState. Holds information needed while lowering arguments and return values. It captures which registers are already assigned and which stack slots are used. It provides accessors to allocate these values.  DebugLoc  References llvm/include/llvm/CodeGen/SelectionDAGNodes.h: class SDLoc Two points where the debug location info is passed from IR to MIR: When an SDNode is created from the DAGBuilder, the DebugLoc is extracted from the original Instruction, and IROrder is the ordinal position of the instruction. When an SDNode is created after the DAG is being built, both DebugLoc and the IROrder are propagated from the original SDNode.  Selection Dag  References: llvm/include/llvm/CodeGen/SelectionDAGISel.h llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp LLVM Selection DAG Introduction Pass registration // llvm/lib/Target/Mips/MipsTargetMachine.cpp // Install an instruction selector pass using // the ISelDag to gen Mips code. bool MipsPassConfig::addInstSelector() { DebugLL(\u0026#34;adding MipsModuleISelDagPass\\n\u0026#34;); addPass(createMipsModuleISelDagPass()); DebugLL(\u0026#34;adding Mips16ISelDag\\n\u0026#34;); addPass(createMips16ISelDag(getMipsTargetMachine(), getOptLevel())); DebugLL(\u0026#34;adding MipsSEISelDag\\n\u0026#34;); addPass(createMipsSEISelDag(getMipsTargetMachine(), getOptLevel())); DebugLL(\u0026#34;done adding MipsSEISelDag\\n\u0026#34;); return false; } SelectionDAGISel::runOnMachineFunction() SelectionDAGISel::runOnMachineFunction(MachineFunction \u0026amp;mf) SelectionDAGISel::runOnMachineFunction() bool SelectionDAGISel::runOnMachineFunction(MachineFunction \u0026amp;mf) { DebugLL(\u0026#34;SelectionDAGISel pass on MF: \u0026#34;\u0026lt;\u0026lt; mf.getName() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;); CurDAG-\u0026gt;init(*MF, *ORE, this, LibInfo, getAnalysisIfAvailable\u0026lt;LegacyDivergenceAnalysis\u0026gt;()); SDB-\u0026gt;init(GFI, AA, LibInfo); // SDB: SelectionDAGBuilder MachineBasicBlock *EntryMBB = \u0026amp;MF-\u0026gt;front(); /////////////////////////////////////////// // Do selection for all basic blocks.\n MIPS ISel Passes  References: llvm/lib/Target/Mips/MipsTargetMachine.cpp 3 Passes for Mips ISel MipsModuleDAGToDAGISel, a pass used to change the subtarget for the Mips Instruction selector. Mips16DAGToDAGISel, Subclass of MipsDAGToDAGISel specialized for mips16. MipsSEDAGToDAGISel, Subclass of MipsDAGToDAGISel specialized for mips32/64. The core passes are Mips16DAGToDAGISel for 16-bit mips and MipsSEDAGToDAGISel for 32\u0026frasl;64 bit mips. Both of them finally calls the parent pass entry (SelectionDAGISel::runOnMachineFunction) in their implementation. See more impl details on SelectionDAGISel.\n GlobalISel  Reference: LLVM in progress: Global Instruction Selection Instruction Selection Reference LLVM Core Pipeline LLVM Core Pipleline \u0026ndash; InstructionSelect InstructionSelect pass transforms generic machine instructions into equivalent target-specifc instructions. It traverses the MachineFunction bottom-up, selecting uses before definitions, enabling trivial dead code elimination. The target implements InstructionSelector class, containing target-specific selection logic. InstructionSelector::select virtual bool select(MachineInstr \u0026amp;MI) This method is responsible for mutating (or replacing) a possibly-generic MI into a fully target-specific equivalent.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/globalisel/",
	"title": "GlobalISel",
	"tags": [],
	"description": "",
	"content": "Reference:\n LLVM in progress: Global Instruction Selection   Instruction Selection  Reference LLVM Core Pipeline LLVM Core Pipleline \u0026ndash; InstructionSelect InstructionSelect pass transforms generic machine instructions into equivalent target-specifc instructions. It traverses the MachineFunction bottom-up, selecting uses before definitions, enabling trivial dead code elimination. The target implements InstructionSelector class, containing target-specific selection logic. InstructionSelector::select virtual bool select(MachineInstr \u0026amp;MI) This method is responsible for mutating (or replacing) a possibly-generic MI into a fully target-specific equivalent. doing the necessary constraining of gvregs into the appropriate register classes passing through COPY instructions to the register allocator.\n IRTranslator  Reference LLVM Core Pipleline LLVM Core Pipeline \u0026ndash; IRTranslator llvm/include/llvm/CodeGen/GlobalISel/IRTranslator.h llvm/lib/CodeGen/GlobalISel/IRTranslator.cpp Overview This pass can be disabled according to LLVM selector type. There are three selector types: FastISel, GlobalISel, and SelectionDAG. Both FastISel and SelectionDAG do not use IRTranslator pass for ISel, but instead uses target dependent passes, such as MipsModuleDAGToDAGISel, Mips16DAGToDAGISel, MipsSEDAGToDAGISel, etc. see MipsPassConfig::addInstSelector() in llvm/lib/Target/Mips/MipsTargetMachine.cpp. Users can provide options to help LLVM determine the right selector type.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/globalisel/ir-translator/call-lowering/",
	"title": "Call Lowering",
	"tags": [],
	"description": "",
	"content": "References:\n llvm/include/llvm/CodeGen/GlobalISel/CallLowering.h llvm/lib/CodeGen/GlobalISel/CallLowering.cpp  CallLowering class describes how to lower LLVM calls to machine code calls.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/tools/mscode/",
	"title": "Mscode",
	"tags": [],
	"description": "",
	"content": "References:\n StackOverflow: Vertical rulers in Visual Studio Code\n\u0026#34;editor.rulers\u0026#34;: [80,120] \u0026#34;workbench.colorCustomizations\u0026#34;: { \u0026#34;editorRuler.foreground\u0026#34;: \u0026#34;#ff4081\u0026#34; }   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/tools/vim/",
	"title": "Vim",
	"tags": [],
	"description": "",
	"content": "References:\n How can I set up a ruler at a specific column?\nset colorcolumn=80   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/mc-streamer/mc-asm-streamer/",
	"title": "MCAsmStreamer",
	"tags": [],
	"description": "",
	"content": "Two implementations of MCStreamer:\n MCAsmStreamer is a straightforward impl that prints out a directive for each method. (e.g EmitValue -\u0026gt; .byte) MCObjectStreamer implements a full assembler.\n// Inheritance relations  MCStreamer (contain an instance of `MCTargetStreamer` as member `TargetStreamer`) -\u0026gt; MCAsmStreamer (final) -\u0026gt; MCObjectStreamer -\u0026gt; MCELFStreamer -\u0026gt; MipsELFStreamer -\u0026gt; MCWasmStreamer // MCTargetStreamer for directives.  // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetAsmStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetELFStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; RISCVTargetStreamer // lib/Target/RISCV/MCTargetDesc/RISCVTargetStreamer.h    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/mc-streamer/mips-target-streamer/",
	"title": "Mips Target Streamer",
	"tags": [],
	"description": "",
	"content": " For Target specific directives, the MCStreamer has a MCTargetStreamer instance.\n// Inheritance relations  // MCTargetStreamer for directives.  // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h  -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.h  -\u0026gt; MipsTargetAsmStreamer // lib/Target/Mips/MipsTargetStreamer.h  -\u0026gt; MipsTargetELFStreamer // lib/Target/Mips/MipsTargetStreamer.h  -\u0026gt; RISCVTargetStreamer // lib/Target/RISCV/MCTargetDesc/RISCVTargetStreamer.h  MipsTargetStreamer Source code list:\n lib/Target/Mips/MipsTargetStreamer.h  MipsTargetStreamer class MipsTargetAsmStreamer class, for ascii asm output  member: MCStreamer \u0026amp;Streamer;.  MipsTargetELFStreamer class, for ELF object output  member: MCStreamer \u0026amp;Streamer;.   lib/Target/Mips/MCTargetDesc/MipsTargetStreamer.cpp  MipsTargetELFStreamer::finish() function. Final step???  lib/Target/Mips/MipsTargetObjectFile.h lib/Target/Mips/MipsTargetObjectFile.cpp  MipsTargetStreamer class Constructor:\nMipsTargetStreamer(MCStreamer \u0026amp;S, llvm::Optional\u0026lt;unsigned\u0026gt; CheriCapSize);   emitStoreWithImmOffset/SCwithSymOffset() emitLoadWithImmOffset() emitGPRestore()  MipsTargetELFStreamer Constructor:\nMipsTargetELFStreamer(MCStreamer \u0026amp;S, const MCSubtargetInfo \u0026amp;STI);  Global/Section/LD/ST related functions:\n emitDirectiveCpLoad/CpLocal/CpRestore/Cpsetup/Cpreturn() emitLabel(MCSymbol *Symbol) emitAssignment(MCSymbol *Symbol, const MCExpr *Value) emitFrame(unsigned StackReg, unsigned StackSize, unsigned ReturnReg)  finish():\n// lib/Target/MipsMCTargetDesc/MipsTargetStreamer.cpp finish() -\u0026gt; MCObjectFileInfo.get_x_Section() // .text, .data, .bss  -\u0026gt; MCAssembler.registerSection(_x_) // TextSection, DataSection, BSSSection  -\u0026gt; MCAssembler.setELFHeaderEFlags(..) // ELF_MIPS_ABI_CHERIABI  -\u0026gt; MipsELFStreamer.EmitMipsOptionRecords(); // `.Mips.options` section: Streamer-\u0026gt;EmitIntValue()....  -\u0026gt; emitMipsAbiFlags(); //?  finish() is called in MCStreamer::Finish() in lib/MC/MCStreamer.cpp\nMCStreamer::Finish() Finish() -\u0026gt; FinishImpl(), both of them finally call a set of functions as\n-\u0026gt; EmitValue() -\u0026gt; EmitZeros() -\u0026gt; finish() -\u0026gt; FinishImpl() is empty.\nvoid MCStreamer::Finish() { if ((!DwarfFrameInfos.empty() \u0026amp;\u0026amp; !DwarfFrameInfos.back().End) || (!WinFrameInfos.empty() \u0026amp;\u0026amp; !WinFrameInfos.back()-\u0026gt;End)) { getContext().reportError(SMLoc(), \u0026#34;Unfinished frame!\u0026#34;); return; } if (!FatRelocs.empty()) { MCSection *DefaultRelocSection = Context.getELFSection(\u0026#34;__cap_relocs\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC); DefaultRelocSection-\u0026gt;setAlignment(llvm::Align(8)); for (auto \u0026amp;R : FatRelocs) { MCSymbol *Sym; const MCExpr *Value; MCSection *RelocSection; StringRef GroupName; std::tie(Sym, Value, GroupName) = R; if (GroupName != StringRef()) { RelocSection = Context.getELFSection(\u0026#34;__cap_relocs\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC | ELF::SHF_GROUP, 0, GroupName); RelocSection-\u0026gt;setAlignment(llvm::Align(8)); } else { RelocSection = DefaultRelocSection; } SwitchSection(RelocSection); EmitValue(MCSymbolRefExpr::create(Sym, Context), 8); if (const MCSymbolRefExpr *Sym = dyn_cast\u0026lt;MCSymbolRefExpr\u0026gt;(Value)) { EmitValue(Sym, 8); EmitZeros(8); } else { const MCBinaryExpr *Bin = cast\u0026lt;MCBinaryExpr\u0026gt;(Value); EmitValue(cast\u0026lt;MCSymbolRefExpr\u0026gt;(Bin-\u0026gt;getLHS()), 8); EmitValue(Bin-\u0026gt;getRHS(), 8); } // TODO: Emit size / perms here.  EmitZeros(16); } } MCTargetStreamer *TS = getTargetStreamer(); if (TS) TS-\u0026gt;finish(); FinishImpl(); }  MipsRegInfoRecord::EmitMipsOptionRecord() // void MipsRegInfoRecord::EmitMipsOptionRecord() { MCAssembler \u0026amp;MCA = Streamer-\u0026gt;getAssembler(); MipsTargetStreamer *MTS = static_cast\u0026lt;MipsTargetStreamer *\u0026gt;(Streamer-\u0026gt;getTargetStreamer()); Streamer-\u0026gt;PushSection(); // We need to distinguish between N64 and the rest because at the moment  // we don\u0026#39;t emit .Mips.options for other ELFs other than N64.  // Since .reginfo has the same information as .Mips.options (ODK_REGINFO),  // we can use the same abstraction (MipsRegInfoRecord class) to handle both.  if (MTS-\u0026gt;getABI().IsN64()) { // The EntrySize value of 1 seems strange since the records are neither  // 1-byte long nor fixed length but it matches the value GAS emits.  MCSectionELF *Sec = Context.getELFSection(\u0026#34;.MIPS.options\u0026#34;, ELF::SHT_MIPS_OPTIONS, ELF::SHF_ALLOC | ELF::SHF_MIPS_NOSTRIP, 1, \u0026#34;\u0026#34;); MCA.registerSection(*Sec); Sec-\u0026gt;setAlignment(llvm::Align(8)); Streamer-\u0026gt;SwitchSection(Sec); Streamer-\u0026gt;EmitIntValue(ELF::ODK_REGINFO, 1); // kind  Streamer-\u0026gt;EmitIntValue(40, 1); // size  Streamer-\u0026gt;EmitIntValue(0, 2); // section  Streamer-\u0026gt;EmitIntValue(0, 4); // info  Streamer-\u0026gt;EmitIntValue(ri_gprmask, 4); Streamer-\u0026gt;EmitIntValue(0, 4); // pad  Streamer-\u0026gt;EmitIntValue(ri_cprmask[0], 4); Streamer-\u0026gt;EmitIntValue(ri_cprmask[1], 4); Streamer-\u0026gt;EmitIntValue(ri_cprmask[2], 4); Streamer-\u0026gt;EmitIntValue(ri_cprmask[3], 4); Streamer-\u0026gt;EmitIntValue(ri_gp_value, 8); } else { MCSectionELF *Sec = Context.getELFSection(\u0026#34;.reginfo\u0026#34;, ELF::SHT_MIPS_REGINFO, ELF::SHF_ALLOC, 24, \u0026#34;\u0026#34;); MCA.registerSection(*Sec); Sec-\u0026gt;setAlignment(MTS-\u0026gt;getABI().IsN32() ? llvm::Align(8) : llvm::Align(4)); Streamer-\u0026gt;SwitchSection(Sec); Streamer-\u0026gt;EmitIntValue(ri_gprmask, 4); Streamer-\u0026gt;EmitIntValue(ri_cprmask[0], 4); Streamer-\u0026gt;EmitIntValue(ri_cprmask[1], 4); Streamer-\u0026gt;EmitIntValue(ri_cprmask[2], 4); Streamer-\u0026gt;EmitIntValue(ri_cprmask[3], 4); assert((ri_gp_value \u0026amp; 0xffffffff) == ri_gp_value); Streamer-\u0026gt;EmitIntValue(ri_gp_value, 4); } Streamer-\u0026gt;PopSection(); }  Steamer-\u0026gt;EmitIntValue MipsELFStreamer Streamer, defined in lib/Target/Mips/MCTargetDesc/MipsELFStreamer.h\nEmitIntValue() is defined as:\n// lib/Target/Mips/MCTargetDesc/MipsELFStreamer.cpp void MipsELFStreamer::EmitIntValue(uint64_t Value, unsigned Size) { MCELFStreamer::EmitIntValue(Value, Size); Labels.clear(); }  See more at MCStreamer - MipsELFSteamer::EmitIntValue\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/mc-streamer/mc-object-streamer/",
	"title": "MCObjectStreamer",
	"tags": [],
	"description": "",
	"content": "Two implementations of MCStreamer:\n MCAsmStreamer is a straightforward impl that prints out a directive for each method. (e.g EmitValue -\u0026gt; .byte) MCObjectStreamer implements a full assembler.\n// Inheritance relations  MCStreamer (contain an instance of `MCTargetStreamer` as member `TargetStreamer`) -\u0026gt; MCAsmStreamer (final) -\u0026gt; MCObjectStreamer -\u0026gt; MCELFStreamer -\u0026gt; MipsELFStreamer -\u0026gt; MCWasmStreamer // MCTargetStreamer for directives.  // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetAsmStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetELFStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; RISCVTargetStreamer // lib/Target/RISCV/MCTargetDesc/RISCVTargetStreamer.h   MipsAsmPrinter::EmitInstruction() acts as a driver to emit an instruction. It will finally calls the MCObjectStreamer to write object (e.g. .o) files or MCAsmStreamer to write assembly (e.g .s) files.\n  tracking `MipsAsmPrinter::EmitInstruction()`   // llvm/lib/Target/Mips/MipsAsmPrinter.cpp void MipsAsmPrinter::EmitInstruction(const MachineInstr *MI) { MipsTargetStreamer \u0026amp;TS = getTargetStreamer(); unsigned Opc = MI-\u0026gt;getOpcode(); ... MachineBasicBlock::const_instr_iterator I = MI-\u0026gt;getIterator(); MachineBasicBlock::const_instr_iterator E = MI-\u0026gt;getParent()-\u0026gt;instr_end(); do { ... MCInst TmpInst0; MCInstLowering.Lower(\u0026amp;*I, TmpInst0); DebugLL(\u0026#34;Instruction lowered: From MachineInstr: \u0026#34;; I-\u0026gt;dump()); DebugLLS(\u0026#34;\\t... TO MCInst\u0026#34;; TmpInst0.dump()); EmitToStreamer(*OutStreamer, TmpInst0); DebugLL(\u0026#34;Instruction emitted to streamer: \u0026#34;; TmpInst0.dump()); } while ((++I != E) \u0026amp;\u0026amp; I-\u0026gt;isInsideBundle()); // Delay slot check }    MCObjectStreamer::EmitInstruction() will:\n call parent method MCStreamer::EmitInstruction(Inst, STI); (to do what??? by visitXXXX) call a child method MCELFStreamer::EmitInstToData() to emit the instruction as a piece of \u0026ldquo;data\u0026rdquo; in the .text section. MCELFStreamer::EmitInstToData() will call Assembler.getEmitter().encodeInstruction() to encode the instruction and store it in as SmallString\u0026lt;256\u0026gt; Code. Assembler.getEmitter().encodeInstruction() is implemented by target arch in . For example in MipsMCCodeEmitter::encodeInstruction(). This is where the instruction in binary form got emitted to a streamer: EmitInstruction(Binary, Size, STI, OS);  Binary is got via Binary = getBinaryCodeForInstr(TmpInst, Fixups, STI) getBinaryCodeForInstr() is a TableGen\u0026rsquo;erated function for getting the binary encoding for an instruction.     tracking MCObjectStreamer::EmitInstruction()   void MCObjectStreamer::EmitInstruction(const MCInst \u0026amp;Inst, const MCSubtargetInfo \u0026amp;STI) { getAssembler().getBackend().handleCodePaddingInstructionBegin(Inst); EmitInstructionImpl(Inst, STI); getAssembler().getBackend().handleCodePaddingInstructionEnd(Inst); } void MCObjectStreamer::EmitInstructionImpl(const MCInst \u0026amp;Inst, const MCSubtargetInfo \u0026amp;STI) { MCStreamer::EmitInstruction(Inst, STI); MCSection *Sec = getCurrentSectionOnly(); Sec-\u0026gt;setHasInstructions(true); // Now that a machine instruction has been assembled into this section, make  // a line entry for any .loc directive that has been seen.  MCDwarfLineEntry::Make(this, getCurrentSectionOnly()); // If this instruction doesn\u0026#39;t need relaxation, just emit it as data.  MCAssembler \u0026amp;Assembler = getAssembler(); if (!Assembler.getBackend().mayNeedRelaxation(Inst, STI)) { EmitInstToData(Inst, STI); return; } // Otherwise, relax and emit it as data if either:  // Mips does not have relax:  // MipsAsmBackend::mayNeedRelaxation() always return false }  MCObjectStreamer::EmitInstruction() calls a child overloaded method for ELF (or ASM) MCELFStreamer::EmitInstToData():\nvoid MCELFStreamer::EmitInstToData(const MCInst \u0026amp;Inst, const MCSubtargetInfo \u0026amp;STI) { MCAssembler \u0026amp;Assembler = getAssembler(); SmallVector\u0026lt;MCFixup, 4\u0026gt; Fixups; SmallString\u0026lt;256\u0026gt; Code; raw_svector_ostream VecOS(Code); Assembler.getEmitter().encodeInstruction(Inst, VecOS, Fixups, STI); for (unsigned i = 0, e = Fixups.size(); i != e; ++i) fixSymbolsInTLSFixups(Fixups[i].getValue()); // There are several possibilities here:  //  // If bundling is disabled, append the encoded instruction to the current data  // fragment (or create a new such fragment if the current fragment is not a  // data fragment, or the Subtarget has changed).  //  // If bundling is enabled:  // - If we\u0026#39;re not in a bundle-locked group, emit the instruction into a  // fragment of its own. If there are no fixups registered for the  // instruction, emit a MCCompactEncodedInstFragment. Otherwise, emit a  // MCDataFragment.  // - If we\u0026#39;re in a bundle-locked group, append the instruction to the current  // data fragment because we want all the instructions in a group to get into  // the same fragment. Be careful not to do that for the first instruction in  // the group, though.  MCDataFragment *DF; if (Assembler.isBundlingEnabled()) { MCSection \u0026amp;Sec = *getCurrentSectionOnly(); if (Assembler.getRelaxAll() \u0026amp;\u0026amp; isBundleLocked()) { // If the -mc-relax-all flag is used and we are bundle-locked, we re-use  // the current bundle group.  DF = BundleGroups.back(); CheckBundleSubtargets(DF-\u0026gt;getSubtargetInfo(), \u0026amp;STI); } else if (Assembler.getRelaxAll() \u0026amp;\u0026amp; !isBundleLocked()) // When not in a bundle-locked group and the -mc-relax-all flag is used,  // we create a new temporary fragment which will be later merged into  // the current fragment.  DF = new MCDataFragment(); else if (isBundleLocked() \u0026amp;\u0026amp; !Sec.isBundleGroupBeforeFirstInst()) { // If we are bundle-locked, we re-use the current fragment.  // The bundle-locking directive ensures this is a new data fragment.  DF = cast\u0026lt;MCDataFragment\u0026gt;(getCurrentFragment()); CheckBundleSubtargets(DF-\u0026gt;getSubtargetInfo(), \u0026amp;STI); } else if (!isBundleLocked() \u0026amp;\u0026amp; Fixups.size() == 0) { // Optimize memory usage by emitting the instruction to a  // MCCompactEncodedInstFragment when not in a bundle-locked group and  // there are no fixups registered.  MCCompactEncodedInstFragment *CEIF = new MCCompactEncodedInstFragment(); insert(CEIF); CEIF-\u0026gt;getContents().append(Code.begin(), Code.end()); CEIF-\u0026gt;setHasInstructions(STI); return; } else { DF = new MCDataFragment(); insert(DF); } if (Sec.getBundleLockState() == MCSection::BundleLockedAlignToEnd) { // If this fragment is for a group marked \u0026#34;align_to_end\u0026#34;, set a flag  // in the fragment. This can happen after the fragment has already been  // created if there are nested bundle_align groups and an inner one  // is the one marked align_to_end.  DF-\u0026gt;setAlignToBundleEnd(true); } // We\u0026#39;re now emitting an instruction in a bundle group, so this flag has  // to be turned off.  Sec.setBundleGroupBeforeFirstInst(false); } else { DF = getOrCreateDataFragment(\u0026amp;STI); } // Add the fixups and data.  for (unsigned i = 0, e = Fixups.size(); i != e; ++i) { Fixups[i].setOffset(Fixups[i].getOffset() + DF-\u0026gt;getContents().size()); DF-\u0026gt;getFixups().push_back(Fixups[i]); } DF-\u0026gt;setHasInstructions(STI); DF-\u0026gt;getContents().append(Code.begin(), Code.end()); if (Assembler.isBundlingEnabled() \u0026amp;\u0026amp; Assembler.getRelaxAll()) { if (!isBundleLocked()) { mergeFragment(getOrCreateDataFragment(\u0026amp;STI), DF); delete DF; } } }  The instruction finally got emitted in target dependent encodeInstruction() method. Mips as an example below:\n/// encodeInstruction - Emit the instruction. /// Size the instruction with Desc.getSize(). void MipsMCCodeEmitter:: encodeInstruction(const MCInst \u0026amp;MI, raw_ostream \u0026amp;OS, SmallVectorImpl\u0026lt;MCFixup\u0026gt; \u0026amp;Fixups, const MCSubtargetInfo \u0026amp;STI) const { // Non-pseudo instructions that get changed for direct object  // only based on operand values.  // If this list of instructions get much longer we will move  // the check to a function call. Until then, this is more efficient.  MCInst TmpInst = MI; switch (MI.getOpcode()) { // If shift amount is \u0026gt;= 32 it the inst needs to be lowered further  case Mips::DSLL: case Mips::DSRL: case Mips::DSRA: case Mips::DROTR: LowerLargeShift(TmpInst); break; // Compact branches, enforce encoding restrictions.  case Mips::BEQC: case Mips::BNEC: case Mips::BEQC64: case Mips::BNEC64: case Mips::BOVC: case Mips::BOVC_MMR6: case Mips::BNVC: case Mips::BNVC_MMR6: LowerCompactBranch(TmpInst); } unsigned long N = Fixups.size(); uint32_t Binary = getBinaryCodeForInstr(TmpInst, Fixups, STI); // Check for unimplemented opcodes.  // Unfortunately in MIPS both NOP and SLL will come in with Binary == 0  // so we have to special check for them.  const unsigned Opcode = TmpInst.getOpcode(); if ((Opcode != Mips::NOP) \u0026amp;\u0026amp; (Opcode != Mips::SLL) \u0026amp;\u0026amp; (Opcode != Mips::SLL_MM) \u0026amp;\u0026amp; (Opcode != Mips::SLL_MMR6) \u0026amp;\u0026amp; !Binary) llvm_unreachable(\u0026#34;unimplemented opcode in encodeInstruction()\u0026#34;); int NewOpcode = -1; if (isMicroMips(STI)) { if (isMips32r6(STI)) { NewOpcode = Mips::MipsR62MicroMipsR6(Opcode, Mips::Arch_micromipsr6); if (NewOpcode == -1) NewOpcode = Mips::Std2MicroMipsR6(Opcode, Mips::Arch_micromipsr6); } else NewOpcode = Mips::Std2MicroMips(Opcode, Mips::Arch_micromips); // Check whether it is Dsp instruction.  if (NewOpcode == -1) NewOpcode = Mips::Dsp2MicroMips(Opcode, Mips::Arch_mmdsp); if (NewOpcode != -1) { if (Fixups.size() \u0026gt; N) Fixups.pop_back(); TmpInst.setOpcode (NewOpcode); Binary = getBinaryCodeForInstr(TmpInst, Fixups, STI); } if (((MI.getOpcode() == Mips::MOVEP_MM) || (MI.getOpcode() == Mips::MOVEP_MMR6))) { unsigned RegPair = getMovePRegPairOpValue(MI, 0, Fixups, STI); Binary = (Binary \u0026amp; 0xFFFFFC7F) | (RegPair \u0026lt;\u0026lt; 7); } } const MCInstrDesc \u0026amp;Desc = MCII.get(TmpInst.getOpcode()); // Get byte count of instruction  unsigned Size = Desc.getSize(); if (!Size) llvm_unreachable(\u0026#34;Desc.getSize() returns 0\u0026#34;); EmitInstruction(Binary, Size, STI, OS); }     "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/globalisel/inst-sel/",
	"title": "Instruction Selection",
	"tags": [],
	"description": "",
	"content": " Reference\n LLVM Core Pipeline LLVM Core Pipleline \u0026ndash; InstructionSelect  InstructionSelect pass transforms generic machine instructions into equivalent target-specifc instructions. It traverses the MachineFunction bottom-up, selecting uses before definitions, enabling trivial dead code elimination.\nThe target implements InstructionSelector class, containing target-specific selection logic.\nInstructionSelector::select virtual bool select(MachineInstr \u0026amp;MI)\nThis method is responsible for\n mutating (or replacing) a possibly-generic MI into a fully target-specific equivalent. doing the necessary constraining of gvregs into the appropriate register classes passing through COPY instructions to the register allocator. fold other instructions into the selected MI, by walking the use-def chain of the vreg operands. The folding can occur across basic blocks as GlobalISel is Global.  TableGen imports SelectionDAG rules TableGen will import SelectDAG rules and provide the following function to execute them:\nbool selectImpl(MachineInstr \u0026amp;MI)   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/metadata/",
	"title": "Metadata",
	"tags": [],
	"description": "",
	"content": "References:\n llvm/unittests/IR/MetadataTest.cpp   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/core-isel/globalisel/ir-translator/",
	"title": "IRTranslator",
	"tags": [],
	"description": "",
	"content": " Reference\n LLVM Core Pipleline LLVM Core Pipeline \u0026ndash; IRTranslator llvm/include/llvm/CodeGen/GlobalISel/IRTranslator.h llvm/lib/CodeGen/GlobalISel/IRTranslator.cpp  Overview This pass can be disabled according to LLVM selector type. There are three selector types: FastISel, GlobalISel, and SelectionDAG. Both FastISel and SelectionDAG do not use IRTranslator pass for ISel, but instead uses target dependent passes, such as MipsModuleDAGToDAGISel, Mips16DAGToDAGISel, MipsSEDAGToDAGISel, etc. see MipsPassConfig::addInstSelector() in llvm/lib/Target/Mips/MipsTargetMachine.cpp. Users can provide options to help LLVM determine the right selector type. The logic is programmed at TargetPassConfig::addCoreISelPasses() in llvm/lib/CodeGen/TargetPassConfig.cpp. GlobalISel is a framework aiming to be used to replace FastISel and SelectionDAG. More on GlobalISel.\n IRTranslator pass is responsible for translating LLVM IR Function into a Generic MIR MachineFunction.\nThis is typically a direct translation but does occasionally get a bit more involved. For example,\n%2 = add i32 %0, %1 becomes:\n%2:_(s32) = G_ADD %0:_(s32), %1:_(s32) and\ncall i32 @puts(i8* %cast210) is translated according to the ABI rules of the target.\nTranslating Function Calls IRTranslator also implements the ABI\u0026rsquo;s calling convention by lowering calls, returns, and arguments to the appropriate physical register usage and instruction sequences.\nThis is achieved using the CallLowering implementation.\nTranslating Constants Constant operands are translated as a use of a virtual register that is defined by a G_CONSTANT or G_FCONSTANT instruction.\nThese instructions are placed in the entry block to allow them to be subject to the continuous CSE implementation (Machine Common Subexpression Elimination Pass)\nTracking the pass code Pass Creation/Registration TargetPassConfig::addCoreISelPasses() -\u0026gt; addIRTranslator() -\u0026gt; MipsPassConfig::addIRTranslator() -\u0026gt; TargetPassConfig::addPass(new IRTranslator());  IRTranslator::runOnMachineFunction Steps:\n get the IR function for this MachineFunction. ??? already has a MachineFunction for this IR function? // Algo: // CallLowering = MF.subtarget.getCallLowering() // F = MF.getParent() // MIRBuilder.reset(MF) // getMBB(F.getEntryBB()) // CallLowering-\u0026gt;translateArguments(MIRBuilder, F, ValToVReg) // for each bb in F // getMBB(bb) // for each inst in bb // if (!translate(MIRBuilder, inst, ValToVReg, ConstantToSequence)) // report_fatal_error(\u0026#34;Don\u0026#39;t know how to translate input\u0026#34;); // finalize()    IRTranslator::runOnMachineFunction()   bool IRTranslator::runOnMachineFunction(MachineFunction \u0026amp;CurMF) { MF = \u0026amp;CurMF; const Function \u0026amp;F = MF-\u0026gt;getFunction(); if (F.empty()) return false; GISelCSEAnalysisWrapper \u0026amp;Wrapper = getAnalysis\u0026lt;GISelCSEAnalysisWrapperPass\u0026gt;().getCSEWrapper(); // Set the CSEConfig and run the analysis.  GISelCSEInfo *CSEInfo = nullptr; TPC = \u0026amp;getAnalysis\u0026lt;TargetPassConfig\u0026gt;(); bool EnableCSE = EnableCSEInIRTranslator.getNumOccurrences() ? EnableCSEInIRTranslator : TPC-\u0026gt;isGISelCSEEnabled(); if (EnableCSE) { EntryBuilder = std::make_unique\u0026lt;CSEMIRBuilder\u0026gt;(CurMF); CSEInfo = \u0026amp;Wrapper.get(TPC-\u0026gt;getCSEConfig()); EntryBuilder-\u0026gt;setCSEInfo(CSEInfo); CurBuilder = std::make_unique\u0026lt;CSEMIRBuilder\u0026gt;(CurMF); CurBuilder-\u0026gt;setCSEInfo(CSEInfo); } else { EntryBuilder = std::make_unique\u0026lt;MachineIRBuilder\u0026gt;(); CurBuilder = std::make_unique\u0026lt;MachineIRBuilder\u0026gt;(); } CLI = MF-\u0026gt;getSubtarget().getCallLowering(); CurBuilder-\u0026gt;setMF(*MF); EntryBuilder-\u0026gt;setMF(*MF); MRI = \u0026amp;MF-\u0026gt;getRegInfo(); DL = \u0026amp;F.getParent()-\u0026gt;getDataLayout(); ORE = std::make_unique\u0026lt;OptimizationRemarkEmitter\u0026gt;(\u0026amp;F); FuncInfo.MF = MF; FuncInfo.BPI = nullptr; const auto \u0026amp;TLI = *MF-\u0026gt;getSubtarget().getTargetLowering(); const TargetMachine \u0026amp;TM = MF-\u0026gt;getTarget(); SL = std::make_unique\u0026lt;GISelSwitchLowering\u0026gt;(this, FuncInfo); SL-\u0026gt;init(TLI, TM, *DL); EnableOpts = TM.getOptLevel() != CodeGenOpt::None \u0026amp;\u0026amp; !skipFunction(F); assert(PendingPHIs.empty() \u0026amp;\u0026amp; \u0026#34;stale PHIs\u0026#34;); if (!DL-\u0026gt;isLittleEndian()) { // Currently we don\u0026#39;t properly handle big endian code.  OptimizationRemarkMissed R(\u0026#34;gisel-irtranslator\u0026#34;, \u0026#34;GISelFailure\u0026#34;, F.getSubprogram(), \u0026amp;F.getEntryBlock()); R \u0026lt;\u0026lt; \u0026#34;unable to translate in big endian mode\u0026#34;; reportTranslationError(*MF, *TPC, *ORE, R); } // Release the per-function state when we return, whether we succeeded or not.  auto FinalizeOnReturn = make_scope_exit([this]() { finalizeFunction(); }); // Setup a separate basic-block for the arguments and constants  MachineBasicBlock *EntryBB = MF-\u0026gt;CreateMachineBasicBlock(); MF-\u0026gt;push_back(EntryBB); EntryBuilder-\u0026gt;setMBB(*EntryBB); DebugLoc DbgLoc = F.getEntryBlock().getFirstNonPHI()-\u0026gt;getDebugLoc(); SwiftError.setFunction(CurMF); SwiftError.createEntriesInEntryBlock(DbgLoc); // Create all blocks, in IR order, to preserve the layout.  for (const BasicBlock \u0026amp;BB: F) { auto *\u0026amp;MBB = BBToMBB[\u0026amp;BB]; MBB = MF-\u0026gt;CreateMachineBasicBlock(\u0026amp;BB); MF-\u0026gt;push_back(MBB); if (BB.hasAddressTaken()) MBB-\u0026gt;setHasAddressTaken(); // Lele: should we pass a similar BB.getOwnershipInfo() -\u0026gt; MBB.setOwnershipInfo()?  } // Make our arguments/constants entry block fallthrough to the IR entry block.  EntryBB-\u0026gt;addSuccessor(\u0026amp;getMBB(F.front())); // Lower the actual args into this basic block.  SmallVector\u0026lt;ArrayRef\u0026lt;Register\u0026gt;, 8\u0026gt; VRegArgs; for (const Argument \u0026amp;Arg: F.args()) { if (DL-\u0026gt;getTypeStoreSize(Arg.getType()) == 0) continue; // Don\u0026#39;t handle zero sized types.  ArrayRef\u0026lt;Register\u0026gt; VRegs = getOrCreateVRegs(Arg); VRegArgs.push_back(VRegs); if (Arg.hasSwiftErrorAttr()) { assert(VRegs.size() == 1 \u0026amp;\u0026amp; \u0026#34;Too many vregs for Swift error\u0026#34;); SwiftError.setCurrentVReg(EntryBB, SwiftError.getFunctionArg(), VRegs[0]); } } if (!CLI-\u0026gt;lowerFormalArguments(*EntryBuilder.get(), F, VRegArgs)) { OptimizationRemarkMissed R(\u0026#34;gisel-irtranslator\u0026#34;, \u0026#34;GISelFailure\u0026#34;, F.getSubprogram(), \u0026amp;F.getEntryBlock()); R \u0026lt;\u0026lt; \u0026#34;unable to lower arguments: \u0026#34; \u0026lt;\u0026lt; ore::NV(\u0026#34;Prototype\u0026#34;, F.getType()); reportTranslationError(*MF, *TPC, *ORE, R); return false; } // Need to visit defs before uses when translating instructions.  GISelObserverWrapper WrapperObserver; if (EnableCSE \u0026amp;\u0026amp; CSEInfo) WrapperObserver.addObserver(CSEInfo); { ReversePostOrderTraversal\u0026lt;const Function *\u0026gt; RPOT(\u0026amp;F); #ifndef NDEBUG  DILocationVerifier Verifier; WrapperObserver.addObserver(\u0026amp;Verifier); #endif // ifndef NDEBUG  RAIIDelegateInstaller DelInstall(*MF, \u0026amp;WrapperObserver); for (const BasicBlock *BB : RPOT) { MachineBasicBlock \u0026amp;MBB = getMBB(*BB); // Set the insertion point of all the following translations to  // the end of this basic block.  CurBuilder-\u0026gt;setMBB(MBB); HasTailCall = false; for (const Instruction \u0026amp;Inst : *BB) { // If we translated a tail call in the last step, then we know  // everything after the call is either a return, or something that is  // handled by the call itself. (E.g. a lifetime marker or assume  // intrinsic.) In this case, we should stop translating the block and  // move on.  if (HasTailCall) break; #ifndef NDEBUG  Verifier.setCurrentInst(\u0026amp;Inst); #endif // ifndef NDEBUG  if (translate(Inst)) continue; OptimizationRemarkMissed R(\u0026#34;gisel-irtranslator\u0026#34;, \u0026#34;GISelFailure\u0026#34;, Inst.getDebugLoc(), BB); R \u0026lt;\u0026lt; \u0026#34;unable to translate instruction: \u0026#34; \u0026lt;\u0026lt; ore::NV(\u0026#34;Opcode\u0026#34;, \u0026amp;Inst); if (ORE-\u0026gt;allowExtraAnalysis(\u0026#34;gisel-irtranslator\u0026#34;)) { std::string InstStrStorage; raw_string_ostream InstStr(InstStrStorage); InstStr \u0026lt;\u0026lt; Inst; R \u0026lt;\u0026lt; \u0026#34;: \u0026#39;\u0026#34; \u0026lt;\u0026lt; InstStr.str() \u0026lt;\u0026lt; \u0026#34;\u0026#39;\u0026#34;; } reportTranslationError(*MF, *TPC, *ORE, R); return false; } finalizeBasicBlock(); } #ifndef NDEBUG  WrapperObserver.removeObserver(\u0026amp;Verifier); #endif  } finishPendingPhis(); SwiftError.propagateVRegs(); // Merge the argument lowering and constants block with its single  // successor, the LLVM-IR entry block. We want the basic block to  // be maximal.  assert(EntryBB-\u0026gt;succ_size() == 1 \u0026amp;\u0026amp; \u0026#34;Custom BB used for lowering should have only one successor\u0026#34;); // Get the successor of the current entry block.  MachineBasicBlock \u0026amp;NewEntryBB = **EntryBB-\u0026gt;succ_begin(); assert(NewEntryBB.pred_size() == 1 \u0026amp;\u0026amp; \u0026#34;LLVM-IR entry block has a predecessor!?\u0026#34;); // Move all the instruction from the current entry block to the  // new entry block.  NewEntryBB.splice(NewEntryBB.begin(), EntryBB, EntryBB-\u0026gt;begin(), EntryBB-\u0026gt;end()); // Update the live-in information for the new entry block.  for (const MachineBasicBlock::RegisterMaskPair \u0026amp;LiveIn : EntryBB-\u0026gt;liveins()) NewEntryBB.addLiveIn(LiveIn); NewEntryBB.sortUniqueLiveIns(); // Get rid of the now empty basic block.  EntryBB-\u0026gt;removeSuccessor(\u0026amp;NewEntryBB); MF-\u0026gt;remove(EntryBB); MF-\u0026gt;DeleteMachineBasicBlock(EntryBB); assert(\u0026amp;MF-\u0026gt;front() == \u0026amp;NewEntryBB \u0026amp;\u0026amp; \u0026#34;New entry wasn\u0026#39;t next in the list of basic block!\u0026#34;); // Initialize stack protector information.  StackProtector \u0026amp;SP = getAnalysis\u0026lt;StackProtector\u0026gt;(); SP.copyToMachineFrameInfo(MF-\u0026gt;getFrameInfo()); return false; }     A DenseMap\u0026lt;const BasicBlock *, MachineBasicBlock *\u0026gt; BBToMBB; store all BB-\u0026gt;MBB.  A one to one mapping.  MachineBasicBlock * MachineFunction::CreateMachineBasicBlock(const BasicBlock *bb) Translate Instructions:IRTranslator::translateXXX()  IRTranslator::translate() IRTranslator::translateLoad() IRTranslator::translateStore() IRTranslator::translateGetElementPtr() IRTranslator::translateMemFunc() IRTranslator::translateCall() IRTranslator::translateInvoke() IRTranslator::translateCallBr() IRTranslator::translateLandingPad() IRTranslator::translateInlineAsm() IRTranslator::translateAlloc() IRTranslator::translatePHI() IRTranslator::translateSimpleIntrinsic() ~ 37 funcs.   IRTranslator::translate() The general algorithm:\n Look for a virtual register for each operand or create one. Update the VMap accordingly.  Alternative: For constant arguments, if they are compile time constants, produce an immediate in the right operand and do not touch ValToVReg. In implementation: Actually we will go with a virtual register for each constants because it may be expensive to actually materialize the constant. Moreover, if the constant spans on several instructions, CSE may not catch them. Update ValToVReg and remember that we saw a constant in Constants. We will materialize all the constant in finalize.  Create the generic instruction.  Reference:\n llvm/include/llvm/CodeGen/GlobalISel/IRTranslator.h ``\n//   IRTranslator::translateLoad() Call path\nIRTranslator::runOnMachineFunction() -\u0026gt; IRTranslator::translate(Inst) -\u0026gt; IRTranslator::translateLoad(), via HANDLE_INST macro, and instruction definitions in llvm/IR/Instructions.def:\n// IRTranslator::translate(const Instruction \u0026amp;Inst)  switch (Inst.getOpcode()) { #define HANDLE_INST(NUM, OPCODE, CLASS) \\ case Instruction::OPCODE: \\ return translate##OPCODE(Inst, *CurBuilder.get()); #include \u0026#34;llvm/IR/Instruction.def\u0026#34; default: return false; }    code IRTranslator::translateLoad()     Call Lowering  References: llvm/include/llvm/CodeGen/GlobalISel/CallLowering.h llvm/lib/CodeGen/GlobalISel/CallLowering.cpp CallLowering class describes how to lower LLVM calls to machine code calls.    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/asm-printer/",
	"title": "Asm Printer",
	"tags": [],
	"description": "",
	"content": " Reference reference\nllvm/include/llvm/CodeGen/AsmPrinter.h llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp\nAsmPrinter is a pass at MachineFunction level: class AsmPrinter : public MachineFunctionPass.\nIt acts as a driver for the MC layer streamers. It defines the MachineFunction pass that calls OutStreamer-\u0026gt;emitXXX() to emit all the stuff to the binary or assembly files.\nThe (misnamed) target-independent AsmPrinter class implements the general lowering process converting MachineFunction\u0026rsquo;s into MC label constructs.\n target-specific subclasses of AsmPrinter, such as SparcAsmPrinter, MipsAsmPrinter target specific functions such as emitFunctionBodyStart()/End()  Additionally, for other code generation other than MachineFunction labels:\n the .td files used to generate instruction printer automatically.  add $dst, $src, $src2 Need routines to print operands. Where???  \u0026lt;target\u0026gt;MCInstLower.cpp: code that lowers a MachineInstr to an MCInst  often target specific is responsible for turning jump table entries, constant pool indicies, global variable address, etc, into MCLabels as appropriate. is responsible for expanding pseudo ops used by the code generator into the actual machine instructions they corresponding to. The MCInst that are generated by this are fed into the instructtion printer or the encoder.  the TargetLoweringObjectFile class  Tracking Pass MipsAsmPrinter MipsAsmPrinter::runOnMachineFunction(MachineFunction \u0026amp;MF)\nThe pass is registered using struct RegisterAsmPrinter:\n  code for pass registration   // llvm/lib/Target/Mips/MipsAsmPrinter.cpp  extern \u0026#34;C\u0026#34; void LLVMInitializeMipsAsmPrinter() { RegisterAsmPrinter\u0026lt;MipsAsmPrinter\u0026gt; X(getTheMipsTarget()); RegisterAsmPrinter\u0026lt;MipsAsmPrinter\u0026gt; Y(getTheMipselTarget()); RegisterAsmPrinter\u0026lt;MipsAsmPrinter\u0026gt; A(getTheMips64Target()); RegisterAsmPrinter\u0026lt;MipsAsmPrinter\u0026gt; B(getTheMips64elTarget()); RegisterAsmPrinter\u0026lt;MipsAsmPrinter\u0026gt; C(getTheMipsCheriTarget()); }    The pass is added to the pass manager in LLVMTargetMachine::addAsmPrinter():\n  tracking `LLVMTargetMachine::addAsmPrinter()`   // llvm/lib/CodeGen/LLVMTargetMachine.cpp  bool LLVMTargetMachine::addAsmPrinter(PassManagerBase \u0026amp;PM, raw_pwrite_stream \u0026amp;Out, raw_pwrite_stream *DwoOut, CodeGenFileType FileType, MCContext \u0026amp;Context) { // ...  // Create the AsmPrinter, which takes ownership of AsmStreamer if successful.  FunctionPass *Printer = getTarget().createAsmPrinter(*this, std::move(AsmStreamer)); errs()\u0026lt;\u0026lt;\u0026#34;Lele: asm printer pass added\\n\u0026#34;; if (!Printer) return true; PM.add(Printer); return false; } // The call path for this function is:  clang::EmitBackendOutput() -\u0026gt; EmitAssemblyHelper::EmitAssembly() -\u0026gt; EmitAssemblyHelper::AddEmitPasses() -\u0026gt; LLVMTargetMachine::addPassesToEmitFile() -\u0026gt; LLVMTargetMachine::addAsmPrinter()    runOnMachineFunction is implemented in both child class, the target-specific AsmPrinter (e.g. MipsAsmPrinter), as well as the parent class, target independent AsmPrinter.\nThe Mips printer will call its parent for target independent prints (SetupMachineFunction(), EmitFunctionBody(), etc.).\nThe Mips specific pass:\n  tracking `MipsAsmPrinter::runOnMachineFunction()`   // llvm/lib/Target/Mips/MipsAsmPrinter.cpp  bool MipsAsmPrinter::runOnMachineFunction(MachineFunction \u0026amp;MF) { Subtarget = \u0026amp;MF.getSubtarget\u0026lt;MipsSubtarget\u0026gt;(); MipsFI = MF.getInfo\u0026lt;MipsFunctionInfo\u0026gt;(); if (Subtarget-\u0026gt;inMips16Mode()) for (std::map\u0026lt; const char *, const Mips16HardFloatInfo::FuncSignature *\u0026gt;::const_iterator it = MipsFI-\u0026gt;StubsNeeded.begin(); it != MipsFI-\u0026gt;StubsNeeded.end(); ++it) { const char *Symbol = it-\u0026gt;first; const Mips16HardFloatInfo::FuncSignature *Signature = it-\u0026gt;second; if (StubsNeeded.find(Symbol) == StubsNeeded.end()) StubsNeeded[Symbol] = Signature; } MCP = MF.getConstantPool(); // In NaCl, all indirect jump targets must be aligned to bundle size.  if (Subtarget-\u0026gt;isTargetNaCl()) NaClAlignIndirectJumpTargets(MF); AsmPrinter::runOnMachineFunction(MF); emitXRayTable(); return true; }    The parent\u0026rsquo;s pass entry (for target independent emission):\n// llvm/include/llvm/CodeGen/AsmPrinter.h  /// Emit the specified function out to the OutStreamer.  bool runOnMachineFunction(MachineFunction \u0026amp;MF) override { SetupMachineFunction(MF); EmitFunctionBody(); return false; }  SetupMachineFunction(MF) (Target independent).\n Set the current function symbol, begin, exception symbol, etc. If has EmitStackSizeSection option, create and set func begin symbol: CurrentFnBegin = createTempSymbol(\u0026quot;func_begin\u0026quot;). Get result from another pass: MachineOptimizationRemarkEmitterPass.   code AsmPrinter::SetupMachineFunction()   // llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp void AsmPrinter::SetupMachineFunction(MachineFunction \u0026amp;MF) { this-\u0026gt;MF = \u0026amp;MF; // Get the function symbol.  CurrentFnSym = getSymbol(\u0026amp;MF.getFunction()); CurrentFnSymForSize = CurrentFnSym; CurrentFnBegin = nullptr; CurExceptionSym = nullptr; bool NeedsLocalForSize = MAI-\u0026gt;needsLocalForSize(); if (needFuncLabelsForEHOrDebugInfo(MF, MMI) || NeedsLocalForSize || MF.getTarget().Options.EmitStackSizeSection) { CurrentFnBegin = createTempSymbol(\u0026#34;func_begin\u0026#34;); if (NeedsLocalForSize) CurrentFnSymForSize = CurrentFnBegin; } ORE = \u0026amp;getAnalysis\u0026lt;MachineOptimizationRemarkEmitterPass\u0026gt;().getORE(); }     EmitFunctionBody(), this emits the body and trailer for a function.\nSteps:\n EmitFunctionHeader(); EmitFunctionBodyStart(); -\u0026gt; virtual -\u0026gt; MipsAsmPrinter::EmitFunctionBodyStart() Core Part: Scan every Basic Block, MBB:  EmitBasicBlockStart(MBB) For Every Instruction, MI:  check and emit labels/comments/debuglocs if applicable Check Mi.getOpcode() and handle different opcodes: CFI_INSTRUCTION: emitCFIInstruction(MI); LOCAL_ESCAPE: emitFrameAlloc(MI); ANNOTATION_LABEL, EH_LABEL, GC_LABEL: OutStreamer-\u0026gt;EmitLabel(MI.getOperand(0).getMCSymbol()); INLINEASM, INLINEASM_BR: EmitInlineAsm(\u0026amp;MI); \u0026hellip; default case: EmitInstruction(\u0026amp;MI); if exists post-instructino symbol: OutStreamer-\u0026gt;EmitLable(S)  EmitBasicBlockEnd(MBB)  if has .subsections_via_symbols, emit a noop to avoid labels collapsing together. get IR function F, and scan every BB, if BB.hasAddressTaken(), do the following:  GetBlockAddressSymbol(\u0026amp;BB) If symbol not defined, emit it. // block address removed by CodeGen??? OutStreamer-\u0026gt;AddComment(\u0026quot;Address of block that was removed by CodeGen\u0026quot;); OutStreamer-\u0026gt;EmitLabel(Sym)  EmitFunctionBodyEnd() If target wants a .size directive for the size of function, emit it  OutStreamer-\u0026gt;emitELFSize(CurrentFnSym, SizeExp)  EmitJumpTableInfo() EmitStackSizeSection(*MF) OutStreamer-\u0026gt;AddBlankLine()    simplified code `AsmPrinter::EmitFunctionBody()`   // llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp  /// EmitFunctionBody - This method emits the body and trailer for a /// function. void AsmPrinter::EmitFunctionBody() { EmitFunctionHeader(); EmitFunctionBodyStart(); ... // Print out code for the function.  bool HasAnyRealCode = false; int NumInstsInFunction = 0; for (auto \u0026amp;MBB : *MF) { // Print a label for the basic block.  EmitBasicBlockStart(MBB); for (auto \u0026amp;MI : MBB) { // Print the assembly for the instruction.  // If there is a pre-instruction symbol, emit a label for it here.  if (MCSymbol *S = MI.getPreInstrSymbol()) OutStreamer-\u0026gt;EmitLabel(S); ... switch (MI.getOpcode()) { ... case TargetOpcode::INLINEASM: case TargetOpcode::INLINEASM_BR: EmitInlineAsm(\u0026amp;MI); break; ... default: EmitInstruction(\u0026amp;MI); break; } ... } EmitBasicBlockEnd(MBB); } // Emit target-specific gunk after the function body.  EmitFunctionBodyEnd(); // Print out jump tables referenced by the function.  EmitJumpTableInfo(); // Emit section containing stack size metadata.  emitStackSizeSection(*MF); ... }    AsmPrinter::EmitInstruction() There is no target independent instruction emission in AsmPrinter::EmitInstruction(), which is a virtual method requires all derived class (such as MipsAsmPrinter), to override this function.\nHere we show the target dependent implemetations to emit instructions in MipsAsmPrinter::EmitInstruction(); We will see many target-independent routines from the MCStreamer derived classes are called to emit the instruction (e.g. emit a MCInst).\nBefore Instruction Emission Instruction Emission see code in llvm/lib/Target/Mips/MipsAsmPrinter.cpp\nMipsAsmPrinter::EmitInstruction(), called by its parent class AsmPrinter::EmitFunctionBody()\nSteps:\nMipsAsmPrinter::EmitInstruction() acts as a driver to emit an instruction. It will finally calls the MCObjectStreamer to write object (e.g. .o) files or MCAsmStreamer to write assembly (e.g .s) files.\n  tracking `MipsAsmPrinter::EmitInstruction()`   // llvm/lib/Target/Mips/MipsAsmPrinter.cpp void MipsAsmPrinter::EmitInstruction(const MachineInstr *MI) { MipsTargetStreamer \u0026amp;TS = getTargetStreamer(); unsigned Opc = MI-\u0026gt;getOpcode(); TS.forbidModuleDirective(); ... MachineBasicBlock::const_instr_iterator I = MI-\u0026gt;getIterator(); MachineBasicBlock::const_instr_iterator E = MI-\u0026gt;getParent()-\u0026gt;instr_end(); do { ... MCInst TmpInst0; MCInstLowering.Lower(\u0026amp;*I, TmpInst0); EmitToStreamer(*OutStreamer, TmpInst0); } while ((++I != E) \u0026amp;\u0026amp; I-\u0026gt;isInsideBundle()); // Delay slot check }    Other Instructino emission:\n MipsAsmPrinter::EmitJal MipsAsmPrinter::EmitInstrReg MipsAsmPrinter::EmitInstrRegReg \u0026hellip;  All above functions finally call OutStreamer-\u0026gt;EmitInstruction(MCInst I, MCSubtargetInfo STI) OutStreamer is of type std::unique_ptr\u0026lt;MCStreamer\u0026gt; OutStreamer, which has basically two implementations: MCObjectStreamer for object file, and MCAsmStreamer for assembly file.\nBut both the implementations (in child class) will call the following (parent) method: MCStreamer::EmitInstruction()\n  A class hierachy for the streamers   // Inheritance relations  MCStreamer (contain an instance of `MCTargetStreamer` as member `TargetStreamer`) -\u0026gt; MCAsmStreamer (final) -\u0026gt; MCObjectStreamer -\u0026gt; MCELFStreamer -\u0026gt; MipsELFStreamer -\u0026gt; MCWasmStreamer // MCTargetStreamer for directives.  // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h  -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.h  -\u0026gt; MipsTargetAsmStreamer -\u0026gt; MipsTargetELFStreamer -\u0026gt; RISCVTargetStreamer // lib/Target/RISCV/MCTargetDesc/RISCVTargetStreamer.h    Actual emission will be done by the actual target implementation.\nSee MCStreamers for more details.\nTracking TextSection Question: Find out where is the TextSection being filled with instructions.\nTracking places where current section is switched to the TextSection:\n in the end of MipsASMPrinter::EmitStartOfAsmFile(Module \u0026amp;M)  EmitStartOfAsmFile() is called in parent class AsmPrinter::doInitialization(Module \u0026amp;M)  in the end of MipsAsmPrinter::EmitEndOfAsmFile(Module \u0026amp;M)  EmitEndOfAsmFile() is called in parent class AsmPrinter::doFinalization(Module \u0026amp;M)   ==\u0026gt; most of time, the text section is the current section; where another section is needed, use PushSection() -\u0026gt; SwitchSection -\u0026gt; do-your-emission -\u0026gt; PopSection(). Examples can be found below in Tracking StackSizeSection.\nTracking the pass where instruction is emitted, see above AsmPrinter::EmitInstruction(), and the instruction emission in MCStreamer\nAsmPrinter::emitGlobalVariable void AsmPrinter::emitGlobalVariable(const GlobalVariable *GV)\nAsmPrinter::doFinalization(Module \u0026amp;M) =\u0026gt; AsmPrinter::emitGlobalVariable(const GlobalVariable *GV) =\u0026gt; MCSymbol *GVSym = getSymbol(GV); MCSymbol *EmittedSym = GVSym; =\u0026gt; emitVisibility(EmittedSym, GV-\u0026gt;getVisitbility(), !GV-\u0026gt;isDeclaration()); =\u0026gt; OutStreamer-\u0026gt;emitSymbolAttribute(Sym, Attr); =\u0026gt; if (GVKind.isCommon()) OutStreamer-\u0026gt;emitCommonSymbol(GVSym, Size,...); // Determine to which section this global should be emitted.  =\u0026gt; MCSection *TheSection = getObjFileLowering().SectionForGlobal(GV, GVKind, TM); =\u0026gt; MCSymbol *EmittedInitSym = GVSym; =\u0026gt; OutStreamer-\u0026gt;SwitchSection(TheSection); =\u0026gt; emitLinkage(GV, EmittedInitSym); =\u0026gt; emitAlignment(Alignment, GV); =\u0026gt; OutStreamer-\u0026gt;emitLabel(EmittedInitSym); =\u0026gt; emitGlobalConstant(GV-\u0026gt;getParent()-\u0026gt;getDataLayout(), GV-\u0026gt;getInitializer(), static_cast\u0026lt;uint64_t\u0026gt;(TailPadding)); =\u0026gt; if (Size) emitGlobalConstantImpl(DL, CV, *this); =\u0026gt; if 1/2/4/8 OutStreamer-\u0026gt;emitIntValue(CI-\u0026gt;getZExtValue(), Size); =\u0026gt; if larger: emitGlobalConstantLargeInt(...) ==\u0026gt; OutStreamer-\u0026gt;emitIntValue(Val, 8) ==\u0026gt; OutStreamer-\u0026gt;emitIntValue(ExtraBits, Size) =\u0026gt; OutStreamer-\u0026gt;AddBlankLine() =\u0026gt; AsmPrinter::emitGlobalGOTEquivs() =\u0026gt; AsmPrinter::emitGlobalVariable(..);  Tracking DataSection Question: find out where is the DataSection being filled with data values.\nSee subpage Global Print\nTracking StackSizeSection AsmPrinter::EmitStackSizeSection(), got called in AsmPrinter::EmitFunctionBody() (as above).\nSteps:\n Check command line option, if no option, return:  if (!MF.getTarget().Options.EmitStackSizeSection) return;  Get StackSizeSection (instance of MCSection) from TargetLoweringObjectFile  MCSection *StackSizeSection = getObjFileLowering().getStackSizesSection(*getCurrentSection());  Switch current section to StackSizeSection.  OutStreamer-\u0026gt;PushSection(); OutStreamer-\u0026gt;SwitchSection(StackSizeSection);  Get StackSize from MachineFrameInfo of current MachineFunction  uint64_t StackSize = FrameInfo.getStackSize();  Emit the function symbol, along with StackSize  OutStreamer-\u0026gt;EmitSymbolValue(FunctionSymbol, TM.getProgramPointerSize()); OutStreamer-\u0026gt;EmitULEB128IntValue(StackSize);  Switch section back. OutStreamer-\u0026gt;PopSection();\n// llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp void AsmPrinter::emitStackSizeSection(const MachineFunction \u0026amp;MF) { if (!MF.getTarget().Options.EmitStackSizeSection) return; MCSection *StackSizeSection = getObjFileLowering().getStackSizesSection(*getCurrentSection()); if (!StackSizeSection) return; const MachineFrameInfo \u0026amp;FrameInfo = MF.getFrameInfo(); // Don\u0026#39;t emit functions with dynamic stack allocations. if (FrameInfo.hasVarSizedObjects()) return; OutStreamer-\u0026gt;PushSection(); OutStreamer-\u0026gt;SwitchSection(StackSizeSection); const MCSymbol *FunctionSymbol = getFunctionBegin(); uint64_t StackSize = FrameInfo.getStackSize(); OutStreamer-\u0026gt;EmitSymbolValue(FunctionSymbol, TM.getProgramPointerSize()); OutStreamer-\u0026gt;EmitULEB128IntValue(StackSize); OutStreamer-\u0026gt;PopSection(); }   Caller path: AsmPrinter::EmitFunctionBody() -\u0026gt; AsmPrinter::emitStackSizeSection\n Emit Globals in AsmPrinter  Reference llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp The call path of emitting a global variable: AsmPrinter::doFinalization(Module \u0026amp;) =\u0026gt; emitGlobalVariable(\u0026amp;G); // for (const auto \u0026amp;G : M.globals()) =\u0026gt; emitGlobalGOTEquivs() =\u0026gt; emitGlobalVariable(GV) // for (auto *GV: FailedCandidates) Function interfaces for global emission in AsmPrinter: // llvm/include/llvm/CodeGen/AsmPrinter.h /// This class is intended to be used as a driving class for all asm writers. classAsmPrinter : public MachineFunctionPass { ... /// Emit the specified global variable to the .\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/mc-assembler/",
	"title": "Mc Assembler",
	"tags": [],
	"description": "",
	"content": "Reference reference\n// lib/MC/MCAssembler.cpp  bool MCAssembler::registerSection(MCSection \u0026amp;Section) { if (Section.isRegistered()) return false; Sections.push_back(\u0026amp;Section); Section.setIsRegistered(true); return true; } // include/llvm/MC/MCAssembler.h  /// \\name Section List Access  /// @{  iterator begin() { return Sections.begin(); } const_iterator begin() const { return Sections.begin(); } iterator end() { return Sections.end(); } const_iterator end() const { return Sections.end(); } size_t size() const { return Sections.size(); }   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/mc-context/",
	"title": "MCContext",
	"tags": [],
	"description": "",
	"content": "Reference include/llvm/MC/MCContext.h lib/MC/MCContext.cpp\nContext object for machine code objects. This class owns all the sections that it creates.\n MCSectionELF *MCContext::getELFSection()\n Search ELFUniquingMap return if hit create new section using createELFSectionImp() if miss.  MCSectionELF *MCContext::createELFSectionImpl()\n get existing or create a new MCSymbolELF *R set binding ELF::STB_LOCAL set type ELF::STT_SECTION create a new MCSectionELF *Ret create new MCDataFragment() *F insert F to Ret-\u0026gt;getFragmentList() F-\u0026gt;setParent(Ret) R-\u0026gt;setFragment(F) return R, the MCSectionELF    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/text/",
	"title": "Text",
	"tags": [],
	"description": "",
	"content": "Reference reference\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/dwarf/",
	"title": "Dwarf Debugging Information",
	"tags": [],
	"description": "",
	"content": " References:\n DWARF Debugging Information Format\n .debug_frame section.  DWARF in LLVM\n How debuggers work: Part 3 - Debugging information\n  Machine code -\u0026gt; source code file, function name, and line numbers\nDWARF sections .debug sections, and all the sections begin with .debug:\n .debug_info .debug_loc .debug_frame \u0026hellip;  DWARF Format DWARF: Debugging Information Entry(DIE). Each DIE has a tag \u0026ndash; its type, and a set of attributes. DIEs are interlinked via sibling and child links, and value of attributes can point at other DIEs.\n.debug_info section. objdump --dwarf=info \u0026lt;binary-file\u0026gt;\nDWARF for Functions:\n Entry tag DW_TAG_subprogram stores the debug info is for a certain function. Attribute DW_AT_low_pc is the program counter (EIP in x86) value for the beginning of the function. Attribute DW_AT_frame_base stores the frame base address for the function.  it can be 0x0 (location list), meaning the frame address is stored in the location list section .debug_loc Entry in .debug_loc, such as `   DWARF for Variables:\n Entry tag DW_TAG_variable, stores the debug info for a variable Attribute DW_AT_type points to another Entry tag, which stores the type information Attribute DW_AT_location stores information how to find the variable in memory. For example, DW_OP_fbreg: -20 means the variable is stored at offset -20 from the DW_AT_frame_base attribute of its containing function.   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/object-file/",
	"title": "Object File",
	"tags": [],
	"description": "",
	"content": " Reference LLVM Source code\nParent -\u0026gt; Child: MCObjectFileInfo -\u0026gt; TargetLoweringObjectFile -\u0026gt; TargetLoweringObjectFileELF -\u0026gt; MipsTargetObjectFile\nMCObjectFileInfo SourceCode of class MCObjectFileInfo\n llvm/MC/MCObjectFileInfo.h llvm/lib/MC/MCObjectFileInfo.cpp  States:\n MCSection *TextSection, *DataSection, *BSSSection MCSection *ReadOnlySection. Not required. MCSection *LSDASection. Section of Language Specific Data Area (LSDA). To support languages with exception handling. DWARF sections  DwarfLineSection DwarfLineStrSection DwarfStrSection \u0026hellip;   Sections Initialization Initialized in function MCObjectFileInfo::initELFMCObjectFileInfo(const Triple \u0026amp;T, bool Large).   code   // lib/MC/MCObjectFileInfo.cpp  void MCObjectFileInfo::initELFMCObjectFileInfo(const Triple \u0026amp;T, bool Large) { switch (T.getArch()) { case Triple::mips: case Triple::mipsel: case Triple::mips64: case Triple::mips64el: case Triple::cheri: FDECFIEncoding = Ctx-\u0026gt;getAsmInfo()-\u0026gt;getCodePointerSize() == 4 ? dwarf::DW_EH_PE_sdata4 : dwarf::DW_EH_PE_sdata8; break; case Triple::ppc64: case Triple::ppc64le: case Triple::x86_64: FDECFIEncoding = dwarf::DW_EH_PE_pcrel | (Large ? dwarf::DW_EH_PE_sdata8 : dwarf::DW_EH_PE_sdata4); break; case Triple::bpfel: case Triple::bpfeb: FDECFIEncoding = dwarf::DW_EH_PE_sdata8; break; case Triple::hexagon: FDECFIEncoding = PositionIndependent ? dwarf::DW_EH_PE_pcrel : dwarf::DW_EH_PE_absptr; break; default: FDECFIEncoding = dwarf::DW_EH_PE_pcrel | dwarf::DW_EH_PE_sdata4; break; } unsigned EHSectionType = T.getArch() == Triple::x86_64 ? ELF::SHT_X86_64_UNWIND : ELF::SHT_PROGBITS; // Solaris requires different flags for .eh_frame to seemingly every other  // platform.  unsigned EHSectionFlags = ELF::SHF_ALLOC; if (T.isOSSolaris() \u0026amp;\u0026amp; T.getArch() != Triple::x86_64) EHSectionFlags |= ELF::SHF_WRITE; // This is (currently) also true for MIPS  // TODO: add a T.isMIPS()?  switch (T.getArch()) { case Triple::mips: case Triple::mipsel: case Triple::mips64: case Triple::mips64el: case Triple::cheri: if (PositionIndependent) { EHSectionFlags |= ELF::SHF_WRITE; } break; default: break; } // ELF  BSSSection = Ctx-\u0026gt;getELFSection(\u0026#34;.bss\u0026#34;, ELF::SHT_NOBITS, ELF::SHF_WRITE | ELF::SHF_ALLOC); TextSection = Ctx-\u0026gt;getELFSection(\u0026#34;.text\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_EXECINSTR | ELF::SHF_ALLOC); DataSection = Ctx-\u0026gt;getELFSection(\u0026#34;.data\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_WRITE | ELF::SHF_ALLOC); ReadOnlySection = Ctx-\u0026gt;getELFSection(\u0026#34;.rodata\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC); TLSDataSection = Ctx-\u0026gt;getELFSection(\u0026#34;.tdata\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC | ELF::SHF_TLS | ELF::SHF_WRITE); TLSBSSSection = Ctx-\u0026gt;getELFSection( \u0026#34;.tbss\u0026#34;, ELF::SHT_NOBITS, ELF::SHF_ALLOC | ELF::SHF_TLS | ELF::SHF_WRITE); DataRelROSection = Ctx-\u0026gt;getELFSection(\u0026#34;.data.rel.ro\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC | ELF::SHF_WRITE); MergeableConst4Section = Ctx-\u0026gt;getELFSection(\u0026#34;.rodata.cst4\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC | ELF::SHF_MERGE, 4, \u0026#34;\u0026#34;); MergeableConst8Section = Ctx-\u0026gt;getELFSection(\u0026#34;.rodata.cst8\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC | ELF::SHF_MERGE, 8, \u0026#34;\u0026#34;); MergeableConst16Section = Ctx-\u0026gt;getELFSection(\u0026#34;.rodata.cst16\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC | ELF::SHF_MERGE, 16, \u0026#34;\u0026#34;); MergeableConst32Section = Ctx-\u0026gt;getELFSection(\u0026#34;.rodata.cst32\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC | ELF::SHF_MERGE, 32, \u0026#34;\u0026#34;); // Exception Handling Sections.  // FIXME: We\u0026#39;re emitting LSDA info into a readonly section on ELF, even though  // it contains relocatable pointers. In PIC mode, this is probably a big  // runtime hit for C++ apps. Either the contents of the LSDA need to be  // adjusted or this should be a data section.  LSDASection = Ctx-\u0026gt;getELFSection(\u0026#34;.gcc_except_table\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC); COFFDebugSymbolsSection = nullptr; COFFDebugTypesSection = nullptr; unsigned DebugSecType = ELF::SHT_PROGBITS; // MIPS .debug_* sections should have SHT_MIPS_DWARF section type  // to distinguish among sections contain DWARF and ECOFF debug formats.  // Sections with ECOFF debug format are obsoleted and marked by SHT_PROGBITS.  if (T.isMIPS()) DebugSecType = ELF::SHT_MIPS_DWARF; // Debug Info Sections.  DwarfAbbrevSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_abbrev\u0026#34;, DebugSecType, 0); DwarfInfoSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_info\u0026#34;, DebugSecType, 0); DwarfLineSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_line\u0026#34;, DebugSecType, 0); DwarfLineStrSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_line_str\u0026#34;, DebugSecType, ELF::SHF_MERGE | ELF::SHF_STRINGS, 1, \u0026#34;\u0026#34;); DwarfFrameSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_frame\u0026#34;, DebugSecType, 0); DwarfPubNamesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_pubnames\u0026#34;, DebugSecType, 0); DwarfPubTypesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_pubtypes\u0026#34;, DebugSecType, 0); DwarfGnuPubNamesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_gnu_pubnames\u0026#34;, DebugSecType, 0); DwarfGnuPubTypesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_gnu_pubtypes\u0026#34;, DebugSecType, 0); DwarfStrSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_str\u0026#34;, DebugSecType, ELF::SHF_MERGE | ELF::SHF_STRINGS, 1, \u0026#34;\u0026#34;); DwarfLocSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_loc\u0026#34;, DebugSecType, 0); DwarfARangesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_aranges\u0026#34;, DebugSecType, 0); DwarfRangesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_ranges\u0026#34;, DebugSecType, 0); DwarfMacinfoSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_macinfo\u0026#34;, DebugSecType, 0); // DWARF5 Experimental Debug Info  // Accelerator Tables  DwarfDebugNamesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_names\u0026#34;, ELF::SHT_PROGBITS, 0); DwarfAccelNamesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.apple_names\u0026#34;, ELF::SHT_PROGBITS, 0); DwarfAccelObjCSection = Ctx-\u0026gt;getELFSection(\u0026#34;.apple_objc\u0026#34;, ELF::SHT_PROGBITS, 0); DwarfAccelNamespaceSection = Ctx-\u0026gt;getELFSection(\u0026#34;.apple_namespaces\u0026#34;, ELF::SHT_PROGBITS, 0); DwarfAccelTypesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.apple_types\u0026#34;, ELF::SHT_PROGBITS, 0); // String Offset and Address Sections  DwarfStrOffSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_str_offsets\u0026#34;, DebugSecType, 0); DwarfAddrSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_addr\u0026#34;, DebugSecType, 0); DwarfRnglistsSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_rnglists\u0026#34;, DebugSecType, 0); DwarfLoclistsSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_loclists\u0026#34;, DebugSecType, 0); // Fission Sections  DwarfInfoDWOSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_info.dwo\u0026#34;, DebugSecType, ELF::SHF_EXCLUDE); DwarfTypesDWOSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_types.dwo\u0026#34;, DebugSecType, ELF::SHF_EXCLUDE); DwarfAbbrevDWOSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_abbrev.dwo\u0026#34;, DebugSecType, ELF::SHF_EXCLUDE); DwarfStrDWOSection = Ctx-\u0026gt;getELFSection( \u0026#34;.debug_str.dwo\u0026#34;, DebugSecType, ELF::SHF_MERGE | ELF::SHF_STRINGS | ELF::SHF_EXCLUDE, 1, \u0026#34;\u0026#34;); DwarfLineDWOSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_line.dwo\u0026#34;, DebugSecType, ELF::SHF_EXCLUDE); DwarfLocDWOSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_loc.dwo\u0026#34;, DebugSecType, ELF::SHF_EXCLUDE); DwarfStrOffDWOSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_str_offsets.dwo\u0026#34;, DebugSecType, ELF::SHF_EXCLUDE); DwarfRnglistsDWOSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_rnglists.dwo\u0026#34;, DebugSecType, ELF::SHF_EXCLUDE); // DWP Sections  DwarfCUIndexSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_cu_index\u0026#34;, DebugSecType, 0); DwarfTUIndexSection = Ctx-\u0026gt;getELFSection(\u0026#34;.debug_tu_index\u0026#34;, DebugSecType, 0); StackMapSection = Ctx-\u0026gt;getELFSection(\u0026#34;.llvm_stackmaps\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC); FaultMapSection = Ctx-\u0026gt;getELFSection(\u0026#34;.llvm_faultmaps\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_ALLOC); EHFrameSection = Ctx-\u0026gt;getELFSection(\u0026#34;.eh_frame\u0026#34;, EHSectionType, EHSectionFlags); StackSizesSection = Ctx-\u0026gt;getELFSection(\u0026#34;.stack_sizes\u0026#34;, ELF::SHT_PROGBITS, 0); RemarksSection = Ctx-\u0026gt;getELFSection(\u0026#34;.remarks\u0026#34;, ELF::SHT_PROGBITS, ELF::SHF_EXCLUDE); }   \nDataSection getDataSection() const { return DataSection; } getTLSExtraDataSection() const { return TLSExtraDataSection; } getTLSDataSection() const { return TLSDataSection; } getConstDataSection() const { return ConstDataSection; }\nCalled in:\n MipsTargetStreamer.cpp: MipsTargetELFStreamer::finish()  from code: .bss, .text, .data are always at least 16-byte aligned.   TextSection TargetLoweringObjectFileELF This class handles lowerings for common ELF object file formats\nSource code:\n llvm/include/llvm/CodeGen/TargetLoweringObjectFileImpl.h llvm/lib/CodeGen/TargetLoweringObjectFileImpl.cpp  SelectSectionForGlobal It will return a section for the input global address.\nMCSection *TargetLoweringObjectFileELF::SelectSectionForGlobal\nIt will use getDataSections() to check whether different variables should use separate sections.\nTargetMachine.h: the -fdata-sections and -ffunction-sections option: put every variable or function into different section:\n//llvm/include/llvm/Target/TargetMachine.h  /// Return true if data objects should be emitted into their own section,  /// corresponds to -fdata-sections.  bool getDataSections() const { return Options.DataSections; } /// Return true if functions should be emitted into their own section,  /// corresponding to -ffunction-sections.  bool getFunctionSections() const { return Options.FunctionSections; }  MipsTargetObjectFile Source: llvm/lib/Target/Mips/MipsTargetObjectFile.h/cpp\nParent class: TargetLoweringObjectFileELF\nRules found in the source About Small Data/BSS Sections:\n Here only define target specific operations. For most target independent object file generation, use functions in parent class TargetLoweringObjectFileELF An address must be loaded from a small section if its size is less than the small section size threshold. Data in the small section must be addressed using gp_rel operator. Data can be  Global variables (SelectSectionForGlobal()) Constant data (SelectSectionForConstant())  To determine a section for global, will treat global declaration and definition differently. Because some place requires a global definitions instead of global declaration. See MipsTargetObjectFile::IsGlobalInSmallSection() If IsGlobalInSmallSectionImpl() and global Kind.isData() || Kind.isBSS() || Kind.isCommon() || Kind.isReadOnly(), then the global should be placed into small data/bss section. Do not put global variable into small sections, in the following cases:  If -mlocal-sdata is given, and global variable -\u0026gt;hasLocalLinkage() If -extern-sdata is given, and global variable (GVA-\u0026gt;hasExternalLinkage() \u0026amp;\u0026amp; GVA-\u0026gt;isDeclaration() ) || GVA-\u0026gt; hasCommonLinkage() If -membedded-data is given, and global variable GVA-\u0026gt;isConstant().   Initialize (No constructor method.)\nMipsTargetObjectFile::Initialize(MCContext \u0026amp;Ctx, const TargetMachine \u0026amp;TM)\n Input:  MCContext \u0026amp;Ctx const TargetMachine \u0026amp;TM  Output (elements being initialized)  SmallDataSection: .sdata in ELF. Init via getContext().getELFSection() SmallBSSSection: .sbss in ELF. Init via getContext().getELFSection() this-\u0026gt;TM = \u0026amp;static_cast\u0026lt;const MipsTargetMachine \u0026amp;\u0026gt; (TM)   LLVM Basics learned in Code  To distinguish a global variable from functions in a GlobalObject\nconst GlobalObject GO; // passed in as parameter. const GlobalVariable *GVA = dyn_cast\u0026lt;GlobalVariable\u0026gt;(GO); if (!GVA) return false; // source: llvm/lib/Target/Mips/MipsTargetObjectFile.cpp: `IsGlobalInSmallSectionImpl()`  To reconginze the subtarget of the Mips Arch: use getSubtargetImpl() from TargetMacine class.\nTailPaddingAmount MipsTargetObjectFile::getTailPaddingForPreciseBounds(uint64_t Size) const { const MipsSubtarget \u0026amp;Subtarget = *static_cast\u0026lt;const MipsTargetMachine \u0026amp;\u0026gt;(*TM).getSubtargetImpl(); if (!Subtarget.isCheri()) return TailPaddingAmount::None; if (Subtarget.isCheri128()) { return static_cast\u0026lt;TailPaddingAmount\u0026gt;( llvm::alignTo(Size, cc128_get_required_alignment(Size)) - Size); } assert(Subtarget.isCheri256()); // No padding required for CHERI256 return TailPaddingAmount::None; } // source: llvm/lib/Target/Mips/MipsTargetObjectFile.cpp    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/stack-frame/",
	"title": "Stack Frame",
	"tags": [],
	"description": "",
	"content": " References:\n Target Code Generation  Class of variables:\n Temporary variables: Local variables: Global variables:  Stack Frame Layout Frame pointer (FP): ptr to beginning of stack frame (fixed)\nStack pointer (SP): ptr to end of stack (can move).\nStack frame hold space for:\n formals local variables return addresses (maybe) dynamic link (ptr to calling stack frame) (maybe) static link (ptr to lexically-enclosing stack frame) other run-time data (e.g. caller-saved registers)  Key property: all data in stack frames is at fixed, statically computed offset from FP.\nGood about this property:\n easy to generate fast code to access data in stack frame, even lexically enclosing stack frames. compute all offsets solely from symbol tables.   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/mc-streamer/",
	"title": "MCStreamer",
	"tags": [],
	"description": "",
	"content": " References:\n LLVM MCStreamer Class Reference llvm/include/llvm/MCStreamer.h llvm/lib/MC/MCStreamer.cpp  MCStreamer class is an abstract API that is implemented in different ways (e.g. to output a .s file, output an ELF .o file, etc). It is effectively an “assembler API”. MCStreamer has one method per directive, such as EmitLabel, EmitSymbolAttribute, SwitchSection, etc, which directly correspond to assembly level directives.\nTwo implementations of MCStreamer:\n MCAsmStreamer is a straightforward impl that prints out a directive for each method. (e.g EmitValue -\u0026gt; .byte) MCObjectStreamer implements a full assembler.  For Target specific directives, the MCStreamer has a MCTargetStreamer instance.\n// Inheritance relations  MCStreamer (contain an instance of `MCTargetStreamer` as member `TargetStreamer`) -\u0026gt; MCAsmStreamer (final) -\u0026gt; MCObjectStreamer -\u0026gt; MCELFStreamer -\u0026gt; MipsELFStreamer -\u0026gt; MCWasmStreamer // MCTargetStreamer for directives.  // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h  -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.h  -\u0026gt; MipsTargetAsmStreamer // lib/Target/Mips/MipsTargetStreamer.h  -\u0026gt; MipsTargetELFStreamer // lib/Target/Mips/MipsTargetStreamer.h  -\u0026gt; RISCVTargetStreamer // lib/Target/RISCV/MCTargetDesc/RISCVTargetStreamer.h  MCStreamer MCStreamer emit related functions. A series of EmitXXX functions\n Emit() EmitIntValue() EmitLabel()  MCStreamer::EmitBytes() MCStreamer::EmitBytes() overridden by child class void MCObjectStreamer::EmitBytes(StringRef Data):\n// llvm/lib/MC/MCStreamer.cpp void MCStreamer::EmitBytes(StringRef Data) {} // a virtual method  // llvm/lib/MC/MCObjectStreamer.cpp void MCObjectStreamer::EmitBytes(StringRef Data) { // override the parent method  MCDwarfLineEntry::Make(this, getCurrentSectionOnly()); MCDataFragment *DF = getOrCreateDataFragment(); flushPendingLabels(DF, DF-\u0026gt;getContents().size()); DF-\u0026gt;getContents().append(Data.begin(), Data.end()); // EmitBytes might not cover all possible ways we emit data (or could be used  // to emit executable code in some cases), but is the best method we have  // right now for checking this.  MCSection *Sec = getCurrentSectionOnly(); Sec-\u0026gt;setHasData(true); }  Steps:\n MCDwarfLineEntry::Make(): if has dwarf, update dwarf section:  EmitLabel in MCObjectStreamer.EmitLabel(LineSym) Update the section entries: MCOS-\u0026gt;getContext().getMCDwarfLineTable(MCOS-\u0026gt;getContext().getDwarfCompileUnitID()).getMCLineSections().addLineEntry(LineEntry, Section);  Create a data fragment Append the bytes data to the data fragment DF-\u0026gt;getContents().append(data.begin, .end) Update section flagging hasData: Sec-\u0026gt;setHasData(true)  Method to update a line in dwarf section: MCOS-\u0026gt;getContext().getMCDwarfLineTable(MCOS-\u0026gt;getContext().getDwarfCompileUnitID())....\nMethod to update a data section: DF-\u0026gt;getContents().append(data.begin, .end)\nMCStreamer::EmitInstruction() Most of the EmitInstruction() implementation should be done by derived classes.\nAs a method in MCStreamer, the parent class, it only handle one kind of instruction operand: Relocatable immediate operand. Call visitUsedExpr(MCExpr). And this is supposed to be called by the same overloaded method in the child class.\nMCStreamer::EmitInstruction() finally calls visitUsedExpr to recognize different operand expressions, but did not emit the instruction (opcode + operands) into binary stream.\n  Tracking `MCStreamer::EmitInstruction()`   // llvm/lib/MC/MCStreamer.cpp void MCStreamer::EmitInstruction(const MCInst \u0026amp;Inst, const MCSubtargetInfo \u0026amp;) { // Scan for values.  for (unsigned i = Inst.getNumOperands(); i--;) if (Inst.getOperand(i).isExpr()) visitUsedExpr(*Inst.getOperand(i).getExpr()); } void MCStreamer::visitUsedExpr(const MCExpr \u0026amp;Expr) { switch (Expr.getKind()) { case MCExpr::Target: // here calls `MipsMCExpr::visitUsedExpr(MCStreamer \u0026amp;)`  // but it finally calls back via Streamer.visitUsedExpr(*getSubExpr())  // `*getSubExpr()` --\u0026gt; the MCExpr used to init the MipsMCExpr instance.  cast\u0026lt;MCTargetExpr\u0026gt;(Expr).visitUsedExpr(*this); break; case MCExpr::Constant: break; case MCExpr::Binary: { const MCBinaryExpr \u0026amp;BE = cast\u0026lt;MCBinaryExpr\u0026gt;(Expr); visitUsedExpr(*BE.getLHS()); visitUsedExpr(*BE.getRHS()); break; } case MCExpr::SymbolRef: visitUsedSymbol(cast\u0026lt;MCSymbolRefExpr\u0026gt;(Expr).getSymbol()); break; case MCExpr::Unary: visitUsedExpr(*cast\u0026lt;MCUnaryExpr\u0026gt;(Expr).getSubExpr()); break; } }    MipsELFStreamer Inheritance:\nMCStreamer (contain an instance of `MCTargetStreamer` as member `TargetStreamer`) -\u0026gt; MCObjectStreamer -\u0026gt; MCELFStreamer -\u0026gt; MipsELFStreamer  Learnings from source code:  To iterate through all the sections in a MCAssember \u0026amp;MCA:\n// Make sections sizes a multiple of the alignment. This is useful for // verifying the output of IAS against the output of other assemblers but // it\u0026#39;s not necessary to produce a correct object and increases section // size. MCStreamer \u0026amp;OS = getStreamer(); for (MCSection \u0026amp;S : MCA) { MCSectionELF \u0026amp;Section = static_cast\u0026lt;MCSectionELF \u0026amp;\u0026gt;(S); unsigned Alignment = Section.getAlignment(); if (Alignment) { OS.SwitchSection(\u0026amp;Section); if (Section.UseCodeAlign()) OS.EmitCodeAlignment(Alignment, Alignment); else OS.EmitValueToAlignment(Alignment, 0, 1, Alignment); } }    Mips Elf Streamer  Reference llvm/lib/Target/Mips/MCTargetDesc/MipsELFStreamer.h llvm/lib/Target/Mips/MCTargetDesc/MipsELFStreamer.cpp // Inheritance relations MCStreamer (contain an instance of `MCTargetStreamer` as member `TargetStreamer`) -\u0026gt; MCAsmStreamer (final) -\u0026gt; MCObjectStreamer -\u0026gt; MCELFStreamer -\u0026gt; MipsELFStreamer -\u0026gt; MCWasmStreamer // MCTargetStreamer for directives. // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetAsmStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetELFStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; RISCVTargetStreamer // lib/Target/RISCV/MCTargetDesc/RISCVTargetStreamer.h MCELFStreamer::EmitInstToData() MCELFStreamer::EmitInstToData() handles how an instruction MCInst is emitted to binary file.\n MCAsmStreamer  Two implementations of MCStreamer: MCAsmStreamer is a straightforward impl that prints out a directive for each method. (e.g EmitValue -\u0026gt; .byte) MCObjectStreamer implements a full assembler. // Inheritance relations MCStreamer (contain an instance of `MCTargetStreamer` as member `TargetStreamer`) -\u0026gt; MCAsmStreamer (final) -\u0026gt; MCObjectStreamer -\u0026gt; MCELFStreamer -\u0026gt; MipsELFStreamer -\u0026gt; MCWasmStreamer // MCTargetStreamer for directives. // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.\n Mips Target Streamer  For Target specific directives, the MCStreamer has a MCTargetStreamer instance. // Inheritance relations // MCTargetStreamer for directives. // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetAsmStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; MipsTargetELFStreamer // lib/Target/Mips/MipsTargetStreamer.h -\u0026gt; RISCVTargetStreamer // lib/Target/RISCV/MCTargetDesc/RISCVTargetStreamer.h MipsTargetStreamer Source code list: lib/Target/Mips/MipsTargetStreamer.h MipsTargetStreamer class MipsTargetAsmStreamer class, for ascii asm output member: MCStreamer \u0026amp;Streamer;.\n MCObjectStreamer  Two implementations of MCStreamer: MCAsmStreamer is a straightforward impl that prints out a directive for each method. (e.g EmitValue -\u0026gt; .byte) MCObjectStreamer implements a full assembler. // Inheritance relations MCStreamer (contain an instance of `MCTargetStreamer` as member `TargetStreamer`) -\u0026gt; MCAsmStreamer (final) -\u0026gt; MCObjectStreamer -\u0026gt; MCELFStreamer -\u0026gt; MipsELFStreamer -\u0026gt; MCWasmStreamer // MCTargetStreamer for directives. // llvm/include/llvm/MCStreamer.h MCTargetStreamer (contain an instance `MCStreamer` as member `Streamer`) -\u0026gt; ARMTargetStreamer // include/llvm/MCStreamer.h -\u0026gt; MipsTargetStreamer // lib/Target/Mips/MipsTargetStreamer.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/symbol-table/",
	"title": "Symbol Table Section",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How does LLVM generate Symbol Table section in an object file?  References:\n ELF specification Computer Systems: A Programmer\u0026rsquo;s Perspective, Chapter 7.6  Symbol Table Section The section .symtab holds a symbol table. The object file use the symbol table to locate and relocate a program\u0026rsquo;s symbolic definitions and references.\nFirst entry is always undefined symbol.\nIf a file has a loadable segment that includes the symbol table, this symbol section\u0026rsquo;s attributes will include the SHF_ALLOC bit; otherwise the bit will be off.\n// one symbol table entry. typedef struct { Elf32_Word\tst_name; // an index into the symbol name stored in symbol string table section. \tElf32_Addr\tst_value; // the value of the associated symbol. may be an address, absolute value, etc. \tElf32_Word\tst_size; // symbol\u0026#39;s size, e.g. data object\u0026#39;s size; 0 if unknown, or no size. \tuint8_t\tst_info; // symbol\u0026#39;s type and binding attributes. \tuint8_t\tst_other; Elf32_Half\tst_shndx; // Every symbol is defined in relation to some section; this memober holds the relavant section header table index. } Elf32_Sym;  Symbol Table Entry \u0026ndash; Symbol Info The symbol table info st_info holds the type and binding attributes for the symbol.\n Binding determines the linkage visibility and behavior.  STB_LOCAL/0, local symbols not visible outside of objec file containing their definition. Local symbols of the same name may exist in multiple files without interfering with each other. STB_GLOBAL/1, Global symbols are visible to all object files being combined. One file\u0026rsquo;s definition of a global symbol will satisfy another file\u0026rsquo;s undefined reference to the same global symbol. STB_WEAK/2, Weak symbols resemble global symbols, but their definitions have lower precedence. ??? STB_LOPROC/13 -- STB_HIPROC/15, processor specific semantics.  Type prvoides a general classification for the associated entity.  STT_NOTYPE/0, no type is specified for the symbol. STT_OBJECT/1, a data object, such as variable, an array, and so on. STT_FUNC/2, a function or other executable code. STT_SECTION/3, a section symbol. This type of entry is primarily used for relocation and normally have STB_LOCAL binding. STT_FILE/4, a file symbol. has STB_LOCAL binding, its section index is SHB_ABS, and it precedes the other STB_LOCAL symbols for the file, if it is present. STT_LOPROC/13 -- STT_HIPROC/15, processor specific semantics.   Symbol Table Entry \u0026ndash; Symbol Value Symbol table entries for different object file types have slightly different interpretation for the symbol value st_value member.\n In relocatable files, two possiblities:  symbol value can hold alignment constraints for a symbol whose section index is SHN_COMMON. In this case, The symbol labels a common block that has not yet been allocated. The symbol\u0026rsquo;s value gives alignment constraints, similar to a section\u0026rsquo;s sh_addralign member. That is, the link editor will allocate the storage for the symbol at an address that is a multiple of st_value. The symbol\u0026rsquo;s size tells how many bytes are required. symbol value can hold a section offset for a defined symbol. That is st_value is an offset from the beginning of the section that st_shndx identifies.  In executable and shared object files, st_value holds a virtual address. The make these files\u0026rsquo; symbol more useful for the dynamic linker, the section offset (file interpretation) gives way to a virtual address (memory interpretation) for which the section number is irrelavant.  Symbols for Special Sections Each symbols is assigned to some section of the object file, denoted by the section field st_shndx, which is an index into the section header table.\nHowever, there are three special pseudosections that do not have entries in the section header table (Note these pseudosections exit only in relocatable object files; will be removed in executbale object files):\n ABS is for symbols that should not be relocated. UNDEF is for undefined symbols \u0026ndash; that is, symbols that are referenced in this object module but defined elsewhere. COMMON is for uninitialized data objects that are not yet allocated. For COMMON symbols, the st_value field gives the alignment requirement, and st_size gives the minumum size.  Distinction between COMMON and .bss section is subtle. Modern versions of GCC assign symbols in relocatable object files to COMMON and .bss using the following convention:\n COMMON: Uninitialized global variables. .bss: Uninitialized static variables, and global or static variables that are initialized to zero.  Linking \u0026ndash; Symbol Resolution References:\n Computer Systems: A Programmer\u0026rsquo;s Perspective, Chapter 7.6  The linker resolves symbol references by associating each reference with exactl yone symbol definition from the symbol tables of its input relocatable object files.\nSymbol resolution is straightforward for references to local symbols that are defined in the same module as the reference. The compiler allows only one definition of each local symbol per module. The compiler also ensures that static local variables, which get local linker symbols, have unique names.\nResolving references to global symbols, however, is tricker. When the compiler encounters a symbol (either a variable of function name) that is not defined in the current module, it assumes that it is defined in some other module, generates a linker symbol table entry, and leaves it for the linker to handle.\nResolve duplicate symbol names Reference: Computer Systems: A Programmer\u0026rsquo;s Perspective, Chapter 7.6.1\nThe input to the linker is a collection of relocatable object modules. Each of these modules defines a set of symbols, some of which are local(visible only to the module that defines it), and some of which are global (visible to other modules).\nIf multiple modules define global symbols with the same name, Linux compilation system will use the following rules (which can cause unintential bugs).\n At compile time, the compiler exports each global symbol to the assembler as either strong or weak, and the assembler encodes this information implicitly in the symbol table of the relocatable object file.  Functions and initialized global variables get strong symbols. Uninitialized global variables get weak symbols.  At linking time, Linux linkers use the following rules for dealing with duplicate symbol names:  Multiple strong symbols with the same name are not allowed. Given a strong symbol and multiple weak symbols with the same name, choose the strong symbol. Given multiple weak symbols with the same name, choose any of the weak symbols. Allow (but give warning) these symbols with the same name be defined with different types in different module. ==\u0026gt; E.g. A strong symbol defined as int in one file and another weak symbol declared as double in another file. ==\u0026gt; buggy if the double is stored while the linker resolves the symbol using address of the int. (See CS-APP book Chapter 7.6.1).  Use -fno-common or -Werror can help to avoid some of these bugs.    Linking with Static Libraries Reference: Computer Systems: A Programmer\u0026rsquo;s Perspective, Chapter 7.6.2\nRelated modules can be packed into a single file called a static library, which can then be supplied as input to the linker. When the system builds the output executable, the linker copies only the object modules in the library that are referenced by the application program.\nIn a static library, related functions are compiled into separate object modules and then packaged in a single static library file.\nAt link time, the linker will only copy the object modules that are referenced by the program, which reduces the size of the executable on disk and in memory.\nOn Linux systems, static libraries are stored on disk in a particular file format known as an archive. An archive is a collection of concatenated relocatable object files, with a header that describes the size and location of each member object file. Archive filenames are denoted with the .a suffix.\nUse AR tool to create a static library: ar rcs libvector.a addvec.o multvec.o\nTo link a static library (say libvector.a), into a program (say main.c):\n If the linker found the symbols defined by addvec.o is referenced by main.o, it will copy addvec.o into the executable. If the linker found there is no symbol in multvec.o is referenced by main.o, then it will not copy this module into the executable.  To resolve references using static libraries, the linker will scan the relocatable object files and archives left to right in the same sequential order that they appear on the compiler driver\u0026rsquo;s command line. During this scan, the linker maintains a set E of relocatable object files that will be merged to form the executable, a set U of unresolved symbols (i.e., symbols referred to but not yet defined), and a set D of symbols that have been defined in previous input files:\n Initially, E, U, and D are empty. For each input file f on the command line, the linker determines if f is an object file or an archive.  If an object file, the linker add f to E. Updates U and D to reflect the symbol definitions and references in f and proceeds to the next input file. If f is an archive, the linker attempts to match the unresolved symbols in U against the symbols defined by the members of the archive. If any member m defines a symbol that resolves a reference in U, then m is added to E, and the linker updates U and D to reflect the symbol definitions and references in m. This process iterates over the member object files in the archive until a fixed point is reached where U and D no longer change. At this point, any member object files not contained in E are simply discarded and the linker proceeds to the next file.  If U is nonempty when the linker finishes scanning the input files on the command line, it prints an error and terminates. Otherwise, it merges and relocates the object files in E to build the output executable file.  Misc Common Symbol Common symbol is for back-compatibility purpose. Using common symbol now is a bad practice.\n References:\n lld/ELF/Symbols.h Investigating linking with COMMON symbols in ELF  Common symbols are a feature that allow a programmer to define several variables of the same name in different source files. This is in contrast with the more popular way of duing extern to reference a variable defined in another file.\nUse GCC flag -fno-common to avoid these multi-place-defined symbols by preventing compiler to use common sections.\n// lld/ELF/Symbols.h  // Represents a common symbol. // // On Unix, it is traditionally allowed to write variable definitions // without initialization expressions (such as \u0026#34;int foo;\u0026#34;) to header // files. Such definition is called \u0026#34;tentative definition\u0026#34;. // // Using tentative definition is usually considered a bad practice // because you should write only declarations (such as \u0026#34;extern int // foo;\u0026#34;) to header files. Nevertheless, the linker and the compiler // have to do something to support bad code by allowing duplicate // definitions for this particular case. // // Common symbols represent variable definitions without initializations. // The compiler creates common symbols when it sees varaible definitions // without initialization (you can suppress this behavior and let the // compiler create a regular defined symbol by -fno-common). // // The linker allows common symbols to be replaced by regular defined // symbols. If there are remaining common symbols after name resolution is // complete, they are converted to regular defined symbols in a .bss // section. (Therefore, the later passes don\u0026#39;t see any CommonSymbols.) classCommonSymbol : public Symbol { public: CommonSymbol(InputFile *file, StringRefZ name, uint8_t binding, uint8_t stOther, uint8_t type, uint64_t alignment, uint64_t size) : Symbol(CommonKind, file, name, binding, stOther, type), alignment(alignment), size(size) {} static bool classof(const Symbol *s) { return s-\u0026gt;isCommon(); } uint32_t alignment; uint64_t size; };   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/tools/kami/",
	"title": "Kami",
	"tags": [],
	"description": "",
	"content": "References\n Kami: A Platform for High-Level Parametric Hardware Specification and Its Modular Verification\n Kami: A Framework for (RISC-V)HW Verification\n   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/tools/coq/",
	"title": "Coq",
	"tags": [],
	"description": "",
	"content": " Reference:\n The Coq Proof Assistant  Isabelle advantages over Coq:\nFrom Benjamin Pierce\n notion of equality is extensional; it eliminates a lot of low-level tedium in proofs of involves equality. a much better story about variable binding; formalizing sth that involves binding variables. nominal data type package.  Coq = Gallina + Tactics\nGallina Core of the Coq: Gallina, a functional programming language;\nHeart of Gallina: typed lambda calculus. - Similar to ML programs. - typed lambda calculus - with dependent types, - also with polymorphic types in the style of ML and Haskell, - also with a built-in inductive definition facility, - So called \u0026ldquo;The Calculus of Inductive Constructions\u0026rdquo;.\nfeatures (\u0026ldquo;strage twists from traditional func langs\u0026rdquo;)\n All functions are total. It has recursion, but all recursion have to terminate, and it has to be obvious to the Gallina type checker that they do.  Tactics Doing proof in Coq is \u0026ldquo;constructing lambda terms of appropriate type\u0026rdquo;:\n A proposition is a type, A proof of that proposition is a term of that type, an inhabitant of that type.   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/basics/dag/",
	"title": "DAG - Directed Acyclic Graph",
	"tags": [],
	"description": "",
	"content": " Directed Acyclic Graph (DAG) is a tool that depicts the structure of basic blocks, helps to see the flow of values flowing among the basic blocks, and offers optimizatino too. 1\nA directed acyclic graph (DAG) for a basic block:\n Leaf nodes represent identifiers, names or constants. Interior nodes are labeled by an operator symbol. Nodes are also given a sequence of identifiers for labels to store the computed value.  DAG provides easy transformation on basic blocks.\nPeephole Optimizations: works locally to transform the input code into an optimized code. By locally, we mean a small portion of the code block at hand. These methods can be applied on intermediate codes as well as on target codes. Possible optimizations are: redundant instruction elimination; unreachable code; flow of control optimization; algebraic expression simplification; strength reduction, replace operations that consume more time and space with other operations that consume less time and space, but produce the same result (x * 2 \u0026ndash;\u0026gt; x \u0026lt;\u0026lt; 1); access machine instructions, leverage target machine\u0026rsquo;s sophisticated instructions.\nMore at Compiler Design - Code Generation\nTo construct the DAG Input: a basic block\nOutput: a DAG, where:\n each node contains a label. For leaves, the label is an identifier. each node contains a list of attached identifiers to hold the computed values.  More at DAG representation for basic blocks see\n  Compiler Design - Code Generation ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-backend/globals/",
	"title": "How Globals are written to the object files by Compilers?",
	"tags": [],
	"description": "",
	"content": " Notes  $gp value can be  a fixed address (static or pic relocation with static link), the start of global address table.  All global varaible names in C are statically linked 1  a dyn loaded address (pic relocation with dynamic link)   Reference: Cpu0 \u0026ndash; Global Variables\n The global variable DAG translation is different from local variable ones. It creates IR DAG nodes at run time in backend C++ code according to llc -relocation-model option while the other DAG just do IR DAG to Machine DAG translation directly according to the input file of IR DAGs(except the Pseudo instruction REtLR used in Chapter 3_4).\n Just like Mips, Cpu0 supports both static and pic mode:\n relocation-model=pic: (default) Use position independent address. relocation-model=static: Use absolute address.  Two different layouts of global variables for each mode:\n -cpu0-use-small-section=false: (default) Will be put in .data or .bss, 32 bits addressable. -cpu0-use-small-section=true: .sdata or .sbss, 16 bits addressable.  When relocation-model=static:\n   option: cpu0-use-small-section false true     addressing mode absolute $gp relative   addressing absolute $gp + offset   Legalized selection DAG (add Cpu0ISD::HiCpu0ISD::Lo) (add register %GP, Cpu0ISD::GPRel)   Cpu0 lui $2, %hi(gl); ori $2, $2, %lo(gl); ori $2, $gp, %gp_rel(gl);   relocation records solved link time link time     In static, cpu0-use-small-section=true, offset between gl and .data can be calculated since the $gp is assigned at fixed address \u0026ndash; the start of global address table. In general relocation-model is used to generate either Absolute Addressing or Position Independent Addressing. The exception is -relocation-model=static and -cpu0-use-small-section=false. In this case, Cpu0 uses $gp relative addressing in this mode.  When relocation-model=pic:\n   option: cpu0-use-small-section false true     addressing mode $gp relative $gp relative   addressing $gp + offset $gp + offset   Legalized selection DAG (load (Cpu0ISD::Wrapper register %GP, )) (load EntryToken, (Cpu0ISD::Wrapper (add Cpu0ISD::Hi, Register %GP), Cpu0ISD::Lo))   Cpu0 ld $2, %got(gl)($gp); lui $2, %got_hi(gl); add $2, $2, $gp; ld $2, $got_lo(gl)($2);   relocation records solved link/load time link/load time     In pic, if the function is loaded at run time (dynamic link), offset between gl and .data cannot be calculated; if use static link, the offset can be calculated; In C, all variable names binding statically. In C++, the overload variable or function are binding dynamically. More dynamic loading (with OS layer): Lindkers and Loaders  Global variable print Chapter6_1/Cpu0MCInstLower.cpp\n  Cpu0 \u0026ndash; Global Variables ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-backend/obj-gen/",
	"title": "Obj Gen",
	"tags": [],
	"description": "",
	"content": "Reference 1\nllc -march=cpu0\nllc -march=cpu0 -relocation-model=pic -filetype=obj ch4_1_match.bc -o ch4_1_match.cpu0.o\nLLVM Code:\n Cpu0InstPrinter.cpp MCTargetDesc/CMakeLists.txt MCTargetDesc/Cpu0AsmBackend.h MCTargetDesc/Cpu0AsmBackend.cpp MCTargetDesc/Cpu0BaseInfo.h MCTargetDesc/Cpu0ELFObjectWriter.cpp MCTargetDesc/Cpu0FixupKinds.h MCTargetDesc/Cpu0MCCodeEmitter.h MCTargetDesc/Cpu0MCCodeEmitter.cpp MCTargetDesc/Cpu0MCExpr.h MCTargetDesc/Cpu0MCExpr.cpp MCTargetDesc/Cpu0MCTargetDesc.h MCTargetDesc/Cpu0MCTargetDesc.cpp MCTargetDesc/Cpu0MCInstLower.h include/llvm/MC/MCRegisterInfo.h Cpu0RegisterInfo.td cmake_debug_build/lib/Target/Cpu0/Cpu0GenRegisterInfo.inc Cpu0InstrInfo.td src/lib/MC/MCELFStreamer.cpp    Cpu0 \u0026ndash; Generating Object Files ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/global/",
	"title": "How Global is stored and accessed in Binary?",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Calling Global Constructors \u0026ndash; CTOR/DTOR ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/",
	"title": "ELF (OS side)",
	"tags": [],
	"description": "",
	"content": " References:\n ELF specification\n ELF Tutorial (i386).\n 目的档格式（ELF）.\n two ELF views: linking and execution. a list of widely used sections in ELF.  Linker and Libraries Guide \u0026ndash; Object File Format\n CTOR/DTOR\n CFI (Call Frame Information) directives\n .cfi_personality directives, etc.  Exception Frames\n .eh_frame section. Format is similar to .debug_frame section specified by DWARF standard. The .eh_frame and .eh_framehdr describes the call frames that must be unwound during the exception.  DWARF Debugging Information Format\n .debug_frame/info/loc/ section.  llvm-objcopy: object copy and editing tool\n llvm/include/llvm/BinaryFormat/ELF.h\n  ELF Data Types\n(Elf32_Half, Elf32_Off, Elf32_Addr, Elf32_Word, Elf32_Sword)\nThree important headers  ELF Header Section Header table. Used during Linking. Program Header table. Used during Execution.  ELF Header ELF file has many headers, but only one header has fixed placement: the ELF header, present at the beginning of every file.\nELF header provides information about the file, such as the machine type, architecture and byte order, etc. as well as a means of identifying and checking whether the file is valid; also provides information about other sections in the file.\n// ? # define ELF_NIDENT\t16  typedef struct { uint8_t\te_ident[ELF_NIDENT]; Elf32_Half\te_type; Elf32_Half\te_machine; Elf32_Word\te_version; Elf32_Addr\te_entry; Elf32_Off\te_phoff; Elf32_Off\te_shoff; Elf32_Word\te_flags; Elf32_Half\te_ehsize; Elf32_Half\te_phentsize; Elf32_Half\te_phnum; Elf32_Half\te_shentsize; Elf32_Half\te_shnum; Elf32_Half\te_shstrndx; } Elf32_Ehdr; ELF Section Header Table ELF file contains a lot of different types of section and their relavant headers, not all of them are present in the every file, and there is no guarantee on which order they appear in. Thus, in order to parse and process these sections, the ELF format also defines section headers, which contain information such as section names, sizes, locations and other relevant information. The list of all the section headers in an ELF image is referred to as the section header table.\n// https://github.com/freebsd/freebsd/blob/master/sys/sys/elf32.h  /* * Section header. */ typedef struct { Elf32_Word\tsh_name;\t/* Section name (index into the section header string table). */ Elf32_Word\tsh_type;\t/* Section type. */ Elf32_Word\tsh_flags;\t/* Section flags. */ Elf32_Addr\tsh_addr;\t/* Address in memory image. */ Elf32_Off\tsh_offset;\t/* Offset in file. */ Elf32_Word\tsh_size;\t/* Size in bytes. */ Elf32_Word\tsh_link;\t/* Index of a related section. */ Elf32_Word\tsh_info;\t/* Depends on section type. */ Elf32_Word\tsh_addralign;\t/* Alignment in bytes. */ Elf32_Word\tsh_entsize;\t/* Size of each entry in section. */ } Elf32_Shdr; sh_name does not point directly to a string. Instead it points to the offset of a string in the section name string table. The index of the table itself is defined in the ELF header by the field e_shstrndx.\nsh_addr ???\nsh_offset is the position in the ELF image file, as an offset from the beginning of the file.\nsh_type stores the type of the section. The value is of the the enum ShT_Type (see below).\n// enum ShT_Types { SHT_NULL\t= 0, // Null section \tSHT_PROGBITS\t= 1, // Program information \tSHT_SYMTAB\t= 2, // Symbol table \tSHT_STRTAB\t= 3, // String table \tSHT_RELA\t= 4, // Relocation (w/ addend) \tSHT_HASH = 5,\tSHT_DYNAMIC = 6,\tSHT_NOTE = 7, SHT_NOBITS = 8,\t// Not present in file \tSHT_REL = 9, // Relocation (no addend) \tSHT_SHLIB = 10, SHT_DYNSYM = 11, SHT_LOPROC = 0x70000000, SHT_HIPROC = 0x7fffffff, // Values in this inclusive range are reserved for processor-specific semantics \tSHT_LOUSER = 0x80000000, // the lower bound of the range of indexes reserved for application programs. SHT_HIUSER = 0xffffffff, // Section types between SHT_LOUSER and SHT_HIUSER may be used by the application, without conflicting with current or future system-defined section types. }; A full list of section types in LLVM:\n  Section Types in LLVM   // https://github.com/llvm/llvm-project/blob/13b63be472233762024ef196dd88612369a51807/llvm/include/llvm/BinaryFormat/ELF.h#L819  // Section types. enum : unsigned { SHT_NULL = 0, // No associated section (inactive entry).  SHT_PROGBITS = 1, // Program-defined contents.  SHT_SYMTAB = 2, // Symbol table.  SHT_STRTAB = 3, // String table.  SHT_RELA = 4, // Relocation entries; explicit addends.  SHT_HASH = 5, // Symbol hash table.  SHT_DYNAMIC = 6, // Information for dynamic linking.  SHT_NOTE = 7, // Information about the file.  SHT_NOBITS = 8, // Data occupies no space in the file.  SHT_REL = 9, // Relocation entries; no explicit addends.  SHT_SHLIB = 10, // Reserved.  SHT_DYNSYM = 11, // Symbol table.  SHT_INIT_ARRAY = 14, // Pointers to initialization functions.  SHT_FINI_ARRAY = 15, // Pointers to termination functions.  SHT_PREINIT_ARRAY = 16, // Pointers to pre-init functions.  SHT_GROUP = 17, // Section group.  SHT_SYMTAB_SHNDX = 18, // Indices for SHN_XINDEX entries.  // Experimental support for SHT_RELR sections. For details, see proposal  // at https://groups.google.com/forum/#!topic/generic-abi/bX460iggiKg  SHT_RELR = 19, // Relocation entries; only offsets.  SHT_LOOS = 0x60000000, // Lowest operating system-specific type.  // Android packed relocation section types.  // https://android.googlesource.com/platform/bionic/+/6f12bfece5dcc01325e0abba56a46b1bcf991c69/tools/relocation_packer/src/elf_file.cc#37  SHT_ANDROID_REL = 0x60000001, SHT_ANDROID_RELA = 0x60000002, SHT_LLVM_ODRTAB = 0x6fff4c00, // LLVM ODR table.  SHT_LLVM_LINKER_OPTIONS = 0x6fff4c01, // LLVM Linker Options.  SHT_LLVM_CALL_GRAPH_PROFILE = 0x6fff4c02, // LLVM Call Graph Profile.  SHT_LLVM_ADDRSIG = 0x6fff4c03, // List of address-significant symbols  // for safe ICF.  SHT_LLVM_DEPENDENT_LIBRARIES = 0x6fff4c04, // LLVM Dependent Library Specifiers.  SHT_LLVM_SYMPART = 0x6fff4c05, // Symbol partition specification.  SHT_LLVM_PART_EHDR = 0x6fff4c06, // ELF header for loadable partition.  SHT_LLVM_PART_PHDR = 0x6fff4c07, // Phdrs for loadable partition.  // Capsule Ownership Section Type  SHT_CAPSULE_OWNERSHIP = 0x6fff4d00, // capsule ownership section  // Android\u0026#39;s experimental support for SHT_RELR sections.  // https://android.googlesource.com/platform/bionic/+/b7feec74547f84559a1467aca02708ff61346d2a/libc/include/elf.h#512  SHT_ANDROID_RELR = 0x6fffff00, // Relocation entries; only offsets.  SHT_GNU_ATTRIBUTES = 0x6ffffff5, // Object attributes.  SHT_GNU_HASH = 0x6ffffff6, // GNU-style hash table.  SHT_GNU_verdef = 0x6ffffffd, // GNU version definitions.  SHT_GNU_verneed = 0x6ffffffe, // GNU version references.  SHT_GNU_versym = 0x6fffffff, // GNU symbol versions table.  SHT_HIOS = 0x6fffffff, // Highest operating system-specific type.  SHT_LOPROC = 0x70000000, // Lowest processor arch-specific type.  // Fixme: All this is duplicated in MCSectionELF. Why??  // Exception Index table  SHT_ARM_EXIDX = 0x70000001U, // BPABI DLL dynamic linking pre-emption map  SHT_ARM_PREEMPTMAP = 0x70000002U, // Object file compatibility attributes  SHT_ARM_ATTRIBUTES = 0x70000003U, SHT_ARM_DEBUGOVERLAY = 0x70000004U, SHT_ARM_OVERLAYSECTION = 0x70000005U, SHT_HEX_ORDERED = 0x70000000, // Link editor is to sort the entries in  // this section based on their sizes  SHT_X86_64_UNWIND = 0x70000001, // Unwind information  SHT_MIPS_REGINFO = 0x70000006, // Register usage information  SHT_MIPS_OPTIONS = 0x7000000d, // General options  SHT_MIPS_DWARF = 0x7000001e, // DWARF debugging section.  SHT_MIPS_ABIFLAGS = 0x7000002a, // ABI information.  SHT_MSP430_ATTRIBUTES = 0x70000003U, SHT_RISCV_ATTRIBUTES = 0x70000003U, SHT_HIPROC = 0x7fffffff, // Highest processor arch-specific type.  SHT_LOUSER = 0x80000000, // Lowest type reserved for applications.  SHT_HIUSER = 0xffffffff // Highest type reserved for applications. };    sh_addr: If the section will appear in the memory image of a process, this member gives the address at which the section\u0026rsquo;s first byte should reside. Otherwise, the member contains 0.\nsh_link and sh_info sh_link: This member holds a section header table index link, whose interpretation depends on the section type.\nsh_info: This member holds extra information, whose interpretation depends on the section type.\nNote: PROGBITS will have not sh_link and sh_info by default.\nAnother table from Oracle book:\n  section types and sh_link/info    Table 3-3 Section Types      Name\u0026nbsp;\nValue\u0026nbsp;\nDescription\u0026nbsp;\n Interpretation by\u0026nbsp;\n \n sh_info\u0026nbsp;\nsh_link\u0026nbsp;\n \n    SHT_NULL 0\u0026nbsp;\nMarks section header as inactive; file has no corresponding section.\u0026nbsp;\n0\u0026nbsp;\n SHN_UNDEF  \n  SHT_PROGBITS 1\u0026nbsp;\nContains information defined by the program, and in a format and with a meaning determined solely by the program.\u0026nbsp;\n0\u0026nbsp;\n SHN_UNDEF  \n  SHT_SYMTAB 2\u0026nbsp;\nIs a complete symbol table, usually for link editing. This table can also be used for dynamic linking; however, it can contain many unnecessary symbols.\u0026nbsp;\nNote: Only one section of this type is allowed in a file\u0026nbsp;\nOne greater than the symbol table index of the last local symbol.\u0026nbsp;\nThe section header index of the associated string table.\u0026nbsp;\n \n  SHT_STRTAB 3\u0026nbsp;\nIs a string table. A file can have multiple string table sections.\u0026nbsp;\n0\u0026nbsp;\n SHN_UNDEF  \n  SHT_RELA 4\u0026nbsp;\nContains relocation entries with explicit addends. A file can have multiple relocation sections.\u0026nbsp;\nThe section header index of the section to where the relocation applies.\u0026nbsp;\nThe section header index of the associated symbol table.\u0026nbsp;\n \n  SHT_HASH 5\u0026nbsp;\nIs a symbol rehash table.\u0026nbsp;\nNote: Only one section of this type is allowed in a file\u0026nbsp;\n0\u0026nbsp;\nThe section header index of the symbol table to which the hash table applies.\u0026nbsp;\n \n  SHT_DYNAMIC 6\u0026nbsp;\nContains dynamic linking information.\u0026nbsp;\nNote: Only one section of this type is allowed in a file\u0026nbsp;\n0\u0026nbsp;\nThe section header index of the string table used by entries in the section.\u0026nbsp;\n \n  SHT_NOTE 7\u0026nbsp;\nContains information that marks the file.\u0026nbsp;\n0\u0026nbsp;\n SHN_UNDEF  \n  SHT_NOBITS 8\u0026nbsp;\nContains information defined by the program, and in a format and with a meaning determined by the program. However, a section of this type occupies no space in the file, but the section header\u0026rsquo;s offset field specifies the location at which the section would have begun if it did occupy space within the file.\n0\u0026nbsp;\n SHN_UNDEF  \n  SHT_REL 9\u0026nbsp;\nContains relocation entries without explicit addends. A file can have multiple relocation sections.\u0026nbsp;\nThe section header index of the section to where the relocation applies.\u0026nbsp;\nThe section header index of the associated symbol table.\u0026nbsp;\n \n  SHT_SHLIB 10\u0026nbsp;\nReserved.\u0026nbsp;\n0\u0026nbsp;\n SHN_UNDEF  \n  SHT_DYNSYM 11\u0026nbsp;\nIs a symbol table with a minimal set of symbols for dynamic linking. \u0026nbsp;\nNote: Only one section of this type is allowed in a file\u0026nbsp;\nOne greater than the symbol table index of the last local symbol.\u0026nbsp;\nThe section header index of the associated string table.\u0026nbsp;\n \n  SHT_LOPROC  SHT_HIPROC 0x70000000\u0026nbsp;\n0x7fffffff\u0026nbsp;\nLower and upper bounds of range of section types reserved for processor-specific semantics.\u0026nbsp;\n0\u0026nbsp;\nSHN_UNDEF\u0026nbsp;\n \n \u0026nbsp;\n \n  SHT_LOUSER  SHT_HIUSER 0x80000000\u0026nbsp;\n0xffffffff\u0026nbsp;\nLower and upper bounds of range of section types reserved for application programs.\u0026nbsp;\nNote: Section types in this range can be used by an application without conflicting with system-defined section types.\u0026nbsp;\n0\u0026nbsp;\n SHN_UNDEF  \n \n  sh_entsize sh_flag sh_entsize: Some sections hold a table of fixed-size entries, such as a symbol table. For such a section, this member gives the size in bytes of each entry. The member contains 0 if the section does not hold a table of fixed-size entries.\nsh_flag stores bit flags to describe the section attributes.\nA list of section flags/attributes enabled in sh_flag in LLVM:   Section Flags in LLVM   // https://github.com/llvm/llvm-project/blob/13b63be472233762024ef196dd88612369a51807/llvm/include/llvm/BinaryFormat/ELF.h#L892  // Section flags. enum : unsigned { // Section data should be writable during execution.  SHF_WRITE = 0x1, // Section occupies memory during program execution.  SHF_ALLOC = 0x2, // Section contains executable machine instructions.  SHF_EXECINSTR = 0x4, // The data in this section may be merged.  SHF_MERGE = 0x10, // The data in this section is null-terminated strings.  SHF_STRINGS = 0x20, // A field in this section holds a section header table index.  SHF_INFO_LINK = 0x40U, // Adds special ordering requirements for link editors.  SHF_LINK_ORDER = 0x80U, // This section requires special OS-specific processing to avoid incorrect  // behavior.  SHF_OS_NONCONFORMING = 0x100U, // This section is a member of a section group.  SHF_GROUP = 0x200U, // This section holds Thread-Local Storage.  SHF_TLS = 0x400U, // Identifies a section containing compressed data.  SHF_COMPRESSED = 0x800U, // This section is excluded from the final executable or shared library.  SHF_EXCLUDE = 0x80000000U, // Start of target-specific flags.  SHF_MASKOS = 0x0ff00000, // Bits indicating processor-specific flags.  SHF_MASKPROC = 0xf0000000, /// All sections with the \u0026#34;d\u0026#34; flag are grouped together by the linker to form  /// the data section and the dp register is set to the start of the section by  /// the boot code.  XCORE_SHF_DP_SECTION = 0x10000000, /// All sections with the \u0026#34;c\u0026#34; flag are grouped together by the linker to form  /// the constant pool and the cp register is set to the start of the constant  /// pool by the boot code.  XCORE_SHF_CP_SECTION = 0x20000000, // If an object file section does not have this flag set, then it may not hold  // more than 2GB and can be freely referred to in objects using smaller code  // models. Otherwise, only objects using larger code models can refer to them.  // For example, a medium code model object can refer to data in a section that  // sets this flag besides being able to refer to data in a section that does  // not set it; likewise, a small code model object can refer only to code in a  // section that does not set this flag.  SHF_X86_64_LARGE = 0x10000000, // All sections with the GPREL flag are grouped into a global data area  // for faster accesses  SHF_HEX_GPREL = 0x10000000, // Section contains text/data which may be replicated in other sections.  // Linker must retain only one copy.  SHF_MIPS_NODUPES = 0x01000000, // Linker must generate implicit hidden weak names.  SHF_MIPS_NAMES = 0x02000000, // Section data local to process.  SHF_MIPS_LOCAL = 0x04000000, // Do not strip this section.  SHF_MIPS_NOSTRIP = 0x08000000, // Section must be part of global data area.  SHF_MIPS_GPREL = 0x10000000, // This section should be merged.  SHF_MIPS_MERGE = 0x20000000, // Address size to be inferred from section entry size.  SHF_MIPS_ADDR = 0x40000000, // Section data is string data by default.  SHF_MIPS_STRING = 0x80000000, // Make code section unreadable when in execute-only mode  SHF_ARM_PURECODE = 0x20000000 };   \nTo access section header:\n e_shoff in ELF header gives the offset of first section header (NULL). e_shnum in ELF header gives the total num of section headers in the file. Section headers are continuous. Given pointer to the first entry, subsequent entries can be accessed with simple pointer arithmetic or array operations.\n// ? static inline Elf32_Shdr *elf_sheader(Elf32_Ehdr *hdr) { return (Elf32_Shdr *)((int)hdr + hdr-\u0026gt;e_shoff); } static inline Elf32_Shdr *elf_section(Elf32_Ehdr *hdr, int idx) { return \u0026amp;elf_sheader(hdr)[idx]; }  ELF Program Header Table A program header defines information about how the ELF program behaves once it\u0026rsquo;s been loaded, as well as runtime linking information.\nFiles used to build a process image (execute a program) must have a program header table; relocatabe files do not need one.\nELF program headers (much like section headers) are all grouped together to make up the program header table.\n// ? typedef struct { Elf32_Word\tp_type; Elf32_Off\tp_offset; Elf32_Addr\tp_vaddr; Elf32_Addr\tp_paddr; Elf32_Word\tp_filesz; Elf32_Word\tp_memsz; Elf32_Word\tp_flags; Elf32_Word\tp_align; } Elf32_Phdr; Reference: Program Header (Linker and Libraries Guide)\n\u0026ldquo;An excutable or shared object file\u0026rsquo;s program header table is an array of structures, each describing a segment or other information that the system needs to prepare the program for execution. An object file segment contains one or more sections\u0026rdquo;.\nSegment Contents: Text segments contain read-only instructions and data. Data segments contain writable data and instructions. See more about Sengment Contenst.\nA PT_DYNAMIC program header element points at the .dynamic section. The .got and .plt sections also hold information related to position-independent code and dynamic linking.\nThe .plt can reside in a text or a data segment, depending on the processor. See processor specific GOT, and Processor specific PLT.\nThe .bss section has the type SHT_NOBITS. Normally, these uninitialized data reside at the the end of the segment, thereby making p_memsz larger than p_filesz in the associated program header element.\n p_type. The kind of segment this array element describes or how to interpret the array element\u0026rsquo;s information. Example types:  PT_NULL, 0. PT_LOAD, 1. A loadable segment. Described by p_filesz and p_memsz. The bytes from the file are mapped to the beginning of the memory segment. If the segment\u0026rsquo;s memory size (p_memsz) is larger than the file size (p_filesz), the extra bytes are defined to hold the value 0 and to follow the segment\u0026rsquo;s initialized area. The file size cannot be larger than the memory size. Loadable segment entries in the program header table appear in ascending order, sorted on the p_vaddr member. PT_DYNAMIC, 2. PT_INTERP, 3. PT_NOTE, 4. PT_SHLIB, 5. PT_PHDR, 6. PT_LOSUNW, 0x6fff.fffa. \u0026hellip;  p_offset. The offset from the beginning of the file at which the first byte of the segment resides. p_vaddr. The virtual address at which the first byte of the segment resides in the memory. p_paddr. The segment\u0026rsquo;s physical address for systems in which physical addressing is relevant. Because the system ignores physical addressing for applicatin programs, this member has unspecified contents for executable files and shared objects. p_filesz. p_memsz. p_flags. Flags relavant to the segment. Examples:  PF_X, 0x1, Execute PF_W, 0x2, Write PF_R, 0x4, Read PF_MASKPROC, 0xf000,0000. Unspecified.  p_align. a positive, integral power of 2. p_vaddr % p_align = p_offset % p_align.  Special Sections Various sections in ELF are pre-defined asn hold program and control information. These Sections are used by the operating system and have different types and attributes for different operating systems.\nSection names with a dot . prefix are reserved for the system. Applications may use names without the prefix to avoid conflicts with system sections.\nAn object file may have more than one section with the same name.\nExecutables are created from individual object files and libraries through the linking process. The linker\u0026rsquo;s tasks include:\n resolves the references (including subroutines and data references) among the different object files adjust the absolute references in the object files relocates instructions.  The linking and loading processes require information defined in the object files and store this information in specific sections such as .dynamic.\nThere are also sections for program control, including .bss, .data, .data1, .rodata, and .rodata1, and sections for debugging, such as .debug, .line, etc.\nA list of special sections for the ELF specification:\nSymbol Table Section Symbol table is a section (or a number of sections) that defines the location, type, visibility and other traits of various symbols declared in the original source, created during compilation or linking, or otherwise present in the file.\nMore info Symbol Table\nString Table Section A number of consecutive zero-terminated strings.\nThe object file use these strings to represent symbol and section names.\n.strtab, the default string table.\n.shstrtab, the section string table.\n.dynstr, the string table for dynamic linking.\nAnytime the loading process needs access to a string, it uses an offset into one of the string tables.\nsh_size specifies the size of the string table in the corresponding section header entry.\nThe simplest program loader may copy all string tables into memory, but a more complete solution would omit any that are not necessary during runtime. Notably those not flagged with SHF_ALLOC in their respective section header (such as .shstrtab, since section names aren\u0026rsquo;t used in program runtime).\nBSS .bss: a block of memory which has been zeroed. (global vars haven\u0026rsquo;t been init or init to 0 or null).\nType (sh_type) is SHT_NOBITS, which means not present in the object file space, but must be allocated during runtime.\nBSS should be allocated before performing any operation that relies on relative addressing (such as relocation), as failing to do so can cause code to reference garbage memory or fault.\nAny section that is of type SHT_NOBITS and has the attribute SHF_ALLOC should be allocated early on duing program loading.\n// ? static int elf_load_stage1(Elf32_Ehdr *hdr) { Elf32_Shdr *shdr = elf_sheader(hdr); unsigned int i; // Iterate over section headers \tfor(i = 0; i \u0026lt; hdr-\u0026gt;e_shnum; i++) { Elf32_Shdr *section = \u0026amp;shdr[i]; // If the section isn\u0026#39;t present in the file \tif(section-\u0026gt;sh_type == SHT_NOBITS) { // Skip if it the section is empty \tif(!section-\u0026gt;sh_size) continue; // If the section should appear in memory \tif(section-\u0026gt;sh_flags \u0026amp; SHF_ALLOC) { // Allocate and zero some memory \tvoid *mem = malloc(section-\u0026gt;sh_size); memset(mem, 0, section-\u0026gt;sh_size); // Assign the memory offset to the section offset \tsection-\u0026gt;sh_offset = (int)mem - (int)hdr; DEBUG(\u0026#34;Allocated memory for a section (%ld).\\n\u0026#34;, section-\u0026gt;sh_size); } } } return 0; } Relocation Sections Position independent code.\nA relocation section is a table of relocation entries.\nTwo types of relocation section entry: SHT_RELA, relocation with explicit addend; SHT_REL, relocation without explicit addend. A given relocation section only have one type of entry.\n// ? typedef struct { Elf32_Addr\tr_offset; Elf32_Word\tr_info; } Elf32_Rel; typedef struct { Elf32_Addr\tr_offset; Elf32_Word\tr_info; Elf32_Sword\tr_addend; } Elf32_Rela; r_info upper byte points to a symbol in the symbol table, meaning to which the relocation applies; lower byte stores the type of relocation.sh_link in the relocation section header stores the index of the symbol table section header.\nNum of entries = section size sh_size / entry size sh_entsize\nEach relocation table is specific to a single section.\nCTOR/DTOR .ctor/.dtor section stores the addresses of global constructor and destructors.\nGlobal constructors are supposed to have run before your main function.\nThe section is a table of pointers, and each pointer is a function that must be executed as global constructor/deconstructors.\nMore at CTOR/DTOR\n Loading  Reference How programs get run: ELF binaries How programs get run: execve() system calls Linux src: fs/binfmt_elf.c load_elf_binary() load_elf_phdrs(), load the program headers load_elf_interp(), load_elf_library(), ? elf_core_dump() ELF文件的加载过程(load_elf_binary函数详解)\u0026ndash;Linux\n Relocation Section  References: ELF specification Computer Systems: A Programmer\u0026rsquo;s Perspective, Chapter 7.7 PLT and GOT - the key to code sharing and dynamic libraries GOT and PLT for pwning Relocation is the process of connecting symbolic references with symbolic definitions. For example, when a program calls a function, the associated call instruction must transfer control to the proper destination address at execution. In other words, relocatable files must have information that describes how to modify their section contents, thus allowing executable and shared object files to hold the right information for a process\u0026rsquo;s program image.\n Text  Reference reference  Dwarf Debugging Information  References: DWARF Debugging Information Format .debug_frame section. DWARF in LLVM How debuggers work: Part 3 - Debugging information Machine code -\u0026gt; source code file, function name, and line numbers DWARF sections .debug sections, and all the sections begin with .debug: .debug_info .debug_loc .debug_frame \u0026hellip; DWARF Format DWARF: Debugging Information Entry(DIE). Each DIE has a tag \u0026ndash; its type, and a set of attributes.\n Symbol Table Section  Q\u0026amp;A How does LLVM generate Symbol Table section in an object file? References: ELF specification Computer Systems: A Programmer\u0026rsquo;s Perspective, Chapter 7.6 Symbol Table Section The section .symtab holds a symbol table. The object file use the symbol table to locate and relocate a program\u0026rsquo;s symbolic definitions and references. First entry is always undefined symbol. If a file has a loadable segment that includes the symbol table, this symbol section\u0026rsquo;s attributes will include the SHF_ALLOC bit; otherwise the bit will be off.\n How Global is stored and accessed in Binary?  Reference 1 Calling Global Constructors \u0026ndash; CTOR/DTOR ↩  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/mpx/llvm-mpx/",
	"title": "LLVM MPX (BOGO)",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to determine the size of object?\n How to store the bound info in MPX?\n How to do bound checking?\n How to choose the instrumentation point?\n A Map from instruction to the pointer it want to access?   Reference 1\nOverview A module pass: class llmpx: public ModulePass\nrunOnModule(Module \u0026amp;)\nMethods:\nmpxPass(Module \u0026amp;)\nharden_cfi(Module \u0026amp;)\ncreate_global_constants(Module \u0026amp;)\ncollect_safe_access(Module \u0026amp;)\ntransform_functions(Module \u0026amp;)\ntransform_global(Module \u0026amp;)\nprocess_each_function(Module \u0026amp;)\ncleanup(Module \u0026amp;)\nverify(Module \u0026amp;)\ndead_bndstx_elimination(Module\u0026amp;);\ndead_bndldx_elimination(Module\u0026amp;);\n/* * Helper function, try to find the real value which has its id * associated with it */ Value* find_true_val_has_aa_id(Value*); /* * remove any used bound, return the number of bound removed */ int remove_dead_bound(Module\u0026amp;); /* * creat symbols for helper library */ void create_llmpx_symbols(Module\u0026amp;);  States:\n/* * the safe access list, which we don\u0026#39;t need to check * map from the instruction to the pointer it want to access */ std::map\u0026lt;Value*, Value*\u0026gt; safe_access_list; /* * MPX Intrinsic Functions */ Function* mpx_bndmk; Function* mpx_bndldx; Function* mpx_bndstx; Function* mpx_bndclrr; Function* mpx_bndclrm; Function* mpx_bndcurr; Function* mpx_bndcurm; Function* mpx_bndcn;  runOnModule Steps:\n Create global constant bound. create_global_constants(module) Create symbols, for  mpx intrinsic external helper library wrapper function in mpxwrap bound cache function  call pass mpxTester or call pass mpxPass\n// mpx/llmpx.cpp  /* * stub function */ bool llmpx::runOnModule(Module \u0026amp;module) { this-\u0026gt;module = \u0026amp;module; ctx = \u0026amp;module.getContext(); //prepare global constant bound create_global_constants(module); /* * create mpx intrinsic symbols */ create_mpx_intr_symbols(module); /* * create symbols for external help library */ create_llmpx_symbols(module); /* * create symbols for wrapper functions in mpxwrap */ create_llmpx_wrapper_symbols(module); /* * create symbol for bound cache functions */ create_llmpx_bnd_cache_symbols(module); #if USE_MPX_TESTER return mpxTester(module); #else return mpxPass(module);; #endif   mpxTester pass  Find the second alloca and insert mpx instructions after it.\n/* * This is MPX extension tester, * it grab the result of second alloc and insert the following code * to test the functionality of mpx * * bndmk r, bnd0 * bndstx r, bnd0 * bndldx r, bnd0 * bndcl r, bnd0 * bndcu r, bnd0 * r+=10 * bndcl r, bnd0; will generate #BR exception * * ---------------------------------- * int main() * { * char p[16] = \u0026#34;123\u0026#34;; * printf(\u0026#34;%s\\n\u0026#34;, p); * return 0; * } */   To find the alloca instruction in a module:\n// mpx/llmpx.cpp  for (Module::iterator f_begin = module.begin(), f_end = module.end(); f_begin != f_end; ++f_begin) { Function *func_ptr = dyn_cast\u0026lt;Function\u0026gt;(f_begin); errs()\u0026lt;\u0026lt;\u0026#34;Function : \u0026#34;; errs()\u0026lt;\u0026lt;func_ptr-\u0026gt;getName(); if (func_ptr-\u0026gt;isDeclaration()) { errs()\u0026lt;\u0026lt;\u0026#34; is external \\n\u0026#34;; continue; } errs()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; //find and get a pointer  PointerType* Int8PtrTy = Type::getInt8PtrTy(*ctx); //Function::iterator bb_begin = func_ptr-\u0026gt;begin();  BasicBlock* bb_begin = \u0026amp; func_ptr-\u0026gt;getEntryBlock(); BasicBlock::iterator II = bb_begin-\u0026gt;begin(); int num_alloc = 0; while(II!=bb_begin-\u0026gt;end()) { Instruction *I = dyn_cast\u0026lt;Instruction\u0026gt;(II); if (isa\u0026lt;AllocaInst\u0026gt;(I) \u0026amp;\u0026amp; I-\u0026gt;getType()-\u0026gt;isPointerTy()) { errs()\u0026lt;\u0026lt;\u0026#34;Found Ptr AllocaInst\\n\u0026#34;; I-\u0026gt;print(errs()); errs()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; errs()\u0026lt;\u0026lt;\u0026#34; return type:\u0026#34;; I-\u0026gt;getType()-\u0026gt;print(errs()); errs()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; ... } ++II; }  To Insert a new instruction:\n Use IRBuilder\u0026lt;\u0026gt; builder (insertPoint). insertPoint is an instruction in the original code. New instruction will be inserted before the insert point. Prepare args: std::vector\u0026lt;Value *\u0026gt; args; args.push_back(...) Use CallInst::Create(func, args, \u0026quot;\u0026quot;, I); to insert instruction. Not using builder???\n// mpx/llmpx.cpp  /* * insert instruction: * * bndmk bnd, m32/m64 Make lower and upper bounds from m32/m64 * and store them in bound register bnd. */ Instruction *srcI = dyn_cast\u0026lt;Instruction\u0026gt;(II); Instruction *insertPoint = dyn_cast\u0026lt;Instruction\u0026gt;(++II); IRBuilder\u0026lt;\u0026gt; builder(insertPoint); Instruction *I = dyn_cast\u0026lt;Instruction\u0026gt;(II); std::vector\u0026lt;Value *\u0026gt; args; //args.push_back(ConstantPointerNull::get(Int8PtrTy));  Value* ptr_arg_for_bndmk = builder.CreateBitCast(srcI,Int8PtrTy,\u0026#34;\u0026#34;); args.push_back(ptr_arg_for_bndmk); Constant* dist_arg_for_bndmk = ConstantInt::get(Type::getInt64Ty(*ctx),(9)); args.push_back(dist_arg_for_bndmk); Function *func = Intrinsic::getDeclaration(\u0026amp;module, Intrinsic::x86_bndmk); I = dyn_cast\u0026lt;Instruction\u0026gt;(II); errs()\u0026lt;\u0026lt;\u0026#34;Insert bndmk before this inst:\u0026#34;; I-\u0026gt;print(errs()); errs()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; Instruction* bndmkcall = CallInst::Create(func, args, \u0026#34;\u0026#34;, I); bndmkcall-\u0026gt;print(errs()); errs()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;   mpx Pass Whole algorithm as stated in the source code (https://github.com/lzto/bogo):\n gather bound information from each instruction and create bound make, bound check and bound propagation into a tree? or something else. The result would be saved to bound_checklist. optimize bound_checklist to eliminate redundant checks. insert corresponding instruction using bound_checklist.  List of methods and call paths:\nmpxPass -\u0026gt; transform_global -\u0026gt; harden_cfi -\u0026gt; return false; mpxPass -\u0026gt; collect_safe_access -\u0026gt; transform_functions -\u0026gt; transform_global -\u0026gt; process_each_function -\u0026gt; clean up -\u0026gt; verify -\u0026gt; return false; // collect_safe_access mpxPass -\u0026gt; collect_safe_access -\u0026gt; is_safe_access -\u0026gt; // update `safe_access_list[inst] = ptr_operand`  // transform_functions to pass bound information during a call/return mpxPass -\u0026gt; transform_functions // transform_global mpxPass -\u0026gt; transform_global // process_each_function mpxPass -\u0026gt; process_each_function -\u0026gt; process_bound_checklist -\u0026gt; process_each_instruction process_each_instruction -\u0026gt; handleGetElementPtr -\u0026gt; associate_meta -\u0026gt; process_each_instruction process_each_instruction -\u0026gt; handleBitCast -\u0026gt; associate_meta -\u0026gt; process_each_instruction process_each_instruction -\u0026gt; handleLoad() -\u0026gt; insert_check -\u0026gt; insert_bound_check -\u0026gt; process_each_instruction process_each_instruction -\u0026gt; handleStore() -\u0026gt; insert_check -\u0026gt; insert_bound_check -\u0026gt; process_each_instruction -\u0026gt; process_each_instruction process_each_instruction -\u0026gt; handleCall -\u0026gt; process_each_instruction -\u0026gt; transform_function_type -\u0026gt; add_transform_type_pair -\u0026gt; // add \u0026lt;orig_type, transformed_type\u0026gt; to tr_typelist.  process_each_instruction -\u0026gt; handleInvoke -\u0026gt; process_each_instruction -\u0026gt; transform_function_type -\u0026gt; add_transform_type_pair -\u0026gt; // add \u0026lt;orig_type, transformed_type\u0026gt; to tr_typelist.  process_each_instruction -\u0026gt; handleBinaryOperator (got #if 0\u0026#39;d) -\u0026gt; process_each_instruction process_each_instruction -\u0026gt; handleInsertValue/PHINode/PtrToInt/Select/ -\u0026gt; process_each_instruction  data structures: Map/Table structure to store a list of new instructions/keys for each instruction or variable\nstd::map\u0026lt;Value*, std::list\u0026lt;Value*\u0026gt;*\u0026gt; bound_checklist: This stores the bound instruction need to be inserted for each instruction.\nFor example:\noriginal instruction =\u0026gt; bndmk/bndldx instructions\noriginal instruction =\u0026gt; bndmov/bndstx instructions\noriginal instruction =\u0026gt; bndcl/bndcu instructions\nkey_checklist. This stores the key instruction need to be inserted.\ngv_bound_checklist. Global variable bound list, initialize only once for each application.\ngv_key_checklist. Global variable key list, initialize only once for each application.\nstd::map\u0026lt;std::pair\u0026lt;Value*, Instruction*\u0026gt;, std::list\u0026lt;Value*\u0026gt;*\u0026gt; gv_bound_checklist_cache, gv_key_checklist_cache: global variable bound/key load cache. Each pair has a list of ???.\ntransform_functions Scan function parameters and function return types, if any pointers, transform the function to add bnd information for pointers.\ntransform_functions -\u0026gt; function_need_to_be_transformed -\u0026gt; is_in_skip_list -\u0026gt; // check return type and parameter type; bnd needed if any ptr or struct-\u0026gt;ptr.  -\u0026gt; has_transformed_type -\u0026gt; // search tr_typelist for a type.  -\u0026gt; get_transformed_type -\u0026gt; // get the transformed type, tr_typelist[orig_type].  -\u0026gt; add_transform_type_pair -\u0026gt; // add \u0026lt;orig_type, transformed_type\u0026gt; to tr_typelist.  -\u0026gt; Function::Create \u0026#34;_wbnd\u0026#34; -\u0026gt; // tr_flist[func_ptr] = new_func, the old func deleted  // revtr_flist[new_func] = func_ptr  // update flist_orig, flist_new  transform_global Transform all global variables. Insert ctor and dtor function, and store bound in ctor.\n// for(GlobalVariable \u0026amp;gvi: module.globals()) { GlobalVariable* gi = \u0026amp;gvi; if (gi-\u0026gt;isDeclaration()) continue; if (!isa\u0026lt;Value\u0026gt;(gi)) continue; Value* gv = dyn_cast\u0026lt;Value\u0026gt;(gi); StringRef gvname = gv-\u0026gt;getName(); if (gvname.startswith(\u0026#34;llvm.\u0026#34;) || gvname.startswith(\u0026#34;llmpx_\u0026#34;)) continue; bool gv_use_func = false; if (!gi-\u0026gt;hasInitializer()) { continue; } Constant* initializer = gi-\u0026gt;getInitializer(); Type* itype = initializer-\u0026gt;getType(); TotalStaticBNDAdded++; /* * make bound * initialization of constant bound has been changed from using bndmk * instruction to series of store instruction in .init_array section, * so that it can possibly be further optimized (i.e. make it as * constant bound) */ PointerType* Int8PtrTy = Type::getInt8PtrTy(*ctx); unsigned allocated_size = module.getDataLayout() .getTypeAllocSize(itype); #if (DEBUG_MPX_PASS_1_5\u0026gt;2)  errs()\u0026lt;\u0026lt;\u0026#34;bnd parm size:\u0026#34;\u0026lt;\u0026lt;allocated_size\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; #endif  /* * create global constant bound for it */ Type* ArrayTy = ArrayType::get(IntegerType::get(*ctx, 64), 2); GlobalVariable* gvbnd = new GlobalVariable(module, ArrayTy, false, gi-\u0026gt;getLinkage(), 0, \u0026#34;llmpx_bnd_\u0026#34;+gvname); gvbnd-\u0026gt;setAlignment(16); gvbnd-\u0026gt;setInitializer(Constant::getNullValue(ArrayTy)); Type* int64ty = IntegerType::get(*ctx,64); Type* int64ptrty = Type::getInt64PtrTy(*ctx); /* * FIXME: the following instruction should be inserted into .init_array */ Constant* lb = ConstantExpr::getPtrToInt(gi, int64ty); std::vector\u0026lt;Constant*\u0026gt; indic_lb; indic_lb.push_back(ConstantInt::get(int64ty,0)); indic_lb.push_back(ConstantInt::get(int64ty,0)); Constant* bnd_lb = ConstantExpr::getGetElementPtr(NULL, gvbnd, indic_lb); Constant* ub = ConstantExpr::getNeg( ConstantExpr::getAdd( ConstantExpr::getPtrToInt(gi, int64ty), ConstantInt::get(int64ty, (allocated_size)))); std::vector\u0026lt;Constant*\u0026gt; indic_ub; indic_ub.push_back(ConstantInt::get(int64ty,0)); indic_ub.push_back(ConstantInt::get(int64ty,1)); Constant* bnd_ub = ConstantExpr::getGetElementPtr( NULL, gvbnd, indic_ub); Instruction* inslb = builder.CreateStore(lb, bnd_lb); Instruction* insub = builder.CreateStore(ub, bnd_ub); gv_bound_checklist[gv] = new std::list\u0026lt;Value*\u0026gt;; gv_bound_checklist[gv]-\u0026gt;push_back(inslb); gv_bound_checklist[gv]-\u0026gt;push_back(insub); gv_bound_checklist[gv]-\u0026gt;push_back(gvbnd); /* * create global key and lock */ if (llmpx_enable_temporal_safety) { std::vector\u0026lt;Value*\u0026gt; args; args.push_back(ConstantExpr::getBitCast(gi,Int8PtrTy)); args.push_back(ConstantInt::get(Type::getInt64Ty(*ctx), (allocated_size))); Value* key = builder.CreateCall(_llmpx_temporal_lock_alloca, args, \u0026#34;llmpx_key.\u0026#34;+gvname); auto* Int64Ty = Type::getInt64Ty(*ctx); GlobalVariable* gvkey = new GlobalVariable(module, Int64Ty, false, gi-\u0026gt;getLinkage(), 0, \u0026#34;llmpx_key_\u0026#34;+gvname); gvkey-\u0026gt;setInitializer(ConstantInt::get(Int64Ty, 0)); Instruction* keystore = builder.CreateStore(key, ConstantExpr::getPointerCast(gvkey, Type::getInt64PtrTy(*ctx))); gv_key_checklist[gv] = new std::list\u0026lt;Value*\u0026gt;; gv_key_checklist[gv]-\u0026gt;push_back(keystore); gv_key_checklist[gv]-\u0026gt;push_back(gvkey); }  process_each_function get_bound Value* get_bound(Value* v, Instruction* I): get bound for the value. If any instruction need to be inserted, should be inserted before I.\n if is a ConstantExpr, :  search gv_bound_checklist_cache, a list of (v,I) pairs for a function. return if found; insert new pair if not found;   search bound_checklist    BOGO, source code. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/trace-cpu/",
	"title": "Trace Cpu",
	"tags": [],
	"description": "",
	"content": " Trace Creation Trace creation example: Create trace after the paddr is ready in the packet.\nin src/cpu/o3/probe/elastic_trace.cc: ElasticTrace::fetchReqTrace.\n// src/cpu/o3/probe/elastic_trace.cc  // Create a protobuf message including the request fields necessary to // recreate the request in the TraceCPU. ProtoMessage::Packet inst_fetch_pkt; inst_fetch_pkt.set_tick(curTick()); inst_fetch_pkt.set_cmd(MemCmd::ReadReq); inst_fetch_pkt.set_pc(req-\u0026gt;getPC()); inst_fetch_pkt.set_flags(req-\u0026gt;getFlags()); inst_fetch_pkt.set_addr(req-\u0026gt;getPaddr()); inst_fetch_pkt.set_size(req-\u0026gt;getSize()); // Write the message to the stream. instTraceStream-\u0026gt;write(inst_fetch_pkt);  Trace reading Trace read example: read one record from trace file and create packet for replay.\nFixedRetryGen class is used to read instruction fetching memory traces, and ElasticDataGen class is used to read data access memory traces.\n TraceCPU::schedIcacheNext() is called as an event EventFunctionWrapper icacheNextEvent. This event is called/scheduled during the initialization of the instruction fetch trace file in TraceCPU::init().\nTraceCPU::schedIcacheNext() will call icacheGen.tryNext(), which is defined as TraceCPU::FixedRetryGen::tryNext(). This method will read a new record from the trace file (via nextExecute()) and compose a packet from the trace and send it down to the icache port (by calling send().\nRelated code shown below:\n// src/cpu/trace/trace_cpu.cc  bool TraceCPU::FixedRetryGen::tryNext() { // If there is a retry packet, try to send it  if (retryPkt) { DPRINTF(TraceCPUInst, \u0026#34;Trying to send retry packet.\\n\u0026#34;); if (!port.sendTimingReq(retryPkt)) { // Still blocked! This should never occur.  DPRINTF(TraceCPUInst, \u0026#34;Retry packet sending failed.\\n\u0026#34;); return false; } ++numRetrySucceeded; } else { DPRINTF(TraceCPUInst, \u0026#34;Trying to send packet for currElement.\\n\u0026#34;); // try sending current element  assert(currElement.isValid()); ++numSendAttempted; if (!send(currElement.addr, currElement.blocksize, currElement.cmd, currElement.flags, currElement.pc)) { DPRINTF(TraceCPUInst, \u0026#34;currElement sending failed.\\n\u0026#34;); ++numSendFailed; // return false to indicate not to schedule next event  return false; } else { ++numSendSucceeded; } } // If packet was sent successfully, either retryPkt or currElement, return  // true to indicate to schedule event at current Tick plus delta. If packet  // was sent successfully and there is no next packet to send, return false.  DPRINTF(TraceCPUInst, \u0026#34;Packet sent successfully, trying to read next \u0026#34; \u0026#34;element.\\n\u0026#34;); retryPkt = nullptr; // Read next element into currElement, currElement gets cleared so save the  // tick to calculate delta  Tick last_tick = currElement.tick; if (nextExecute()) { assert(currElement.tick \u0026gt;= last_tick); delta = currElement.tick - last_tick; } return !traceComplete; } bool TraceCPU::FixedRetryGen::nextExecute() { if (traceComplete) // We are at the end of the file, thus we have no more messages.  // Return false.  return false; //Reset the currElement to the default values  currElement.clear(); // Read the next line to get the next message. If that fails then end of  // trace has been reached and traceComplete needs to be set in addition  // to returning false. If successful then next message is in currElement.  if (!trace.read(\u0026amp;currElement)) { traceComplete = true; instLastTick = curTick(); return false; } DPRINTF(TraceCPUInst, \u0026#34;inst fetch: %c addr %d pc %#x size %d tick %d\\n\u0026#34;, currElement.cmd.isRead() ? \u0026#39;r\u0026#39; : \u0026#39;w\u0026#39;, currElement.addr, currElement.pc, currElement.blocksize, currElement.tick); return true; }  The send() methods will create a packet in Gem5 and send it to icache port. Necessary elements include:\n addr (this is a physical address; we can know it from how the trace is generated above) size flags masterID pc ContextID MemCmd cmd newly allocated space for packet data  if a write request, set the data as 0xA chunks \u0026ndash;\u0026gt; dummy content   Definition of this methods TraceCPU::FixedRetryGen::send() is shown below\n// src/cpu/trace/trace_cpu.cc  bool TraceCPU::FixedRetryGen::send(Addr addr, unsigned size, const MemCmd\u0026amp; cmd, Request::FlagsType flags, Addr pc) { // Create new request  auto req = std::make_shared\u0026lt;Request\u0026gt;(addr, size, flags, masterID); req-\u0026gt;setPC(pc); // If this is not done it triggers assert in L1 cache for invalid contextId  req-\u0026gt;setContext(ContextID(0)); // Embed it in a packet  PacketPtr pkt = new Packet(req, cmd); uint8_t* pkt_data = new uint8_t[req-\u0026gt;getSize()]; pkt-\u0026gt;dataDynamic(pkt_data); if (cmd.isWrite()) { memset(pkt_data, 0xA, req-\u0026gt;getSize()); } // Call MasterPort method to send a timing request for this packet  bool success = port.sendTimingReq(pkt); if (!success) { // If it fails, save the packet to retry when a retry is signalled by  // the cache  retryPkt = pkt; } return success; }  Reference 1\n  src/cpu/trace/trace_cpu.hh/cc ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/mm/",
	"title": "Memory Mapping in GEM5",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Virt to Phy addr in Gem5?\n Binary loading (process creation) in Gem5?\n  Reference 1\nVirtual Memory Management in Gem5 Use ARM as example.\n TLB/Translation in ARM:  src/generic/tlb.hh src/arch/arm/  table_walker.hh/cc tlb.hh/cc    Physical Memory Management in Gem5 To access a memory for the packet in DRAM:\nsrc/mem/dram_ctrl.c: DRAMCtrl::accessAndRespond() -\u0026gt;\nsrc/mem/abstract_mem.cc: AbstractMemory::access():\nTo convert the Gem5 address into host machine address:\nuint8_t *host_addr = toHostAddr(pkt-\u0026gt;getAddr());  The address transformation is simply to add an addent (pmemAddr) to the gem5 address, with tweaked offset according to the memory range starting point. The defined as:\n// src/mem/abstract_mem.hh inline uint8_t * toHostAddr(Addr addr) const { return pmemAddr + addr - range.start(); }  The addent pmemAddr is the starting address for the backing store of this DRAM memory on the host machine. It is set by PhysicalMemory::createBackingStore -\u0026gt; AbstractMemory::setBackingStore. This is done when create the PhysicalMemory physmem; object when creating the System object.\n// src/sim/system.cc System::System(Params *p) : SimObject(p), _systemPort(\u0026#34;system_port\u0026#34;, this), multiThread(p-\u0026gt;multi_thread), pagePtr(0), init_param(p-\u0026gt;init_param), physProxy(_systemPort, p-\u0026gt;cache_line_size), workload(p-\u0026gt;workload), #if USE_KVM  kvmVM(p-\u0026gt;kvm_vm), #else  kvmVM(nullptr), #endif  physmem(name() + \u0026#34;.physmem\u0026#34;, p-\u0026gt;memories, p-\u0026gt;mmap_using_noreserve), memoryMode(p-\u0026gt;mem_mode), _cacheLineSize(p-\u0026gt;cache_line_size), workItemsBegin(0), workItemsEnd(0), numWorkIds(p-\u0026gt;num_work_ids), thermalModel(p-\u0026gt;thermal_model), _params(p), _m5opRange(p-\u0026gt;m5ops_base ? RangeSize(p-\u0026gt;m5ops_base, 0x10000) : AddrRange(1, 0)), // Create an empty range if disabled  totalNumInsts(0), redirectPaths(p-\u0026gt;redirect_paths) {  To copy the data from host_addr to the packet:\npkt-\u0026gt;setData(host_addr);  Phy Memory Mapping in Gem5 Gem5 phy address space (AddrRange, AbstractMemory) \u0026ndash;\u0026gt; mmap \u0026ndash;\u0026gt; host machine address space (Backing stores, host memory blocks, one for each Range/AbstractMemory object)\nSee definition in PhysicalMemory::createBackingStore\n// src/mem/physical.cc  void PhysicalMemory::createBackingStore(AddrRange range, const vector\u0026lt;AbstractMemory*\u0026gt;\u0026amp; _memories, bool conf_table_reported, bool in_addr_map, bool kvm_map) { panic_if(range.interleaved(), \u0026#34;Cannot create backing store for interleaved range %s\\n\u0026#34;, range.to_string()); // perform the actual mmap  DPRINTF(AddrRanges, \u0026#34;Creating backing store for range %s with size %d\\n\u0026#34;, range.to_string(), range.size()); int map_flags = MAP_ANON | MAP_PRIVATE; // to be able to simulate very large memories, the user can opt to  // pass noreserve to mmap  if (mmapUsingNoReserve) { map_flags |= MAP_NORESERVE; } uint8_t* pmem = (uint8_t*) mmap(NULL, range.size(), PROT_READ | PROT_WRITE, map_flags, -1, 0); if (pmem == (uint8_t*) MAP_FAILED) { perror(\u0026#34;mmap\u0026#34;); fatal(\u0026#34;Could not mmap %d bytes for range %s!\\n\u0026#34;, range.size(), range.to_string()); } // remember this backing store so we can checkpoint it and unmap  // it appropriately  backingStore.emplace_back(range, pmem, conf_table_reported, in_addr_map, kvm_map); // point the memories to their backing store  for (const auto\u0026amp; m : _memories) { DPRINTF(AddrRanges, \u0026#34;Mapping memory %s to backing store\\n\u0026#34;, m-\u0026gt;name()); m-\u0026gt;setBackingStore(pmem); } }    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/stats/",
	"title": "Stats",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Gem5 Stats Package ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/guest-ram/code/",
	"title": "Code",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Where is the virt to physical address translated? What is the fast path without tlb?  Addr Translation tlb_vaddr_to_host In accel/tcg/cputlb.c: tlb_vaddr_to_host.\n If tlb hit: return host vaddr as guest physical address. If tlb miss: tlb_fill: Called to resize the TLB. All the caller\u0026rsquo;s prior references to the TLB table must be discard and looked up again via tlb_entry().\n// accel/tcg/cputlb.c: void *tlb_vaddr_to_host(CPUArchState *env, abi_ptr addr, MMUAccessType access_type, int mmu_idx) { CPUTLBEntry *entry = tlb_entry(env, mmu_idx, addr); target_ulong tlb_addr, page; //... page = addr \u0026amp; TARGET_PAGE_MASK; tlb_addr = tlb_read_ofs(entry, elt_ofs); if (!tlb_hit_page(tlb_addr, page)) { uintptr_t index = tlb_index(env, mmu_idx, addr); if (!victim_tlb_hit(env, mmu_idx, index, elt_ofs, page)) { CPUState *cs = env_cpu(env); CPUClass *cc = CPU_GET_CLASS(cs); if (!cc-\u0026gt;tlb_fill(cs, addr, 0, access_type, mmu_idx, true, 0)) { /* Non-faulting page table read failed. */ return NULL; } trace_guest_mem_before_exec(env_cpu(env), addr, 0xbee); /* TLB resize via tlb_fill may have moved the entry. */ entry = tlb_entry(env, mmu_idx, addr); } tlb_addr = tlb_read_ofs(entry, elt_ofs); } if (tlb_addr \u0026amp; ~TARGET_PAGE_MASK) { /* IO access */ return NULL; } void *paddr = (void *)((uintptr_t)addr + entry-\u0026gt;addend); trace_guest_mem_before_exec(env_cpu(env), addr, 0xbdd); trace_guest_mem_before_exec(env_cpu(env), paddr, 0xbdd); return paddr; }  get_page_addr_code_hostp in accel/tcg/cputlb.c: get_page_addr_code_hostp:\n// accel/tcg/cputlb.c: tb_page_addr_t get_page_addr_code_hostp(CPUArchState *env, target_ulong addr, void **hostp) { uintptr_t mmu_idx = cpu_mmu_index(env, true); uintptr_t index = tlb_index(env, mmu_idx, addr); CPUTLBEntry *entry = tlb_entry(env, mmu_idx, addr); void *p; if (unlikely(!tlb_hit(entry-\u0026gt;addr_code, addr))) { if (!VICTIM_TLB_HIT(addr_code, addr)) { tlb_fill(env_cpu(env), addr, 0, MMU_INST_FETCH, mmu_idx, 0); index = tlb_index(env, mmu_idx, addr); entry = tlb_entry(env, mmu_idx, addr); //...  } assert(tlb_hit(entry-\u0026gt;addr_code, addr)); } //...  p = (void *)((uintptr_t)addr + entry-\u0026gt;addend); if (hostp) { *hostp = p; } trace_guest_mem_before_exec(env_cpu(env), addr, 0xbff); trace_guest_mem_before_exec(env_cpu(env), p, 0xbff); return qemu_ram_addr_from_host_nofail(p); } probe_access // accel/tcg/cputlb.c  /* * Probe for whether the specified guest access is permitted. If it is not * permitted then an exception will be taken in the same way as if this * were a real access (and we will not return). * If the size is 0 or the page requires I/O access, returns NULL; otherwise, * returns the address of the host page similar to tlb_vaddr_to_host(). */ void *probe_access(CPUArchState *env, target_ulong addr, int size, MMUAccessType access_type, int mmu_idx, uintptr_t retaddr) CPUTLBEntry: typedef struct CPUTLBEntry { /* bit TARGET_LONG_BITS to TARGET_PAGE_BITS : virtual address bit TARGET_PAGE_BITS-1..4 : Nonzero for accesses that should not go directly to ram. bit 3 : indicates that the entry is invalid bit 2..0 : zero */ union { struct { target_ulong addr_read; target_ulong addr_write; target_ulong addr_code; /* Addend to virtual address to get host address. IO accesses use the corresponding iotlb value. */ uintptr_t addend; }; /* padding to get a power of two size */ uint8_t dummy[1 \u0026lt;\u0026lt; CPU_TLB_ENTRY_BITS]; }; } CPUTLBEntry; TLB Entry Creation accel/tcg/cputlb.c: tlb_set_page_with_attrs()\n Compute the host virtual address for this new RAMBlock, store as addend : addend = (uintptr_t)memory_region_get_ram_ptr(section-\u0026gt;mr) + xlat;\n Subtract the guest virtual addr page number, store in tlb entry\u0026rsquo;s addend: tn.addend = addend - vaddr_page;\n Set other fields, such as addr_read/write/code, etc.\n// accel/tcg/cputlb.c:  /* Add a new TLB entry. At most one entry for a given virtual address * is permitted. Only a single TARGET_PAGE_SIZE region is mapped, the * supplied size is only used by tlb_flush_page. * * Called from TCG-generated code, which is under an RCU read-side * critical section. */ void tlb_set_page_with_attrs(CPUState *cpu, target_ulong vaddr, hwaddr paddr, MemTxAttrs attrs, int prot, int mmu_idx, target_ulong size) { CPUArchState *env = cpu-\u0026gt;env_ptr; CPUTLB *tlb = env_tlb(env); CPUTLBDesc *desc = \u0026amp;tlb-\u0026gt;d[mmu_idx]; MemoryRegionSection *section; uintptr_t addend; CPUTLBEntry *te, tn; hwaddr iotlb, xlat, sz, paddr_page; target_ulong vaddr_page; int asidx = cpu_asidx_from_attrs(cpu, attrs); vaddr_page = vaddr \u0026amp; TARGET_PAGE_MASK; paddr_page = paddr \u0026amp; TARGET_PAGE_MASK; section = address_space_translate_for_iotlb(cpu, asidx, paddr_page, \u0026amp;xlat, \u0026amp;sz, attrs, \u0026amp;prot); assert(sz \u0026gt;= TARGET_PAGE_SIZE); tlb_debug(\u0026#34;vaddr=\u0026#34; TARGET_FMT_lx \u0026#34; paddr=0x\u0026#34; TARGET_FMT_plx \u0026#34; prot=%x idx=%d\\n\u0026#34;, vaddr, paddr, prot, mmu_idx); address = vaddr_page; if (size \u0026lt; TARGET_PAGE_SIZE) { /* Repeat the MMU check and TLB fill on every access. */ address |= TLB_INVALID_MASK; } if (attrs.byte_swap) { address |= TLB_BSWAP; } is_ram = memory_region_is_ram(section-\u0026gt;mr); is_romd = memory_region_is_romd(section-\u0026gt;mr); if (is_ram || is_romd) { /* RAM and ROMD both have associated host memory. */ addend = (uintptr_t)memory_region_get_ram_ptr(section-\u0026gt;mr) + xlat; } else { /* I/O does not; force the host address to NULL. */ addend = 0; } write_address = address; if (is_ram) { iotlb = memory_region_get_ram_addr(section-\u0026gt;mr) + xlat; /* * Computing is_clean is expensive; avoid all that unless * the page is actually writable. */ if (prot \u0026amp; PAGE_WRITE) { if (section-\u0026gt;readonly) { write_address |= TLB_DISCARD_WRITE; } else if (cpu_physical_memory_is_clean(iotlb)) { write_address |= TLB_NOTDIRTY; } } } else { /* I/O or ROMD */ iotlb = memory_region_section_get_iotlb(cpu, section) + xlat; /* * Writes to romd devices must go through MMIO to enable write. * Reads to romd devices go through the ram_ptr found above, * but of course reads to I/O must go through MMIO. */ write_address |= TLB_MMIO; if (!is_romd) { address = write_address; } } index = tlb_index(env, mmu_idx, vaddr_page); te = tlb_entry(env, mmu_idx, vaddr_page); /* * Hold the TLB lock for the rest of the function. We could acquire/release * the lock several times in the function, but it is faster to amortize the * acquisition cost by acquiring it just once. Note that this leads to * a longer critical section, but this is not a concern since the TLB lock * is unlikely to be contended. */ qemu_spin_lock(\u0026amp;tlb-\u0026gt;c.lock); /* Note that the tlb is no longer clean. */ tlb-\u0026gt;c.dirty |= 1 \u0026lt;\u0026lt; mmu_idx; /* Make sure there\u0026#39;s no cached translation for the new page. */ tlb_flush_vtlb_page_locked(env, mmu_idx, vaddr_page); /* * Only evict the old entry to the victim tlb if it\u0026#39;s for a * different page; otherwise just overwrite the stale data. */ if (!tlb_hit_page_anyprot(te, vaddr_page) \u0026amp;\u0026amp; !tlb_entry_is_empty(te)) { unsigned vidx = desc-\u0026gt;vindex++ % CPU_VTLB_SIZE; CPUTLBEntry *tv = \u0026amp;desc-\u0026gt;vtable[vidx]; /* Evict the old entry into the victim tlb. */ copy_tlb_helper_locked(tv, te); desc-\u0026gt;viotlb[vidx] = desc-\u0026gt;iotlb[index]; tlb_n_used_entries_dec(env, mmu_idx); } /* refill the tlb */ /* * At this point iotlb contains a physical section number in the lower * TARGET_PAGE_BITS, and either * + the ram_addr_t of the page base of the target RAM (RAM) * + the offset within section-\u0026gt;mr of the page base (I/O, ROMD) * We subtract the vaddr_page (which is page aligned and thus won\u0026#39;t * disturb the low bits) to give an offset which can be added to the * (non-page-aligned) vaddr of the eventual memory access to get * the MemoryRegion offset for the access. Note that the vaddr we * subtract here is that of the page base, and not the same as the * vaddr we add back in io_readx()/io_writex()/get_page_addr_code(). */ desc-\u0026gt;iotlb[index].addr = iotlb - vaddr_page; desc-\u0026gt;iotlb[index].attrs = attrs; /* Now calculate the new entry */ tn.addend = addend - vaddr_page; if (prot \u0026amp; PAGE_READ) { tn.addr_read = address; if (wp_flags \u0026amp; BP_MEM_READ) { tn.addr_read |= TLB_WATCHPOINT; } } else { tn.addr_read = -1; } if (prot \u0026amp; PAGE_EXEC) { tn.addr_code = address; } else { tn.addr_code = -1; } tn.addr_write = -1; if (prot \u0026amp; PAGE_WRITE) { tn.addr_write = write_address; if (prot \u0026amp; PAGE_WRITE_INV) { tn.addr_write |= TLB_INVALID_MASK; } if (wp_flags \u0026amp; BP_MEM_WRITE) { tn.addr_write |= TLB_WATCHPOINT; } } copy_tlb_helper_locked(te, \u0026amp;tn); tlb_n_used_entries_inc(env, mmu_idx); qemu_spin_unlock(\u0026amp;tlb-\u0026gt;c.lock); }  TLB hit test Given a virtual address, get its page number.\nGet TLB entry for the virtual address, get tlb.addr_read/write/code field, the virtual address in tlb entry.\nGet the page number of the virtual address of guest, and test valid bit.\nIf valid tlb entry, and the page number matches, then TLB hit.\nThe physical address is virtual addr + tlb.addend.\n/** * tlb_hit_page: return true if page aligned @addr is a hit against the * TLB entry @tlb_addr * * @addr: virtual address to test (must be page aligned) * @tlb_addr: TLB entry address (a CPUTLBEntry addr_read/write/code value) */ static inline bool tlb_hit_page(target_ulong tlb_addr, target_ulong addr) { // Get the page number of the virtual address of guest,  // and test valid bit.  // If valid tlb entry, and the page number matches, then TLB hit.  return addr == (tlb_addr \u0026amp; (TARGET_PAGE_MASK | TLB_INVALID_MASK)); } /** * tlb_hit: return true if @addr is a hit against the TLB entry @tlb_addr * * @addr: virtual address to test (need not be page aligned) * @tlb_addr: TLB entry address (a CPUTLBEntry addr_read/write/code value) */ static inline bool tlb_hit(target_ulong tlb_addr, target_ulong addr) { return tlb_hit_page(tlb_addr, addr \u0026amp; TARGET_PAGE_MASK); } Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/guest-ram/",
	"title": "Guest RAM",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How can we convert a virt addr in QEMU to a (faked) physical addr?  Reference 1 2\nMemory Regions Entire physical memory is modelled as an acyclic graph of MemoryRegion objects 1. Sinks(leaves) are RAM and MIMO regions. While other nodes represents buses, memory controllers, and memory regions that have been rerouted.\nIn addition to MemoryRegsion objects, the memory API provides AddressSpace objects for every root and possibly for intermediate MemoryRegsions too. These represent memory as seen from the CPU or a device\u0026rsquo;s viewpoint.\nTypes of Regions All are C type MemoryRegion:\n RAM. A range of host memory available to the guest. Init with  memory_region_init_ram(), or memory_region_init_resizeable_ram(), memory_region_init_ram_from_file(), memory_region_init_ram_ptr()  MIMO. A range of guest memory that is implemented by host callbacks; each read and write cause a callback to be called on the host. Init with memory_region_init_io(), passing it a MemoryRegsionOps structure describing the callbacks. ROM. A ROM memory region works like RAM for reads(directly accessing a region of a host memory), and forbids writes. Init with memory_region_init_rom(). ROM device. A memory region can be read like RAM, and written like MMIO (via callbacks). Init with memory_region_init_rom_device. IOMMU. Address translation, and forwards access to other target memory region. Only for IOMMU, not for simple device. Init with memory_region_init_iommu(). container. A container is a set of other memory regions, each with a different offset. Containers are useful for grouping several regions into one unit. For example, a PCI BAR may be composed of a RAM region and an MMIO region. Different containers can contain overlapped regions: for example a memory controller that can overlay a subregion of RAM with MMIO or ROM, or a PCI controller that does not prevent card from claiming overlapping BARs. Init with memory_region_init(). alias. A subsection of another region. Aliases allow a region to be split apart into discontiguous regions. Examples of uses are memory banks used when the guest address space is smaller than the amount of RAM addressed, or a memory controller that splits main memory to expose a \u0026ldquo;PCI hole\u0026rdquo;. Aliases may point to any type of region, including other aliases, but an alias may not point back to itself, directly or indirectly. You initialize these with memory_region_init_alias(). reservation region. A reservation region is primarily for debugging. It claims I/O space that is not supposed to be handled by QEMU itself. The typical use is to track parts of the address space which will be handled by the host kernel when KVM is enabled. You initialize these by passing a NULL callback parameter to memory_region_init_io().  Example Memory Map (simplified): system_memory: container@0-2^48-1 | +---- lomem: alias@0-0xdfffffff ---\u0026gt; #ram (0-0xdfffffff) | +---- himem: alias@0x100000000-0x11fffffff ---\u0026gt; #ram (0xe0000000-0xffffffff) | +---- vga-window: alias@0xa0000-0xbffff ---\u0026gt; #pci (0xa0000-0xbffff) | (prio 1) | +---- pci-hole: alias@0xe0000000-0xffffffff ---\u0026gt; #pci (0xe0000000-0xffffffff) pci (0-2^32-1) | +--- vga-area: container@0xa0000-0xbffff | | | +--- alias@0x00000-0x7fff ---\u0026gt; #vram (0x010000-0x017fff) | | | +--- alias@0x08000-0xffff ---\u0026gt; #vram (0x020000-0x027fff) | +---- vram: ram@0xe1000000-0xe1ffffff | +---- vga-mmio: mmio@0xe2000000-0xe200ffff ram: ram@0x00000000-0xffffffff  Above is a (simplified) PC memory map. The 4GB RAM block is mapped into the system address space via two aliases: \u0026ldquo;lomem\u0026rdquo; is a 1:1 mapping of the first 3.5GB; \u0026ldquo;himem\u0026rdquo; maps the last 0.5GB at address 4GB. This leaves 0.5GB for the so-called PCI hole, that allows a 32-bit PCI bus to exist in a system with 4GB of memory.\nThe memory controller diverts addresses in the range 640K-768K to the PCI address space. This is modelled using the \u0026ldquo;vga-window\u0026rdquo; alias, mapped at a higher priority so it obscures the RAM at the same addresses. The vga window can be removed by programming the memory controller; this is modelled by removing the alias and exposing the RAM underneath.\nThe pci address space is not a direct child of the system address space, since we only want parts of it to be visible (we accomplish this using aliases). It has two subregions: vga-area models the legacy vga window and is occupied by two 32K memory banks pointing at two sections of the framebuffer. In addition the vram is mapped as a BAR at address e1000000, and an additional BAR, vga-mmio, containing MMIO registers is mapped after it.\nRegion Lifecycle A region is created by one of memory_region_init* functions and attached to an object, which act as its owner or parent.\nA region can be added to an address space or a container with memory_region_add_subregion(), and removed using memory_region_del_subregion()\nOverlapping Regions and Priority Priority: 2\u0026gt;1\n 0 1000 2000 3000 4000 5000 6000 7000 8000 |------|------|------|------|------|------|------|------| A: [ ] C: [CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC] B: [ ] D: [DDDDD] E: [EEEEE]  Container A@0x0 \u0026ndash; 0x8000. Region C @0x0 \u0026ndash; 0x6000, priority 1.\nContainer B@0x2000 \u0026ndash; 0x6000, priority 2. Region D @0x0 \u0026ndash; 0x1000, E @ 0x2000 \u0026ndash; 0x3000\nThe regions will be seen within this address range:\n[CCCCCCCCCCCC][DDDDD][CCCCC][EEEEE][CCCCC]  Overlap created in memory_region_add_subregion_overlap()\nPriority can be set in any regions, RAM, containers, alias, etc..\nVisibility Rules to select a memory region when the guest accesses an address:\n all direct subregions of the root region are matched against the address, in descending priority order\n if the address lies outside the region offset/size, the subregion is discarded if the subregion is a leaf (RAM or MMIO), the search terminates, returning this leaf region if the subregion is a container, the same algorithm is used within the subregion (after the address is adjusted by the subregion offset) if the subregion is an alias, the search is continued at the alias target (after the address is adjusted by the subregion offset and alias offset) if a recursive search within a container or alias subregion does not find a match (because of a \u0026ldquo;hole\u0026rdquo; in the container\u0026rsquo;s coverage of its address range), then if this is a container with its own MMIO or RAM backing the search terminates, returning the container itself. Otherwise we continue with the next subregion in priority order  if none of the subregions match the address then the search terminates with no match found\n  From the Blog2: Implementation:\nGuest RAM: memory backend (-m [size=]megs) + hotpluggable guest memory (DIMM, pc-dimm, slots=n, maxmem=size)\nThe \u0026ldquo;pc-dimm\u0026rdquo; and \u0026ldquo;memory-backend\u0026rdquo; objects are user-visible parts of guest RAM in QEMU. They can be managed using the QEMU command-line and QMP monitor interface.\nHotpluggable guest physical mem Defined in hw/mem/pc-dimm.c. A pc-dimm device models a DIMM.\nA pc-dimm must be associated with a \u0026ldquo;memory-backend\u0026rdquo; object.\nMemory backends Defined in backends/hostmem.c\nContains the actual host memory that backs guest RAM. Can either be anonymous mmapped memory or file-backed mmapped memory. (File-backed guest RAM allows Linux hugetlbfs usage for huge pages on the host and also shared-memory so other host applications can access to guest RAM).\nRAMBlock:\nMemory inside a \u0026ldquo;memory-backend\u0026rdquo; is acutally mmapped by RAMBlock through qemu_ram_alloc() in exec.c. Each RAMBlock has a pointer to the mmap memory and also a ram_addr_t offset. The ram_addr_t offset is in the global namespace and is used to identify the RAMBlock.\nHowever, ram_addr_t namespace is just a part of the entire guest physical memory space. It is tightly packed address space containing all RAMBlocks. But some guest physical memory regions, such as reserved memory, memory mapped I/O, etc., are not being identified by ram_addr_t.\nAll RAMBlocks are in a global list RAMList.\nDefinition of RAMBlock\n// include/exec/ramblock.h  struct RAMBlock { struct rcu_head rcu; struct MemoryRegion *mr; uint8_t *host; uint8_t *colo_cache; /* For colo, VM\u0026#39;s ram cache */ ram_addr_t offset; // Lele: offset used for dirty bitmap  ram_addr_t used_length; ram_addr_t max_length; void (*resized)(const char*, uint64_t length, void *host); uint32_t flags; /* Protected by iothread lock. */ char idstr[256]; /* RCU-enabled, writes protected by the ramlist lock */ QLIST_ENTRY(RAMBlock) next; QLIST_HEAD(, RAMBlockNotifier) ramblock_notifiers; int fd; size_t page_size; /* dirty bitmap used during migration */ unsigned long *bmap; /* bitmap of already received pages in postcopy */ unsigned long *receivedmap; /* Bitmap of CHERI tag bits */ struct CheriTagMem *cheri_tags; /* * bitmap to track already cleared dirty bitmap. When the bit is * set, it means the corresponding memory chunk needs a log-clear. * Set this up to non-NULL to enable the capability to postpone * and split clearing of dirty bitmap on the remote node (e.g., * KVM). The bitmap will be set only when doing global sync. * * NOTE: this bitmap is different comparing to the other bitmaps * in that one bit can represent multiple guest pages (which is * decided by the `clear_bmap_shift\u0026#39; variable below). On * destination side, this should always be NULL, and the variable * `clear_bmap_shift\u0026#39; is meaningless. */ unsigned long *clear_bmap; uint8_t clear_bmap_shift; };  Definition of MemoryRegion:\n// include/exec/memory.h  /** MemoryRegion: * * A struct representing a memory region. */ struct MemoryRegion { Object parent_obj; /* private: */ /* The following fields should fit in a cache line */ bool romd_mode; bool ram; bool subpage; bool readonly; /* For RAM regions */ bool nonvolatile; bool rom_device; bool flush_coalesced_mmio; bool global_locking; uint8_t dirty_log_mask; bool is_iommu; RAMBlock *ram_block; Object *owner; const MemoryRegionOps *ops; void *opaque; MemoryRegion *container; Int128 size; hwaddr addr; void (*destructor)(MemoryRegion *mr); uint64_t align; bool terminates; bool ram_device; bool enabled; bool warning_printed; /* For reservations */ uint8_t vga_logging_count; MemoryRegion *alias; hwaddr alias_offset; int32_t priority; QTAILQ_HEAD(, MemoryRegion) subregions; QTAILQ_ENTRY(MemoryRegion) subregions_link; QTAILQ_HEAD(, CoalescedMemoryRange) coalesced; const char *name; unsigned ioeventfd_nb; MemoryRegionIoeventfd *ioeventfds; };   Code  Q\u0026amp;A Where is the virt to physical address translated? What is the fast path without tlb? Addr Translation tlb_vaddr_to_host In accel/tcg/cputlb.c: tlb_vaddr_to_host. If tlb hit: return host vaddr as guest physical address. If tlb miss: tlb_fill: Called to resize the TLB. All the caller\u0026rsquo;s prior references to the TLB table must be discard and looked up again via tlb_entry(). // accel/tcg/cputlb.c: void *tlb_vaddr_to_host(CPUArchState *env, abi_ptr addr, MMUAccessType access_type, int mmu_idx) { CPUTLBEntry *entry = tlb_entry(env, mmu_idx, addr); target_ulong tlb_addr, page; //.\n  docs/devel/memory.txt ↩ QEMU Internals: How guest physical RAM works ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/basics/memory-manage/",
	"title": "Memory Management",
	"tags": [],
	"description": "",
	"content": "Reference 1\nLayout of FreeBSD process in memory and on disk:\n![figure-3-3. Layout of FreeBSD process in memory and on disk]\nTo begin execution of a binary file, kernel:\n Text portion of the binary is mapped into the low part of the process\u0026rsquo;s address space. (The first page of the address space is marked as invalid, so that attempts to read or write through a null pointer will fault) Initilized data portion of the file is mapped into the address space following the text. Uninitialized region is mapped with zero-filled memory after the initialized data region. The stack is also created from zero-filled memory. (zero-fill stack to avoid misuse previous old process\u0026rsquo;s content)  Demanding paging is used to avoid copying into memory the entire text and initialized data portion of a large program:\n Program is loaded in small pieces(pages) as it is needed rather than all at once before it begins execution. For each page, the kernel records the offset into the executable file of the corresponding data. The first access on each page cause a page-fault trap in the kernel. The page-fault handler reads the correct page of the executable file into the memory  sbrk used to extend uninitialized data area with zero-filled pages. Grows from the initialized data segment. Called Heap.\nAbove the user stack are areas of memory that created by the system when the process is started.\n number of arguments (argc) pointer of argument vector (argv) pointer of processor env vector (envp) argument and environment strings signal code, used when system delivers signals to the process. finally the ps_strings structure, used by ps the locate the argv of the process.  Shared libraries:\n When the executable is run, a set of shared libraries containing the routines that is needs to use are mapped into its address space as part of its startup.  convention is to map then just below the lower limit of the stack, since stack is not allowd to grow below the limit. But if the stack needs grow during execution, process must be restarted by itself (exec) with a larger stack and replace shared library. alternatively, place shared lib just above the heap limit. But this means heap cannot increase its limit during normal execution. Therefore, FreeBSD chooses to put shared lib below stack limit.  The first time it calls a routine, that routine is located in the shared library and a dynamic linkage is created to it.    FreeBSD Book. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/traffic-gen/",
	"title": "Traffic Gen",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to run traffic gen   \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;   Overview  (src/cpu/testers/traffic_gen/traffic_gen.hh) describes a state transition graph where each state is a specific generator behaviour. Examples include idling, generating linear address sequences, random sequences and replay of captured traces. By describing these behaviours as states, it is straight forward to create very complex behaviours, simply by arranging them in graphs. The graph transitions can also be annotated with probabilities, effectively making it a Markov Chain.\n Example Usage in configs/dram/lat_mem_rd.py\n This script is helpful to observe the memory latency for various levels in a cache hierarchy, and various cache and memory configurations, in essence replicating the lmbench lat_mem_rd thrash behavior\n  Collect memory traces. This script create random trace by iteself.  in create_trace(filename, max_addr, burst_size, itt) with names like lat_mem_rd0.trc.gz  Create config file for TrafficGen.  Put the trace file name in cfg file: STATE 0 153600000 TRACE m5out/lat_mem_rd0.trc.gz 0  Create TrafficGen: system.tgen = TrafficGen(...) Configure port connection: system.tgen.port = system.monitor.slave. System monitor is connected to L1_DCache: system.monitor.master = system.l1cache.cpu_side  Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/memobj/",
	"title": "Memory Objects in Gem5",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How does the memory request generated?  From CPU: system.cpu = TimingSimpleCPU() see src/cpu/simple/timing.hh/cc CPU Ports: I/DcachePort -\u0026gt; TimingCPUPort -\u0026gt; MasterPort` Instruction Fetch request:  TimingSimpleCPU::advanceInst \u0026gt;\u0026gt; fetch() \u0026gt;\u0026gt; thread-\u0026gt;itb-\u0026gt;translateTiming \u0026gt;\u0026gt; translateTiming.finish() \u0026gt;\u0026gt; sendFetch TimingSimpleCPU::schedule \u0026gt;\u0026gt; fetch() \u0026gt;\u0026gt; \u0026hellip; \u0026gt;\u0026gt; sendFetch  Instruction Fetch response:  TimingSimpleCPU::IcachePort::recvTimingResp \u0026gt;\u0026gt; tickEvent.schedule \u0026gt;\u0026gt; cpu-\u0026gt;schedule ?  Instruction Exec:  ?   What is the binary to be executed in the simple mem object simulation?  tests/test-progs/hello/bin/x86/linux/hello  How does binary loaded?  Reference 1\nAn example memory System with a simple memory object which sits between CPU and memory bus\nA simple master-slave interaction when both can accept the request and response:\nSimple master-slave interaction when slave is busy:\nSimple master-slave interaction when master is busy:\nOverview of all the ports for the simple memory object:\n  Creating SimObjects in the memory system ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/extending/",
	"title": "Extending",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to replay the memory trace?\n How to add a last level cache/cache controller?\n  Creating SimObject\nEvent-driven Programming in Gem5\nDebug Printing in Gem5\nReference 1\n  https://www.gem5.org/documentation/learning_gem5/part2/environment/ ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/",
	"title": "Gem5",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How does the simulator load the binary into the memory for execution?  Reference 1\nA memory object:\nExample system configurations in gem5/configs/:\ngem5/configs/boot/: for Full-System mode. rcS files. These files will be loaded by the simulator after Linux boots and are executed by the shell.\ngem5/configs/common/:\n Caches.py: example cache configuration. Options.py: a script to set a variety of options, such as  number of CPUs system clock \u0026hellip;  CacheConfig.py: setting cache parameters for the classic memory system. MemConfig.py: helper functions for setting the memory system. FSConfig.py: Full-System simulation settings.  see full-system chapter.  Simulation.py: gem5 settings.  saving/restoring checkpoints;   gem5/configs/dram/: scripts to test DRAM.\ngem5/configs/example/: examples to run gem5 out-of-box\n se.py fs.py  gem5/configs/ruby/: Configuration scripts for Ruby cache coherence protocols.\ngem5/configs/splash2/: Scripts to run splash2 benchmark suite.\ngem5/configs/topologies/: impl of the topologies used in Ruby cache hierarchy.\nse.py and fs.py Optioins in Options.py:addCommonOptions(\u0026hellip;)\nTo run:\n# atomic cpu and memory (no real timing) build/X86/gem5.opt configs/example/se.py --cmd=tests/test-progs/hello/bin/x86/linux/hello # enable timing mode option build/X86/gem5.opt configs/example/se.py --cmd=tests/test-progs/hello/bin/x86/linux/hello --cpu-type=TimingSimpleCPU --l1d_size=64kB --l1i_size=16kB --caches Common Options for se.py and fs.py  --cpu-type= --sys-clock= --cpu-clock= --mem-type= --caches --l2cache --ruby -m TICKS, --abs-max-tick=TICKS: total ticks to run simulation. -I MAXINSTS, --maxinsts=: total number of instructions to simulate. c CMD, --cmd= the binary to run in syscall emulation mode. -o OPTIONS, --options=: option passed to binary. --output=: redirect the stdout of the simulated application to a file. errout=: similar to above but stderr is redirected to a file.   Trace Cpu  Trace Creation Trace creation example: Create trace after the paddr is ready in the packet. in src/cpu/o3/probe/elastic_trace.cc: ElasticTrace::fetchReqTrace. // src/cpu/o3/probe/elastic_trace.cc // Create a protobuf message including the request fields necessary to // recreate the request in the TraceCPU. ProtoMessage::Packet inst_fetch_pkt; inst_fetch_pkt.set_tick(curTick()); inst_fetch_pkt.set_cmd(MemCmd::ReadReq); inst_fetch_pkt.set_pc(req-\u0026gt;getPC()); inst_fetch_pkt.set_flags(req-\u0026gt;getFlags()); inst_fetch_pkt.set_addr(req-\u0026gt;getPaddr()); inst_fetch_pkt.set_size(req-\u0026gt;getSize()); // Write the message to the stream. instTraceStream-\u0026gt;write(inst_fetch_pkt); Trace reading Trace read example: read one record from trace file and create packet for replay.\n Memory Mapping in GEM5  Q\u0026amp;A Virt to Phy addr in Gem5? Binary loading (process creation) in Gem5? Reference 1 Virtual Memory Management in Gem5 Use ARM as example. TLB/Translation in ARM: src/generic/tlb.hh src/arch/arm/ table_walker.hh/cc tlb.hh/cc Physical Memory Management in Gem5 To access a memory for the packet in DRAM: src/mem/dram_ctrl.c: DRAMCtrl::accessAndRespond() -\u0026gt; src/mem/abstract_mem.cc: AbstractMemory::access(): To convert the Gem5 address into host machine address:\n Stats  Reference 1 Gem5 Stats Package ↩  Traffic Gen  Q\u0026amp;A How to run traffic gen \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; Overview (src/cpu/testers/traffic_gen/traffic_gen.hh) describes a state transition graph where each state is a specific generator behaviour. Examples include idling, generating linear address sequences, random sequences and replay of captured traces. By describing these behaviours as states, it is straight forward to create very complex behaviours, simply by arranging them in graphs. The graph transitions can also be annotated with probabilities, effectively making it a Markov Chain.\n Memory Objects in Gem5  Q\u0026amp;A How does the memory request generated? From CPU: system.cpu = TimingSimpleCPU() see src/cpu/simple/timing.hh/cc CPU Ports: I/DcachePort -\u0026gt; TimingCPUPort -\u0026gt; MasterPort` Instruction Fetch request: TimingSimpleCPU::advanceInst \u0026gt;\u0026gt; fetch() \u0026gt;\u0026gt; thread-\u0026gt;itb-\u0026gt;translateTiming \u0026gt;\u0026gt; translateTiming.finish() \u0026gt;\u0026gt; sendFetch TimingSimpleCPU::schedule \u0026gt;\u0026gt; fetch() \u0026gt;\u0026gt; \u0026hellip; \u0026gt;\u0026gt; sendFetch Instruction Fetch response: TimingSimpleCPU::IcachePort::recvTimingResp \u0026gt;\u0026gt; tickEvent.schedule \u0026gt;\u0026gt; cpu-\u0026gt;schedule ? Instruction Exec: ? What is the binary to be executed in the simple mem object simulation?\n Extending   Q\u0026amp;A How to replay the memory trace? How to add a last level cache/cache controller? Creating SimObject Event-driven Programming in Gem5 Debug Printing in Gem5 Reference 1 https://www.gem5.org/documentation/learning_gem5/part2/environment/ ↩  Fs   References: 2018 thesis: Simulation of RISC-V based Systems in gem5, by Robert Scheffel Full System: peripheral devices: UART, Timers More  Ruby   References: Introduction to Ruby SLICC: a domain-specific language (Specification Language including Cache Coherence) for specifying coherence protocols. Files end in .sm for state machine files. Each state machine file describes states, transitions from a begin to an end state on some event, and actions to take during the transition. Coherance protocol (in SLICC) --\u0026gt; SLICC compiler (in Python/gem5) --\u0026gt; C++ files with gem5 (SimObjects, etc.) More  O3 CPU  References: O3CPU Out of order CPU model loosely based on the Alpha 21264. Fetch Fetch instructions each cycle; Create DynInst Branch prediction Decode Decode instructions each cycle; Early resolution of PC-relative unconditional branches Rename Rename instructions using a physical register file with a free list Stall when no regs to rename to, or back-end resources have filled up Issue/Execute/Writeback Three stages combined in one stage, IEW, using execute() function Dispatching instructions to the instruction queue Telling the instruction queue to issue instruction Executing and write back instructions Commit Commit instructions each cycle; Handling any faults that the instructions may have caused; Also handles redirecting the front-end in the case of a branch misprediction.\n Arch Supports in gem5  References: From the outdated docs: Architecture Support. x86 A generic x86 CPU, with 64 bit extensions; More similar to AMD\u0026rsquo;s version of the arch than Intel\u0026rsquo;s but not strictly like either; Unmodified versions of Linux kernel can be booted in UP and SMP configurations; patches are available for speeding up boot; SSE/3dnow are implemented; no majority of x87 floating point; syscall emulation mode: both 64 and 32 bit binaries; ARM\n Gem5 KVM  References: x86 Full System Tutorial Tutorial: Run SPEC CPU 2017 / SPEC CPU 2006 Benchmarks in full System Mode with gem5art \u0026ldquo;gem5 features a KVM-based CPU that uses virtualisation to accelerate simulation.\u0026rdquo; In this tutorial we will build an X86 simulation, capable of running a full-system simulation, booting an Ubuntu operating system, and running a benchmark. This system will utilize gem5’s ability to switch cores, allowing booting of the operating system in KVM fast-forward mode and switching to a detailed CPU model to run the benchmark, and use a MESI Two Level Ruby cache hierarchy in a dual-core setup.\n  http://learning.gem5.org/book/index.html ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/memtrace/simple/",
	"title": "Simple",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  What kind of operations the guest_mem_before_exec trace?  trace the virtual address when the CPU access the memory  Load cap: no mem trace when TLB hit(probe_read). A bug?  probably no. A TLB hit means the table entry already loaded into TLB. Loading this entry can only be counted once as a memory access.   guest_mem_before_exec Event format def The def of trace event:\n# tcg/tcg-op.c # @vaddr: Access\u0026#39; virtual address. # @info : Access\u0026#39; information (see below). # # Start virtual memory access (before any potential access violation). # # Does not include memory accesses performed by devices. # # Access information can be parsed as: # # struct mem_info { # uint8_t size_shift : 4; /* interpreted as \u0026#34;1 \u0026lt;\u0026lt; size_shift\u0026#34; bytes */ # bool sign_extend: 1; /* sign-extended */ # uint8_t endianness : 1; /* 0: little, 1: big */ # bool store : 1; /* whether it is a store operation */ # pad : 1; # uint8_t mmuidx : 4; /* mmuidx (softmmu only) */ # }; # # Mode: user, softmmu # Targets: TCG(all) vcpu tcg guest_mem_before(TCGv vaddr, uint16_t info) \u0026#34;info=%d\u0026#34;, \u0026#34;vaddr=0x%016\u0026#34;PRIx64\u0026#34; info=%d\u0026#34; The function def of trace_guest_mem_before_exec/trans is auto generated during qemu build to print out the trace info with above format.\nEvent handling code Event handling code is automatically generated. It is where the trace information got written to the trace file.\n// qemu-build/trace-root.c void _simple_trace_guest_mem_before_exec(CPUState * __cpu, uint64_t vaddr, uint16_t info) { TraceBufferRecord rec; if (!true) { return; } if (trace_record_start(\u0026amp;rec, _TRACE_GUEST_MEM_BEFORE_EXEC_EVENT.id, 8 + 8 + 8)) { return; /* Trace Buffer Full, Event Dropped ! */ } trace_record_write_u64(\u0026amp;rec, (uintptr_t)(uint64_t *)__cpu); trace_record_write_u64(\u0026amp;rec, (uint64_t)vaddr); trace_record_write_u64(\u0026amp;rec, (uint64_t)info); trace_record_finish(\u0026amp;rec); }  Event hook points accel/tcg/cputlb.c: cpu_ldub/ldsb/lduw/ldsw/ldl/ldq_data_ra -\u0026gt; cpu_ldub/ldsb/lduw/ldsw/ldl/ldq/_mmuidx_ra -\u0026gt; cpu_load/store_helper -\u0026gt; trace_guest_mem_before_exec\naccel/tcg/cputlb.c: cpu_ldq_cap_data_ra -\u0026gt; cpu_load/store_helper -\u0026gt; trace_guest_mem_before_exec\naccel/tcg/use-exec.c: cpu_ldub/ldsb/lduw/ldsw/ldl/ldq/stb/stw/stl/stq_data -\u0026gt; trace_guest_mem_before_exec\naccel/atomic_common.inc.c: atomic_trace_rmw/ld/st_pre -\u0026gt; trace_guest_mem_before_exec\nCap related hooking: target/mips/op_helper_cheri.c: load_cap_from_memory() -\u0026gt;accel/tcg/cputlb.c: cpu_ldq_data_ra -\u0026gt; cpu_ldq_mmuidx_ra -\u0026gt; trace_guest_mem_before_exec\ntarget/cheri-common/op_helper_cheri_common.c: load_cap_from_memory_128: -\u0026gt; accel/tcg/cputlb.c: cpu_ldq_cap_data_ra -\u0026gt; cpu_load/store_helper -\u0026gt; trace_guest_mem_before_exec: \u0026ldquo;avoid logging memory accesses that load capability components as normal memory accesses.\u0026rdquo;\n???? Will not trace if a TLB hit happens. Is this a missing trace point in target/cheri-common/op_helper_cheri_common.c: load_cap_from_memory_128:\n// target/cheri-common/op_helper_cheri_common.c:  bool load_cap_from_memory_128(CPUArchState *env, uint64_t *pesbt, uint64_t *cursor, uint32_t cb, const cap_register_t *source, target_ulong vaddr, target_ulong retpc, hwaddr *physaddr) { ... void *host = probe_read(env, vaddr, CHERI_CAP_SIZE, cpu_mmu_index(env, false), retpc); // When writing back pesbt we have to XOR with the NULL mask to ensure that  // NULL capabilities have an all-zeroes representation.  if (likely(host)) { // Fast path, host address in TLB  // Lele: tracing needed here  *pesbt = ldq_p((char *)host + CHERI_MEM_OFFSET_METADATA) ^ CC128_NULL_XOR_MASK; *cursor = ldq_p((char *)host + CHERI_MEM_OFFSET_CURSOR); } else { // Slow path for e.g. IO regions.  qemu_maybe_log_instr_extra(env, \u0026#34;Using slow path for load from guest \u0026#34; \u0026#34;address \u0026#34; TARGET_FMT_plx \u0026#34;\\n\u0026#34;, vaddr); *pesbt = cpu_ldq_cap_data_ra(env, vaddr + CHERI_MEM_OFFSET_METADATA, retpc) ^ CC128_NULL_XOR_MASK; *cursor = cpu_ldq_cap_data_ra(env, vaddr + CHERI_MEM_OFFSET_CURSOR, retpc); } ... } Similarly, probe_read also used in:\n target/arm/helper.c:dccvap_writefn(): haddr = probe_read(...)  Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/memtrace/",
	"title": "Memtrace",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Simple  Q\u0026amp;A What kind of operations the guest_mem_before_exec trace? trace the virtual address when the CPU access the memory Load cap: no mem trace when TLB hit(probe_read). A bug? probably no. A TLB hit means the table entry already loaded into TLB. Loading this entry can only be counted once as a memory access. guest_mem_before_exec Event format def The def of trace event: # tcg/tcg-op.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/rust/oxide/",
	"title": "Oxide: The Essence of Rust",
	"tags": [],
	"description": "",
	"content": "Reference 1\n at its heart lies a novel approach to ownership that balances type system expressively with usability.\nRust integrates decades of programming languages research into a production system.\n   Oxide: The Essence of Rust. 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/example-csc/",
	"title": "Example CSC",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How a store cap via cap instruction got implemented in a processor?  ISAv7\nCSC: Store Capability via Capability\nCSC cs,rt,offset(cb) CSCR cs,rt(cb) CSCI cs,offset(cb)  Cap register cs is stored at the memory location of cb.base + cb.offset + rt + 16*offset\n| Bit | size | value | |\u0026mdash;\u0026mdash;-|\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026ndash;| | 31-26 | 6 | 0x3e | | 25-21 | 5 | cs | | 20-16 | 5 | cb | | 15-11 | 5 | rt | | 10-0 | 11 | offset |\nDecode enq(ControlTokenT ct):\ndecodeInstruction(ControlToken i, MIPSReg rc, MIPSReg pc):\ncheck i.inst: 4 categories: Immediate, Jump, Register, Coprocessor; return new control token di\nRegister .ri: check opcode ri.op (6 bits)\n SPECIAL: decodeSpecial SPECIAL2: decodeSpecial2 SPECIAL3: check func field ri.f  if ri.f is RDHWR: if rd is 0-14/29/30: opA=rc \u0026amp; 64'hFFFF  CP0: \u0026hellip;  Coprocessor .ci: check opcode ci.op (6 bits)\n COP1, COP3 COP2, LWC2, LDC2, SWC2 (0x3a), SDC2 (0x3e):  check cp2 enabled or not: cpEn.cu2: if zero will throw exception. if COP2: check ci.cOp:  if CBTS, CBTU, CBEZ, CBNZ: reset the instruction type to be Immediate: di.inst = tagged Immediate unpack(pack(ci)) if CJALR: set second operand to be pc+8; CClear:  create a mask of all ones; cast instruction to immediate instruction; check ci.r1 0/1/2/3: determine 15 registers to clear: 15-0/31-16 regular regs; or 15-0/31-16 cap regs. Update mask accordingly. set first operand to be the mask value: di.opA = zeroExtend(mask)     Execute input ControkTokenT di: enq(ControlTokenT di)\nouput ControlTokenT er: outQ.enq(er);, or pendingOps.enq(er);, or\nSteps:\n determine er.opA, er.opB  if di.opAsrc/di.opBsrc is RegFile: grab RegFile.regA/regB  determine er.storeData\n if di.storeDatasrc is RegFile: RegFile.regB  pass opA, opB to coprocessor 1, get result and check exception.\n determine er.archPC\n prepare capReq:\n if di.alu==Add: the offset set to be opA+opB otherwise, capReq.offset is er.opB  Grab cap Response as capVal:\n if di.alu==Cap, store capVal.data in calcResult. er.opA = capVal.data; if di.mem == Write and di.storeDatasrc == CoPro2, store er.storeData = capVal.storeData;  Parse di.alu: store result at calcResult.\n Add,Sub,Or,Nor,Xor,And,SLT,SLTU,SLL,SRL,SRA. Cop1: FHi,FLo,Mul,Div,MulI,Madd,Msub,THi,TLo.   MemAccess in/out ControlTokenT er/mi enq(ControlTokenT er)\nSteps:\n check address in bound: CoProResponse capResp \u0026lt;- capCop.getAddress() Check whether cap access instruction:  er.inst matches tagged Coprocessor .ci \u0026amp;\u0026amp;\u0026amp; er.memSize==CapWord  Take address from er.opA check er.mem == Write\n put in write. if scResult, handle store conditional  if er.test==SC, set storeConditional = True; Otherwise, memAccess write complete.  if not scResult, set er.mem = None  pass memory request down to dataMemory. Parameters:\n mi.mem addr er.cop er.storeData er.memSize er.test == LL, cap, er.id, er.epoch, er.fromDebug, storeConditional  grab result from arith cap instructions that produce a late result\n for alu instructions: mi.opA = capResp.data; for branch instructions: mi.opB = capResp.data;   startMem goes to dcache\u0026ndash;l2cache\u0026ndash;tagcontroller\u0026ndash;memory.\nReference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/inst-encoding/",
	"title": "Inst Encoding",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A Reference 1\nISA instructions MIPS encoding MIPS-IV encoding:\n MIPS-IV encoding.pdf R4000 Encoding.pdf  I-Type (Immediate), 6 (op) + 5r + 5r + 16(i)\nJ-Type (Jump), 6 (op) + 26 (index)\nR-Type (Register), 6 (op) + 5r + 5r + 5r + 5 (shift) + 6 (func)\nCHERI MIPS encoding ISAv7\nSummary:\n all three-register-operand, non-memory-accessing CHERI-MIPS instructions using the following encodeing:  | Bit | size | value | |\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;-| | 31-26 | 6 | 0x12 | | 25-21 | 5 | 0x00 | | 20-16 | 5 | r1 | | 15-11 | 5 | r2 | | 10-6 | 5 | r3 | | 5-0 | 6 | func |\nAll three-oprands non-mem instructions:\nTwo operands instructions:\nOne operands instructions:\nCLoadTags rd, cb\n| Bit | size | value | |\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;-| | 31-26 | 6 | 0x12 | | 25-21 | 5 | 0x00 | | 20-16 | 5 | rd | | 15-11 | 5 | cb | | 10-6 | 5 | 0x1E | | 5-0 | 6 | 0x3F |\nCClearTag cd, cb\n| Bit | size | value | |\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;-| | 31-26 | 6 | 0x12 | | 25-21 | 5 | 0x00 | | 20-16 | 5 | cd | | 15-11 | 5 | cb | | 10-6 | 5 | 0xB | | 5-0 | 6 | 0x3F |\nCS[BHWD]: Store Integer via Capability\nPart of integer register rs is stored to the memory location specified by cb.base + cb.offset + rt + 2^t * offset. Register cb must contain a capability that grants permission to store data. The t field determines how many bits of the register are stored to memory:\n 0 byte (8 bits) 1 halfword (16 bits) 2 word (32 bits) 3 doubleword (64 bits)  | Bit | size | value | |\u0026mdash;\u0026mdash;-|\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026ndash;| | 31-26 | 6 | 0x3A | | 25-21 | 5 | rs | | 20-16 | 5 | cb | | 15-11 | 5 | rt | | 10-3 | 11 | offset | | 2 | 1 | 0 | | 1-0 | 2 | t |\nCSC: Store Capability via Capability\nCSC cs,rt,offset(cb) CSCR cs,rt(cb) CSCI cs,offset(cb)  Cap register cs is stored at the memory location of cb.base + cb.offset + rt + 16*offset\n| Bit | size | value | |\u0026mdash;\u0026mdash;-|\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026ndash;| | 31-26 | 6 | 0x3e | | 25-21 | 5 | cs | | 20-16 | 5 | cb | | 15-11 | 5 | rt | | 10-0 | 11 | offset |\n Cap Mode   References: More More   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/cheriops/cloadtags/",
	"title": "CLoadTags",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How it is accessing the tag table without access data memory?  call cheri_get_many   Reference 1\n// in disas/mips.c  {\u0026#34;cloadtags\u0026#34;, \u0026#34;t,+b\u0026#34;, 0x4800.07bf, 0xffe0,07ff, 0, 0, I1}, Instruction ISA definition in C:\n// target/mips/helper.h  DEF_HELPER_3(cloadtags, tl, env, i32, cap_checked_ptr) // target/mips/os_helper_cheri.c  target_ulong CHERI_HELPER_IMPL(cloadtags(CPUArchState *env, uint32_t cb, uint64_t cbcursor)) Helper function to access tag table in memory.\n// in target/cheri-common/cheri_tagmem.c  int cheri_tag_get_many(CPUArchState *env, target_ulong vaddr, int reg, hwaddr *ret_paddr, uintptr_t pc)// target/mips/translate_cheri.c  static inline void generate_cloadtags(DisasContext *ctx, int32_t rd, int32_t cb) --\u0026gt; gen_helper_cloadtags(ttags, cpu_env, tcb, tcbc); static void gen_cp2 (DisasContext *ctx, uint32_t opc, int r16, int r11, int r6){ ... switch (MASK_CP2(opc)) { case OPC_CGET: /* same as OPC_CAP_NI, 0x00 */ switch(MASK_CAP6(opc)) { /* Two-operand cap instructions. */ case OPC_C2OPERAND_NI: /* 0x3f */ switch(MASK_CAP7(opc)) { case OPC_CLOADTAGS_NI: /* 0x1e \u0026lt;\u0026lt; 6 */ ==\u0026gt; 0x11110 \u0026lt;\u0026lt; 6 = 0b111.1000.0000 = 0x780 check_cop2x(ctx); generate_cloadtags(ctx, r16, r11); opn = \u0026#34;cloadtags\u0026#34;; break; ... } } ... } // target/mips/translate.c  enum { /* Two Operand Instructions */ ... OPC_CSEALENTRY_NI = OPC_C2OPERAND_NI | (0x1d \u0026lt;\u0026lt; 6), OPC_CLOADTAGS_NI = OPC_C2OPERAND_NI | (0x1e \u0026lt;\u0026lt; 6), OPC_CLOADCOLORS_NI = OPC_C2OPERAND_NI | (0x1e \u0026lt;\u0026lt; 6), }; // OPC_C2OPERAND_NI  /* Version 1.17 and 1.22 ISA encodings (*_NI) to replace above. */ enum { /* Common new ISA encoding blocks */ /* non-immediate capability instructions */ OPC_CAP_NI = OPC_CP2 | (0x00 \u0026lt;\u0026lt; 21), /* 2-operand capability instructions */ OPC_C2OPERAND_NI = OPC_CAP_NI | (0x3f), /* 1-operand capability instructions */ OPC_C1OPERAND_NI = OPC_C2OPERAND_NI | (0x1f \u0026lt;\u0026lt; 6), }; enum { //...  OPC_CP0 = (0x10 \u0026lt;\u0026lt; 26), OPC_CP1 = (0x11 \u0026lt;\u0026lt; 26), OPC_CP2 = (0x12 \u0026lt;\u0026lt; 26), OPC_CP3 = (0x13 \u0026lt;\u0026lt; 26), //...  /* Load and stores */ OPC_LDL = (0x1A \u0026lt;\u0026lt; 26), OPC_LDR = (0x1B \u0026lt;\u0026lt; 26), OPC_LB = (0x20 \u0026lt;\u0026lt; 26), OPC_LH = (0x21 \u0026lt;\u0026lt; 26), OPC_LWL = (0x22 \u0026lt;\u0026lt; 26), OPC_LW = (0x23 \u0026lt;\u0026lt; 26), OPC_LWPC = OPC_LW | 0x5, OPC_LBU = (0x24 \u0026lt;\u0026lt; 26), OPC_LHU = (0x25 \u0026lt;\u0026lt; 26), OPC_LWR = (0x26 \u0026lt;\u0026lt; 26), OPC_LWU = (0x27 \u0026lt;\u0026lt; 26), OPC_SB = (0x28 \u0026lt;\u0026lt; 26), OPC_SH = (0x29 \u0026lt;\u0026lt; 26), OPC_SWL = (0x2A \u0026lt;\u0026lt; 26), OPC_SW = (0x2B \u0026lt;\u0026lt; 26), OPC_SDL = (0x2C \u0026lt;\u0026lt; 26), OPC_SDR = (0x2D \u0026lt;\u0026lt; 26), OPC_SWR = (0x2E \u0026lt;\u0026lt; 26), OPC_LL = (0x30 \u0026lt;\u0026lt; 26), OPC_LLD = (0x34 \u0026lt;\u0026lt; 26), OPC_LD = (0x37 \u0026lt;\u0026lt; 26), OPC_LDPC = OPC_LD | 0x5, OPC_SC = (0x38 \u0026lt;\u0026lt; 26), OPC_SCD = (0x3C \u0026lt;\u0026lt; 26), OPC_SD = (0x3F \u0026lt;\u0026lt; 26), }; ISA instruction ISAv7\nCLoadTags rd, cb\n| Bit | size | value | |\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;-| | 31-26 | 6 | 0x12 | | 25-21 | 5 | 0x00 | | 20-16 | 5 | rd | | 15-11 | 5 | cb | | 10-6 | 5 | 0x1E | | 5-0 | 6 | 0x3F |\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/writeback/",
	"title": "Writeback",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Who calls this module and what is the input?\n The final pipeline stage, previous one is MemAccess connected via FIFO of ControlToken. update register file.  Where does it go?\n  Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/mips/",
	"title": "MIPS.bsv",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheriabi/refinement/",
	"title": "Refinement",
	"tags": [],
	"description": "",
	"content": "Reference 1\nFrom CheriABI, CL-TR-932 ch4.4\nStack capabilities: compiler generated code sets bounds on references to variables on the stack. These prevent classic stack-based buffer overflows.\nHeap capabilities: malloc() is modified and will return capabilities with tight bounds and no overlaps between heap objects. If other allocators are used, they will need to be modified in the same way.\nGlobal capabilities: capabilities for global variables (such as const char* string constants, etc.) are set-up at program startup by the runtime linker. In statically linked binaries, the initialization code is embedded into each static library as part of the C startup code.\n  CheriABI, CL-TR-932. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheriabi/execve/",
	"title": "Process creation",
	"tags": [],
	"description": "",
	"content": "Reference 1\ncompiler enforced stack bounds.\nauxiliary argument array:\naltered C run-time to take a pointer to the ELF auxiliary argument array and extended it to contain pointers to the argument and environment arrays(argv and environ)\n  CHERIABI, 2019 ASPLOS. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/icache/",
	"title": "ICache",
	"tags": [],
	"description": "",
	"content": " Todones  CacheInstIfc (in MIPS.bsv) - put() -\u0026gt; rule doPut() // - getRead() - invalidate() - getConfig() - getResponse() // - interface Master#  Q\u0026amp;A  Who calls this module and what is the input?\n called from Memory.bsv: rule feedICache, after TLB translation. iCache.put(req); The input is the physical memory access request req of type CacheRequestInstT. see Memory.bsv.  Where does it go?\n it send a memory request to CacheCore, iCache.put(req); see CacheCore. it returns the response back to Memory.bsv: interface InstMemory:getResponse. CacheResponseInstT resp \u0026lt;- iCache.getRead(); The response then forwarded to Scheduler.bsv: mkScheduler: method enq(): CacheResponseInstT instResp \u0026lt;- m.getInstruction();  Where to fetch the tag and attach it to the instruction?\n  Reference 1\nConnections // Memory.bsv mkConnection(iCache.memory, theMemMerge.slave[0]); mkConnection(dCache.memory, theMemMerge.slave[1]);  States FIFO#(CacheResponseInstT) preRsp_fifo \u0026lt;- mkLFIFO; FIFO#(CheriPhyByteOffset) addrs \u0026lt;- mkLFIFO; Reg#(CacheRequestInstT) reqInWire \u0026lt;- mkWire; FIFOF#(Bool) nextFromCore \u0026lt;- mkLFIFOF; //FIFOF#(Bool) returnNext \u0026lt;- mkUGSizedFIFOF(4); // Lots of room due to being unguarded. FF#(CheriMemRequest, 2) memReqs \u0026lt;- mkUGFF(); FF#(CheriMemResponse, 2) memRsps \u0026lt;- mkUGFF(); // If this FIFO has capacity for less than 4 (the size of one burst response) the system can wedge on a SYNC when the data interface stalls waiting for all responses. CacheCore#(2, Indices, 1) core \u0026lt;- mkCacheCore(cacheId, WriteThrough, OnlyReadResponses, InOrder, ICache, zeroExtend(memReqs.remaining()), ff2fifof(memReqs), ff2fifof(memRsps)); Reg#(CheriTransactionID) transactionNum \u0026lt;- mkReg(0); Reg#(PhyAddress) lastInvalidate \u0026lt;- mkRegU;  interface CacheInstIfc method getRead() method ActionValue#(CacheResponseInstT) getRead()\n grab one resp from preRsp_fifo grab one addr from addrs  test_cp2_ccall.log debug with icache tagcontroller taglookup\nfirst instruction from start: 0x4000.0000; line number (cut 5-bits): 0x0200.0000\nicache-\u0026gt; flit=BYTE_4, l2cache-\u0026gt;tagcontroller-\u0026gt; taglookup \u0026amp; memory \u0026lt;- MemoryResponse with tag and 64-bit data.\n   byte addr line num offset tagTb byte addr tagTb line num offset     0x4000.0000 0x0200.0000 00 0x3fff.f000 0x0.01ff.ff80 00     tagController:  send mem request: send tag request to tag cache (BYTE_4), if tag cache miss, forward the req to memory(BYTE_32): taglookup: received request Read MemoryRequest; Injecting request from tag lookup engine  tagController: get mem response, get tag response.    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-llvm/builtins/",
	"title": "Builtin",
	"tags": [],
	"description": "",
	"content": "Reference 1\nFrom github/clang old repo Feb 2019:\n clang/include/clang/Basic/Builtins.def: __builtin_cheri_*\n clang/include/clang/Basic/BuiltinsMips.def: __builtin_mips_cheri_*\n    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/tag-mem/",
	"title": "Tag Mem",
	"tags": [],
	"description": "",
	"content": " References:\n github/qemu, 202005.  tagbit{set|get} tag_bit_set will create a new tag block if the indexed block does not exist.\ntag_bit_get will return zero tags if the inidexed tag block does not exist.\nThis is how the tag (efficiently) stored: it exists only after the tag has been set/initialized. Otherwise, it is assumed to be always zero tags and will not have a tag block to store their values.\nOverview target/cheri-common/cheri_tagmem.c\n/* * Tagged Memory Emulation * * CHERI requires a 1-bit tag for every capability-aligned, * capability-sized word in physical memory. This allows capabilities * to be safely loaded and stored in meory without loss of integrity. * * For emulation purposes the tag is stored in a two-level array containing * fixed size bitmaps. To reduce the amount of memory needed the tag flag array * is allocated sparsely, 4K tags at at time, and on demand. * This 4K number is arbitary and depending on the workload other sizes may be * better. * * Note: We also support an mode where we use one byte per tag. This makes it * easy to set or unset a tag without the need of locking or atomics. * This requires eight times the memory. ==\u0026gt; Lele: use 7-bits for color. * * As tag accesses are not atomic with regard to data writes/reads spurious * invalid capabilities could be created in a threaded context. * Therefore, we don\u0026#39;t use atomic bitwise RMW operations and the one byte per * tag variant actually performs slightly worse due to increased memory usage. * * FIXME: find a solution to make tags safe (or just always disable multi-tcg) * * XXX Should consider adding a reference count per tag block so that * blocks can be deallocated when no longer used maybe. * * FIXME: rewrite using somethign more like the upcoming MTE changes (https://github.com/rth7680/qemu/commits/tgt-arm-mte-user) */ Common functions\nDEF_HELPER_4(store_cap_via_cap, void, env, i32, i32, tl) -\u0026gt;CHERI_HELPER_IMPL(store_cap_via_cap(CPUArchState *env, uint32_t cs, uint32_t cb, target_ulong offset)) -\u0026gt; store_cap_to_memory (target/cheri-common/op_helper_cheri_common.c) -\u0026gt; cheri_tag_invalidate (see next list) -\u0026gt; cheri_tag_set -\u0026gt; tag_bit_get -\u0026gt; tagblock_get_tag -\u0026gt; tag_bit_set -\u0026gt; cheri_tag_new_tagblk -\u0026gt; tagblock_set_tag void CHERI_HELPER_IMPL(cheri_invalidate_tags(CPUArchState *env, target_ulong vaddr, MemOp op)) -\u0026gt; DEF_HELPER_3(cheri_invalidate_tags, void, env, cap_checked_ptr, memop) -\u0026gt; CHERI_HELPER_IMPL(cheri_invalidate_tags(CPUArchState *env, target_ulong vaddr, MemOp op)) -\u0026gt; cheri_tag_invalidate -\u0026gt; cheri_tag_phys_invalidate -\u0026gt; tagblock_get_tag -\u0026gt; tagblock_clear_tag cheri_tag_get_many(env, vaddr, reg, ret_paddr, pc) -\u0026gt; tagblk = cheritag_get_block(vaddr,...): find the tag block, and the tag index in the block. -\u0026gt; tagblock_get_tag(tagblk,tagidx[0-7]): read 8 tags one time, return as integer.  Target specific\nMIPS: CHERI_HELPER_IMPL(cscc_without_tcg(CPUArchState *env, uint32_t cs, uint32_t cb)) -\u0026gt; store_cap_to_memory (target/mips/op_helper_cheri.c) target_ulong CHERI_HELPER_IMPL(cloadtags(CPUArchState *env, uint32_t cb, uint64_t cbcursor)) -\u0026gt; cheri_tag_get_many RISCV: void HELPER(amoswap_cap)(CPUArchState *env, uint32_t dest_reg, uint32_t addr_reg, uint32_t val_reg) -\u0026gt; store_cap_to_memory static target_ulong sc_c_impl(CPUArchState *env, uint32_t addr_reg, uint32_t val_reg, target_ulong offset, uintptr_t _host_return_address) -\u0026gt; store_cap_to_memory   cheri_tag_get_many, CLoadTags, in target/cheri-common/cheri_tagmem.c.  Currently only called in MIPS.   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/test/",
	"title": "Test",
	"tags": [],
	"description": "",
	"content": " Reference 1\nFiles in test suite cheritest/trunk. root of test suite\n gxemul_log/ output of gxemul test log/ holds output of test obj/ holds obj files, memory images, and assembly dumps. tests/ Individual tests and their matching Python Nose classes tools/ Utility functions to perform common functions such as interpreting BERI simulator and gxemul output fuzzing/ Scripts for fuzz testing the TLB  init.s A thin loader to set up various aspects of CPU and memory configuration.\n set up a stack at the top of memory. install default before- and after-boot exception vectors and handlers, which will dump the register file and terminate if triggered. Explicitly clear all general-purpose registers except stack-related registers that may have been modified during startup. Invoke a user-provided test function using JAL; currently all test written in assembly, but the calling convention should support C as well. On return from test, dump the register file and terminate.  Nose invocation Run individual test: go to directory and run nosetests.\n nosetests xxx.py nosetests -a 'capabilities'  Automation in Makefile:\nhttp://somethingaboutorange.com/mrl/projects/nose/\nmake test -\u0026gt;: nosetest -\u0026gt;: nosetests_uncached.xml -\u0026gt;: $(CHERI_TEST_LOGS) // RUN bluesim and generate log file -\u0026gt; $(LOGDIR)/test_raw_trace.log -\u0026gt; $(LOGDIR)/test_raw_trace_cached.log -\u0026gt; $(LOGDIR)/test_raw_trac%.log -\u0026gt;: $(OBJDIR)/test_raw_trac%.mem $(SIM) $(CHERICTL) -\u0026gt; $(call PREPARE_TEST, $\u0026lt;) \u0026amp;\u0026amp; \\ ((BERI_DEBUG_SOCKET_0=$$TMPDIR/sock \\ CHERI_TRACE_FILE=$(CHERI_TRACE_FILE) \\ $(call RUN_TEST,$*); \\ $(CLEAN_TEST)) \u0026amp;) \u0026amp;\u0026amp; \\ $(call WAIT_FOR_SOCKET,$$TMPDIR/sock) \u0026amp;\u0026amp; \\ $(CHERICTL) setreg -r 12 -v 1 -p $$TMPDIR/sock \u0026amp;\u0026amp; \\ $(CHERICTL) memtrace -v 6 -p $$TMPDIR/sock -\u0026gt; $(LOGDIR)/test_clang_dma%.log: -\u0026gt;: $(OBJDIR)/startdramtest.mem $(OBJDIR)/test_clang_dma%.mem $(SIM) -\u0026gt; $(call PREPARE_TEST,$\u0026lt;) \u0026amp;\u0026amp; \\ cp $(PWD)/$(word 2, $^) . \u0026amp;\u0026amp; \\ $(call REPEAT_5, CHERI_KERNEL=$(notdir $(word 2, $^)) $(RUN_TEST_COMMAND)); \\ $(CLEAN_TEST) -\u0026gt; $(LOGDIR)/%.log : $(OBJDIR)/%.mem $(SIM) -\u0026gt; $(call PREPARE_TEST,$\u0026lt;) \u0026amp;\u0026amp; $(call RUN_TEST,$*); $(CLEAN_TEST) -\u0026gt; $(TEST_PYTHON) // a list of python test files; no target for them. -\u0026gt; FORCE -\u0026gt; PYTHONPATH=tools/sim PERM_SIZE=31 CACHED=0 nosetests --with-xunit --xunit-file=nosetests.uncached.xml $(NOSEFLAGS_UNCACHED) $(TESTDIRS) || true -\u0026gt;: nosetest_cached -\u0026gt;: nosetests_cached.xml -\u0026gt; PYTHONPATH=tools/sim PERM_SIZE=31 CACHED=1 nosetests --with-xunit --xunit-file=nosetests_cached.xml $(NOSEFLAGS) $(TESTDIRS) || true -\u0026gt; PREPARE_TEST, $\u0026lt; (*.mem) -\u0026gt; mktemp \u0026amp;\u0026amp; cd tmp \u0026amp;\u0026amp; cp $(PWD)/$(1) mem.bin \u0026amp;\u0026amp; memConv.py bsim \u0026amp;\u0026amp; memConv.py bsimc2 \u0026amp;\u0026amp; $(COPY_PISM_CONFS) -\u0026gt; cp cheri/trunk/memoryconfig $TMPDIR/memoryconfig -\u0026gt; RUN_TEST, $* ($* as the test name) -\u0026gt; $(call REPEAT_5, $(RUN_TEST_COMMAND)) -\u0026gt; RUN_TEST_COMMAND = \\ LD_LIBRARY_PATH=$(CHERILIBS_ABS)/peripherals \\ PISM_MODULES_PATH=$(PISM_MODULES_PATH) \\ CHERI_CONFIG=$$TMPDIR/simconfig \\ CHERI_DTB=$(DTB_FILE) \\ BERI_DEBUG_SOCKET_0=$(CHERISOCKET) $(SIM) -w +regDump $(SIM_TRACE_OPTS) -m $(TEST_CYCLE_LIMIT) \u0026gt; \\ $(PWD)/$@; \\ -\u0026gt; REPEAT_5 = \\ for attempt in 0 1 2 4 5; do if \\ $(1) \\ then break; else false; fi; done  Note: Make Basics:\n automatic variables:\n $\u0026lt; the first dependence; $^ all the dependences; $@ target; $* stem in pattern matching, or target name with a recognized extension removed, or empty. more on GNU manual.  $(word n,text): returns the nth word in the text, first index is 1.\n $(basename, names...) (remove extension if exists), $(addprefix, prefix, names...), $(addsuffix, suffix, names...), apply the option for all names one by one and return a list of new names. more\n  nosetests --with-xunit --xunit-file=nosetests.uncached.xml: use xunit plugin, which write results in standard XUnit XML format. The result xml file is given via \u0026ndash;xunit-file=xxx option, default nosetest.xml if not given.\n$(NOSEFLAGS_UNCACHED): -A \u0026ldquo;$(NOSEPRED) and not cached\u0026rdquo;\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-train/2018-mobile-crowd/",
	"title": "2018 Mobile Crowd",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Anh, Tran The, Nguyen Cong Luong, Dusit Niyato, Dong In Kim, and Li-Chun Wang. \u0026ldquo;Efficient training management for mobile crowd-machine learning: A deep reinforcement learning approach.\u0026rdquo; IEEE Wireless Communications Letters 8, no. 5 (2019): 1345-1348. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2019-jointdnn/",
	"title": "2019 Jointdnn",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Eshratifar, Amir Erfan, Mohammad Saeed Abrishami, and Massoud Pedram. \u0026ldquo;JointDNN: an efficient training and inference engine for intelligent mobile cloud computing services.\u0026rdquo; IEEE Transactions on Mobile Computing (2019). ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-train/2011-realtime-train/",
	"title": "2011 Realtime Train",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Choi, Kwontaeg, Kar-Ann Toh, and Hyeran Byun. \u0026ldquo;Realtime training on mobile devices for face recognition applications.\u0026rdquo; Pattern recognition 44, no. 2 (2011): 386-400. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-train/2019-sec-object/",
	"title": "2019 Efficient incremental learning for mobile object detection",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Li, Dawei, Serafettin Tasci, Shalini Ghosh, Jingwen Zhu, Junting Zhang, and Larry Heck. \u0026ldquo;Efficient incremental learning for mobile object detection.\u0026rdquo; arXiv preprint arXiv:1904.00781 (2019). ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2019-eurosys-ulayer/",
	"title": "2019 Eurosys ULayer",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Kim, Youngsok, Joonsung Kim, Dongju Chae, Daehyun Kim, and Jangwoo Kim. \u0026ldquo;μLayer: Low Latency On-Device Inference Using Cooperative Single-Layer Acceleration and Processor-Friendly Quantization.\u0026rdquo; In Proceedings of the Fourteenth EuroSys Conference 2019, pp. 1-15. 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2018-hotedge-inference/",
	"title": "2018 Hotedge Inference",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Ogden, Samuel S., and Tian Guo. \u0026ldquo;{MODI}: Mobile Deep Inference Made Efficient by Edge Computing.\u0026rdquo; In {USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 18). 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2018-deepcache/",
	"title": "2018 Deepcache",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2018-ispn-deepx/2016-deepx-kit/",
	"title": "2016 Deepx Kit",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Lane, Nicholas D., Sourav Bhattacharya, Akhil Mathur, Claudio Forlivesi, and Fahim Kawsar. \u0026ldquo;DXTK: Enabling Resource-efficient Deep Learning on Mobile and Embedded Devices with the DeepX Toolkit.\u0026rdquo; In MobiCASE, pp. 98-107. 2016. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2017-emdl-mobirnn/",
	"title": "2017 Emdl Mobirnn",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Cao, Qingqing, Niranjan Balasubramanian, and Aruna Balasubramanian. \u0026ldquo;MobiRNN: Efficient recurrent neural network execution on mobile GPU.\u0026rdquo; In Proceedings of the 1st International Workshop on Deep Learning for Mobile Systems and Applications, pp. 1-6. 2017. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2018-mobisys-on-demand-compression/",
	"title": "2018 Mobisys on Demand Compression",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Liu, Sicong, Yingyan Lin, Zimu Zhou, Kaiming Nan, Hui Liu, and Junzhao Du. \u0026ldquo;On-demand deep model compression for mobile devices: A usage-driven model selection framework.\u0026rdquo; In Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services, pp. 389-400. 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2018-lctes-adaptive-selection/",
	"title": "2018 Lctes Adaptive Selection",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2017-pmlr-mec/",
	"title": "2017 MEC: Memory-efficient Convolution for Deep Neural Network",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Cho, Minsik, and Daniel Brand. \u0026ldquo;MEC: memory-efficient convolution for deep neural network.\u0026rdquo; In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 815-824. JMLR. org, 2017. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2018-mobicom-nestdnn/",
	"title": "2018 Mobicom Nestdnn",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Fang, Biyi, Xiao Zeng, and Mi Zhang. \u0026ldquo;Nestdnn: Resource-aware multi-tenant on-device deep learning for continuous mobile vision.\u0026rdquo; In Proceedings of the 24th Annual International Conference on Mobile Computing and Networking, pp. 115-127. 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2020-asplos-patdnn/",
	"title": "2020 Asplos Patdnn",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/mobiles/",
	"title": "Mobiles",
	"tags": [],
	"description": "",
	"content": "Reference 1\nOptimization of neural network inference to run on IoT/mobile devices.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2018-ispn-deepx/",
	"title": "2018 Ispn Deepx",
	"tags": [],
	"description": "",
	"content": "Reference 1\n 2016 Deepx Kit  Reference 1 Lane, Nicholas D., Sourav Bhattacharya, Akhil Mathur, Claudio Forlivesi, and Fahim Kawsar. \u0026ldquo;DXTK: Enabling Resource-efficient Deep Learning on Mobile and Embedded Devices with the DeepX Toolkit.\u0026rdquo; In MobiCASE, pp. 98-107. 2016. ↩   Lane, Nicholas D., Sourav Bhattacharya, Petko Georgiev, Claudio Forlivesi, Lei Jiao, Lorena Qendro, and Fahim Kawsar. \u0026ldquo;Deepx: A software accelerator for low-power deep learning inference on mobile devices.\u0026rdquo; In 2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN), pp. 1-12. IEEE, 2016. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/automl/2013-kdd-auto-weka/",
	"title": "2013 Kdd Auto WEKA",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Thornton C, Hutter F, Hoos HH, Leyton-Brown K (2013). Auto-WEKA: Combined Selection and Hyperparameter Optimization of Classification Algorithms. KDD \u0026lsquo;13 Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. pp. 847–855. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2016-isca-eie/",
	"title": "2016 Isca Eie",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-train/",
	"title": "Training Opt",
	"tags": [],
	"description": "",
	"content": "Reference 1\n 2018 Mobile Crowd  Reference 1 Anh, Tran The, Nguyen Cong Luong, Dusit Niyato, Dong In Kim, and Li-Chun Wang. \u0026ldquo;Efficient training management for mobile crowd-machine learning: A deep reinforcement learning approach.\u0026rdquo; IEEE Wireless Communications Letters 8, no. 5 (2019): 1345-1348. ↩  2011 Realtime Train  Reference 1 Choi, Kwontaeg, Kar-Ann Toh, and Hyeran Byun. \u0026ldquo;Realtime training on mobile devices for face recognition applications.\u0026rdquo; Pattern recognition 44, no. 2 (2011): 386-400. ↩  2019 Efficient incremental learning for mobile object detection  Reference 1 Li, Dawei, Serafettin Tasci, Shalini Ghosh, Jingwen Zhu, Junting Zhang, and Larry Heck. \u0026ldquo;Efficient incremental learning for mobile object detection.\u0026rdquo; arXiv preprint arXiv:1904.00781 (2019). ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/",
	"title": "Optimizing Inference",
	"tags": [],
	"description": "",
	"content": "Reference 1\n 2019 Jointdnn  Reference 1 Eshratifar, Amir Erfan, Mohammad Saeed Abrishami, and Massoud Pedram. \u0026ldquo;JointDNN: an efficient training and inference engine for intelligent mobile cloud computing services.\u0026rdquo; IEEE Transactions on Mobile Computing (2019). ↩  2019 Eurosys ULayer  Reference 1 Kim, Youngsok, Joonsung Kim, Dongju Chae, Daehyun Kim, and Jangwoo Kim. \u0026ldquo;μLayer: Low Latency On-Device Inference Using Cooperative Single-Layer Acceleration and Processor-Friendly Quantization.\u0026rdquo; In Proceedings of the Fourteenth EuroSys Conference 2019, pp. 1-15. 2019. ↩  2018 Hotedge Inference  Reference 1 Ogden, Samuel S., and Tian Guo. \u0026ldquo;{MODI}: Mobile Deep Inference Made Efficient by Edge Computing.\u0026rdquo; In {USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 18). 2018. ↩  2018 Deepcache  Reference 1 reference ↩  2017 Emdl Mobirnn  Reference 1 Cao, Qingqing, Niranjan Balasubramanian, and Aruna Balasubramanian. \u0026ldquo;MobiRNN: Efficient recurrent neural network execution on mobile GPU.\u0026rdquo; In Proceedings of the 1st International Workshop on Deep Learning for Mobile Systems and Applications, pp. 1-6. 2017. ↩  2018 Mobisys on Demand Compression  Reference 1 Liu, Sicong, Yingyan Lin, Zimu Zhou, Kaiming Nan, Hui Liu, and Junzhao Du. \u0026ldquo;On-demand deep model compression for mobile devices: A usage-driven model selection framework.\u0026rdquo; In Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services, pp. 389-400. 2018. ↩  2018 Lctes Adaptive Selection  Reference 1 reference ↩  2017 MEC: Memory-efficient Convolution for Deep Neural Network  Reference 1 Cho, Minsik, and Daniel Brand. \u0026ldquo;MEC: memory-efficient convolution for deep neural network.\u0026rdquo; In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 815-824. JMLR. org, 2017. ↩  2018 Mobicom Nestdnn  Reference 1 Fang, Biyi, Xiao Zeng, and Mi Zhang. \u0026ldquo;Nestdnn: Resource-aware multi-tenant on-device deep learning for continuous mobile vision.\u0026rdquo; In Proceedings of the 24th Annual International Conference on Mobile Computing and Networking, pp. 115-127. 2018. ↩  2020 Asplos Patdnn  Reference 1 reference ↩  Mobiles  Reference 1 Optimization of neural network inference to run on IoT/mobile devices. reference ↩  2018 Ispn Deepx  Reference 1 2016 Deepx Kit Reference 1 Lane, Nicholas D., Sourav Bhattacharya, Akhil Mathur, Claudio Forlivesi, and Fahim Kawsar. \u0026ldquo;DXTK: Enabling Resource-efficient Deep Learning on Mobile and Embedded Devices with the DeepX Toolkit.\u0026rdquo; In MobiCASE, pp. 98-107. 2016. ↩ Lane, Nicholas D., Sourav Bhattacharya, Petko Georgiev, Claudio Forlivesi, Lei Jiao, Lorena Qendro, and Fahim Kawsar. \u0026ldquo;Deepx: A software accelerator for low-power deep learning inference on mobile devices.\n 2016 Isca Eie  Reference 1 reference ↩  AMC: AutoML for Model Compression and Acceleration on Mobile Devices  Reference1 AMC: leverage reinforcement learning to efficiently sample the design space. 4x FLOPs reduction, 2.7% better accuracy than hand-crafted model compression for VGG-16 on ImageNet. speedup 1.53x on GPU (Titan Xp) and 1.95x on Android phone (Google Pixel I), with negligible loss of accuracy. He, Yihui, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. \u0026ldquo;Amc: Automl for model compression and acceleration on mobile devices.\u0026rdquo; In Proceedings of the European Conference on Computer Vision (ECCV), pp.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/opt-infer/2018-eccv-amc/",
	"title": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices",
	"tags": [],
	"description": "",
	"content": "Reference1\nAMC: leverage reinforcement learning to efficiently sample the design space.\n4x FLOPs reduction, 2.7% better accuracy than hand-crafted model compression for VGG-16 on ImageNet.\nspeedup 1.53x on GPU (Titan Xp) and 1.95x on Android phone (Google Pixel I), with negligible loss of accuracy.\n  He, Yihui, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. \u0026ldquo;Amc: Automl for model compression and acceleration on mobile devices.\u0026rdquo; In Proceedings of the European Conference on Computer Vision (ECCV), pp. 784-800. 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/automl/",
	"title": "Automl",
	"tags": [],
	"description": "",
	"content": "Reference 1\n 2013 Kdd Auto WEKA  Reference 1 Thornton C, Hutter F, Hoos HH, Leyton-Brown K (2013). Auto-WEKA: Combined Selection and Hyperparameter Optimization of Classification Algorithms. KDD \u0026lsquo;13 Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. pp. 847–855. ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-piccolo/",
	"title": "Piccolo",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-flute/",
	"title": "Flute",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/seminars/2020-sp/",
	"title": "Oakland 2020",
	"tags": [],
	"description": "",
	"content": " Reference 1\nVideos: https://www.youtube.com/channel/UC6pXMS7qre9GZW7A7FVM90Q/videos\nOpening Missing Doug Tygar, from UC berkeley.\nAwards.\n104 out of 8xx. ~12%\nMem Safety xMP Data oriented programming\nxen altp2m\nptr -\u0026gt; hash -\u0026gt; key\nBuddy allocator\ncontext switch\nread-only permissions from outside of xMP domain.\nTalk with P. seL4: no trust on hardware; verified safe.\nPSOS: layer ontop of layer; verify one layer ontop of a verified layer.\nCHERI: security in market in 3~4 years.\nKaronte taint ana across binaries over RPC.\ndata key. e.g. \u0026ldquo;QUERY_STRING\u0026rdquo;\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/deep/6s191/",
	"title": "6s191",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How many ways to split training process into multiple steps, where each step can be done at different place.  Reference 1\nIntro - Perceptron   Perceptron, 1985.\nActivation Functions: non-linearity\ntwo input, 1 output.\nmulti output.\nTraning init weight. \u0026ndash;\u0026gt; wrong prediction \u0026ndash;\u0026gt; big loss\nmultiple data \u0026ndash;\u0026gt; loss of all predictions\nLoss function Binary Cross Entropy Loss: for output to be 0 or 1.\nMean Squared Error Loss: for output to be continuous real numbers.\nLoss Optimization Find the weights $W$ that achieve the least loss.\nGradient Descent:\n pick a random weight compute gradient (find the right direction to move down hill) update weights loop above 2 steps until convergence  ==\u0026gt; The key: compute the gradient ==\u0026gt; backpropagation\nBackpropagation Given a loss, and weight, how do we know which way to move to reach the lowest point of the loss function?\nE.G. One in, one hidden, one out learning model.\ninput x (layer 0) \u0026ndash; w1 (layer 1) \u0026ndash; w2 (layer2) \u0026ndash; output J(W)\nHow does a small change in one weight $(ex, w_2)$ affects the final loss J(W)?\nTraining Optimization Dec 2017, Visualizing the loss landscape of neural nets.\nLearning rate Fixed learning rate:\n small: moves slowly, trapped in local minima. large: miss the minima, divege.  Adaptive learning rate: the size of small changes in weight is adaptive, depending on\n how large the gradient; how fast learning is happening; size of particular weights; \u0026hellip;  Algorithms: 1952 ~ 2014\n SGD, 1952[^sgd1952] Adam, 2014[^adam2014] Adadelta, 2012[^adadelta2012] Adagrad, 2011[^adagrad2011] RMSProp  Mini-batches To compute gradient descent: pick a single point vs all the points vs a set of points: mini-batch.\nMini-batch: much quicker\nAvoid overfit Regularization.\n Dropout Early Stopping  Recurrent Neural Networks Deep Sequence Modeling\nA ball, where to go next? Need a sequence of position over time.\nA sequence modeling problem: Predict the Next Word.\n\u0026ldquo;This morning I took my cat for a ____\u0026ldquo;. (Walk)\nFixed Window:\n Cannot model long-term dependencies.  -\u0026gt; count words in entire sequence\n==\u0026gt; count does not preserve order info\n-\u0026gt; A big fixed window:\nStandard feed-forward network\nRecurrent Neural Network: a feed back loop; can be viewed as multiple sub-networks got connected inside\nthe RNN network inside have recurrent cell that can be fed by input as well as the previous output of itself.\nBackpropagation Through Time TODO\nConvolutional Neural Networks Vision\n  For computers, images are just numbers.\n(LLM: For humans, images are ???.)\nTasks in computer vision: regression, classification.\nFeatures detection.\n Manual feature extraction.  LLM: How does human extract features under the hood? Domain knowledge, define features (How does this happen?)  learning features  Learning visual features Dense(fully connected) Neural Network\nConvolution:\n Connect a patch of input to a single neuron in the hidden layer. use a sliding window to define connections. weight all patches one by one using a filter (matrix) to detect particular feature. such as boundaries, sharping, etc. The feature maps will be generated.  Input image \u0026mdash;\u0026gt; Convolution (filters, feature maps) \u0026mdash;\u0026gt; Maxpooling \u0026ndash;\u0026gt; fully connected layer as output.\nThree main parts:\n convolution. learn weights of filters in convolutional layers. tf.keras.layers.Conv2D non-linearity. Often ReLU. tf.keras.activations.* pooling. Downsampling operation on each feature map. tf.keras.layers.MaxPool2D  Convolution operation: applying filters to generate feature maps. one filter one feature.\ne.g. tf.keras.layers.Conv2D(filters = d, kernel_size = (h,w), strides = s)\nGenerative modeling Myth of cove. Find hidden variables even only the observable is given. Finding hidden cause/reason/laws.\nAutoencoders/decoders.\nInput object \u0026ndash;\u0026gt; reconstructed object.\nReinforcement Learning Learning in dynamic environment.\nSupervised, unsupervised, vs. reinforcement learning.\nTODO\u0026hellip;.\nnitty-gritty 事实真相，本质\n  MIT Deep Learning 6S.191 ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/capability/cap/",
	"title": "Capability",
	"tags": [],
	"description": "",
	"content": " Reference 1\nACL vs Capability Access control list: attributes on objects, stating which subjects has which permissions;\n e.g. file permission attribute bits on Linux.  Capability: attributes on subjects, stating the subject has what permissions over certain objects;\n format, each capability has form of ; a subject can have a list of capabilities.    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/verified/psos/",
	"title": "PSOS",
	"tags": [],
	"description": "",
	"content": " The Provably Secure Operating System (PSOS) project began in 1973 and continued until 1983. The 1980 PSOS final report includes the system architecture and many of the basic hardware and operating system layers, plus some illustrative applications (all formal specified in the SPECIAL language of HDM, the Hierarchical Development Methodology). The Feiertag/Neumann paper summarizing the architecture as of 1979 is available in a retyped, more or less correct, hand-edited pdf form. A 2003 paper, PSOS Revisited by me and Rich Feiertag, was presented at ACSAC 2003 in Las Vegas in December 2003, as part of the Classic Papers track (which was initiated at ACSAC 2002 for the Karger-Schell paper on the Multics multilevel secure evaluation). Please read it if you are interested in capability architectures. The PSOS project continued from 1980 to 1983, supporting the Goguen-Meseguer papers and the Extended HDM effort that led to SRI\u0026rsquo;s PVS system.\n Reference 12[^3]\n  The foundations of a provably secure operating system (PSOS). By Richard J. Feiertag and Peter G. Neumann. 1979. ↩ PSOS report, 1980. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/capability/",
	"title": "Capability",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Capability   Reference 1 ACL vs Capability Access control list: attributes on objects, stating which subjects has which permissions; e.g. file permission attribute bits on Linux. Capability: attributes on subjects, stating the subject has what permissions over certain objects; format, each capability has form of ; a subject can have a list of capabilities. reference ↩  Confused Deputy  References: N. Hardy, “The confused deputy (or why capabilities might have been invented),” ACM SIGOPS Operating Systems Review, vol. 22, no. 4, pp. 36–38, 1988. Overview A story in a system much like Unix (of AT\u0026amp;T): RUN (SYSX)FORT, to invoke a compiler FORT. (SYSX)A_FILE, customized file from the invoker to write debug information to A_FILE. (SYSX)STAT, to write statistics as output, filename hardcoded in the compiler. In order to access STAT file, we give compiler home files license \u0026ndash;\u0026gt; to write files in the home directory (SYSX), then write (SYSX)STAT\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/tagsparams/",
	"title": "tagsparams.py",
	"tags": [],
	"description": "",
	"content": "file cherilibs/trunks/tagsparams.py\nParameters:\n -c, \u0026ndash;cap-size, default=256, capability size in bits; -s, \u0026ndash;structure, default=[0], list from leaf to root of branching factors describing the tags tree; -t, \u0026ndash;top-addr, default=0x4000_0000, memory address the tag should start growing down from; -a, \u0026ndash;addr-align, default=32, alignment requirement (in bytes) for table levels addresses; -m, \u0026ndash;mem-size, default=(2^32 + 2^20), size of the memory to be covered by the tags; -b, \u0026ndash;bsv-inc-output, const=\u0026ldquo;TagTableStructure.bsv\u0026rdquo;, default = None; -l, \u0026ndash;linker-inc-output, const=\u0026ldquo;tags-params.ld\u0026rdquo;, default = None;   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/deep/fedarated/",
	"title": "Fedarated DLearning",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A/Top Wonderings/Todones  Can docker migration assist the fedarated learning?  Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/memtypes/data/",
	"title": "Data",
	"tags": [],
	"description": "",
	"content": " Reference 1\nThe type of Data#, CapTags, CapsPerFlit, and BytesPerFlit.\nSee CheriBusBytes in MemTypes\nData It contains both data and capability tag.\nTODO: What is the data_width? and the relationship between number of tag bits and this data_width, and the CHERI bits?\nData# definition:\n // Data type typedef struct { `ifdef USECAP // is this frame has capabilities CapTags cap; `endif // actual data Bit#(width) data; } Data#(numeric type width) deriving (Bits, Eq, FShow);  CapTags definition\nCapsPerFlit CapsPerFlit is originally defined as the number of capabilities on a bus width data transmission, i.e. one flit transmission.\nused to define CapNumber/CheriCapAddress\n`ifdef USECAP typedef TDiv#(CheriBusBytes,CapBytes) CapsPerFlit; typedef Vector#(CapsPerFlit,Bool) CapTags; typedef Bit#(TSub#(40,TLog#(CapBytes))) CapNumber; typedef struct { CapNumber capNumber; Bit#(TLog#(CapBytes)) offset; } CheriCapAddress deriving (Bits, Eq, Bounded, FShow); `endif see CapBytes\nThere can be many caps per flit; According to \u0026hellip;, one CheriMemRequest/Response will have exactly one flit of data; then a CheriMemRequest/Response will have one flit with \u0026gt;=1 tags in it.\nFor example, in CacheCore.bsv: rule finishLookup. ???\n// cherilibs/trunk/CacheCore.bsv: rule finishLookup: 1368-1419 // Only finish the write if this is the next operation in order. if (req.operation matches tagged Write .wop \u0026amp;\u0026amp;\u0026amp; !dead) begin cacheResp.operation = tagged Write; if (cachedWrite) begin //Construct new line. function Byte choose(Byte o, Byte n, Bool sel) = (sel) ? ((n\u0026amp;wop.bitEnable)|(o\u0026amp;~wop.bitEnable)):o; // zipWith3 combines the three vectors with the function \u0026#34;choose\u0026#34;, defined above, producing another vector. // In this case it is just selecting the old byte or new byte based on byteEnable. Vector#(CheriBusBytes,Byte) maskedWriteVec = zipWith3(choose, unpack(dataRead.data), unpack(wop.data.data), wop.byteEnable); Data#(CheriDataWidth) maskedWrite = wop.data; maskedWrite.data = pack(maskedWriteVec); `ifdef USECAP // Fold in capability tags. CapTags capTags = dataRead.cap; $display(\u0026#34;wop.byteEnable: %x, capTags: %x, wop.data.cap: %x\u0026#34;, wop.byteEnable, capTags, wop.data.cap); Integer i; for (i=0; i\u0026lt;valueOf(CapsPerFlit); i=i+1) begin Integer bot = i*valueOf(CapBytes); Integer top = bot + valueOf(CapBytes) - 1; Bit#(CapBytes) capBytes = pack(wop.byteEnable)[top:bot]; if (capBytes != 0) capTags[i] = wop.data.cap[i]; end //$display(\u0026#34;capTags: %x\u0026#34;, capTags); maskedWrite.cap = capTags; `ifdef STATCOUNTERS cacheCoreEvents.incSetTagWrite = pack(capTags) != 0; `endif `endif //Write updated line to cache. debug2(\u0026#34;CacheCore\u0026#34;, $display(\u0026#34;\u0026lt;time %0t, cache %0d, CacheCore\u0026gt; wrote cache bank %x, way %x with %x\u0026#34;,$time, cacheId, {addr.key, addr.bank}, way, maskedWrite)); dataRead = maskedWrite; data[way].write(DataKey{key:addr.key, bank:addr.bank}, dataRead); `ifdef WRITEBACK_DCACHE if (supportDirtyBytes) begin // Update the dirty bytes if we didn\u0026#39;t write through. Could check performWritethrough, but possibly checking doMemRequest is more reliable. if (!writeThrough \u0026amp;\u0026amp; !doMemRequest) dirties = unpack(pack(dirties)|pack(wop.byteEnable)); // Mark newly written bytes as dirty. else dirties = unpack(pack(dirties)\u0026amp;~pack(wop.byteEnable)); // If we have written through, these bytes are clean. dirtyBytes[way].write(DataKey{key:addr.key, bank:addr.bank}, dirties); debug2(\u0026#34;CacheCore\u0026#34;, $display(\u0026#34;\u0026lt;time %0t, cache %0d, CacheCore\u0026gt; updated dirties bank %x, way %x with %x, doMemRequest: %d\u0026#34;,$time, cacheId, {addr.key, addr.bank}, way, dirties, doMemRequest)); end `endif respValid = True; end // If this is a store conditional and we\u0026#39;re not handling it, // the response is coming later. if (conditional \u0026amp;\u0026amp; (performWritethrough)) dead = True; if (supportInvalidates \u0026amp;\u0026amp; writethroughNext.notEmpty \u0026amp;\u0026amp; doMemRequest \u0026amp;\u0026amp; !dead) writethroughNext.deq; if (miss \u0026amp;\u0026amp; (performWritethrough)) respValid = True; if (wop.uncached) respValid = True; end end BytesPerFlit What is the flit here? Flit is a chunk of data with the actual size being requested/responsed, it is also equal to the data width of memory data bus. But the memory could be read in \u0026lsquo;burst\u0026rsquo;, where multiple \u0026lsquo;flit\u0026rsquo;, or multiple bus width data, will be returned (in multipel bus cycles) even if only one \u0026lsquo;flit\u0026rsquo; is useful in this request.\nWhat does this mean?\nMax number of flits is 8; The max number of flits to be returned in a read request.\n// cherilibs/trunk/MemTypes.bsv typedef 8 MaxTransactions; typedef 8 MaxNoOfFlits;  The memory request has a field noting the bytes per flit:\nmReq.operation.bytesPerFlit, which is usually set to be CheriBusBytes.\n// file: cherilibs/trunk/MultiLevelTagLookup.bsv // A CheriMemRequest mReq mReq.operation = tagged Read { uncached: False, linked: False, noOfFlits: 0, // Lele: why 0??? bytesPerFlit: cheriBusBytes // one flit == busbytes }; BytesPerFlit and CheriBusBytes // cherilibs/trunk/MemTypes.bsv // bytes per flit typedef enum { BYTE_1 = 0, // 8 bits BYTE_2 = 1, // 16 bits BYTE_4 = 2, // 32 bits // used in ICache. BYTE_8 = 3, // 64 bits BYTE_16 = 4, // 128 bits BYTE_32 = 5, // 256 bits BYTE_64 = 6, // 512 bits BYTE_128 = 7 // 1024 bits } BytesPerFlit deriving (Bits, Eq, Bounded, FShow);// cherilibs/trunk/MemTypes.bsv // physical address for cheri `ifdef MEM128 typedef 16 CheriBusBytes; BytesPerFlit cheriBusBytes = BYTE_16; //4 `elsif MEM64 typedef 8 CheriBusBytes; BytesPerFlit cheriBusBytes = BYTE_8; //3 `else typedef 32 CheriBusBytes; BytesPerFlit cheriBusBytes = BYTE_32; //5 `endif `ifdef CAP BytesPerFlit capBytesPerFlit = BYTE_32; `elsif CAP128 BytesPerFlit capBytesPerFlit = BYTE_16; `elsif CAP64 BytesPerFlit capBytesPerFlit = BYTE_8; `endif BytesPerFlit in Memory Reqeust typedef struct { // byte address addr_t addr; \u0026hellip; union tagged { // read operation struct { // uncached / cached access Bool uncached; // LL / standard load Bool linked; // number of flits to be returned UInt#(TLog#(MaxNoOfFlits)) noOfFlits; // number of bytes per flit BytesPerFlit bytesPerFlit; } Read; \u0026hellip; } \u0026hellip; } MemoryRequest#(type addr_t, type masterid_t, type transactionid_t, numeric type data_width) deriving (Bits);\nFlit in Burst.bsv // cherilibs/trunk/Burst.bsv interface Master master; interface CheckedGet request; method Bool canGet(); return req_fifo.notEmpty(); endmethod method CheriMemRequest peek(); return req; endmethod method ActionValue#(CheriMemRequest) get(); CheriMemRequest reqIn = req_fifo.first(); if (reqIn.operation matches tagged Read .rop) begin if (rop.noOfFlits == flit) begin flit \u0026lt;= 0; req_fifo.deq(); last_fifo.enq(True); end else begin flit \u0026lt;= flit + 1; last_fifo.enq(False); end end else begin req_fifo.deq(); last_fifo.enq(True); end return req; endmethod endinterface interface CheckedPut response; method Bool canPut(); return resp_fifo.notFull(); endmethod method Action put(CheriMemResponse resp); if (resp.operation matches tagged Read .rop) resp.operation = tagged Read{last: last_fifo.first}; last_fifo.deq(); resp_fifo.enq(resp); endmethod endinterface endinterface endmodule    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/expand-bits/",
	"title": "Expand Bits",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/tag-lookup/",
	"title": "Tag Lookup",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A How many tags it caches for physical memory access request? Overview Get a physical addr access request, and return a tag associated with this physical address.\nThis is a cache impl based on CacheCore, similar to D/ICache, L2Cache.\nOne Covered Region is a cached tag region. It is of type LineTags, which is a vector (of size 4) of tags, each vector element contains the tags for one flit (i.e. tags for data in one CheriMemRequest)\nCheriTagResponse \u0026ndash; LineTags \u0026ndash; 4 * Bit#(CapsPerFlit)\nCapsPerFlit = number of capabilities in a flit of memory request/response.\nInterfaces - TagLookupIfc // cherilibs/trunk/TagLookup.bsv // interface types /////////////////////////////////////////////////////////////////////////////// typedef Vector#(4,Bit#(CapsPerFlit)) LineTags; typedef union tagged { void Uncovered; LineTags Covered; } CheriTagResponse deriving (Bits); interface TagLookupIfc; interface Slave#(CheriMemRequest, CheriTagResponse) cache; interface Master#(CheriMemRequest, CheriMemResponse) memory; `ifdef STATCOUNTERS interface Get#(ModuleEvents) cacheEvents; `endif endinterface Type CapsPerLine Important types:\nOne line contains four flits (four mem-bus-wide data):\ntypedef TMul#(CapsPerFlit,4) CapsPerLine;\nReturn struct CheriTagResponse A LineTags is a 4-ele vector of type Bit#(CapsPerFlit); each tag cache line could store tags for 4 flits of data (4 memory transmission on the memory bus).\n256-bit flit line:\n 256-bit caps: caps per flit = 1; 256 cap tags cover 256 * 256 bit = 64KB memory; LineTags contain 4 * 1 tags; ==\u0026gt; wasted 252 bits??? 64-bit caps: caps per flit = 4; 256 cap tags cover 256 * 64 = 16 KB memory; LineTags contain 4 * 4 tags;\n// cherilibs/trunk/TagLookup.bsv typedef Vector#(4,Bit#(CapsPerFlit)) LineTags; typedef union tagged { void Uncovered; LineTags Covered; } CheriTagResponse deriving (Bits);  States FIFOs:\n readReqs mReqs mRsps\n// state register Reg#(State) state \u0026lt;- mkReg(Init); // address to zero when in Init state Reg#(CheriPhyAddr) zeroAddr \u0026lt;- mkReg(tagTabStrtAddr); // transaction number for memory requests Reg#(CheriTransactionID) transNum \u0026lt;- mkReg(0); // pending read requests fifo // pending read requests fifo FF#(Tuple2#(Bool,CheriPhyBitOffset),4) readReqs \u0026lt;- mkFF(); // memory requests fifo FF#(CheriMemRequest, 5) mReqs \u0026lt;- mkUGFFDebug(\u0026#34;TagLookup_mReqs\u0026#34;); // memory response fifo FF#(CheriMemResponse, 2) mRsps \u0026lt;- mkUGFFDebug(\u0026#34;TagLookup_mRsps\u0026#34;); // tag cache CacheCore module CacheCore#(4, TSub#(Indices, 1), 1) tagCache \u0026lt;- mkCacheCore( 12, WriteAllocate, OnlyReadResponses, InOrder, TCache, zeroExtend(mReqs.remaining()), ff2fifof(mReqs), ff2fifof(mRsps));  // state register Reg#(State) state \u0026lt;- mkReg(Init); // address to zero when in Init state Reg#(CheriPhyAddr) zeroAddr \u0026lt;- mkReg(tagTabStrtAddr); // transaction number for memory requests Reg#(CheriTransactionID) transNum \u0026lt;- mkReg(0); // pending read requests fifo\nInterface Slave Two subinterfaces:\n interface CheckedPut request; // the interface to receive request from outside;\n method Bool canPut(); method Action put(CheriMemRequest req)  interface CheckedGet response; // the interface to send response out;\n method Bool canGet(); method CheriTagResponse peek(); method ActionValue#(CheriTagResponse) get() if (tagCache.response.canGet());   Slave request Overview: the interface to receive tag r/w request from tagController; It\nIt contains the follow two methods:\n method Bool canPut() = state == Serving; // can receive request when Serving\n method Action put(CheriMemRequest req) if (state == Serving); // got a new request and put in queue tagCache.put(mReq)\n  The put method:\nfunction Bool isCovered (CheriPhyAddr addr); Bool r = True; if (addr \u0026lt; coveredStrtAddr \u0026amp;\u0026amp; addr \u0026gt;= coveredEndAddr) r = False; if (addr \u0026gt;= tagTabStrtAddr \u0026amp;\u0026amp; addr \u0026lt; tagTabEndAddr) r = False; return r; endfunction // interface Slave cache: // interface CheckedPut request: method Action put(CheriMemRequest req) if (state == Serving); // check whether we are in the covered region Bool doTagLookup = isCovered(req.addr); // various addresses variables CheriCapAddress capAddr = unpack(pack(req.addr)); CheriPhyAddr tblAddr = tagTabStrtAddr; // The byte address in the table is the line number \u0026gt;\u0026gt; 3 (the byte we seek) added to the table base. // Only caclulate the table address for lower general-purpose memory. tblAddr = unpack(zeroExtend(capAddr.capNumber\u0026gt;\u0026gt;3) + pack(tagTabStrtAddr)); // build the request to the tag cache // common part of the request CheriMemRequest mReq = defaultValue; mReq.addr = tblAddr; mReq.masterID = mID; mReq.transactionID = transNum; case (req.operation) matches // when it\u0026#39;s a read ////////////////////////////// tagged Read .rop: begin mReq.operation = tagged Read { uncached: False, linked: False, noOfFlits: 0, bytesPerFlit: cheriBusBytes }; readReqs.enq(tuple2(doTagLookup,truncate(capAddr.capNumber))); end // when it\u0026#39;s a write ////////////////////////////// tagged Write .wop: begin Vector#(CapBytes, Bool) byteEnable = replicate(False); // select the table byte to write byteEnable[tblAddr.byteOffset] = True; // select the table bits to write Bit#(3) bitOffset = capAddr.capNumber[2:0]; Bit#(8) bitEnable = 0; Bit#(8) tw = 0; Integer i = 0; for (i = 0; i \u0026lt; valueOf(CapsPerFlit); i = i + 1) begin bitEnable[bitOffset+fromInteger(i)] = 1; tw[bitOffset+fromInteger(i)] = pack(wop.data.cap[i]); end // Just replicate the byte and let the byte and bit select choose the bits to write. CheriData tagsToWrite = Data{ cap: ?, data: pack(replicate(tw)) }; mReq.operation = tagged Write { uncached: False, conditional: False, byteEnable: byteEnable, bitEnable: bitEnable, data: tagsToWrite, last: True }; end // ignore other types of requests default: doTagLookup = False; endcase // when a lookup is required if (doTagLookup) begin debug2(\u0026#34;taglookup\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagLookup\u0026gt; Request to cache core \u0026#34;, $time, fshow(mReq) )); // send the tag cache request tagCache.put(mReq); // increment the transaction number transNum \u0026lt;= transNum + 1; end endmethod  call isCovered: check whether the request addr is in covered memory, if not, the request would be an invalid physical address for the current hardware setting. see physical memory regions\n covered region: [coveredStrtAddr, coveredEndAddr] - [tagTabStrtAddr, tagTabEndAddr) tagRegion:dataRegion:totalRegion should be 1:256:257 or 1:128:129, see physical memory regions  calculate the byte address in the table:\n tblAddr = unpack(zeroExtend(capAddr.capNumber\u0026gt;\u0026gt;3) + pack(tagTabStrtAddr)); capAddr is byte address for an capability, with CapNumber is the cap aligned address and offset as byte index into the capability, see CheriCapAddress definition CapNumber \u0026gt;\u0026gt; 3, gives the 8-capability size aligned physical address, which has 8-bit tags;  To extend it from 1-bit=tag per cap to a 2-bit=tag per cap: use CapNumber \u0026gt;\u0026gt; 2, gives the 4-capability size aligned physical address, which corresponds to 4 bits of cap tags and 4-bits of color tags;   craft the memory request to the tag cache:\n CheriMemRequest mReq, with .masterID to be 12 means a tag request. if read, enqueue fifo readReqs.enq(tuple2(doTagLookup,truncate(capAddr.capNumber))); if write, set the index of bits need to be written   Slave response The interface defines the get method, which send response back to tagController.\n// lookup Slave response interface ////////////////////////////////////////////////////// interface CheckedGet response; method Bool canGet() = tagCache.response.canGet(); method CheriTagResponse peek(); CheriMemResponse mRsp = tagCache.response.peek(); return tagsFromCacheRsp(mRsp); endmethod method ActionValue#(CheriTagResponse) get() if (tagCache.response.canGet()); // get response from the tag cache and read fifo CheriMemResponse mRsp \u0026lt;- tagCache.response.get(); readReqs.deq(); // debug debug2(\u0026#34;taglookup\u0026#34;, $display( \u0026#34;\u0026lt;time %0t TagLookup\u0026gt; got valid cache response \u0026#34;, $time, fshow(mRsp) )); return tagsFromCacheRsp(mRsp); endmethod endinterface To prepare a response:\n grab a response CheriMemResponse mRsp from tagCache.response dequeue an element from readReqs // why? dequeue even if a write? pass the response CheriMemResponse and return as CheriTagResponse, via tagsFromCacheRsp(mRsp).  The definition of tagsFromCacheRsp gives the details how a regular memory response is converted into a tag response. See [./#function-tagsfromcachersp]\nfunction tagsFromCacheRsp // cherilibs/trunk/TagLookup.bsv function CheriTagResponse tagsFromCacheRsp (CheriMemResponse mr); CheriTagResponse r; Data#(CheriDataWidth) rData = mr.data; match {.covered,.offset} = readReqs.first(); // Cast to a vector of tag chunks. The chunks are the set of tags for one line. Vector#(TDiv#(CheriDataWidth,CapsPerLine), Bit#(CapsPerLine)) sets = unpack(rData.data); // Pick out the index CheriPhyBitOffset index = (offset \u0026gt;\u0026gt; valueOf(TLog#(CapsPerLine))); // Shift by the bottom two bits so that non-burst requests will have // the tag bit in the bottom. Bit#(TLog#(CapsPerLine)) shift = truncate(offset); LineTags thisSet = unpack(sets[index] \u0026gt;\u0026gt; shift); if (!covered) r = tagged Uncovered; else r = tagged Covered thisSet; return r; endfunction  get first in readReqs, store as {.covered, .offset} unpack the data in memory response struct CheriMemResponse, convert it to a vector of type Bit#(CapsPerLine): Vector#(TDiv#(CheriDataWidth,CapsPerLine), Bit#(CapsPerLine)) sets = unpack(rData.data);: one set is contains CapsPerLine number of tag bits, which is seen as the 4 times of Tags inside one Data# (Caps in one flit). Why tags for four Data# in one set? the burst? Note: MultiLevelTagLookup.bsv does not use this CapsPerLine.\n return all four Data# tags as response.\n  ==\u0026gt; **One CheriMemResponse.data = CheriDataWidth \u0026gt; **\nInterface Master Interface of request and response is connected with mReqs and mRsps:\nmReqs and mRsps are regular memory request that are no difference with non-tag memory access.\n// module Master interface ///////////////////////////////////////////////////////////////////////////// interface Master memory; interface request = toCheckedGet(ff2fifof(mReqs)); interface response = toCheckedPut(ff2fifof(mRsps)); endinterface rule initialize zero out all the tags table in memory.\nWhen table zeroed, go to Serving state.\nPhysical Memory Region Constant physical memory region\ntagRegion:totalRegion should be\n \u0026gt;= 1:257, 1:128, or \u0026gt;=2:258, 1:64; or \u0026gt;=3:259, 1:64; or \u0026gt;=4:260, 1:64; or  Now the ratio is 2^24:2^30 = 1: 2^6 = 1: 64 // good\n   region start addr \u0026ndash; end addr size in hex size     total in use 40\u0026rsquo;h0000,0000 \u0026ndash; 40\u0026rsquo;h4000,0000 h4000,0000 2^30 1GB   tag mem 40\u0026rsquo;h3F00,0000 \u0026ndash; 40\u0026rsquo;h4000,0000 h0100,0000 2^24 16MB   regular mem 40\u0026rsquo;h0000,0000 \u0026ndash; 40\u0026rsquo;h3EFF,FFFF h3F00,0000 1024-16=1008 MB    Now support only 1GB physical memory?!\n// file: cherilibs/trunk/TagLoopup.bsv // covered region include DRAM and BROM // starting address of the covered region CheriPhyAddr coveredStrtAddr = unpack(40\u0026#39;h00000000); // ending address of the covered region CheriPhyAddr coveredEndAddr = unpack(40\u0026#39;h40010000); // Lele: 1GB + 64KB? // tagd table is at top of DRAM // starting address of the tags table CheriPhyAddr tagTabStrtAddr = unpack(40\u0026#39;h3F000000); // ending address of the tags table CheriPhyAddr tagTabEndAddr = unpack(40\u0026#39;h40000000); Reference 1\n  github/beri ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/multi-level-tag-lookup/",
	"title": "MultiLevelTagLookup.bsv",
	"tags": [],
	"description": "",
	"content": " Todones rules/functions processing different states: - Init: - doLookup condition !Init - Idle: - Slave cache.request.canPut(), put(), - doLookup condition !Idle - ReadTag, SetTag, ClearTag: - used in doLookup - set in Slave cache.request.put(req) - FoldZeroes: - used in doLookup - set in doLookup, rules triggered by getReq.send(): -\u0026gt; rule drainMemRsp: // done rule doLookup: -\u0026gt; ClearTags: -\u0026gt; getOldTagsEntry() // done // do nothing if flat table. -\u0026gt; getReq.send() // done -\u0026gt; doTransition() // done Slave: -\u0026gt; request.put(): -\u0026gt; craftTagReadReq() // done -\u0026gt; getTableAddr() // done -\u0026gt; read -\u0026gt; nextState = ReadTag -\u0026gt; rule doLookup // done -\u0026gt; write: -\u0026gt; nextState = Idle -\u0026gt; rule doLookup // done -\u0026gt; nextState = ClearTag -\u0026gt; rule doLookup // done -\u0026gt; nextState = SetTag -\u0026gt; rule doLookup // done -\u0026gt; set globals - pendingCapNumber, used in rule doLookup, send this to functions getTableEntry(,,), getTableAddr(,), craftTagReadReq(,),craftTagWriteReq(,,,,), getNewTagsEntry(,),getOldTagsEntry(,,) // todo - pendingTags, used in rule doLookup, send this to functions craftTagWriteReq(,,,,),getNewTagsEntry(,) // todo - pendingCapEnable, used in rule doLookup, send this to functions craftTagWriteReq(,,,,),getNewTagsEntry(,,,,) // todo -\u0026gt; doTransition() -\u0026gt; tagCacheReq.enq(mr) // rule feedTagCache: forward from tagCacheReq to tagCache module // done -\u0026gt; useNextRsp.enq(useRsp) // used in rule drainMemRsp: drain unused response; used in rule doLookup condition: only if not full, doLookup will be triggered. -\u0026gt; state \u0026lt;= newState; // new state in effect. -\u0026gt; response.get(): return lookupRsp.first // done. Reference 1\nParameters:\n ways = 4, keyBits is Indices - 1, inFlight = 1\n cacheID = 12,\n writeMissBehavior = WriteAllocate,\n responseBehavior = ResponseAll,\n orderBehavior = InOrder,\n whichCache = TCache,\n memReqFifoSpace = zeroExtend(mReqs.remaining()),\n memReqs = ff2fifof(mReqs),\n memRsps = ff2fifof(mRsps)\n  Return struct CheriTagResponse // cherilibs/trunk/MultiLevelTagLookup.bsv // interface types /////////////////////////////////////////////////////////////////////////////// typedef Vector#(4,Bit#(CapsPerFlit)) LineTags; typedef union tagged { void Uncovered; LineTags Covered; } CheriTagResponse deriving (Bits,FShow); Interfaces - TagLookupIfc // cherilibs/trunk/MultiLevelTagLookup.bsv interface TagLookupIfc; interface Slave#(CheriMemRequest, CheriTagResponse) cache; interface Master#(CheriMemRequest, CheriMemResponse) memory; `ifdef STATCOUNTERS interface Get#(ModuleEvents) cacheEvents; `endif endinterface same as in TagLookup.bsv\nInternal Types  State: Init, Idle, ReadTag, SetTag, ClearTag, FoldZeroes  ReadTag, SetTag, ClearTag, FoldZeroes, Only handle one request a time; State will tell us which kind of operation the request has. The state is set during Slave request - put interface   Table Node Leaf Node:\n if node is 0, means all the tags under its covered addr range are 0s; This case will improve the search performance; If node is 1, means at least one of tags under its covered addr is 1, then we will need to got to next level of node to search for tag values; This case will hurt the search performance.  Leaf: the tags for every address is stored and can be accessed directly. Usually it will contain non-zero tags.\n TableEntry deriving(Bits)\n Bool Node LineTags Leaf; tags of 4 flits.  Tablelvl deriving(FShow)\n CheriPhyAddr startAddr; int size int shiftAmnt; int groupFactor; int groupFactorLog;  TDepth: maximum table depth of 8;\n  state Parameters/Instantiate\n CheriMasterID mID, (= 12) CheriPhyAddr tagTabEndAddr, (= 40\u0026rsquo;h4000_0000) Vector#(tdepth, Integer) tableStructure, ( = ???, in TagTableStructure.bsv generated by tagsparams.py) Integer memCoveredSize  Interface TagLookupIfc arguments:\n ways = 4, keyBits is Indices - 1, inFlight = 1\n cacheID = 12,\n writeMissBehavior = WriteAllocate,\n responseBehavior = ResponseAll,\n orderBehavior = InOrder,\n whichCache = TCache,\n memReqFifoSpace = zeroExtend(mReqs.remaining()),\n memReqs = ff2fifof(mReqs),\n memRsps = ff2fifof(mRsps)\n  State Registers:\n state, zeroAddr, init as tagTabStrtAddr transNum, transaction number for mem requests currentDepth, pendingCapNumber, pendingTags, pendingCapEnable  Vectors:\n Vector#(tdepth, Tablelvl) tableDesc = genWith(lvlDesc)  call lvlDesc from 0 to tdepth - 1; return values composes the Vector#  Vector#(tdepth, Reg#(Bit#(CheriDataWidth))) oldTags  FIFOs:\n readReqs lookupRsp mReqs mRsps useNextRsp tagCacheReq PulseWire getReq \u0026lt;- mkPulseWire(); // ??  Submodules:\n CacheCore#(4, TSub#(Indices, 1), 1) tagCache \u0026lt;- mkCacheCore(12, WriteAllocate, RespondAll, InOrder, TCache, zeroExtend(mReqs.remaining()), ff2fifof(mReqs), ff2fifof(mRsps));  CacheCore instance // cherilibs/trunk/MultiLevelTagLookup.bsv: // tag cache CacheCore module CacheCore#(4, TSub#(Indices, 1), 1) tagCache \u0026lt;- mkCacheCore( 12, WriteAllocate, RespondAll, InOrder, TCache, zeroExtend(mReqs.remaining()), ff2fifof(mReqs), ff2fifof(mRsps)); // cherilibs/trunk/CacheCore.bsv: module mkCacheCore#(Bit#(16) cacheId, WriteMissBehaviour writeBehaviour, ResponseBehaviour responseBehaviour, OrderBehaviour orderBehaviour, WhichCache whichCache, // Must be \u0026gt; 5 or we can\u0026#39;t issue reads with evictions! // This means that a write-allocate cache must have \u0026gt;=5 capacity in the output fifo. Bit#(10) memReqFifoSpace, FIFOF#(CheriMemRequest) memReqs, FIFOF#(CheriMemResponse) memRsps) (CacheCore#(ways, keyBits, inFlight)) Functions  function TableLvl lvlDesc(Integer d); function Bool isCovered(CheriPhyAddr addr); function CheriPhyBitAddr getTableAddr(TDepth cd, CapNumber cn); function TableEntry getTableEntry(TDepth cd, CapNumber cn, Bit#(CheriDataWidth) tags); function Bit#(CheriDataWidth) getOldTagsEntry(TDepth cd, CapNumber cn, Bit#(CheriDataWidth) tags); function Bit#(CheriDataWidth) getNewTagsEntry(\u0026hellip;); function CheriMemRequest craftTagReadReq(TDepth d, CapNumber cn); function CheriMemRequest craftTagWriteReq(\u0026hellip;); function Action doTransition(\u0026hellip;);  function getOldTagsEntry Overview: when table only have one level, it does no transformation to tags, and will return the input as output\nfunction getTableEntry function craftTagWriteReq function doTransition Overview: put memory request in the fifo so it will be fed to tagCache, at the same time, put a bool switch useRsp to flag whether the response will be ignored or not in rule doLookup;\n// file: cherilibs/trunk/MultiLevelTagLookup.bsv function Action doTransition ( Maybe#(CheriMemRequest) mmr, // Contains one valid bit, and then request. TDepth newDepth, State newState, Bool useRsp ) = action debug2(\u0026#34;taglookup\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagLookup\u0026gt; table structure -\u0026#34;, $time, fshow(tableDesc) )); case (mmr) matches tagged Valid .mr: begin // send the tag cache request and increment the transaction number debug2(\u0026#34;taglookup\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagLookup\u0026gt; sending lookup: \u0026#34;, $time, fshow(mr) )); tagCacheReq.enq(mr); useNextRsp.enq(useRsp); transNum \u0026lt;= transNum + 1; end endcase // update lookup depth currentDepth \u0026lt;= newDepth; // do state transistion state \u0026lt;= newState; debug2(\u0026#34;taglookup\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagLookup\u0026gt; pendingCapNumber %x, currentDepth %d -\u0026gt; %d, state \u0026#34;, $time, pendingCapNumber, currentDepth, newDepth, fshow(state), \u0026#34; -\u0026gt; \u0026#34;, fshow(newState) )); endaction; If a valid memory request, send the cache request and increment the transaction number\n tagCacheReq.enq(mr); // request will then be fed to tagCache.put(tagCacheReq.first()) useNextRsp.enq(useRsp); // whether this request will have a response being parsed in rule doLookup. ??? transNum \u0026lt;= transNum + 1;  Rules  rule feedTagCache; rule initialise (state == Init); rule stuffCommits; rule drainMemRsp(\u0026hellip;) rule doLookup(\u0026hellip;)  rule doLookup Overview: lookup the multi level table\nBy default only one-level table is used. That is all nodes are leaf nodes.\nTODO: where does the read response generated?\nCheck the current state\n Check current state if ReadTag: check the table entry\u0026rsquo;s union type\n If Node type entry: check Node value for short cut (all 0 tags), or go to next level table entry by calling craftTagReadReq // If Leaf type entry: enqueue lookupRsp the leaf LineTags, where the first bit is the start of the requested capNumber\u0026rsquo;s flit\u0026rsquo;s tags. getReq.send() // drain unused memory response (for unused write responses) doATransition = True // will call doTransition() to put request to tagCache, the request can be invalid.  if SetTag:\n Only triggered when memRspReady meaning the memory content to be written has been loaded from memory into the tagCache. If Node \u0026hellip;. If Leaf table entry: set state to Idle; // already done write??? getReq.send() // drain unused memory response (for unused write responses) doATransition = True // will call doTransition() to put request to tagCache  if ClearTag:\n only triggered when memRspReady, meaning the memory is loaded into the cache already; get all the tags: getOldTagsEntry(dpth,capNumber,rspData) // todo if Node table entry \u0026hellip; if Leaf table entry:  craft a tag write memory request set state to Idle  getReq.send() // drain unused memory response (for unused write responses) doATransition = True // will call doTransition() to put request to tagCache  if FoldZeroes \u0026hellip;\n doTransition(): put mem request to tagCache\n  Interface - Slave interface Slave cache; two subinterfaces\n interface CheckedPut request; interface CheckedGet response;  Slave - request  Bool canPut() = (state == Idle); // only can receive request when Idle\n Action put(CheriMemRequest req) if (state == Idle); // only when Idle\n  The put method, in steps:\n doTagLookup = isCovered(req.addr); newPendingTags: temporal store number of tags in a flit; newPendingCapEnable: temporal store enable bits for each cap in a flit; create a mem request to initialise a toplevel table lookup.  CheriMemRequest mReq = craftTagReadReq(rootLvl, capAddr.capNumber)  if read: read tags:  readReqs.enq(doTagLookup); nextState = ReadTag; // will trigger code only in rule doLookup  if write: write tags:  use capEnable to mask the cap bits to be written in a flit; get capTags from the request; compute bool vector andTags = capEnable \u0026amp; newPendingTags; check capEnable: set to IDLE if all disabled, i.e. no write ops; check andTags: if all 0, mean all tag to write is 0, then set to ClearTag state. // Lele: we might use similar solution to initialize color tags in scale. if has at least one non-zero tag, craft a tag write memory request and set next state as SetTag  set globals  pendingCapNumber \u0026lt;= capAddr.capNumber; // the cap aligned address pendingTags \u0026lt;= newPendingTags; // tags to be written, 0 if read; pendingCapEnable \u0026lt;= newPendingCapEnable; // enabled cap bits to be written, 0 if read.  call doTransition(tagged Valid mReq, rootLvl, nextState, True)  put mReq to tagCache: tagCacheReq.enq(mr); put one bool in fifo: useNextRsp.enq(useRsp); trigger rules by change state to newState   Slave - response The get method, for tagController to get response from here. Returned struct is CheriTagResponse, a tagged union, contain LineTags tagged as Covered as valid type; LineTags is a vector of tags in 4*flits width (every bit is a tag)\nThe get() steps:\n condition: !readReqs.first() || lookupRsp.notEmpty()  no read request in queue (not covered?) or has a response in queue  if readReq.first(), meaning the request addr is covered (valid), grab the rsp from fifo and return CheriTagResponse tr = tagged Covered lookupRsp.first(); if readReq.first() is not true, an invalid addr (not covered), return invalid response (CheriTagResponse tr = tagged Uncovered;)  Interface - Master interface Master memory; two subinterfaces\n interface request = toCheckedGet(ff2fifof(mReqs)); interface response = toCheckedPut(ff2fifof(mRsps));  Physical Memory Region // Constant physical memory region\n// file: cherilibs/trunk/MultiLevelTagLoopup.bsv // static parameters ///////////////////////////////////////////////////////////////////////////// // covered region include DRAM and BROM // starting address of the covered region CheriPhyAddr coveredStrtAddr = unpack(40\u0026#39;h00000000); // ending address of the covered region CheriPhyAddr coveredEndAddr = unpack(40\u0026#39;h40010000); // Lele: 1GB + 64KB. Why 64KB here? // tagd table is at top of DRAM // starting address of the tags table CheriPhyAddr tagTabStrtAddr = unpack(40\u0026#39;h3F000000);   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/bluespec/packages/connectable/get-put/",
	"title": "Get Put",
	"tags": [],
	"description": "",
	"content": " Reference 1 C.7.1 GetPut\nimport GetPut::*;\nTwo blocks: Someone else gets or retrieves an item from an interface and Someone else put or gives an item to an iterface.\nCommonly used in Transaction Level Modeling, or TLM.\nGet You can retrieve (get) data from an object.\nmethod: get(): returns an item from an interface and removes it from the object.\ninterface Get#(type a); method ActionValue#(a) get(); endinterface: Get Example:\nmodule mkMyFifoUpstream (Get#(int)); ... method ActionValue#(int) get(); f.deq; return f.first; endmethod ... Put You can give (put) data to an object.\nmethod: put(a_type a) give an item of type a_type to an interface.\ninterface Put#(type element_type); method Action put(element_type x1); endinterface: Put Example:\nmodule mkMyFifoDownstream (Put#(int)); ... method Action put(int x); F.enq(x); endmethod ... ToGet/ToPut Two typeclasses: ToGet and ToPut, used to create associated Get and Put interfaces from other types.\n typeclass ToGet#(a,b); function Get#(b) toGet(a ax); endtypeclass typeclass ToPut#(a,b); function Put#(b) toPut(a ax); endtypeclass  GetS Like a Get interface, but separates the get method into two methods: a first and a deq.\nGetPut Todo.\n  Bluespec Reference Guide. 2017 ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/bluespec/packages/connectable/client-server/",
	"title": "Client Server",
	"tags": [],
	"description": "",
	"content": " Reference 1\nClient two subinterfaces:\n Get#(req_type) request; // outside world will go through this interface to get a request from client Put#(resp_type) response; // outside world will go through this interface to send response to client  Server two subinterfaces:\n Put#(req_type) request; // outside world (client) will go throught this interface to send request to server; Get#(resp_type) response; // outside world (client) will go through this interface to get response from server.  ==\u0026gt; interface of Put# is used to grab something from outside to inside; interface of Get# is used to send something from inside out. (LLM: weird. This is from third-person view: this interface is used for others to xxx. As first-person view would be totally opposite: this interface is used for me to xxx).\nClientServer request (type Get) of the client will connect to request (type Put) of the Server.\nresponse (type Put) of the client will connect to response (type Get) of the Server.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/modern89/logic-methods/",
	"title": "Logic Methods",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  什么是语形论/语义论/语用论方法？ 什么是应用逻辑？  Reference 1\n（前言）\n对逻辑方法的大致划分，三个方面：\n 语形论方法 语义论方法 语用论方法  纯逻辑（不包括应用逻辑），要使用语形论方法和语义论方法。\n  现代逻辑方法论，永井成男，1989. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/master-slave/",
	"title": "Master Slave",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Master Slave: how do they communicate?  ModuleA (master)\u0026lt;\u0026mdash;-\u0026gt; (slave) ModuleB (master) \u0026lt;\u0026mdash;-\u0026gt; (slave) ModuleC Master controls the communication: do the put/get things by calling slave\u0026rsquo;s interface method. Slave will be waiting for being called and receive the data; One has Slave interface will also have a Master interface in order to pass this data to the Slave interface of next module. Right?   See Bluespec basics for connectable interfaces [/en/arch/basics/bluespec/packages/connectable/client-server/]\nMaster // cherilibs/trunk/MasterSlave.bsv interface Master#(type req_t, type rsp_t); interface CheckedGet#(req_t) request; // interface to send request out interface CheckedPut#(rsp_t) response; // interface to get a response in endinterface Master-Slave Master# is used as client interface and Slave# is used as server interface.\nMaster.request.get() \u0026ndash;\u0026gt; Slave.request.put() // Master send a request ot Master.response.put() \u0026lt;\u0026ndash; Slave.response.get() // Master receive a new response from Slave.\n// file: cherilibs/trunk/MasterSlave.bsv // Slave to Server: A Server# interface with request and response function Server#(req_t,rsp_t) slaveToServer (Slave#(req_t, rsp_t) s) = interface Server#(req_t, rsp_t); interface request = toPut(s.request); // A Put# interface, allow others to send request into this server; interface response = toGet(s.response); // A Get# interface, allow others to get responses froms this server; endinterface; // Master to Client: A client# interface with request and response function Client#(req_t,rsp_t) masterToClient (Master#(req_t, rsp_t) m) = interface Client#(req_t, rsp_t); interface request = toGet(m.request); // a Get#(req_t) interface, allow the client to send out request out; interface response = toPut(m.response); // a Put#(rsp_t), allow the client to receive a new repsonse from outside; endinterface; // Master as client and Slave as server instance Connectable#(Master#(req_t, rsp_t), Slave#(req_t, rsp_t)); module mkConnection#(Master#(req_t, rsp_t) m, Slave#(req_t, rsp_t) s)(Empty); mkConnection(masterToClient(m), slaveToServer(s)); endmodule endinstance function Server#(req_t,rsp_t) slaveToServer (Slave#(req_t, rsp_t) s) = interface Server#(req_t, rsp_t); interface request = toPut(s.request); interface response = toGet(s.response); endinterface; instance Connectable#(Slave#(req_t, rsp_t), Master#(req_t, rsp_t)); module mkConnection#(Slave#(req_t, rsp_t) s, Master#(req_t, rsp_t) m)(Empty); mkConnection(masterToClient(m), slaveToServer(s)); endmodule endinstance ToCheckedGet // cherilibs/trunk/MasterSlave.bsv instance ToCheckedGet#(FIFOF#(data_t), data_t); function CheckedGet#(data_t) toCheckedGet (FIFOF#(data_t) f) = interface CheckedGet#(data_t); method canGet = f.notEmpty; method data_t peek if (f.notEmpty); return f.first; endmethod method ActionValue#(data_t) get if (f.notEmpty); f.deq; return f.first; endmethod endinterface; endinstance Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/l2cache/",
	"title": "L2Cache",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Who calls it and what is the input?\n Where does it go?\n hand over the request to tagControllers Calls tagController to get response  How is it related tagged memory?\n The master interface memory is re-used by TagController   file: cherilibs/trunk/L2Cache.bsv\nInterface L2CacheIfc Master is memory; Slave is cache;\nmkConnection(l2CacheMemory, tagController.cache); means Master is l2CacheMemory and slave is tagController.cache, that is tag controller is being called by l2Cache; and l2Cache send request and get response from tagController.\ninterface L2CacheIfc; interface Slave#(CheriMemRequest, CheriMemResponse) cache; interface Master#(CheriMemRequest, CheriMemResponse) memory; `ifdef MULTI `ifndef TIMEBASED method ActionValue#(Maybe#(InvalidateCache)) getInvalidate; method Action putInvalidateDone(Bool didWriteback); `endif `endif `ifdef STATCOUNTERS interface Get#(ModuleEvents) cacheEvents; `endif endinterface: L2CacheIfc  Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/merge/",
	"title": "Merge.bsv",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Who calls this and what is the input?\n i/dcache requests goes through here and being forwarded to l2cache; l2cache response being sent back here and forwarded to i/dcache;  Where does this go?\n forward request to l2cache memory; Memory.bsv: mkConnection(theMemMerge.merged, l2Cache.cache) return response to icache/dcache via slaves[i]   file: cheri/trunk/Merge.bsv\nmodule mkMergeFast module mkMergeFast(MergeIfc#(numIfc));\nnumIfc = 2 in Memory.bsv\nConnections: // Memory.bsv mkConnection(iCache.memory, theMemMerge.slave[0]); mkConnection(dCache.memory, theMemMerge.slave[1]); States FIFOF#(CheriMemRequest) nextReq \u0026lt;- mkBypassFIFOF; FIFOF#(CheriMemResponse) rsp_fifo \u0026lt;- mkBypassFIFOF; Vector#(numIfc, Wire#(Bool)) fired \u0026lt;- replicateM(mkDWire(False)); Vector#(numIfc, Bool) block;\nInterface MergeIfc  interface Master#(CheriMemRequest, CheriMemResponse) merged; interface Vector#(numIfc, Slave#(CheriMemRequest, CheriMemResponse)) slave;  Slave interface Vector#(numIfc, Slave#(CheriMemRequest, CheriMemResponse)) slaves;\ninterface slave = slaves;\n subinterface response; subinterface request;  Response: check rsp_fifo.first.masterID, only return response when masterID matches icache (0) or dcache(1).\nRequest: put req to nextReq: nextReq.enq(req). Set fired[i] to true,\nMaster interface merged  interface CheckedGet request = toCheckedGet(nextReq); interface CheckedPut response = toCheckedPut(rsp_fifo);  rule debugRule print time and rsp_fifp status .notFull\nReference 1\n  github/beri ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/mem-tag/addr-san/",
	"title": "Addr San",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/bluespec/packages/connectable/",
	"title": "Connectable",
	"tags": [],
	"description": "",
	"content": "  The Connectable type class defines the module mkConnection, which is used to connect a pair of related types.\n typeclass Connectable#(type a, type b); module mkConnection#(a x1, b x2)(Empty); endtypeclass  Instances of typeclass to be connectable Get and Put instance Connectable#(Get#(a), Put#(a));\nOne put and another will get the element.\nTuples instance Connectable#(Tuple2#(a, c), Tuple2#(b, d)) provisos (Connectable#(a, b), Connectable#(c, d));  This is used by ClientServer to connect the Get of Client to the Put of the Server and visa-versa.\nReference 1\n Get Put  Reference 1 C.7.1 GetPut import GetPut::*; Two blocks: Someone else gets or retrieves an item from an interface and Someone else put or gives an item to an iterface. Commonly used in Transaction Level Modeling, or TLM. Get You can retrieve (get) data from an object. method: get(): returns an item from an interface and removes it from the object. interface Get#(type a); method ActionValue#(a) get(); endinterface: Get Example:\n Client Server  Reference 1 Client two subinterfaces: Get#(req_type) request; // outside world will go through this interface to get a request from client Put#(resp_type) response; // outside world will go through this interface to send response to client Server two subinterfaces: Put#(req_type) request; // outside world (client) will go throught this interface to send request to server; Get#(resp_type) response; // outside world (client) will go through this interface to get response from server.\n  C.7.2 Bluespec Reference Guide. 2017. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/bluespec/packages/",
	"title": "Packages",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Connectable  The Connectable type class defines the module mkConnection, which is used to connect a pair of related types. typeclass Connectable#(type a, type b); module mkConnection#(a x1, b x2)(Empty); endtypeclass Instances of typeclass to be connectable Get and Put instance Connectable#(Get#(a), Put#(a)); One put and another will get the element. Tuples instance Connectable#(Tuple2#(a, c), Tuple2#(b, d)) provisos (Connectable#(a, b), Connectable#(c, d)); This is used by ClientServer to connect the Get of Client to the Put of the Server and visa-versa.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/cache-core/",
	"title": "CacheCore.bsv",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Does it treat the memory tags read/write request differently?\n no. tag read/write can only be distinguished by masterID. However, master ID does not change the logic routines in CacheCore. CacheCore only transfer this master ID from request to response.  Who calls this and what is the input?\n DCache calls this to send request and get response via core.put(CheriMemRequest reqIn) and core.response.get init: CacheCore#(4, TSub#(Indices,1), 1) core \u0026lt;- mkCacheCore(cacheId, wmb, RespondAll, InOrder, DCache, zeroExtend(memReqs.remaining()), ff2fifof(memReqs), memRsps); ICache calls this to send request and get response via core.put(CheriMemRequest mem_req) and core.response.get() init: CacheCore#(2, Indices, 1) core \u0026lt;- mkCacheCore(cacheId, WriteThrough, OnlyReadResponses, InOrder, ICache,zeroExtend(memReqs.remaining()), ff2fifof(memReqs), ff2fifof(memRsps)); L2Cache calls this to send request to and get response from CacheCore via  core.put(CheriMemRequest cmr) CheriMemResponse unused \u0026lt;- core.response.get(); and CheriMemResponse resp = core.response.peek();  init: CacheCore#(4, TAdd#(Indices, 2), 4) core \u0026lt;- mkCacheCore(8, WriteAllocate, RespondAll, InOrder, L2,zeroExtend(memReqs.remaining()),ff2fifof(memReqs), ff2fifof(memRsps)); TagCache send request: core.put(CheriMemRequest tabReq); get response: CheriMemResponse memResp \u0026lt;- core.response.get(); init: CacheCore#(4, TSub#(Indices, 1), 1) core \u0026lt;- mkCacheCore(12, WriteAllocate, OnlyReadResponses, InOrder, TCache, zeroExtend(tabReqs.remaining()), ff2fifof(tabReqs), ff2fifof(tabRsps)); MultiLevelTagLookup init: `` TagLookup init: ``  Where does it go?\n From request goes to: next level request sending response back Multilevel reused Interfaces: goes to theMemMerge.slave[1], then l2Cache, in Memory.bsv: mkConnection(dCache.memory, theMemMerge.slave[1]); mkConnection(theMemMerge.merged, l2Cache.cache);   How does CacheCore handles that tag?\n How to change number of bits? Where does it check tags at runtime? Can we gather \u0026amp; check multiple contigous bits at sametime? See TagController.bsv    File: cherilibs/trunk/CacheCore.bsv\nNote from source code:\n The CacheCore module is a generic cache engine that is parameterisable by number of sets, number of ways, number of outstanding request, and selectable write-allocate or write-through behaviours. In addition, if the cache core is used as a level1 cache (ICache or DCache) it will return the 64-bit word requested in the bottom of the data field.\n Return 64-bit word requested in the bottom of the data field.\nParameters and Provisos module mkCacheCore#(Bit#(16) cacheId, WriteMissBehaviour writeBehaviour, ResponseBehaviour responseBehaviour, OrderBehaviour orderBehaviour, WhichCache whichCache, // Must be \u0026gt; 5 or we can\u0026rsquo;t issue reads with evictions! // This means that a write-allocate cache must have \u0026gt;=5 capacity in the output fifo. Bit#(10) memReqFifoSpace, FIFOF#(CheriMemRequest) memReqs, FIFOF#(CheriMemResponse) memRsps) (CacheCore#(ways, keyBits, inFlight)) provisos ( Bits#(CheriPhyAddr, paddr_size), // CheriPhyAddr can be cast to/from Bit#(paddr_size), that is 40-bit addr. ifdef MEM128 // The line size is different for each bus width. Log#(64, offset_size), elsif MEM64 Log#(32, offset_size), else Log#(128, offset_size), endif Add#(TAdd#(offset_size, keyBits), tagBits, paddr_size), // Lele: offset_size + keyBits + tagBits = paddr_size = 40 bit addr. Add#(smaller1, TLog#(ways), keyBits), Add#(smaller2, TLog#(ways), tagBits), Add#(smaller3, tagBits, 30), Add#(0, TLog#(TMin#(TExp#(keyBits), 16)), wayPredIndexSize), Add#(smaller4, wayPredIndexSize, keyBits), Add#(smaller5, 4, keyBits), Add#(a__, TAdd#(TLog#(inFlight), 1), 8), Bits#(CacheAddress#(keyBits, tagBits), 40) );\nCache Basics Cache basics: Cache Basics\n cache line: also cache block. The basic unit for cache storage. May contain multiple bytes/words of data. Not the same thing as \u0026ldquo;row\u0026rdquo; of cache. cache set: A \u0026ldquo;row\u0026rdquo; in the cache. The number of blocks/lines per set is determined by the layout of the cache (e.g. direct mapped, set-associate, or fully associate) tag: a unique identifier for a group of data. Because different regions of memory may be mapped into a block, the tag is used to differentiate between them. valid bit: a bit of information that indicates whether the data in a block is valid(1) or not(0).  A divisioin of address for cache use:\n------------------------------------------------------------- | -------- tag --------- | --- set index --- | block offset | ------------------------------------------------------------- t bits s bits b bits  Bytes vs Word (vs Bits) Addressing format: the design need to be consistent with the block size and requested address format.\nstructs CacheAddress#\n // cherilibs/trunk/CacheCore.bsv typedef Bit#(tagBits) Tag#(numeric type tagBits); typedef Bit#(keyBits) Key#(numeric type keyBits); typedef 2 BankBits; typedef Bit#(BankBits) Bank; typedef CheriPhyByteOffset Offset; typedef struct { Tag#(tagBits) tag; Key#(keyBits) key; Bank bank; Offset offset; // Lele: an offset between [0, CheriBusBytes] } CacheAddress#(numeric type keyBits, numeric type tagBits) deriving (Bits, Eq, Bounded, FShow);  TagLine#\n typedef struct { Tag#(tagBits) tag; Bool pendMem; Bool dirty; Vector#(TExp#(BankBits), Bool) valid; } TagLine#(numeric type tagBits) deriving (Bits, Eq, Bounded, FShow);  see more type def\ninterface CacheCore methods\n Bool canPut(); Action put(CheriMemRequest req); CheckedGet#(CheriMemResponse) response(); Action nextWillCommit(Bool nextCommitting); Action invalidate (CheriPhyAddr addr); ActionValue#(bool) invalidateDone();  method put() method Action put(CheriMemRequest req) if (putCondition);\ncondition putCondition\nsteps:\n unpack request address: CacheAddress#(keyBits, tagBits) ca = unpack(pack(req.addr)); get request id: ReqId id = getReqId(req); put id to fifo next (or nextSet for OOO)  at the same time: update newReq as this req; nextIncomingReqId to be the next one after this req: nextIncomingReqId \u0026lt;= ReqId{masterID: id.masterID, transactionID: id.transactionID + 1};   CapTag in Cache Read/Write defined in rule finishLookup: L545 ~ 1536\nTODO\nSource: Type definitions // cherilibs/trunk/CacheCore.bsv typedef Bit#(tagBits) Tag#(numeric type tagBits); typedef Bit#(keyBits) Key#(numeric type keyBits); typedef 2 BankBits; typedef Bit#(BankBits) Bank; typedef CheriPhyByteOffset Offset; typedef struct { Tag#(tagBits) tag; Key#(keyBits) key; Bank bank; Offset offset; } CacheAddress#(numeric type keyBits, numeric type tagBits) deriving (Bits, Eq, Bounded, FShow); typedef Bit#(TLog#(ways)) Way#(numeric type ways); typedef struct { Key#(keyBits) key; Bank bank; } DataKey#(numeric type ways, numeric type keyBits) deriving (Bits, Eq, Bounded, FShow); typedef struct { CheriTransactionID id; Bool commit; } CacheCommit deriving (Bits, Eq, Bounded, FShow); typedef struct { Tag#(tagBits) tag; Bool pendMem; Bool dirty; Vector#(TExp#(BankBits), Bool) valid; } TagLine#(numeric type tagBits) deriving (Bits, Eq, Bounded, FShow); typedef enum {Init, Serving} CacheState deriving (Bits, Eq, FShow); typedef enum {Serve, Writeback, MemResponse} LookupCommand deriving (Bits, Eq, FShow); typedef enum {WriteThrough, WriteAllocate} WriteMissBehaviour deriving (Bits, Eq, FShow); typedef enum {OnlyReadResponses, RespondAll} ResponseBehaviour deriving (Bits, Eq, FShow); typedef enum {InOrder, OutOfOrder} OrderBehaviour deriving (Bits, Eq, FShow); typedef struct { CacheAddress#(keyBits, tagBits) addr; TagLine#(tagBits) tag; Way#(ways) way; Bool cached; ReqId reqId; } AddrTagWay#(numeric type ways, numeric type keyBits, numeric type tagBits) deriving (Bits, FShow); typedef struct { Tag#(tagBits) tag; Key#(keyBits) key; Way#(ways) way; Bool valid; } InvalidateToken#(numeric type ways, numeric type keyBits, numeric type tagBits) deriving (Bits, FShow); typedef struct { LookupCommand command; CheriMemRequest req; // Original request that triggered the lookup. CacheAddress#(keyBits, tagBits) addr; // Byte address of the frame that was fetched. BytesPerFlit readWidth; // Latch read width for speed, in case it is a read. DataKey#(ways, keyBits) dataKey; // Datakey used in the fetch (which duplicates some of addr and adds the way). Way#(ways) way; Bool last; Bool fresh; InvalidateToken#(ways, keyBits, tagBits) invalidate; // Token containing any invalidate request Error rspError; } ControlToken#(numeric type ways, numeric type keyBits, numeric type tagBits) deriving (Bits, FShow); typedef struct { CheriMemResponse resp; CheriMemRequest req; // Request to potentially enq into retryReqs. Bank rspFlit; Maybe#(ReqId) rspId; Bool deqNext; ReqId deqId; Bool deqReqCommits; Bool enqRetryReq; Bool deqRetryReqs; } ResponseToken deriving (Bits, FShow); function ReqId getReqId(CheriMemRequest req); //Bool reqWrite = False; //if (req.operation matches tagged Write .wop) reqWrite = True; return ReqId{masterID: req.masterID, transactionID: req.transactionID}; endfunction function ReqId getRespId(CheriMemResponse resp); //Bool respWrite = False; //if (resp.operation matches tagged Write .wop) respWrite = True; return ReqId{masterID: resp.masterID, transactionID: resp.transactionID}; endfunction typedef struct { Key#(keyBits) key; ReqId inId; Bool cached; Vector#(ways,TagLine#(tagBits)) oldTags; Way#(ways) oldWay; Bool oldDirty; Bool write; Bank noOfFlits; } RequestRecord#(numeric type ways, numeric type keyBits, numeric type tagBits) deriving (Bits, Eq, FShow); typedef struct { Bank first; Bank last; } BankBurst deriving (Bits, Eq, FShow); typedef struct { ReqId inId; Bool isSC; Bool scResult; } ReqIdWithSC deriving (Bits, Eq, FShow); typedef struct { Bool doWrite; Key#(keyBits) key; Vector#(ways,TagLine#(tagBits)) newTags; } TagUpdate#(numeric type ways, numeric type keyBits, numeric type tagBits) deriving (Bits, Eq, FShow); typedef Vector#(TDiv#(CheriDataWidth,8), Bool) ByteEnable; Reference 1\n github/beri ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/linux/page-table/",
	"title": "Page Table",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  What does an page table entry contain? Where is the page permission stored?\n If one entry\u0026rsquo;s present flag is off, OS can use this entry for other purpose. What can be other purpose? and How to use it properly?\n  Page table descriptors Descriptors (types of different PT entries):\n pte_t: 64-bit/PAE, page table pmd_t: 64-bit/PAE, page middle directory pud_t: 64-bit/PAE, page upper directory pgd_t: 64-bit/PAE, page global directory pgprot_t: 64-bit/PAE, represents the protection flags associated with a single entry.  Cast from integer to the PT entries type: __pte, __pmd, __pud, __pgd, __pgprot\nEntries of page directories and page tables have the same structure. Each entry includes the following fields:\n Present flag. If set, the page is in main memory; If the flag is 0, the page is not contained in main memory and the remaining entry bits may be used by the operating system for its own purposes.  when present is cleared for a virtual-physical translation request, then the vaddr will be stored in cr2, and exception 14 - Page Fault will be generated.  20-bit (=32-12) field as page frame physical address. accessed flag. set each time the paging unit addresses the page. OS can use this for swapping. Paging unit will not reset the flag. OS should reset it instead. dirty read/write user/supervisor: contains the privilege level required to access the page or Page Table. PCD \u0026amp; PWT flag. cache control. Page Size flag. Only for Page Table entries. If set, the entry refers to a 2MB or 4MB long page frame. Global flag. Only for Page Table entries. Prevent frequently used pages from being flushed from TLB cache. Works only if Page Global Enable flag of register cr4 is set.  Page Flag setting functions  pte_wrprotect() // clears the Read/Write flag pte_rdprotect() // clears the User/Supervisor flag pte_exprotect() // clears the User/Supervisor flag \u0026hellip; pte_modify(p,v) // set all access right in a PT entry p to a specified value v  Macros acting on Page Table entries  pgd_index(addr) // get the index in the page global directory for address addr. pgd_offset(mm, addr) // get the linear address of the entry in a page global directory. mk_pte(p, prot) // receives as parameters the address of a page descriptor p and a group of access rights prot, and builds the correponding Page Table entry.  Page Allocation Functions  pgd_alloc(mm) // page global directory pgd_free(pgd)   Reference 1\n  Understanding the Linux Kernel, 3rd Edition. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/mips/cp0/regs/",
	"title": "Regs",
	"tags": [],
	"description": "",
	"content": "Reference 1\nEntryLo0: low half of TLB entry for even virtual address (VPN)\nEntryLo1: low half of TLB entry for odd virtual address (VPN)\n  R4000 book. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/mips/cp0/",
	"title": "CP0",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Regs  Reference 1 EntryLo0: low half of TLB entry for even virtual address (VPN) EntryLo1: low half of TLB entry for odd virtual address (VPN) R4000 book. ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/cp0/",
	"title": "CP0",
	"tags": [],
	"description": "",
	"content": " Todos  tracking tlbLookupData.request/response for TLB hit/miss handling\n MIPS.bsv: CP0Ifc declaration, contains subinterface of TranslationIfc tlbLookupData; COP0.bsv: mkCP0: definition of TranslationIfc tlbLookupData: .request(reqIn) and .response() invokes tlb.lookup[1/2].request(reqIn) and .response(), which is defined in mkTLB module in TLB.bsv: lookup = lookups. see [../tlb], Do TLB search  tracking cache for hit/miss handling\n  Reference 1\nFile: cheri/trunk/CP0.bsv\nModule mkCP0 mkCP0#(Bit#(16) coreId)(CP0Ifc)\nInterfaces interface CP0Ifc, in cheri/trunk/MIPS.bsv:\n methods:  method for register read: readReq method for register writePending bool flag writePending; method for register write: writeReg; \u0026hellip; method for reading current address space identifier: getAsid // a method to get current code/data page tags???  subinterfaces\n interface TranslationIfc tlbLookupInstruction; // Initiate an instruction TLB lookup interface TranslationIfc tlbLookupData; // Initiate a data TLB lookup interface Vector#(2, TranslationIfc) tlbs; // For the DMA\n// cheri/trunk/MIPS.bsv // The CPOIfc interface is the interface for the system control processor, or coprocessor 0 (CP0). interface CP0Ifc; method Action readReq(RegNum rn, Bit#(3) sel); // Initiate a CP0 register read method Bool writePending; // Report whether there is a write pending in CP0 method ActionValue#(Word) readGet(Bool goingToWrite); // Deliver a read CP0 register to the main pipeline method Action writeReg(RegNum rn, Bit#(3) sel, Word data, Bool forceKernelMode, Bool writeBack); // Write a CP0 register method Cp0ExceptionReport getException(); // Get an exception report from CP0 (in writeback) method Action putException(ExceptionWriteback exp, Address ivaddr, MIPSReg dvaddr); // Report the final exception to CP0 from writeback method ActionValue#(Bool) setLlScReg(Address matchAddress, Bool link, Bool store); // Set the load linked address method Action interrupts(Bit#(5) interruptLines); // Put the external interrupt line state into CP0 method CoProEn getCoprocessorEnables(); // Report the current state of the coprocessor enable signals. method HWREna getHardwareRegisterEnables(); method Bit#(8) getAsid(); // Report the current address space identifier. method Action putCount(Bit#(48) commonCount); // Put the common count register for all cores. method Action putCacheConfiguration(L1ChCfg iCacheConfig, L1ChCfg dCacheConfig); // Recieve a report of // the L1 cache configurations. This allows the caches to define their // own configurations. method Action putDeterministicCycleCount(Bool cycleCount); // Whether the CP0 thinks tracing should be turned on method Bool shouldTrace(); `ifndef CHERIOS interface TranslationIfc tlbLookupInstruction; // Initiate an instruction TLB lookup interface TranslationIfc tlbLookupData; // Initiate a data TLB lookup `endif // CHERIOS `ifdef DMA_VIRT interface Vector#(2, TranslationIfc) tlbs; // For the DMA `endif endinterface   States States includes:\n FIFOs:\n readRegs tlbReads tlbProbes tlbProbeResponses eretHappened\n rnUpdate // store register write request in writeReg sand do it in rule updateCP0Registers\n dataUpdate\n foreUpdate\n expectWrites\n deqExpectWrites\n  RWries, write then read in same cycle:\n RWire#(Bit#(41)) pteWire \u0026lt;- mkRWire; RWire#(Bit#(31)) xpteWire \u0026lt;- mkRWire;  default values\n Registers: StatusRegister defaultSR = StatusRegister{\u0026hellip;}; PRId defaultProcID; // processor ID\n TlbEntryLo defaulttlbEntryLo; //\n TlbEntryHi defaultTlbEntryHi; //\n TlbResponse defaultTlbResponse;\n Config0 defaultConfig0; // cache coherency algorithm; MMU type; Little/Big endian; \u0026hellip;\n LxChCfg l2ChCfg, l3ChCfg; // cache associativity; cache line size; \u0026hellip;\n Config1 defaultConfig1; // coprocessor 2; size of TLB entry. (MMU has mmuSize +1 entries)\n Config2 defaultConfig2; // l2 config, l3 config\n Config3 defaultConfig3; // \u0026hellip;\n Config6 defaultConfig6; // inferred from nlm\u0026rsquo;s source code in FreeBSD; tlbSize 271, \u0026hellip;\n  Registers: 30 different categories\n tlbIndex: index into the TLB tlbEntryLo0: entry Lo of even virtual address of a pair tlbEntryLo1: entry Hi of odd virtual address of a pair ??? tlsPointer: ??? 64 bits, tlbPageMask: 12 bits, status register Reg#(StatusRegister) sr \u0026lt;- mkConfigReg(defaultSR); \u0026hellip;  TLB module: TLBIfc tlb \u0026lt;- mkTLB(coreid.coreID);\n  rules  readTlb; reportWiredToTLB; probeStart; \u0026hellip; updateContextRegisters_And_Count updateCP0Registers (!tlbReads.notEmpty \u0026amp;\u0026amp; !tlbProbeResponses.notEmpty)  Interface tlbLookupData (ifndef MICRO \u0026amp;\u0026amp; ifndef CHERIOS)\ndeclaration: in cheri/trunk/MIPS.bsv:\n// cheri/trunk/MIPS.bsv: interface TranslationIfc; method ActionValue#(TlbResponse) request(TlbRequest reqIn); method ActionValue#(TlbResponse) response(); definition:\nrequest(reqIn) Steps: query tlb using tlb.lookup[2].requets(reqIn) and return result that contains success/failure/exception info\n lookup tlb according to request reqIn: TlbResponse retVal \u0026lt;- tlb.lookup[2].request(reqIn); check the return value for exceptions;  check Kernel/User mode matches current kernelMode or debug mode. update retVal if exceptions.  return the retVal  Code:\n// cheri/trunk/CP0.bsv method ActionValue#(TlbResponse) request(TlbRequest reqIn); TlbResponse retVal \u0026lt;- tlb.lookup[2].request(reqIn); if (!kernelMode \u0026amp;\u0026amp; !retVal.fromDebug) begin// \u0026amp;\u0026amp; retVal.exception==None) begin if (retVal.priv==Kernel) retVal.exception = (retVal.write) ? DADES : DADEL; else if (retVal.priv == Supervisor \u0026amp;\u0026amp; !supervisorMode) retVal.exception = (retVal.write) ? DADES : DADEL; end if (retVal.addr[35:0] == {watchHi,watchLo[31:3],3\u0026#39;b0} \u0026amp;\u0026amp; // If there has not been an exception and the address matches ((watchLo[1]==1\u0026#39;b1 \u0026amp;\u0026amp; !retVal.write) || (watchLo[0]==1\u0026#39;b1 \u0026amp;\u0026amp; retVal.write))) begin // and the address is watching for a read or a write and the operation matches. if (retVal.exception == None) retVal.exception = Watch; end return retVal; endmethod response() Steps: query response info via tlb.lookup[2].response() and return result with failure/success/exception info\n get response from tlb: TlbResponse retVal \u0026lt;- tlb.lookup[2].response(); check and update the TlbResponse; return the TlbResponse.  interface tlbLookupInstruction request(TlbRequest reqIn) TlbResponse retVal \u0026lt;- tlb.lookup[1].request(reqIn);\nresponse() tlb.lookup[1].response()\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/memtypes/",
	"title": "MemTypes.bsv",
	"tags": [],
	"description": "",
	"content": " Data  Reference 1 The type of Data#, CapTags, CapsPerFlit, and BytesPerFlit. See CheriBusBytes in MemTypes Data It contains both data and capability tag. TODO: What is the data_width? and the relationship between number of tag bits and this data_width, and the CHERI bits? Data# definition: // Data type typedef struct { `ifdef USECAP // is this frame has capabilities CapTags cap; `endif // actual data Bit#(width) data; } Data#(numeric type width) deriving (Bits, Eq, FShow); CapTags definition\n Reference 1\nImportant types:\nData#(data_width) The struct that contains both tag and tagged data. see Data MemoryRequest#(\u0026hellip;) MemoryResponse#(\u0026hellip;) CheriMemRequest CheriMemResponse\nbytesPerLine type of bytesPerLine is parameter, and is set to be =CheriBusBytes . That is, one line contains one bus widths data.\nUsed to define PhyLineNumber, PhyByteOffset, PhyBitOffset, PhyByteAddress, etc:\ntype of PhyLineNumber, is the index type for lines at granularity of one line. i.e an address of line.\ntype of PhyByteOffset, is the index type inside one line, at granularity of one byte.\ntype of PhyBitOffset, is the index type inside one line, at granularity of one bit.\ntype of PhyByteAddress, is an byte address representation format with Line address, and byte offset inside the line.\ntype of PhyBitAddress, is an bit address representation format with byte address, and the bit offset inside the byte.\ntypedef Bit#(TSub#(width,TLog#(bytePerLine))) PhyLineNumber#(numeric type width, numeric type bytePerLine); typedef Bit#(TLog#(bytePerLine)) PhyByteOffset#(numeric type bytePerLine); typedef Bit#(TAdd#(TLog#(bytePerLine),3)) PhyBitOffset#(numeric type bytePerLine); // physical byte address type // CR: width is the TOTAL width of the type; this type is a clever way to allow byte // slicing from Alexendre. typedef struct { PhyLineNumber#(width, bytePerLine) lineNumber; PhyByteOffset#(bytePerLine) byteOffset; } PhyByteAddress#(numeric type width, numeric type bytePerLine) deriving (Bits, Eq, Bounded, FShow); typedef struct { PhyByteAddress#(width, bytePerLine) byteAddr; Bit#(3) bitOffset; } PhyBitAddress#(numeric type width, numeric type bytePerLine) deriving (Bits, Eq, Bounded, FShow); CheriBusBytes type of CheriBusBytes is the total bytes of data on the bus between CPU and memory. Default to be 32 bytes data on the bus, can be set to 16 bytes using MEM128, 8 bytes using MEM64.\n   CheriBusBytes Bus bit cheriBusBytes (enum_v)     8 bytes 64 bits BYTE_8 (3)   16 bytes 128 bits BYTE_16 (4)   32 bytes 256 bits BYTE_32 (5)       CAP Mode CAP width capBytesPerFlit     CAP64 8 bytes BYTE_8 (3)   CAP128 16 bytes BYTE_16 (4)   CAP 32 bytes BYTE_32 (5)    (type of capBytesPerFlit seems to be capability version of bytesPerFlit. Only used once in MIPS.bsv: L2010. A confusing name. According to the test scripts, CAP128 is always used with MEM128, thus by design, cheriBusBytes = capBytesPerFlit, should always be the equal.)\nNote: the enum value seems should be used as its semantic meaning, but just a type matching number.\nused to define serveral CHERI related types:\ntype of CapsPerFlit is defined as the number of capabilities we can have on the bus; thus here the Flit means a bus width data.\ntype of CapTags is defined as a vector of bool values that represents the tag values for this flit of data (bus-wide data).\ntype of CapNumber is defined as an physical index type aligned at capability width memory. Bit width is BitsOf(MemBus)-BitsOf(Cap)\ntype of CheriCapAddress is defined as a full physical byte address with CapNumber as index of an aligned capability, and offset as the byte index inside the capability. This type can be packed/unpacked to/from an physical address. For example, see Memory.bsv:dataMemory.getResponse\ntype of CheriDataWidth is defined as the number of bits for a capability: 256 by default, or 128\u0026frasl;64.\ntype of CheriLineAddrWidth\ntype of CheriPhyLineNumber\ntype of CheriPhyAddr is a byte address composed of Line address and offset in a line via PhyByteAddress, where total width is 40 bits, and bytes per line is equal to CheriBusBytes. ==\u0026gt; One line is one bus width.\ntype of CheriPhyBitAddr type of CheriPhyByteOffset\ntype of CheriPhyBitOffset is the number index of a single bit in a [0, CheriBusBytes * 8] bits range.\ntype of CheriPeriphAddr\nRelated Bluespec code:\n// file: cherilibs/trunk/MemTypes.bsv // physical address for cheri `ifdef MEM128 typedef 16 CheriBusBytes; BytesPerFlit cheriBusBytes = BYTE_16; `elsif MEM64 typedef 8 CheriBusBytes; BytesPerFlit cheriBusBytes = BYTE_8; `else typedef 32 CheriBusBytes; BytesPerFlit cheriBusBytes = BYTE_32; `endif `ifdef CAP BytesPerFlit capBytesPerFlit = BYTE_32; `elsif CAP128 BytesPerFlit capBytesPerFlit = BYTE_16; `elsif CAP64 BytesPerFlit capBytesPerFlit = BYTE_8; `endif `ifdef USECAP typedef TDiv#(CheriBusBytes,CapBytes) CapsPerFlit; typedef Vector#(CapsPerFlit,Bool) CapTags; typedef Bit#(TSub#(40,TLog#(CapBytes))) CapNumber; typedef struct { CapNumber capNumber; Bit#(TLog#(CapBytes)) offset; } CheriCapAddress deriving (Bits, Eq, Bounded, FShow); `endif typedef TMul#(CheriBusBytes,8) CheriDataWidth; typedef TSub#(40,TLog#(CheriBusBytes)) CheriLineAddrWidth; typedef PhyLineNumber#(40,CheriBusBytes) CheriPhyLineNumber; typedef PhyByteAddress#(40,CheriBusBytes) CheriPhyAddr; typedef PhyBitAddress#(40,CheriBusBytes) CheriPhyBitAddr; typedef PhyByteOffset#(CheriBusBytes) CheriPhyByteOffset; typedef PhyBitOffset#(CheriBusBytes) CheriPhyBitOffset; typedef PhyByteAddress#(40,8) CheriPeriphAddr; PhyByteAddress type fo PhyByteAddress, contains a line number, and its byte offset into the line.\n // physical byte address type // CR: width is the TOTAL width of the type; this type is a clever way to allow byte // slicing from Alexendre. typedef struct { PhyLineNumber#(width, bytePerLine) lineNumber; PhyByteOffset#(bytePerLine) byteOffset; } PhyByteAddress#(numeric type width, numeric type bytePerLine) deriving (Bits, Eq, Bounded, FShow);  MemoryRequest Read or write request format.\nFor write, contains the data to be written. The data contains one-bit cap tag, and actual data with 256-bit/128/64 width\n// cherilibs/trunk/MemTypes.bsv ///////////////////////////////// // cheri memory request format // ///////////////////////////////// typedef struct { // byte address addr_t addr; // master ID to identify the requester // XXX THIS FIELD HAS TO BE MIRRORED BY THE SLAVE XXX masterid_t masterID; // transaction ID field used to identify a unique transaction amongst // several outstanding transactions // XXX THIS FIELD HAS TO BE MIRRORED BY THE SLAVE XXX transactionid_t transactionID; // operation to be performed by the request union tagged { // read operation struct { // uncached / cached access Bool uncached; // LL / standard load Bool linked; // number of flits to be returned UInt#(TLog#(MaxNoOfFlits)) noOfFlits; // number of bytes per flit BytesPerFlit bytesPerFlit; } Read; struct { // True for the last flit of the burst Bool last; // uncached / cached access Bool uncached; // SC / standard write Bool conditional; // byte enable vector Vector#(TDiv#(data_width,8), Bool) byteEnable; // A bit mask for each byte, enabling bit updates. Bit#(8) bitEnable; // line data, // at the bottom so we can \u0026#34;truncate(pack())\u0026#34; this field // to get the data without \u0026#34;matches\u0026#34;. Data#(data_width) data; } Write; // for a cache operation CacheOperation CacheOp; } operation; } MemoryRequest#(type addr_t, type masterid_t, type transactionid_t, numeric type data_width) deriving (Bits); CheriMemRequest Typedef for CheriMemRequest: a 40-bit physical address, 32-bytes line, 32*8=256 DataWidth or 128\u0026frasl;64 data width:\ntypedef MemoryRequest#(CheriPhyAddr,CheriMasterID,CheriTransactionID,CheriDataWidth) CheriMemRequest;\nOne Memory Request contains\n 4-bit masterID 4-bit transactionID 2-bit error (3 enum values) 1-bit ?? for tagged union {read{bool last}, bool SC, void write} 1/1/2-bit = (data-bus width / capwidth) for CapTags 128\u0026frasl;256-bit data-bus width  So one memory request contains following bits to send to memory as a request:\n 4+4+2+1+1+128 = 12-bit control + 128-bit data = 140 bits; for 128-bit cap 128-bit data bus; 4+4+2+1+1+256 = 12 bit control + 256-bit data = 268 bits, for 256-bit cap 256-bit data bus  The parameter definitions:\n// physical address for cheri `ifdef MEM128 typedef 16 CheriBusBytes; BytesPerFlit cheriBusBytes = BYTE_16; `elsif MEM64 typedef 8 CheriBusBytes; BytesPerFlit cheriBusBytes = BYTE_8; `else typedef 32 CheriBusBytes; // CHERI bus has 32 bytes??? A 512-bit Bus? BytesPerFlit cheriBusBytes = BYTE_32; `endif typedef PhyByteAddress#(40,CheriBusBytes) CheriPhyAddr; typedef Bit#(4) CheriMasterID; typedef Bit#(4) CheriTransactionID; typedef TMul#(CheriBusBytes,8) CheriDataWidth; // CheriDataWidth = CheriBusBytes * 8. PhyByteAddress: a struct with a line number and byteoffset. The type is 40 bits in width, and each line has 32 bytes (cheri128). What is type here? What is the line here? What is the relation with a physical address?\n// physical byte address type // CR: width is the TOTAL width of the type; this type is a clever way to allow byte // slicing from Alexendre. typedef struct { PhyLineNumber#(width, bytePerLine) lineNumber; PhyByteOffset#(bytePerLine) byteOffset; } PhyByteAddress#(numeric type width, numeric type bytePerLine) deriving (Bits, Eq, Bounded, FShow); MemoryResponse Read or Write response struct\nIf Read, will have Data# back contains, cap tag and actual data with width of 256/128/64.\n////////////////////////////////// // cheri memory response format // ////////////////////////////////// typedef struct { // master ID to identify the requester // XXX THIS FIELD HAS TO BE MIRRORED BY THE SLAVE XXX masterid_t masterID; // transaction ID field used to identify a unique transaction amongst // several outstanding transactions // XXX THIS FIELD HAS TO BE MIRRORED BY THE SLAVE XXX transactionid_t transactionID; // error being returned Error error; // content of the response union tagged { struct { // True for the last flit of the burst Bool last; } Read; // no information for write responses void Write; // True for a success Bool SC; } operation; // line data for Read (could be in tagged Union, but avoid muxes by putting it here) Data#(data_width) data; } MemoryResponse#(type masterid_t, type transactionid_t, numeric type data_width) deriving (Bits); CheriMemResponse Customized parameters:\n CheriMasterID CheriTransactionID CheriDataWidth = CheriBusBytes * 8\ntypedef MemoryResponse#(CheriMasterID,CheriTransactionID,CheriDataWidth) CheriMemResponse;   beri/cherilibs/trunk/MemTypes.bsv ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/tag-controller/",
	"title": "Tag Controller",
	"tags": [],
	"description": "",
	"content": " Todones  peekMemResponse(): when grab the tag response from tagCache: lookupRsp.first: need to review it to match the CheriTagResponse returned in MultiLevelTagLookup.bsv  Q\u0026amp;A Who calls this and what is the input?  see Input/Output  How does it get feedback from memory?  via function peekMemResponse(): mRsps.first. See section helper function  Where does this being connected? Connect to l2 cache; and connect to memory to provide proxied memory interface.\nThe Connection:\nL2Cache \u0026mdash; tagController \u0026mdash; main memory\n in Memory.bsv: mkMIPSMemory(\u0026hellip;):\n mkConnection(l2CacheMemory, tagController.cache); // tagController cache is connected with l2 cache\u0026rsquo;s memory interface. They share the same memory interface. SO there WILL be conflicts and thus performance overhead. memory = topMemIfc = tagControllerMemory; // Master/client interface to main memory module (not included in .bsv) see Memory.bsv  in MIPSTop.bsv\n exports a generic memory client interface: memory = theMem = mkMIPSMemory, see MIPSTop.bsv   What is multi-flit transactions? 4-flit transaction?  in MemTypes.bsv: CapsPerFlit is used to count how many tagged bits in one flit. One flit is one data in CheriMemoryResponse/Request. see MemTypes.bsv But still, what is a flit here? how it is related with the capability, data cache line, and tag cache line?  One flit in this project means one chunk of bus-width data got transmitted via the memory-cpu bus. see MemTypes   How this is connected with data/instruction caches?  It does not connect with d/iCache, only connects to the master interface of L2Cache  How does it handle tags of every memory addr?  A submodule called MultiLevelTagLookup, see MultiLevelTagLoopup, or TagLookup One memory access request from L2Cache will generate 2 sub-requests: data request and tag request Data request goes to traditional memory interface tag request goes to another layer of cache interface: tagLookup.cache If tag cache hit, the tag will be parsed and being written into the memory request response struct and sent back to l2cache; in this case, one memory request from l2cache, will only generate one request in main memory. If tag cache miss, then, another memory request will be put ot the traditional memory interface. In this case, one memory request from l2cache, will generate two memory request to the main memory.  How does it distinguish tag memory response vs regular memory response ? CheriMemRequest/Response contains a masterID, the value is used to distinguish which level of cache the request is issued and which level of cache the response is for. In addition, at tagController, it is used to distinguish a regular memory response or a tag response.\n CheriMemRespone is distinguished at Master response interface, and dispatched either back to L2Cache or back to tagLookup.\n masterID for tag request/response is first initialized when a tag cache miss happens and a new CheriMemRequest is crafted. see function CheriMemRquest craftTagReadReq/craftTagWriteReq in cherilibs/trunk/MultiLevelTagLookup.bsv;\n Every CacheCore derived module has the cacheID as the masterID.\n tagController has the same masterID = 12 as its submodule tagLookup; a request contains this masterID means a tag request/response;\n  TagController provides a proxy for memory accesses which adds support for tagged memory.\n Tag values are stored in memory (currently at the top of DRAM)\n There is a cache of 32ki tags (representing 1MB memory) stored in BRAM (SRAM in FPGA?).\n Read responses are amended with the correct tag value and write requests update the value in the tag cache (which is later written back to memory)\n// cherilibs/trunk/TagController.bsv /****************************************************************************** * mkTagController * * This module provides a proxy for memory accesses which adds support for * tagged memory. It connects to memory on one side and the processor/L2 cache * on the other. Tag values are stored in memory (currently at the top of DRAM * and there is a cache of 32ki tags (representing 1MB memory) stored in BRAM. * Read responses are amended with the correct tag value and write requests update * the value in the tag cache (which is later written back to memory). * *****************************************************************************/  Interface TagControllerIfc Two sub-interfaces:\n interface Slave#(CheriMemRequest, CheriMemResponse) cache;  // a server interface // connected to l2 cache\u0026rsquo;s memory; // as Slave means it receives request from l2cache\u0026rsquo;s memory, and generate response for the l2Cache\u0026rsquo;s memory interface to get from. // does this mean TagController is under l2-cache? Yes. See 2017 paper.  interface Master#(CheriMemRequest, CheriMemResponse) memory;  // a client interface // provide the proxy interface for memory access to physical memory. i.e., this is the CPU\u0026rsquo;s memory interface that will be connected to the main memory. // as master means it send request to memory and grab response back by calling interface. // The memory interface is slave in this case: phycial memory interface?   The definition of CheriMemRequest/CheriMemResponse is in MemTypes.bsv, which contains the data to be write/read with tags (Data#).\nModule mkTagController(TagControllerIfc) Input/Output The connections:\nmkConnection(l2CacheMemory, tagController.cache);\nmkConnection(tagLookup.cache.response,toCheckedPut(ff2fifof(lookupRsp)));\n... ----------------------- | (slave/srv/cache) | | L2Cache | | (master/clt/memory) | ----------------------- /\\ | \\/ ------------------------------------------------------------------- | (slave/srv/cache) | | | | | | | | | TagController | -\u0026gt; tag cache req: tagLookup..put(req) | | | | \u0026lt;- tag cache hit: lookupRsp..first() | | mem | tag \u0026lt;------------------\u0026gt; (slave/srv/cache) | | | | | | | | | tagLookup (~L3Cache) | | | | | | | | | |\u0026lt;--------------------\u0026gt; (master/clt/memory) | | \\/ | \\/ \u0026lt;- tag cache miss (forwardLookupReqs) | | (master/clt/memory) -\u0026gt; tag mem rsps () | ------------------------------------------------------------------- /\\ | \\/ | ----------------------------------------------------------------- | mReqs.enq(r) mRsps.first | | memory | ------------------------------------------------------------------- Input from L2Cache: Overview: Get input request, hand it over to fifo mReqs and tagLookup.cache.request, and wait for the response\n memory request CheriMemRequest req: -\u0026gt; mReqs.enq(req)\n input from L2Cache\u0026rsquo;s master interface memory.request.get() which returns memReqs.first from L2Cache: received via TagController\u0026rsquo;s slave interface cache.put() which enqueue the request mReqs.enq(req), which will The cache.put() will also put the request in tagLookup module: tagLookup.cache.request.put(req), which will\n// cherilibs/trunk/TagController.bsv interface Slave cache; // request side /////////////////////////////////////////////////////// interface CheckedPut request; method Bool canPut() = slvCanPut; method Action put(CheriMemRequest req) if (slvCanPut); debug2(\u0026#34;tagcontroller\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagController\u0026gt; New request: \u0026#34;, $time, fshow(req))); mReqs.enq(req); `ifndef NOTAG tagLookup.cache.request.put(req); `endif endmethod endinterface   Output to L2Cache Output2: (Slave) memory response from here up to l2.\nCall peekMemResponse() when slvCanGet, means there is a response.\n mRsps.first/.deq() , lookupRsp.first()/.deq() response will be returned as CheriMemResponse to L2Cache\n// cherilibs/trunk/TagController.bsv interface Slave cache; // response side /////////////////////////////////////////////////////// interface CheckedGet response; method Bool canGet() = slvCanGet; method CheriMemResponse peek() = peekMemResponse(); method ActionValue#(CheriMemResponse) get() if (slvCanGet); // prepare memory response CheriMemResponse resp = peekMemResponse(); // dequeue memory response fifo mRsps.deq(); `ifndef NOTAG // in case of read response ... if (resp.operation matches tagged Read .rop) begin // on the last flit, if (rop.last) begin lookupRsp.deq(); // dequeue the tag lookup response fifo frame \u0026lt;= 0; // reset the current frame end else frame \u0026lt;= frame + 1; // for non last flits, increment frame end `endif debug2(\u0026#34;tagcontroller\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagController\u0026gt; Returning response: \u0026#34;, $time, fshow(resp))); return resp; endmethod endinterface endinterface  Output/Input to/from Memory (Master/Client) memory requests CheriMemRequest req from tagController down to mem;\nIf got a response from memory, the request will be distinguished according to its reqType:\n if tag request, will send response to tag cache tagLookup.memory.response otherwise, will send response to data response fifo mRsps which will be forwarded to l2Cache, as in above section.\n// cherilibs/trunk/TagController.bsv interface Master memory; // an interface of type CheckedGet#(CheriMemRequest mReqs, see [cherilibs/trunk/MasterSlave.bsv](../master-slave) // used to send request to memory interface request = toCheckedGet(ff2fifof(mReqs)); // an interface of type CheckedPut // used to get response from memory interface CheckedPut response; method Bool canPut(); return (mRsps.notFull() \u0026amp;\u0026amp; tagLookup.memory.response.canPut()); endmethod method Action put(CheriMemResponse r) if (mRsps.notFull() \u0026amp;\u0026amp; tagLookup.memory.response.canPut()); `ifdef NOTAG mRsps.enq(r); `else MemReqType reqType = (r.masterID == mID) ? TagLookupReq : StdReq; debug2(\u0026#34;tagcontroller\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagController\u0026gt; response from memory: source=%x \u0026#34;, $time, reqType, fshow(r))); if (reqType == TagLookupReq) begin if (r.operation matches tagged Read.rop) tagLookup.memory.response.put(r); debug2(\u0026#34;tagcontroller\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagController\u0026gt; tag response\u0026#34;, $time)); end else begin mRsps.enq(r); debug2(\u0026#34;tagcontroller\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagController\u0026gt; memory response\u0026#34;, $time)); end `endif endmethod endinterface endinterface  States: TagLookupIfc tagLookup \u0026lt;-mkMultiLevelTagLookup(\u0026hellip;);\n CheriMasterID mID = 12; // masterID used for memory requests from the lookup engine TagTableStructure; // declares and initialize the tableStructure Vector of interger\n FF#(CheriTagResponse,4) lookupRsp; // lookup responses fifo\n Reg#(Bit#(2)) frame; // lookup response frame to access (for multi-flit transaction)\n FF#(CheriMemRequest, 2) mReqs \u0026lt;- mkFF(); // memory request fifo\n FF#(CheriMemResponse, 32) mRsps \u0026lt;- mkUGFF(); // memory response fifo\n  submodule tagLookup tagLookup module is the core module that handles tag search and tag cache miss, where a cache miss will be forwarded as a normal memory request via mReqs in this module.\nA memory request is sent to tagLookup via connections on Slave request interface\nA memory response can be get from tagLookup via this connection: Connetion between tagLookup.cache.response(A Slave#/Server# CheckedGet#) \u0026ndash; lookupRsp (toCheckedPut#):\nmkConnection(tagLookup.cache.response,toCheckedPut(ff2fifof(lookupRsp)));\nA tag lookup miss will be forward as a regular memory request in rule forwardLookupReqs\nRules  rule forwardLookupReqs(tagLookup.memory.request.canGet() \u0026amp;\u0026amp; mReqs.notFull()); // forwards the tag lookup requests to the memory interface\n rule debug; // print debug2 information every cycle?\n  Rule forwardLookupReqs Forwards tag lookup requests (tagLookup.memory.request) to the memory interface (via fifo mReqs.enq(r)).\nNote: if tagLookup module got a tag cache miss, then this rule will be triggered and new tag-related memory request will be put in the queue mReqs.\n// forwards tag lookup requests to the memory interface rule forwardLookupReqs(tagLookup.memory.request.canGet() \u0026amp;\u0026amp; mReqs.notFull()); debug2(\u0026#34;tagcontroller\u0026#34;, $display( \u0026#34;\u0026lt;time %0t TagController\u0026gt; Injecting request from tag lookup engine: \u0026#34;, $time, fshow(tagLookup.memory.request.peek()) )); CheriMemRequest r \u0026lt;- tagLookup.memory.request.get(); mReqs.enq(r); endrule helper Function: peekMemResponse(): grab a response from fifo mRsps, parse the tag if read and return the response struct.\n function CheriMemResponse peekMemResponse(); // look at the next memory response\n prepare mRsps.first for return if read, need to construct tags, i.e. parse the tag response from tag cache and send response with tag: Vector#(TDiv#(CheriDataWidth,CapWidth),Bool) tags = replicate(True); ??? Now it seems (CheriDataWidth == CapWidth), and tags is 1-bit long? look at the tag lookup response: case lookupRsp.first(): // check this place if we will expand tag bits. if matches Covered .ts: tags = unpack(ts[frame]);\n if matches Unconvered : tags = unpack(0);\n// cherilibs/trunk/TagController.bsv // look at the next memory response function CheriMemResponse peekMemResponse(); // look at the next response from the memory master interface CheriMemResponse resp = mRsps.first; // initialise new response to response coming from memory CheriMemResponse newResp = resp; // in case of read, need to construct the tags if (resp.operation matches tagged Read .rop) begin Vector#(TDiv#(CheriDataWidth,CapWidth),Bool) tags = replicate(True); `ifndef NOTAG // look at the tag lookup response case (lookupRsp.first()) matches tagged Covered .ts : tags = unpack(ts[frame]); // check this place if we will expand tag bits. tagged Uncovered : tags = unpack(0); endcase `endif // update the new response with appropriate tags newResp.data.cap = tags; end return newResp; endfunction   Steps:  receive request from l2cache and put them in 2 fifo: one mReqs, another at tagLookup.cache.request ask memory to process mReqs; ask tagLookup to find tags in tag cache; response to l2Cache based on responses from memory (mRsps) and tag cache (lookupRsp)  Slave - cache mkConnection(l2CacheMemory, tagController.cache);\ntwo sub-interfaces that are connected with the L2CacheMemory:\n request side interface: CheckedPut request; // to receive mem req from L2Cache response side interface: CheckedGet response; // to send response back to L2Cache  defined in\n// cherilibs/trunk/MasterSlave.bsv interface Slave#(type req_t, type rsp_t); interface CheckedPut#(req_t) request; interface CheckedGet#(rsp_t) response; endinterface The interface declaration of CheckedPut/Get, similar to Get/Put in Bluespec, where Get is for others to get sth out, and Put for others to put sth in; CheckedPut/Get are defined in cherilibs/trunk/MasterSlave.bsv\nSlave CheckedPut request Type of CheckedPut: is for L2Cache to send in new request.\nmethods:\n method Bool canPut() = slvCanPut; method Action put(CheriMemRequest req) if (slvCanPut);  put req to queue mReqs.enq(req); put req to tagLookup.cache.request.put(req);   Slave CheckedGet response Type of CheckedGet: is for L2Cache to\nmethods:\n method Bool canGet() = slvCanGet; method CheriMemResponse peek() = peekMemResponse(); method ActionValue#(CheriMemResponse) get() if (slvCanGet);  peek mem response and save as resp: CheriMemResponse resp = peekMemResponse(); dequeue memory response fifo: mRsps.deq()   Master - memory Connected to main memory interface:\nMIPSTop.bsv (mkMIPSMemory theMem: interface memory = theMem.memory) ==\u0026gt;\nMemory.bsv: (MIPSMemory Ifc: Master# memory = topMemIfc = tagControllerMemory) ==\u0026gt; this master interface\nThe memory interface transfers bit-convertable data type of CheriMemRequest and CheriMemResponse.\nNo distinguish to the request sent to the memory, but distinguish the response being send back from the memory. The bus will contain these bits being transferred to and from the memory.\nTwo sub-interfaces\n interface CheckedGet request interface CheckedPut response  declared in:\n// cherilibs/trunk/MasterSlave.v interface Master#(type req_t, type rsp_t); interface CheckedGet#(req_t) request; interface CheckedPut#(rsp_t) response; endinterface Master CheckedGet request request is an interface of CheckedGet#()\ninterface request = toCheckedGet(ff2fifof(mReqs));\nDefinition of toCheckedGet(fifo) (also see MemTypes)\n// cherilibs/trunk/MasterSlave.bsv instance ToCheckedGet#(FIFOF#(data_t), data_t); function CheckedGet#(data_t) toCheckedGet (FIFOF#(data_t) f) = interface CheckedGet#(data_t); method canGet = f.notEmpty; method data_t peek if (f.notEmpty); return f.first; endmethod method ActionValue#(data_t) get if (f.notEmpty); f.deq; return f.first; endmethod endinterface; endinstance Master CheckedPut response Used to grab response from main memory. Responses of main memory will be found at fifo mRsps.\n// cherilibs/trunk/TagController.bsv interface CheckedPut response; method Bool canPut(); return (mRsps.notFull() \u0026amp;\u0026amp; tagLookup.memory.response.canPut()); endmethod method Action put(CheriMemResponse r) if (mRsps.notFull() \u0026amp;\u0026amp; tagLookup.memory.response.canPut()); `ifdef NOTAG mRsps.enq(r); `else MemReqType reqType = (r.masterID == mID) ? TagLookupReq : StdReq; debug2(\u0026#34;tagcontroller\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagController\u0026gt; response from memory: source=%x \u0026#34;, $time, reqType, fshow(r))); if (reqType == TagLookupReq) begin if (r.operation matches tagged Read.rop) tagLookup.memory.response.put(r); debug2(\u0026#34;tagcontroller\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagController\u0026gt; tag response\u0026#34;, $time)); end else begin mRsps.enq(r); debug2(\u0026#34;tagcontroller\u0026#34;, $display(\u0026#34;\u0026lt;time %0t TagController\u0026gt; memory response\u0026#34;, $time)); end `endif endmethod endinterface  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/dcache/",
	"title": "DCache.bsv",
	"tags": [],
	"description": "",
	"content": " Todones CacheDataIfc - put() -\u0026gt; rule doPut() // - getResponse() // done.  Q\u0026amp;A  Who calls this module and what is the input?\n called from Memory.bsv: interface DataMemory:startMem, after TLB translation. dCache.put(req); The input is the physical memory access request req of type CacheRequestDataT. see Memory.bsv.  Where does it go?\n it send a memory request to CacheCore, see CacheCore. it returns the response back to Memory.bsv: interface DataMemory:getResponse. CacheResponseDataT cr \u0026lt;- dCache.getResponse();  Given the tlb response, how does the tagged memory being accessed? How this is connected with tag controller?\n  mkDCache 1\nStates FIFOF#(CacheResponseDataT) preRsp_fifo \u0026lt;- mkLFIFOF; Reg#(CacheRequestDataT) reqInWire \u0026lt;- mkWire; FF#(CheriMemRequest,1) coreReq \u0026lt;- mkFFBypass1; Reg#(CheriTransactionID) transactionNum \u0026lt;- mkReg(0); Reg#(CacheState) state \u0026lt;- mkReg(Serving); FIFOF#(CheriMemResponse) memRsps \u0026lt;- mkUGFIFOF(); CacheCore#(4, TSub#(Indices,1), 1) core \u0026lt;- mkCacheCore(cacheId, wmb, RespondAll, InOrder, DCache, zeroExtend(memReqs.remaining()), ff2fifof(memReqs), memRsps );  Interface: CacheDataIfc // cheri/trunk/MIPS.bsv interface CacheDataIfc; method Action put(CacheRequestDataT reqIn); method ActionValue#(CacheResponseDataT) getResponse(); method Action invalidate(PhyAddress addr); method ActionValue#(Bool) getInvalidateDone; method Action nextWillCommit(Bool committing); method L1ChCfg getConfig(); interface Master#(CheriMemRequest, CheriMemResponse) memory; `ifdef STATCOUNTERS interface Get#(ModuleEvents) cacheEvents; `endif endinterface: CacheDataIfc method ActionValue#(CacheResponseDataT) getResponse() parse the CheriMemResponse and construct CacheResponseDataT to return.\nmethod put(CacheRequestDataT reqIn) Condition: if (putReady) // putReady is on only if coreReq preRsp_fifo not full and state==Serving, and writebacks.notFull if writeback DCache enabled.\nreqInWire \u0026lt;= reqIn\nSee rule doPut\nrule doPut(putReady) Overview: prepare a memory request in coreReq and hand it over to CacheCore core. See rule feedCore.\nData path: physical addr reqIn.tr.addr -\u0026gt; {CheriPhyAddr addr, CheriMemRequest mem_req, CacheResponseDataT resp} -\u0026gt; { coreReq.enq(mem_req), preRsp_fifo.enq(resp)}\n input reqInWire/reqIn get physical address, store to  CheriPhyAddr: CheriPhyAddr addr = unpack(reqIn.tr.addr), and CheriMemRequest: CheriMemRequest mem_req = next_mem_req; mem_req.addr = addr; CacheResponseDataT: resp = {isCap, ..., data: {?,pack(addr)}, ...}  check cache operation case(cop.inst), then update mem_req.operation, resp.exception , and flags state, willPutToCore.\n if CacheNop if CachePrefetch if Read if Write, StoreConditional if CacheSync mem_req.operation defined in MemTypes.bsv  put request and response struct into FIFO: coreReq.enq(mem_req); preRsp_fifo.enq(resp)\n coreReq is a one size fifo contain one ele of type CheriMemRequest preRsp_fifo is fifof# of type CacheResponseDataT  increase the transactionNum: transactionNum \u0026lt;= transactionNum + 1;\n  rule feedCore(core.canPut) pick the request from fifo coreReq and put it into fifo core\n  github/beri. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/tlb/",
	"title": "TLB.bsv",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How does TLB read/write permissions on page table? Can we add more bits for permission/types?  Reference 1 2\nMIPS R4000 Basics  48 TLB entries, each can map variable-sized pages from 4Kb to 16Mb. Address translation value is tagged with the most-significant bits of its virtual address, and a per-process identifier.  Instruction TLB: a two-entry instruction TLB.s\nJoint TLB: upon TLB miss, software will refill the JTLB from a page table resident in memory. This JTLB contains both data and instruction jointly. JTLB entry to be rewritten is selected at random.\nmkTLB Struct/State TLBEntryLo, MIPS register TLBEntryLo: describes the format of the EntryLo 0 \u0026amp; 1 CP0 register in MIPS, and also the two low records of each TLB entry.\nBits: 2 + 28 + 3 + x = 34-36 bits\nElements:\n CHERI added: two cap permission bits: noCapStore, noCapLoad, to allow storing/loading capabilities on the tlb entry. physical address of a page, 28 bits cache algorithm, dirty bit, valid bit, global bit.\n// file: cheri/trunk/MIPS.bsv // The TlbEntryLo type describes the format of the EntryLo 0 \u0026amp; 1 CP0 register in MIPS, and also the two low records // of each TLB entry typedef struct { `ifdef USECAP Bool noCapStore; // Allow storing capabilities Bool noCapLoad; // Allow loading capabilities `endif //Bit#(28) zeros; Bit#(28) pfn; // Physical address of the page. CacheCA c; // Cache algorithm or cache coherency attribute for multi-processor systems. Bool d; // Dirty - True if writes are allowed. Writes will cause exception otherwise. Bool v; // Valid - If False, attempts to use this location cause an exception. Bool g; // Global - If True this entry will match regardless of ASID. Both \u0026#34;Lo(G)\u0026#34;s in an odd/even pair should be identical. } TlbEntryLo deriving(Bits, Eq, FShow); // 34-36 bits  CachedTLBEntry: // TLB.bsv typedef struct { Bool valid; Bit#(5) whichLoBit; // Bit to check for which EntryLo to use, the MSB of the page mask. Bit#(1) oddPage; // Which page is cached. Bool global; Bit#(12) pageMask; TlbEntryHi entryHi; TlbEntryLo entryLo; } CachedTLBEntry deriving (Bits, Eq); Module mkTLB module mkTLB#(Bit#(16) coreId)(TLBIfc ifc);\nInterfaces TLBIfc\ninterface TLBIfc; interface Server#(TLBEntryT, TLBEntryT) readWrite; interface Vector#(NumTLBLookups, TranslationIfc) lookup; method Action debugDump; method Action putConfig(Bit#(LogAssosTLBSize) tlbRandom, Bool largeTlb, Bit#(8) entryHiAsid); endinterface States: 3? lookups interfaces, each have its request(reqIn) and response() method.\nlookups1 is used for lookup instruction in tlb;\nlookups2 is used for lookup data in tlb;\n Vector#(NumTLBLookups, TranslationIfc) lookups; lookups [0] = interface TranslationIfc; // This is the TLB probe interface lookups [i] = interface TranslationIfc;  rules  startTLB(tlbState == Serving);\n initialize\n doRead(tlbState == DoRead);\n pick/dep the request from readWrite_fifo.first read tlb entry from entryLo0 and entryLo1 store address as tlbAddr, and readOut_fifo.enq(tlbAddr)  doWrite(tlbState == DoWrite);\n pick/dep the request from readWrite_fifo.first choose and save write victim oldEnt. set tlbState \u0026lt;= WriteVictim write tlb entry to entryLo0 and entryLo1  writeVictimOut(tlbState == WriteVictim);\n randomIndex ???  readTLB(tlbState == Serving);\n  interface lookups[i] i = 1, 2, \u0026hellip;, \u0026lt; NumTLBLookups\ncanPut = (req_fifo[i].notFull);\nrequest(TlbRequest reqIn) guarded by canPut. CPU will wait until the req_fifo has space to insert new request.\nSteps:\n for xkphys, kseg1, kseg0, regions, use simple translation, not using page tables; ==\u0026gt; no page table permissions!!! micro TLB hit? compare with last_hit[i][ti] TLB search: req_fifos[i].enq(reqIn); rule startTLB will consume the req_fifos[i]  response() guarded by if (rsp_fifos[i].notEmpty). CPU will wait here until there is a response.\n  github/beri. ↩ MIPS R4000 manual. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/tagcache/",
	"title": "TagCache.bsv",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Who calls this and what is the input?\n ??? No one calls mkTagCache?!  Where does this go?\n  Reference 1\ncherilibs/trunk/TagCache.bsv\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/memory/",
	"title": "Memory.bsv",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Who calls this and what is the input?\n Where does it go?\n it sends a cache memory request to DCache: dCache.put(req);, see DCache.bsv   Reference 1\nMIPS memory module file cheri/trunk/Memory.bsv\nmodule mkMIPSMemory#(Bit#(16) coreId, CP0Ifc tlb)(MIPSMemory);\nMIPS memory interfaces  MIPSMemory\n DataMemory InstructionMemory MemConfiguration Server#(CoProMemAccess, CoProRegs)\n// cheri/trunk/Memory.bsv  interface MIPSMemory; interface DataMemory dataMemory; interface InstructionMemory instructionMemory; interface MemConfiguration configuration; `ifdef COP1 interface Server#(CoProMemAccess, CoProReg) cop1Memory; `endif `ifdef MULTI method Action invalidateICache(PhyAddress addr); method Action invalidateDCache(PhyAddress addr); method ActionValue#(Bool) getInvalidateDone; interface Master#(CheriMemRequest, CheriMemResponse) dmemory; interface Master#(CheriMemRequest, CheriMemResponse) imemory; `else interface Master#(CheriMemRequest, CheriMemResponse) memory; // the generic main memory interface as a client. `endif method Action nextWillCommit(Bool commiting); `ifdef STATCOUNTERS interface StatCounters statCounters; `endif endinterface    module in/out/states input\n Bit#(16) coreId CP0Ifc tlb Interfaces: dataMemory, instructionMemory  output\n sends memory request to dCache, iCache  states\n Reg#(CacheRequestInstT) iCacheFetch \u0026lt;- mkConfigRegU; Reg#(Bool) iCacheDelayed \u0026lt;- mkConfigReg(False); FIFOF#(CacheRequestInstT) iCacheOp \u0026lt;- mkUGSizedFIFOF(4); Reg#(CacheRequestDataT) dCacheFetch \u0026lt;- mkConfigRegU; Reg#(Bool) dCacheDelayed \u0026lt;- mkConfigReg(False); PrefetcherIfc pftch \u0026lt;- mkCapPrefetcher(dcachePrefetch); PrefetcherIfc pftch \u0026lt;- mkCapPrefetcher(l2Prefetch); MergeIfc#(2) theMemMerge \u0026lt;- mkMergeFast(); // This module merges the Memory interfaces of the instruction and data caches. TagControllerIfc tagController \u0026lt;- mkTagController(); CacheDataIfc dCache \u0026lt;- mkDCache(truncate({coreId,1\u0026rsquo;b1})); CacheInstIfc iCache \u0026lt;- mkICache(truncate({coreId,1\u0026rsquo;b0})); L2CacheIfc l2Cache \u0026lt;- mkL2Cache();  Steps:\n connect iCache.memory and dCache.memory to theMemMerge.slave[0/1] connect theMemMerge.merged to l2Cache.cache connect l2Cache.cache to tagController.cache topMemIfc = tagControllerMemory;// previously the topMemIfc is l2CacheMemory rule: feedICache(iCacheDelayed) rule: feedDCache(dCacheDelayed) rule: iCacheOperation(iCacheOp.notEmpty \u0026amp;\u0026amp; !iCacheDelayed) interface DataMemory dataMemory; interface InstructionMemory instructionMemory; interface MemConfiguration configuration; memory = topMemIfc method nextWillCommit = dCache.nextWillCommit;  How does it make connections mkConnection(iCache.memory, theMemMerge.slave[0]); mkConnection(dCache.memory, theMemMerge.slave1); mkConnection(theMemMerge.merged, l2Cache.cache); mkConnection(l2CacheMemory, tagController.cache);\nsee mkConnection in BSV\nDataMemory called in MemoryAccess.bsv:157: m.startMem(mi.mem, addr, er.cop, er.storeData, er.memSize, er.test==LL, cap, er.id, er.epoch, er.fromDebug, storeConditional);\nInterface decl:\ninterface DataMemory; method Action startMem(MemOp mop, Bit#(64) addr, CacheOperation cop, SizedWord sizedData, MemSize size, Bool ll, Bool cap, InstId instId, Epoch epoch, Bool fromDebug, Bool storeConditional); method ActionValue#(MemResponseDataT) getResponse(MIPSReg oldReg, Bool signExtend, Bit#(8) addr, MemSize size, Bool exception, Bool cacheOpResponse); endinterface Method startMem Overview: request tlb, get tlb result, then put mem request to DCache\nCondition: !dCacheDelayed\nInput:\n MemOp mop, type of memory operation. Read/Write/Nones Bit#(64) addr, CacheOperation cop, er.cop SizedWord sizedData, er.storeData MemSize size, er.memSize Bool ll, Bool cap, InstId instId, Epoch epoch, Bool fromDebug, Bool storeConditional  Output:\n get result from TLB, (vaddr -\u0026gt; paddr), assign to req.tr.\n dCache.put(req);\n  States:\n CacheRequestDataT req, contains:\n cop: CacheOperation{\u0026hellip;} byteEnable: signExtend(4\u0026rsquo;h0), memSize: size data: ?. instId: instId, epoch: epoch, tr: TlbResponse{\u0026hellip;}  TlbRequest tlbReq = TlbRequest{addr, \u0026hellip;};\n pftch, global prefetch module.\n  Steps: request tlb, then put request to D/ICache\n check mop: Read, Write, ICacheOp, DCacheOp, None. Compose the req accordingly.\n if Read:\n get byteMask (1,2,4,8) according to the requested size. for CAP: `byteMask = insert (mask, offset) ??? req = CacheRequestDataT{cap, ..., size, byteMask, ...} pftch.spyCacheReq(req)  if Write:\n todo  if ICacheOp, DCacheOp:\n if None: exception.\n invoke TLB query:\n req.tr \u0026lt;- tlb.tlbLookupData.request(tlbReq);  put TLB result to dCache: dCache.put(req);\ninterface DataMemory dataMemory; method Action startMem(MemOp mop, Bit#(64) addr, CacheOperation cop, SizedWord sizedData, MemSize size, Bool ll, Bool cap, InstId instId, Epoch epoch, Bool fromDebug, Bool storeConditional ) if (!dCacheDelayed); TlbRequest tlbReq = TlbRequest{ addr: alignAddress(addr,size), write: mop==Write, ll: ll, fromDebug: fromDebug, exception: None, instId: instId };   InstructionMemory Overview: request tlb, get tlb result, then put request to ICache\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/cheri-tlb/",
	"title": "Cheri Tlb",
	"tags": [],
	"description": "",
	"content": " Reference 1\nISAv7 ch3.8.3 Virtual Memory -\u0026gt; Authorizing MMU Control\n  CHERI controls the use of privileged instructions and control registers that configure the MMU: Access_System_Registers permission must be present on PCC; for software managed-TLB, retrieving and inserting TLB entries also requires above permission on PCC/KCC/KDC; for hardware page-table walker, CHERI currently does not control memory acecesses performed by the walker via physical addresses.   Page-Table Entry \u0026amp; TLB entry Permissions ISAv7 ch3.8.3\nPermission checking of TLB or PTE is extended with two new page permissions.\n Page-Table Load Capability Permission. Permit loading tagged capability if this bit is set and read perm also exists. Otherwise, tag is stripped before register write back.\n Page-Table Store Capability Permission. Permit store tagged capability if this bit is set and write perm also exists. Otherwise, exception. (could allow dynamic capability tracking using this perm bit)\n    ISAv7, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/mem-tag/",
	"title": "Mem Tag",
	"tags": [],
	"description": "",
	"content": " Q \u0026amp; A  Is it possible to automatically set/check tags without changing ISA interface?  Taint tracking tags?\nReferences:\n Efficient Tagged Memory, ICCD, 2017. CheriABI UCAM-CL-TR-932, 2019. Secure program execution via dynamic information flow tracking. 2004, ASPLOS. A small cache of large ranges: Hardware methods for efficiently searching, storing, and updating big dataflow tags. 2008. MICRO. Hardware enforcement of application security policies using tagged memory. 2008, OSDI. E. Witchel, J. Cates, and K. Asanović, Mondrian memory protection. ACM, 2002, vol. 30, no. 5 D. Y. Deng, Flexible and efficient accelerator architecture for runtime monitoring. Cornell University, 2016.  More  Tags for Pointers   2004 SigNotice: Secure Program Execution via Dynamic Information Flow Tracking   References: Suh, G. Edward, Jae W. Lee, David Zhang, and Srinivas Devadas. \u0026ldquo;Secure program execution via dynamic information flow tracking.\u0026rdquo; ACM Sigplan Notices 39, no. 11 (2004): 85-96. More  Addr San  Reference 1 reference ↩  2012 Watchdog  References: Watchdog: Hardware for Safe and Secure Manual Memory Management and Full Memory Safety, Nagarakatte, Santosh, Milo MK Martin, and Steve Zdancewic. In 2012 39th Annual International Symposium on Computer Architecture (ISCA), pp. 189-200. IEEE, 2012. Identifier for all pointers: For pointers in registers: Watchdog extends every register with a sidecar identifier register. For pointers in memory: Watchdog provides a shadow memory that shadows every word of memory with an identifier for pointers.\n 2002 Mondrian  References: E. Witchel, J. Cates, and K. Asanovi´c. Mondrian memory protection. In Proceedings of the 10th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pages 304–316, Oct 2002. MMP: Mondrian memory protection. In constrast to earlier page-based systems, MMP allows arbitrary permissions control at granularity of individual words. a compressed permissions table to reduce space overheads employ two levels of permissions caching to reduce run-time overheads Evaluation: zero-copy networking underneath the standard read system call interface, where packet payload fragements are connected together by the translation system to avoid data copying.\n 2005 Safemem  References: reference A novel use of ECC memory technology to detect first access to a user-directed memory region \u0026ndash;\u0026gt; can be used to detect memory leaks and memory corruption. ECC 7 bits to protect 32 bits, or 8 bits to protect 64 bits [c18] Four modes: Disabled. Check-Only. detect single-bit and multi-bit errors. Correct-Error. + correct single-bit errors. Correct-and-Scrub. + Scrubs memory periodically to check and correct hardware errors.\n Memory Protection Keys  References: Memory Protection Keys Overview: Up to 16 protection domains with 4-bit tag on each page: Four (previously unused) bits in each page-table entry can be used to assign one of sixteen \u0026ldquo;key\u0026rdquo; values to any given page. A new 32-bit processor register with two bits for each key value. Setting \u0026ldquo;write disable\u0026rdquo; bit for a given key will block all attempts to write a page with that key value; Setting \u0026ldquo;access disable\u0026rdquo; bit will block reads; MPK feature thus allows a process to partition its memory into a maximum of sixteen regions and to selectively disable or enable access to any of those regions.\n MTE: Memory Tag Extension  References: Memory Tagging Extension: Enhancing memory safety through architecture Armv8.5-A Memory Tagging Extension, White Paper The Arm64 memory tagging extension in Linux MTE aims to increase the memory safety of code written in unsafe languages without requiring source changes, and in some cases, without requiring recompilation. MTE provides a mechanism to detect both main categories of memory safety violation (spatial \u0026amp; temporal). MTE assists the detection of potential vulnerabilities before\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/vmi/hwvmi/2016-flexcore/",
	"title": "2016 Flexcore",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  D. Y. Deng, Flexible and efficient accelerator architecture for runtime monitoring. Cornell University, 2016. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/llvm-elf/",
	"title": "ELF (LLVM Side)",
	"tags": [],
	"description": "",
	"content": "  ELF Basics llvm-objcopy: object copy and editing tool Relocation wiki  Object File Editing llvm-objcopy [options] input [output]:\n --add-section \u0026lt;section=file\u0026gt;, add a section named \u0026lt;section\u0026gt; with the content of \u0026lt;file\u0026gt; to the output. --dump-section \u0026lt;section\u0026gt;=\u0026lt;file\u0026gt;, dump the content of section \u0026lt;section\u0026gt; into the file \u0026lt;file\u0026gt; --discard-all, -x, remove most local symbols from the output.  ELF Section Flags // include/llvm/BinaryFormat/ELF.h  // Section flags. enum : unsigned { // Section data should be writable during execution.  SHF_WRITE = 0x1, // Section occupies memory during program execution.  SHF_ALLOC = 0x2, // Section contains executable machine instructions.  SHF_EXECINSTR = 0x4, // The data in this section may be merged.  SHF_MERGE = 0x10, // The data in this section is null-terminated strings.  SHF_STRINGS = 0x20, // A field in this section holds a section header table index.  SHF_INFO_LINK = 0x40U, // Adds special ordering requirements for link editors.  SHF_LINK_ORDER = 0x80U, // This section requires special OS-specific processing to avoid incorrect  // behavior.  SHF_OS_NONCONFORMING = 0x100U, // This section is a member of a section group.  SHF_GROUP = 0x200U, // This section holds Thread-Local Storage.  SHF_TLS = 0x400U, // Identifies a section containing compressed data.  SHF_COMPRESSED = 0x800U, // This section is excluded from the final executable or shared library.  SHF_EXCLUDE = 0x80000000U, // Start of target-specific flags.  SHF_MASKOS = 0x0ff00000, // Bits indicating processor-specific flags.  SHF_MASKPROC = 0xf0000000, /// All sections with the \u0026#34;d\u0026#34; flag are grouped together by the linker to form  /// the data section and the dp register is set to the start of the section by  /// the boot code.  XCORE_SHF_DP_SECTION = 0x10000000, /// All sections with the \u0026#34;c\u0026#34; flag are grouped together by the linker to form  /// the constant pool and the cp register is set to the start of the constant  /// pool by the boot code.  XCORE_SHF_CP_SECTION = 0x20000000, // If an object file section does not have this flag set, then it may not hold  // more than 2GB and can be freely referred to in objects using smaller code  // models. Otherwise, only objects using larger code models can refer to them.  // For example, a medium code model object can refer to data in a section that  // sets this flag besides being able to refer to data in a section that does  // not set it; likewise, a small code model object can refer only to code in a  // section that does not set this flag.  SHF_X86_64_LARGE = 0x10000000, // All sections with the GPREL flag are grouped into a global data area  // for faster accesses  SHF_HEX_GPREL = 0x10000000, // Section contains text/data which may be replicated in other sections.  // Linker must retain only one copy.  SHF_MIPS_NODUPES = 0x01000000, // Linker must generate implicit hidden weak names.  SHF_MIPS_NAMES = 0x02000000, // Section data local to process.  SHF_MIPS_LOCAL = 0x04000000, // Do not strip this section.  SHF_MIPS_NOSTRIP = 0x08000000, // Section must be part of global data area.  SHF_MIPS_GPREL = 0x10000000, // This section should be merged.  SHF_MIPS_MERGE = 0x20000000, // Address size to be inferred from section entry size.  SHF_MIPS_ADDR = 0x40000000, // Section data is string data by default.  SHF_MIPS_STRING = 0x80000000, // Make code section unreadable when in execute-only mode  SHF_ARM_PURECODE = 0x20000000 };  Interesting flags: Reference: [code], elf-doc: Sections\nSHF_LINK_ORDER = 0x80U: Adds special ordering requirements for link editors.\nSHF_OS_NONCONFORMING = 0x100U: This section requires special OS-specific processing to avoid incorrect behavior.\nRelocation Relocation wiki:\n Relocation table is a list of pointers created by the translator (a compiler or assembler) and stored in the object or executable file. Each entry in the table, or \u0026ldquo;fixup\u0026rdquo;, is a pointer to an absolute address in the object code that must be changed when the loader relocates the program so that it will refer to the correct location.\nFixups are designed to support relocation of the program as a complete unit. In some cases, each fixup in the table is itself relative to a base address of zero, so the fixups themselves must be changed as the loader moves through the table.\nIn some archtectures a fixup that crosses certain boundaries (such as a segment boundary) or that is not aligned on a word boundary is illegal and flagged as an error by the linker.\nDOS and 16-bit Windows: far pointers (segment:offset), segments will be corrected when the executable was loaded into memory.\n32-bit Windows: relocation table optional for exe; but if ASLR is enabled, relocation table is mandatory.\n64-bit Windows: ASLR is mandatory, thus relocation is mandatory.\nUnix-like systems: ELF and shared library format allows serveral types of relocaton.\n Linux relocation:  relocation entries in ELF header has section header type (sh_type) of SHT_RELA or SHT_REL struct Elf32_Rela, Elf64_Rela, Elf32_Rel, Elf64_Rel. section name  FreeBSD relocation:  section header type (sh_type) of relocation entries (SHT_RELA, SHT_REL); section name .relName and .relaName    llvm: ELFRelocs/Mips.def .def file defines a list of case statement by the macro ELF_RELOC\n.def file is included as header file in ELF.cpp; used by getELFRelocationTypeName(Machine, Type)\neach processor has its own set of relocation types.\n// lib/Object/ELF.cpp  #define STRINGIFY_ENUM_CASE(ns, name) \\ case ns::name: \\ return #name;  #define ELF_RELOC(name, value) STRINGIFY_ENUM_CASE(ELF, name)  StringRef llvm::object::getELFRelocationTypeName(uint32_t Machine, uint32_t Type) { switch (Machine) { ... case ELF::EM_MIPS: switch (Type) { #include \u0026#34;llvm/BinaryFormat/ELFRelocs/Mips.def\u0026#34; default: break; } break; ...   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-backend/regression/",
	"title": "Regression",
	"tags": [],
	"description": "",
	"content": "LLVM has its test cases (regression test) for each backend to verify the backend compiler without implementing any simulator or real hardware platform.\nregression test for arch in ./llvm/test/src/test/CodeGen/\nTo run:\ncheri# pwd /root/cheri/llvm-project/llvm/test/CodeGen/Mips/cheri cheri# /llvm-build-bin/llvm-lit cheri-sandbox-vaargs.ll llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/config.py:317: note: Running tests for CHERI_CAP_SIZE=16 llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/config.py:405: note: using clang: /root/sva/cheri/bsd112_sync_root/root/cheri/build/llvm-project-build/bin/clang llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/subst.py:127: note: Did not find llvm-exegesis in /root/sva/cheri/bsd112_sync_root/root/cheri/build/llvm-project-build/./bin llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/subst.py:127: note: Did not find llvm-mca in /root/sva/cheri/bsd112_sync_root/root/cheri/build/llvm-project-build/./bin llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/subst.py:127: note: Did not find llvm-rc in /root/sva/cheri/bsd112_sync_root/root/cheri/build/llvm-project-build/./bin -- Testing: 1 tests, 1 workers -- PASS: LLVM :: CodeGen/Mips/cheri/cheri-sandbox-vaargs.ll (1 of 1) Testing Time: 0.31s Expected Passes : 1 cheri#  Regression test file:\n provides llvm input, assembly output, running command, options in the sample input file. can be run to check and provide dynamic running document for users. once backend compiler changed, the regression test cases guard the changes has no side effect or bugs for other parts of backend program.\n// llvm/test/CodeGen/Mips/setule.ll ; RUN: llc -march=mipsel -mattr=mips16 -relocation-model=pic -O3 \u0026lt; %s | FileCheck %s -check-p refix=16 ; RUN: llc -march=mips -mcpu=mips32r6 -mattr=micromips -relocation-model=pic -O3 \u0026lt; %s | FileC heck %s -check-prefix=MMR6 @j = global i32 5, align 4 @k = global i32 10, align 4 @l = global i32 20, align 4 @m = global i32 10, align 4 @r1 = common global i32 0, align 4 @r2 = common global i32 0, align 4 @r3 = common global i32 0, align 4 define void @test() nounwind { entry: %0 = load i32, i32* @j, align 4 %1 = load i32, i32* @k, align 4 %cmp = icmp ule i32 %0, %1 %conv = zext i1 %cmp to i32 store i32 %conv, i32* @r1, align 4 ; 16: sltu ${{[0-9]+}}, ${{[0-9]+}} ; MMR6: sltu ${{[0-9]+}}, ${{[0-9]+}}, ${{[0-9]+}} ; 16: move $[[REGISTER:[0-9]+]], $24 ; 16: xor $[[REGISTER]], ${{[0-9]+}} %2 = load i32, i32* @m, align 4 %cmp1 = icmp ule i32 %2, %1 %conv2 = zext i1 %cmp1 to i32 store i32 %conv2, i32* @r2, align 4 ret void }   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/tools/",
	"title": "Tools",
	"tags": [],
	"description": "",
	"content": "LLVM Command Guide\nAn Example Using the LLVM Tool Chain\nclang hello.c -o hello\nclang -O3 -emit-llvm hello.c -c -o hello.bc\nclang -S -emit-llvm hello.c -o hello.ll\nlli hello.bc # invoke LLVM JIT\nllvm-dis \u0026lt; hello.bc | less # .bc to .ll\nllvm-as hello.ll -o hello.bc # .ll to bc\nllc hello.bc -o hello.s\nllc hello.ll -o hello.s\nllvm-lit: LLVM integrated tester.\n Regression Tests  References: LLVM doc: Writing new regression tests Lit documentation More Cheri References: reference # llvm/utils/lit/lit/llvm/config.py tool_substitutions = [ # CHERI substitutions (order is important due to repeated substitutions!) ToolSubst(\u0026#39;%cheri_purecap_cc1\u0026#39;, command=\u0026#39;%cheri_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%cheri128_purecap_cc1\u0026#39;, command=\u0026#39;%cheri128_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%cheri256_purecap_cc1\u0026#39;, command=\u0026#39;%cheri256_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%cheri_cc1\u0026#39;, command=self.config.clang, extra_args=cheri_cc1_args+additional_flags), ToolSubst(\u0026#39;%cheri128_cc1\u0026#39;, command=self.config.clang, extra_args=cheri128_cc1_args+additional_flags), ToolSubst(\u0026#39;%cheri256_cc1\u0026#39;, command=self.config.clang, extra_args=cheri256_cc1_args+additional_flags), ToolSubst(\u0026#39;%cheri_clang\u0026#39;, command=self.config.clang, extra_args=cheri_clang_args+additional_flags), ToolSubst(\u0026#39;%cheri_purecap_clang\u0026#39;, command=self.config.clang, extra_args=cheri_clang_args + [\u0026#39;-mabi=purecap\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_purecap_cc1\u0026#39;, command=\u0026#39;%riscv32_cheri_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;il32pc64\u0026#39;, \u0026#39;-target-feature\u0026#39;, \u0026#39;+cap-mode\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv64_cheri_purecap_cc1\u0026#39;, command=\u0026#39;%riscv64_cheri_cc1\u0026#39;, extra_args=[\u0026#39;-target-abi\u0026#39;, \u0026#39;l64pc128\u0026#39;, \u0026#39;-target-feature\u0026#39;, \u0026#39;+cap-mode\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_purecap_clang\u0026#39;, command=\u0026#39;%riscv32_cheri_clang\u0026#39;, extra_args=[\u0026#39;-mabi=il32pc64\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv64_cheri_purecap_clang\u0026#39;, command=\u0026#39;%riscv64_cheri_clang\u0026#39;, extra_args=[\u0026#39;-mabi=l64pc128\u0026#39;]+additional_flags), ToolSubst(\u0026#39;%riscv32_cheri_cc1\u0026#39;, command=self.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/call-conv/",
	"title": "Calling Convention",
	"tags": [],
	"description": "",
	"content": " References:\n LLVM Language Reference \u0026ndash; Calling Conventions Writing an llvm backend \u0026ndash; Calling Convention  TableGen for Calling Convention TargetCallingConv.td\nCalling convention from writing an llvm backend:\n To support target-specific calling conventions, _XXX_GenCallingConv.td uses interfaces (such as CCIfType and CCAssignToReg) that are defined in lib/Target/TargetCallingConv.td. TableGen uses the target descriptor file _XXX_GenCallingConv.td to generate the header file _XXX_GenCallingConv.inc, which is typically included in _XXX_ISelLowering.cpp. The inferfaces in _XXX_GenCalllingConv.td can specify:  the order of parameter allocation. where parameters and return values are placed (on the stack or in registers) which registers may be used. whether the caller or callee unwinds the stack.   TableGen Interfaces  CCIfType\u0026lt;cond, action\u0026gt;. If the predicate is true, then the action is performed. CCAssignToReg\u0026lt;[reg1, ...]\u0026gt;. An action assigns the argument value to the first available register.  Examples:\nCCIfType\u0026lt;[f32,f64], CCAssignToReg\u0026lt;[R0, R1]\u0026gt;\u0026gt; means: if the current argument is of type f32 or f64, then the action CCAssignToReg is performed: assign the argument value to the first available register: either R0 or R1.\nThe return calling convention RetCC_Sparc32:\ndef RetCC_Sparc32 : CallingConv\u0026lt;[ // 32-bit integer is returned in register T0 or T1: CCIfType\u0026lt;[i32], CCAssignToReg\u0026lt;[I0, I1]\u0026gt;\u0026gt;, // single-precision float is returned to register F0: CCIfType\u0026lt;[f32], CCAssignToReg\u0026lt;[F0]\u0026gt;\u0026gt;, // double-precision float is returned to register D0: CCIfType\u0026lt;[f64], CCAssignToReg\u0026lt;[D0]\u0026gt;\u0026gt; ]\u0026gt;;  CCAssignToStack\u0026lt;size, align\u0026gt;. Assign values to a stack slot with the specified size and alignment.\ndef CC_Sparc32 : CallingConv\u0026lt;[ // All arguments get passed in integer registers if there is space. CCIfType\u0026lt;[i32, f32, f64], CCAssignToReg\u0026lt;[I0, I1, I2, I3, I4, I5]\u0026gt;\u0026gt;, // assigns the value to stack with size of 4 bytes and alignment of 4 bytes. CCAssignToStack\u0026lt;4, 4\u0026gt; ]\u0026gt;; CCDelegateTo\u0026lt;subCC\u0026gt;. Call a specified sub-calling convention.\n  e.g. in X86CallingConv.td:\ndef RetCC_X86_32_C : CallingConv\u0026lt;[ CCIfType\u0026lt;[f32], CCAssignToReg\u0026lt;[ST0, ST1]\u0026gt;\u0026gt;, CCIfType\u0026lt;[f64], CCAssignToReg\u0026lt;[ST0, ST1]\u0026gt;\u0026gt;, CCDelegateTo\u0026lt;RetCC_X86Common\u0026gt; // after the current value is assigned to the register ST0 or ST1, // the RetCC_X86Common is invoked. ]\u0026gt;;  CCIfCC\u0026lt;CC_x, action\u0026gt;. If the current calling convention is CC_x, then do the action.  e.g. in X86CallingConv.td:\ndef RetCC_X86_32 : CallingConv\u0026lt;[ // If the Fast calling convention is in use, then RetCC_X86_32_Fast is invoked. CCIfCC\u0026lt;\u0026#34;CallingConv::Fast\u0026#34;, CCDelegateTo\u0026lt;RetCC_X86_32_Fast\u0026gt;\u0026gt;, // If the SSECall calling convention is in use, then RetCC_X86_32_SSE is invoked. CCIfCC\u0026lt;\u0026#34;CallingConv::X86_SSECall\u0026#34;, CCDelegateTo\u0026lt;RetCC_X86_32_SSE\u0026gt;\u0026gt;, CCDelegateTo\u0026lt;RetCC_X86_32_C\u0026gt; ]\u0026gt;;  CCIf\u0026lt;predicate, action\u0026gt;. If the predicate matches, apply the action.\n CCIfInReg\u0026lt;action\u0026gt;. If the argument is marked with the \u0026lsquo;inreg\u0026rsquo; attribute\n CCIfNest\u0026lt;action\u0026gt;. If the argument is marked with the \u0026lsquo;nest\u0026rsquo; attribute\n CCIfNotVarArg\u0026lt;action\u0026gt;. If the current function does not take a variable number of arguments\n CCAssignToRegWishShadow\u0026lt;registerList, shadowList\u0026gt;. similar to CCAssignToReg, but with a shadow list of registers.\n CCPassByVal\u0026lt;size, align\u0026gt;. Assign value to a stack slot with the min specified size and alignment\n CCPromoteToType\u0026lt;type\u0026gt;. Promote the current value the specified type\n CallingConv\u0026lt;[actions]\u0026gt;. Define each calling convention that is supported.\n  Code Overview Example calling conventions in LLVM:\nSee [llvm/include/llvm/IR/CallingConv.h]\n \u0026ldquo;ccc\u0026rdquo; - The C calling convention. This calling convention (the default if no other calling convention is specified).\n \u0026ldquo;fastcc\u0026rdquo; - The fast calling convention. This allows the target to use whatever tricks it wants to produce fast code for the target, without having to conform to an externally specified ABI (Application Binary Interface).\n \u0026ldquo;cc 10\u0026rdquo; - GHC convention.\n \u0026ldquo;cc 11\u0026rdquo; - The HiPE calling convention. For High-Performance Erlang (HiPE) compiler.\n It uses more registers for argument passing than the ordinary C calling convention and defines no callee-saved registers.  \u0026ldquo;webkit_jscc\u0026rdquo; - The WebKit\u0026rsquo;s JavaScript calling convention. For WebKit FTL JIT.\n \u0026ldquo;anyregcc\u0026rdquo; - Dynamic calling convention for code patching. Patching an arbitrary code sequence in place for a call site.\n Forces the call arguments into registers but allows them to be dynamically allocated. This can currently only be used with calls to llvm.experimental.patchpoint because only this intrinsic records the location of its arguments in a side table. see Stack maps and patch points in LLVM.  \u0026ldquo;cfguard_checkcc\u0026rdquo; - Windows Control Flow Guard (Check mechanism).\n \u0026ldquo;cc {n}\u0026rdquo; - Numbered convention\n  CallingConvLower References:\n [llvm/include/llvm/CodeGen/CallingConvLower.h] [llvm/lib/CodeGen/CallingConvLower.cpp]  Classes:\n CCState CCValAssign  Target specific calling conventions:\n [llvm/lib/Target/ARM/ARMCallingConv.h] [llvm/lib/Target/ARM/ARMCallLowering.h] [llvm/lib/Target/ARM/ARMCallLowering.cpp]\n [llvm/lib/Target/Mips/Mips16ISelLowering.h]\n [llvm/lib/Target/Mips/Mips16ISelLowering.cpp]\n [llvm/lib/Target/Mips/MipsCallingConv.td]\n [llvm/lib/Target/Mips/MipsCallLowering.cpp]\n [llvm/lib/Target/Mips/MipsCCState.h]\n [llvm/lib/Target/Mips/MipsCCState.cpp]\n [llvm/lib/Target/Mips/MipsISelLowering.h]\n [llvm/lib/Target/Mips/MipsISelLowering.cpp]\n [llvm/lib/Target/RISCV/RISCVISelLowering.h]\n [llvm/lib/Target/RISCV/RISCVISelLowering.cpp]\n  More  Syscall  References: The Definitive Guide to Linux System Calls FreeBSD - System Calls FreeBSD - Alternate Calling Convention X86-32 (i386) %eax for syscall number %ebx, %ecx, %edx, %esi, %edi, %ebp are used for passing 6 parameters to system calls. if there are more than six arguments, %ebx must contain the memory location where the list of arguments is stored. FreeBSD System Calls By default, FreeBSD kernel uses the C calling convention.\n Riscv Call   References: reference More  Mips Call   References: [llvm/lib/Target/Mips/Mips16ISelLowering.h] [llvm/lib/Target/Mips/Mips16ISelLowering.cpp] [llvm/lib/Target/Mips/MipsCallingConv.td] [llvm/lib/Target/Mips/MipsCallLowering.cpp] [llvm/lib/Target/Mips/MipsCCState.h] [llvm/lib/Target/Mips/MipsCCState.cpp] [llvm/lib/Target/Mips/MipsISelLowering.h] [llvm/lib/Target/Mips/MipsISelLowering.cpp] MipsCallingConv.td More  The calling convention of CC_CHERI_CCall  References: llvm/lib/Target/Mips/MipsCallingConv.td build/lib/Target/Mips/MipsGenCallingConv.inc CHERI_CCall calling conv: Definition Defined in .td file, code generated (during build) as MipsGenCallingConv.inc // llvm/lib/Target/Mips/MipsCallingConv.td def CC_CHERI_CCall : CallingConv\u0026lt;[ CCIfType\u0026lt;[iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR512], CCAssignToReg\u0026lt;[C1, C2, C3, C4, C5, C6, C7, C8, C9, C10]\u0026gt;\u0026gt;, CCIfType\u0026lt;[i64], CCAssignToReg\u0026lt;[V0_64]\u0026gt;\u0026gt;, CCDelegateTo\u0026lt;CC_MipsN\u0026gt; ]\u0026gt;; def CC_MipsN : CallingConv\u0026lt;[ CCIfType\u0026lt;[i8, i16, i32, i64], CCIfSubtargetNot\u0026lt;\u0026#34;isLittle()\u0026#34;, CCIfInReg\u0026lt;CCPromoteToUpperBitsInType\u0026lt;i64\u0026gt;\u0026gt;\u0026gt;\u0026gt;, // All integers (except soft-float integers) are promoted to 64-bit. CCIfType\u0026lt;[i8, i16, i32], CCIfOrigArgWasNotFloat\u0026lt;CCPromoteToType\u0026lt;i64\u0026gt;\u0026gt;\u0026gt;, // The only i32\u0026#39;s we have left are soft-float arguments.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-llvm/call-convention/",
	"title": "Call Convention",
	"tags": [],
	"description": "",
	"content": " Reference 1\ncalling convention in LLVM lib/Target/Mips/\n./CheriStackInvalidatePass.cpp ./CheriAddressingModeFolder.cpp ./MipsInstrCheri.td ./CheriRangeChecker.cpp ./Cheri128FailHard.cpp ./MipsInstrFormatsCheri.td ./CheriLoopPointerDecanonicalize.cpp ./cheri-compressed-cap ./cheri-compressed-cap/decompress_c128_cap.c ./cheri-compressed-cap/LICENSE ./cheri-compressed-cap/README.md ./cheri-compressed-cap/.editorconfig ./cheri-compressed-cap/.gitignore ./cheri-compressed-cap/cheri_compressed_cap.c ./cheri-compressed-cap/.gitrepo ./cheri-compressed-cap/cheri_compressed_cap.h ./cheri-compressed-cap/test ./cheri-compressed-cap/test/fuzz-decompress.cpp ./cheri-compressed-cap/test/decode_inputs.cpp ./cheri-compressed-cap/test/test_util.h ./cheri-compressed-cap/test/setbounds_test.cpp ./cheri-compressed-cap/test/random_inputs_test.cpp ./cheri-compressed-cap/test/simple_test.cpp ./cheri-compressed-cap/test/FuzzedDataProvider.h ./cheri-compressed-cap/test/catch.hpp ./cheri-compressed-cap/test/setbounds_inputs.cpp ./cheri-compressed-cap/.clang-format ./cheri-compressed-cap/CMakeLists.txt\nin MipsCallingConv.td\nCC_Mips -\u0026gt; CC_Mips_VarArg -\u0026gt; CC_MipsCheriPureCap_VarArg -\u0026gt; CC_Mips_ByVal -\u0026gt; CC_Mips_N_VarArg -\u0026gt; CC_Mips_FixedArg -\u0026gt; CC_CHERI_CCall -\u0026gt; CC_MipsN -\u0026gt; CC_Mips_ByVal -\u0026gt; CC_Mips_FastCC -\u0026gt; CC_MIpsN  CC_CHERI_CCall CC_CHERI_CCall convention -\u0026gt; CC_MipsN -\u0026gt; CC_MipsCheriCapOnStack:\n// lib/Target/Mips/MipsCallingConv.td def CC_CHERI_CCall : CallingConv\u0026lt;[ CCIfType\u0026lt;[iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR512], CCAssignToReg\u0026lt;[C1, C2, C3, C4, C5, C6, C7, C8, C9, C10]\u0026gt;\u0026gt;, CCIfType\u0026lt;[i64], CCAssignToReg\u0026lt;[V0_64]\u0026gt;\u0026gt;, CCDelegateTo\u0026lt;CC_MipsN\u0026gt; ]\u0026gt;; See definition in build/lib/Target/Mips/MipsGenCallingConv.inc\nCC_MipsN // lib/Target/Mips/MipsCallingConv.td def CC_MipsN : CallingConv\u0026lt;[ ... // All integers (except soft-float integers) are promoted to 64-bit. CCIfType\u0026lt;[i8, i16, i32], CCIfOrigArgWasNotFloat\u0026lt;CCPromoteToType\u0026lt;i64\u0026gt;\u0026gt;\u0026gt;, // The only i32\u0026#39;s we have left are soft-float arguments. CCIfSubtarget\u0026lt;\u0026#34;useSoftFloat()\u0026#34;, CCIfType\u0026lt;[i32], CCDelegateTo\u0026lt;CC_MipsN_SoftFloat\u0026gt;\u0026gt;\u0026gt;, ... // All stack parameter slots become 64-bit doublewords and are 8-byte aligned. CCIfType\u0026lt;[f32], CCAssignToStack\u0026lt;4, 8\u0026gt;\u0026gt;, CCIfType\u0026lt;[i64, f64], CCAssignToStack\u0026lt;8, 8\u0026gt;\u0026gt;, CCIfType\u0026lt;[iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR512], CCAssignToReg\u0026lt;[C3, C4, C5, C6, C7, C8, C9, C10]\u0026gt;\u0026gt;, CCIfType\u0026lt;[iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR512], CCDelegateTo\u0026lt;CC_MipsCheriCapOnStack\u0026gt;\u0026gt; ]\u0026gt;; CC_MipsCheriCapOnStack // lib/Target/Mips/MipsCallingConv.td def CC_MipsCheriCapOnStack : CallingConv\u0026lt;[ CCIfSubtarget\u0026lt;\u0026#34;isCheri128()\u0026#34;, CCAssignToStack\u0026lt;16, 16\u0026gt;\u0026gt;, CCIfSubtargetNot\u0026lt;\u0026#34;isCheri128()\u0026#34;, CCAssignToStack\u0026lt;32, 32\u0026gt;\u0026gt; ]\u0026gt;; CC_MipsCheriPureCap_VarArg Purecap: variadic argument on stack:\n// In purecap mode, all variadic arguments are passed on the stack. def CC_MipsCheriPureCap_VarArg : CallingConv\u0026lt;[ // Promote i8/i16 arguments to i32. CCIfType\u0026lt;[i8, i16, i32], CCPromoteToType\u0026lt;i64\u0026gt;\u0026gt;, // All stack parameter slots become 64-bit doublewords and are 8-byte aligned. CCIfType\u0026lt;[f32], CCAssignToStack\u0026lt;4, 8\u0026gt;\u0026gt;, CCIfType\u0026lt;[i64, f64], CCAssignToStack\u0026lt;8, 8\u0026gt;\u0026gt;, CCIfType\u0026lt;[iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR512], CCDelegateTo\u0026lt;CC_MipsCheriCapOnStack\u0026gt;\u0026gt; ]\u0026gt;; CC_Mips_FixedArg -\u0026gt; CC_CHERI_CCall\nCC_Mips_VarArg -\u0026gt; CC_MipsCheriPureCap_VarArg\ndef CC_Mips_FixedArg : CallingConv\u0026lt;[ ... CCIf\u0026lt;\u0026#34;State.getCallingConv() == CallingConv::CHERI_CCall\u0026#34;, CCDelegateTo\u0026lt;CC_CHERI_CCall\u0026gt;\u0026gt;, ... ]\u0026gt;; def CC_Mips_VarArg : CallingConv\u0026lt;[ // If this is the CHERI purecap ABI then we need to pass everything on the // stack for variadic functions. CCIfSubtarget\u0026lt;\u0026#34;isABI_CheriPureCap()\u0026#34;, CCDelegateTo\u0026lt;CC_MipsCheriPureCap_VarArg\u0026gt;\u0026gt;, CCIfByVal\u0026lt;CCDelegateTo\u0026lt;CC_Mips_ByVal\u0026gt;\u0026gt;, ... ]\u0026gt;;def CSR_N64_Cheri : CalleeSavedRegs\u0026lt;(add (sequence \u0026#34;D%u_64\u0026#34;, 31, 24), RA_64, FP_64, GP_64, (sequence \u0026#34;S%u_64\u0026#34;, 7, 0), (sequence \u0026#34;C%u\u0026#34;, 23, 17))\u0026gt;; def CSR_Cheri_Purecap : CalleeSavedRegs\u0026lt;(add (sequence \u0026#34;D%u_64\u0026#34;, 31, 24), RA_64, FP_64, GP_64, (sequence \u0026#34;S%u_64\u0026#34;, 7, 0), (sequence \u0026#34;C%u\u0026#34;, 25, 17))\u0026gt;; pull requests Only mangle the capability qualifier for pointers in the hybrid ABI #390\n capability qualifier in name mangling. Having all pointers mangled was useful to catch incorrect linker paths before CHERI support in LLD was added; because C++ programs would fail to link due to missing symbols. But no longer useful since now errors will be catched by LLD when linking purecap and non-purecap libraries. TODO: LLD link support for CHERI. Capability mangling is now only used in hybrid mode. Mangling is now U12_capability: void test(void *__capability) now mangles as _Z4testU12__capabilityPv instead of _Z4testU3capPv; llvm-cxxfilt demangles it to test(void *__capability) instead of test(void *cap).  [CHERI-MIPS] Return structs that are pairs of capabilities in C3/C4 #391\nRemove C++ struct calling convention hack and fix bug masked by it #393\n clang/lib/GodeGen/TargetInfo.cpp: MipsABIInfo::HandleAggregates(QualType Ty, uint64_t TySize) clang/lib/GodeGen/TargetInfo.cpp: MipsABIInfo::classifyArgumentType(QualType Ty, uint64_t \u0026amp;Offsets, bool \u0026amp;HasV0s) clang/test/CodeGenCXX/cheri/cheri-qdebug-crash.cpp    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/2020-java-partition-sgx/",
	"title": "2020 Java Partition Sgx",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Tsai, Chia-Che, Jeongseok Son, Bhushan Jain, John McAvey, Raluca Ada Popa, and Donald E. Porter. \u0026ldquo;Civet: An Efficient Java Partitioning Framework for Hardware Enclaves.\u0026rdquo; Usenix Security 2020. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/basics/mangling/",
	"title": "Name Mangling",
	"tags": [],
	"description": "",
	"content": " Reference 1\nA technique to resolve unique names for programming entities in many modern programming languages.\nProvides a way of encoding additional information in the name of a function, structure, class or another datatype in order to pass more semantic information from compilers to linkers.\nLinker: To link different object code together, linker needs a great deal of information on each program entity. For example, to correctly link a function, it needs the function name, the number of arguments and their types, and so on.\nC: distinguish pieces of code by function name only, ignoring any other information like parameter types or return types.\nC++: distinguish by function name, parameter types, return type, and calling convention of a function. To implement this, additional information was encoded in the name of a symbol.\nC no function overloading, but have different calling conventions to be used when being called.\nCompilers targeted at Microsoft Windows platforms support a variety of calling conventions.\nA consistant mangling scheme across different language, allows subroutines in those languages to call or be called correctly.\nExample of name mangling for C in Windows:\nint _cdecl f (int x) {return 0;} int _stdcall g (int y) {return 0;} int _fastcall h (int z) {return 0;}  After compiled ni 32-bit compilers:\n_f _g@4 @h@4  C++ Example 1. Before mangling:\nint f (void) { return 1; } int f (int) { return 0; } void g (void) { int i = f(), j = f(0); }  After mangling:\nint __f_v (void) { return 1; } int __f_i (int) { return 0; } void __g_v (void) { int i = __f_v(), j = __f_i(0); }  Example 2. Source code with mangled names in comments:\nnamespace wikipedia { class article { public: std::string format (void); /* = _ZN9wikipedia7article6formatEv */ bool print_to (std::ostream\u0026amp;); /* = _ZN9wikipedia7article8print_toERSo */ class wikilink { public: wikilink (std::string const\u0026amp; name); /* = _ZN9wikipedia7article8wikilinkC1ERKSs */ }; }; }  Mangled symbols begin with _Z, followed by N for nested names, then a series of , where length is the length of next identifier, and finally E, then type information. For example, wikipedia::article::format becomes:\nformat: _ZN9Wikipedia7article6formatEv print_to: _ZN9Wikipedia7article8print_toERSo   v: function parameter type is void So: function parameter type is the standard type std::ostream RSo: function parameter is a reference to So. i: int c: char  C/C++ compatibility the common C++ idiom:\n#ifdef __cplusplus extern \u0026quot;C\u0026quot; { #endif #ifdef __cplusplus } #endif  is used to avoid the name mangling by C++ compilers to be applied to C code.\n  Name mangling, wiki ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/hacking/cross/cheribuild/",
	"title": "Cheribuild",
	"tags": [],
	"description": "",
	"content": " cheribuild Guide lines from github issue\nIf you\u0026rsquo;re using one of the CMake-based builds, you have two options:\n cross-compiled examples in /cheribuild/pycheribuild/projects/cross Copy one of them and modify the project name and git repository, and then cutting out most of the CMake options Once the *.py file in the cross directory is created, cheribuild will find it (you can verify with ./cheribuild.py \u0026ndash;list-targets). Then you can just try to build it like any other target (e.g., ./cheribuild.py openssl).  defaultconfig.py //pycheribuild/config/defaultconfig.py:62 class DefaultCheriConfig(CheriConfig): def __init__(self, loader: ConfigLoaderBase, availableTargets: list): ...  boolean flags: quiet, q; verbose, v; clean, c; force, f; logfile; skip-update; foree-update; skip-configure; reconfigure; -force-configure;  compilation-db-in-source-dir; cross-compile-for-mips; cross-compile-for-host: make cross compile projects target the host systems, use cheri clang to compile (tests that we don\u0026rsquo;t break x86) make-without-nice; make-jobs, j, type=int;  Configure paths:  source-root; output-root; build-root;  all options added to loader: ConfigLoaderBase object.  class ConfigLoaderBase:\ndefined in pycheribuild/config/loader.py\n argument groups:  actionGroup pathGroup crossCompileOptionsGroup testsGroup benchmarkGroup run_group freebsdGroup dockerGroup   projects source  project  contains: warning options.  bear binutils bmake bsdtar build_qemu cheri_afl cherios cherisim cheritrace cherivis cmake disk_image effectivesan elftoolchain gnustep go kdevelop llvm makefs_linux ninja qtcreator run_fpga run_qemu sail samba sdk soaap softboundcerts spike syzkaller valgrind  cheribsd pycheribuild/projects/cross/cheribsd.py pycheribuild/boot_cheribsd/init.py\ncherios pycheribuild/projects/cherios.py\ndisk-image pycheribuild/projects/disk_image.py\nllvm pycheribuild/projects/llvm.py\ncross-compiling source  asio bbl benchmarks bodiagsuite cheribsd cheritest compiler-rt crosscompilerproject dlmalloc gdb juliet_test_suite libcxx libemwalk llvm_test_suite mrs newlib nginx opensbi postgres python qt5 rsync simple_benchmark snmalloc sqlite  gdb nginx two files:\n pycheribuild/projects/cross/crosscompilerproject.py pycheribuild/projects/cross/nginx.py  openssl  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/hacking/cross/",
	"title": "Cross",
	"tags": [],
	"description": "",
	"content": " Reference 1\nCross-compiling for CheriBSD  In order to cross-compile projects such as NGINX or PostgreSQL for CheriBSD you will first need a full SDK: cheribuild.py cheribsd-sdk. The you can then run cheribuild.py postgres-cheri or cheribuild.py nginx-mips, etc. By default these projects will be installed into your CheriBSD rootfs under /opt and will therefore be automatically included the next time you build a disk image.\nSee cheribuild.py --list-targets for a full list of targets.\n  Cheribuild  cheribuild Guide lines from github issue If you\u0026rsquo;re using one of the CMake-based builds, you have two options: cross-compiled examples in /cheribuild/pycheribuild/projects/cross Copy one of them and modify the project name and git repository, and then cutting out most of the CMake options Once the *.py file in the cross directory is created, cheribuild will find it (you can verify with ./cheribuild.py \u0026ndash;list-targets). Then you can just try to build it like any other target (e.\n  cheribuild.git. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/execute/",
	"title": "Execute.bsv",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How does it caculate the memory access address?  where does it access TLB?   Global Functions:\n function Bit#(a) arithmeticShift(Bit#(a) toShift, Bit#(b) shiftAmount) function Bit#(a) arithmeticShift2(Bit#(a) toShift, Bit#(b) shiftAmount)  mkExecute module s Input:\n MIPSRegFileIfc rf WritebackIfc writeback CP0Ifc cp0 CoProIfc cop1 CapCopIfc capCop FIFO#(ControlTokenT) inQ  Rules:\n finishMultiplyOrDivide deliverPendingOp  Methods:\n enq first deq clear  States:\n FIFO#(ControlTokenT) outQ \u0026lt;- mkFIFO; MulDivIfc mul \u0026lt;- mkMulDiv; Reg#(MIPSReg) hi \u0026lt;- mkReg(64\u0026rsquo;b0); Reg#(MIPSReg) lo \u0026lt;- mkReg(64\u0026rsquo;b0); FIFOF#(Bool) hiLoPending \u0026lt;- mkFIFOF1; FIFOF#(ControlTokenT) pendingOps \u0026lt;- mkFIFOF1; Reg#(Bit#(16)) coreid \u0026lt;- mkConfigReg(0);  method Action enq(ControlTokenT di) Condition:\n !hiOrLoIsBlocking !pendingOps.notEmpty  Input:\n ControlTokenT di.{ opA, opB, pc, memSize, mem, inst, \u0026hellip;}  Output:\n ControlTokenT er.{opA, opB, }  Steps:\n pre-execute instruction  check di.inst to see whether the instruction is for COP2, if so set cap=True; get cop1 response with opA, opB get PC from cap.Cop.getArchPc(er.pc, er.epoch) call capCop.getArchPc(er.pc, er.epoch) assign to er.archPc test the instruction is memory, or branch, or other instruction. if instruction is for memory access: use opA + opB, or just opB as offset to retrieve CapResponse by calling capVal \u0026lt;- capCop.getCapResponse(capReq, Memory) and grab the result from capVal. bring result and store it at er.opA = capVal.data go through coprocessor0 (MMU) by scResult \u0026lt;- cp0.setLlScReg(er.opA[63:0], er.test == LL, di.mem == Write)  cp0.setLlScReg: ???  if write, store conditional, get data to be written, either from cop1 (di.storeDatasrc == CoPro1) or from cop2 (di.storeDatasrc == CoPro2) set write value writeVal = er.opB ?? Which one is address to be stored, opA or opB??? if instruction is for branch: what does opA opB mean? which is the target address? It seems to be opA; and opB will be used to store the old PCC. capReq.offset = unpack(er.opB) capVal \u0026lt;- capCop.getCapResponse(capReq, Branch) check capVal.valid and read capability data form Cop2 er.opB = capVal.data (the old pcc)  other instruction (not a memory op or a branch, classified as Arithmetic) capVal \u0026lt;- capCop.getCapResponse(capReq, Arithmetic) check capVal.valid. do alu and store result to calcResult[64:0]; copy result to er.opA, er.carryout pendingOps.enq(er) outQ.enq(er)    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/coprofp_conversion_functions/",
	"title": "CoProConversionFunctions.bsv",
	"tags": [],
	"description": "",
	"content": "// cheri/trunk/FPU/CoProFPConversionFunctions.bsv function Bit#(m) truncateLSB(Bit#(n) value); return value[valueOf(n)-1:valueOf(n)-valueOf(m)]; endfunction  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/scheduler/",
	"title": "Scheduler.bsv",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Who calls this module and what is the input?\n Where does it go?\n  Reference 1\n//cheri/trunk/Scheduler.bsv // The mkScheduler module does a \u0026#34;pre-decode\u0026#34; of the instruction to find which // register numbers may be fetched and to classify the branch behaviour of the // instruction for the branch predictor. module mkScheduler#( // The scheduler needs the branch interface so that it can report the branch type // for the next prediction. This saves the branch predictor from having to guess // if the next instruction is a branch or not. BranchIfc branch, // The scheduler needs the register file interface because it submits the // register fetches that are retrieved in the decode stage. MIPSRegFileIfc theRF, // The scheduler needs the CP0 interface because it also submits potential register // reads to the CP0 interface, which are also retrieved in the decode stage. CP0Ifc cp0, CoProIfc cop1, `ifdef USECAP CapCopIfc capCop, `endif // The scheduler needs the instruction memory interface because it pulls the next // instruction out of the instruction memory to begin pre-decode analysis. InstructionMemory m // The scheduler exports a PipeStageIfc interface, (a FIFO#(ControlTokenT) interface), // for integration with the pipeline. `ifdef STATCOUNTERS , StatCounters statCounters `endif )(PipeStageIfc); Methods:\n enq \u0026hellip; first = outQ.first; deq = outQ.deq; clear = noAction  method Action enq(ControlTokenT cti)  Input: ControlTokenT cti Output: ControlTokenT cto: // outQ.enq(cto)\n CapInst goes to CapCop  -  call sites:\n cheri/trunk/MIPSTop.bsv: 398: (in rule fromFetchToScheduler) toScheduler.enq(ct)   case(cit.inst) can be: tagged Immediate/Jump/Register/Coprocessor/\nFor Coprocessor (ci) case:\ncase(ci.op) -\u0026gt; {COP2, LWC2, LDC2, SWC2, SDC2}.\n COP2: includes ci.cOp:{COffset, CCompare, MFC, MTC, CSetBounds, CRelBase, CJR, CJALR, CBTS, CBTU, CBEZ, CBNZ, CSeal, CUnseal, Check, CCall, CReturn, CClear, CLLSC}    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/memaccess/",
	"title": "MemAccess.bsv",
	"tags": [],
	"description": "",
	"content": " Reference 1\nMemory access stage of the pipeline\n//cheri/trunk/MemAccess.bsv module mkMemAccess#( DataMemory m `ifdef USECAP , CapCopIfc capCop `endif )(PipeStageIfc); Overview Input:\n DataMemory m. The memory hierachy which needs the system control processor for TLB integration CapCopIfc capCop.  Methods:\n enq (ControlTokenT er) first deq clear // should never be called  method Action enq(ControlTokenT er) Input: ControlTokenT er Output: ControlTokenT mi. // outQ.enq(mi) // mi has the updated\nSteps:\n Call capCop.getAddress(), check exception. getAddress() is defined in CapCop.bsv; it will check the length violation for the capability being used.\n check alignment of memory\n ??? L86-88, L140-156, scResult er.test er.opB[0]==1'b1 ??? what is those used for? Choose a value of mi.mem from Write/None, and set storeConditional?\n m.startMem(mi.mem, addr, er.cop, er.storeData, er.memSize, er.test==LL, cap, er.id, er.epoch, er.fromDebug, storeConditional);\n mi.mem: Read/Write/None     reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/capcop/",
	"title": "CapCop.bsv",
	"tags": [],
	"description": "",
	"content": " Reference 1\nCapCop.bsv cheri/trunk/CapCop.bsv\nOverview Interface: CapCopIfc\nModule: mkCapCop#(Bit#(16) coreId) (CapCopIfc)\nFunctions: getBase(cap), getLength(cap), getOffset(cap), getType(cap), getSealed(cap), checkRegAccess(Perms, CapReg), privileged(Perms), getPerms(CapFat).\nmkCapCop States:\n Reg#(Capability) pcc \u0026lt;- mkConfigReg(defaultCap); FIFOF#((BufferedPCC)) pccUpdate \u0026lt;- mkUGFIFOF1(); FIFO#(CapControlToken) inQ FIFO#(CapControlToken) dec2exeQ FIFO#(CapControlToken) exe2memQ FIFO#(CapControlToken) mem2wbkQ FIFOF#(ExceptionEvent) exception Reg#(CapCause) causeReg FIFOF#(CapCause) causeUpdate FIFO#(LenCheck) lenChecks FIFO#(CapCause) lenCause Reg#(Bool) capBranchDelay Reg#(CapState) capState Reg#(UInt#(5)) count  Rules:\n initialize: regFile.writeRaw for 32 times and set capState from Init to Ready. doException. Check exception, an FIFOF#(ExceptionEvent) inQtoBuffer  Methods:\n getArchPc(\u0026hellip;) putCapInst(capInst) getCapResponse(\u0026hellip;) getAddress() commitWriteback()  getAddress() Overview: do length checks for the first lenCheck in the queue of lenChecks. If success, response{.valid:True, }\ninput:\n FIFO(LenCheck) lenChecks, will consume one element from it; FIFO(CapCause) lenCause, will add one element to it;  output:\n ActionValue#(CoProResponse): return response;  exception = None if check passes  lenCause.enq(cause)  cause.exp = None if check passes   Steps:\n pass along one control token ct from exe2memQ to mem2wbkQ. create one CapCause cause, update the value cause.exp if length check fails; put it in queue lenCause. grab one lenCheck from lenChecks, and update the value if certain checks fail.  getCapResponse(CapReq capReq, ExecuteType opType) condition\n capState == Ready ! (pccUpdate.notEmpty \u0026amp;\u0026amp; dec2exeQ.first.jump): not if there is an outstanding jump and this is a jump ! causeUpdate.notFull  input\n CapReq capReq, ExecuteType opType, can be Memory, Branch, Arithmetic  output\n ActionValue#(CoProResponse).  globals:\n pcc: forwardedPCC: the pcc, or the pccUpdate.first.pcc;  Steps:\n check opType: Arithmetic, Branch, Memory if Arithmetic: the operation (capInst.op) can be Move, SetOffset, IncBaseNull, IncOffset, \u0026hellip;\n Move; SetOffset, IncBaseNull, IncOffset; SetBounds, SetBoundsExact; AndPerm; SetConfig, GetConfig; ClearTag, GetTag; GetLen, GetBase, GetOffset, GetType; GetPCC, SetPCCOffset; ReportRegs; GetPerm; GetSealed; Seal; Unseal; Unseal: Unseal capB with sealing capability capA: check capB.sealed bit; writeback.otype = 0 after unseal. GetRelBase; Subtract; CheckPerms; CheckType; CheckType: check capA.otype == capB.otype; if not match, set cause=CapCause{exp:Type, pcc: False, capReg: regB} as exception. CmpEQ, CmpNE, CmpLT, CmpLE, CmpLTU, CmpLEU; CmpEQX; Clear; Call; Return; Call: capA and capB must be sealed; check capA.otype == capB.otype; exception if not matched; check capA is code(permit_execute) and capB is data (!permit_execute); finally throw call exception; Return: throw return exception.  if Branch: operation (capInst.op) can be:\n BranchTagSet; BranchTagUnset; BranchEqZero; BranchNEqZero; JALR; JR; JALR: capA(code) is not sealed; update lenCheck; newPcc=capA; response.data=capA.offset; writeback=forwardedPCC; writeback.offset=pack(aCapReq.offset) // writeback contains link Cap Reg content. JR: capA(code) is not sealed; update lenCheck; response.data=capA.offset; newPcc = capA; CallFast; capA(code) and capB(code) must be sealed; unseal capA,capB; newPcc=capA; unseal capA, capB; writeback=capB; response.data=capA.offset; ERET; JumpRegister; None; default  if Memory: according to diferent operations (capInst.op), check capabilities, might set the lenCheck.valid, lenCheck.memSize, aCapReq.memOp, etc :\n L, LegacyL, S, LegacyS; \u0026ndash;\u0026gt; checking cause.exp, capA.perms.hard.permit_load/store, capA.sealed; if good, lenCheck.valid=True; LC, load cap reg; \u0026ndash;\u0026gt; check cause/capA.perms/capA.sealed; if good, set lenCheck.valid=True; lenCheck.memsize=CapWord; aCapReq.memOp=Read; SC, store cap reg, \u0026ndash;\u0026gt; check cause/CapA.perms.hard.permit_store_cap/permit_store_ephemeral_cap/sealed/CapB.perms.hard.non_ephemeral; if good, lenCheck.valid=True; lenCheck.memSize=CapWord; aCapReq.memOp=Write; response.storeData=tagged CapLine truncate(pack(capB)); writeback=capB; None; default  testPc=capReq.pc\n if jmp: set branch delay flag; testPc=capReq.pc+4; pccUpdate.enq(BufferedPCC{pcc: newPccc, epoch: ct.epoch})\n if not jmp: check testPc is in range of forwardedPCC.[base,length]\n exe2memQ.enq(ctOut) // after this,\n lenChecks.enq(lenCheck) // after this,\n check branch delay\n \u0026hellip;\n  getAddress()  input:  lenChecks. global variable. exe2memQ. mem2wbkQ.  output  ActionValue#(CoProResponse)   Steps:\n lenCheck = lenChecks.deq() CapControlToken ct \u0026lt;- toGet(exe2memQ).get() mem2wbkQ.enq(ct)  commitWriteback(CapWritebackRequest wbReq)  condition/guard  capState == Ready !exception.notEmpty()  input  CapWriteBackRequest wbReq CapControlToken ct (from mem2wbkQ) CapCause lenCheckCause (from lenCause)  output  regFile: regFile.writeReg(ct.writeCap, commit) regFile.clearRegs(ct.newRegMask) regFile.readRawPut(fetch) return ct.writeCap   Steps:\n parse information in wbReq and control token, and update the regFile accordingly\n// cheri/trunk/CapCop.bsv method ActionValue#(CapFat) commitWriteback(CapWritebackRequest wbReq) if (capState == Ready/* \u0026amp;\u0026amp; !exception.notEmpty()*/); //CapCause fetchCheckCause = fetchCause.first; //fetchCause.deq; CapCause lenCheckCause \u0026lt;- toGet(lenCause).get(); CapControlToken ct \u0026lt;- toGet(mem2wbkQ).get(); Bool commit = (!wbReq.dead \u0026amp;\u0026amp; wbReq.mipsExp == None); Capability newPcc = pcc; if (ct.jump \u0026amp;\u0026amp; commit) begin newPcc = pccUpdate.first.pcc; Capability dc = pccUpdate.first.pcc; trace($display(\u0026#34;Time:%0d, Core:%0d, Thread:0 :: PCC \u0026lt;- tag:%d s:%d perms:0x%x type:0x%x offset:0x%x base:0x%x length:0x%x\u0026#34;, $time, coreId, dc.isCapability, dc.sealed, dc.perms, dc.otype, dc.offset-dc.base, dc.base, getLength(dc))); end// else pcc.offset \u0026lt;= wbReq.pc; if (ct.jump \u0026amp;\u0026amp; pccUpdate.notEmpty) pccUpdate.deq; if (ct.capInst.op==SetConfig \u0026amp;\u0026amp; causeUpdate.notEmpty) causeUpdate.deq; if (ct.doWrite \u0026amp;\u0026amp; commit) begin if (ct.capInst.op == LC) ct.writeCap = wbReq.memResponse; `ifdef BLUESIM debugCaps[ct.writeReg] \u0026lt;= ct.writeCap; `endif Capability dc = ct.writeCap; trace($display(\u0026#34;Time:%0d, Core:%0d, Thread:0 :: CapReg %d \u0026lt;- tag:%d s:%d perms:0x%x type:0x%x offset:0x%x base:0x%x length:0x%x\u0026#34;, $time, coreId, ct.writeReg, dc.isCapability, dc.sealed, dc.perms, dc.otype, dc.offset-dc.base, dc.base, getLength(dc))); end regFile.writeReg(ct.writeCap, commit); if (!wbReq.dead \u0026amp;\u0026amp; (wbReq.mipsExp==CAP ||wbReq.mipsExp==CAPCALL|| wbReq.mipsExp==CTLBS||wbReq.mipsExp==ICAP)) begin // Length exception has priority over Call exception. if (ct.cause.exp==None || ct.cause.exp==Call) begin if (lenCheckCause.exp != None) ct.cause = lenCheckCause; end if (wbReq.mipsExp==CTLBS) ct.cause.exp = Ctlbs; if (wbReq.mipsExp==ICAP) ct.cause = CapCause{exp: Len, pcc: True, capReg: ?}; causeReg \u0026lt;= ct.cause; trace($display(\u0026#34;Time:%0d, Core:%0d, Thread:0 :: Exception CapCause \u0026lt;- CapExpCode: 0x%x CauseReg: %d\u0026#34;, $time, coreId, ct.cause.exp, ct.cause.capReg)); end else if (ct.capInst.op == SetConfig \u0026amp;\u0026amp; commit) begin causeReg \u0026lt;= ct.cause; trace($display(\u0026#34;Time:%0d, Core:%0d, Thread:0 :: SetConfig CapCause \u0026lt;- CapExpCode: 0x%x CauseReg: %d\u0026#34;, $time, coreId, ct.cause.exp, ct.cause.capReg)); end if (commit \u0026amp;\u0026amp; ct.writeRegMask) regFile.clearRegs(ct.newRegMask); if (!wbReq.dead) begin ExceptionEvent ee = None; if (wbReq.mipsExp!=None) ee = Except; else if (ct.capInst.op==ERET) ee = Return; if (ee != None) begin newPcc.offset = wbReq.pc; // Request KCC (register 29) from the register file to be placed in PCC // Or request EPCC (register 31) from the register file to be returned to PCC CapReg fetch = (ee==Except) ? 29:31; regFile.readRawPut(fetch); exception.enq(ee); end end `ifdef BLUESIM if (reportCapRegs.notEmpty) begin debugInst($display(\u0026#34;====== RegFile ======\u0026#34;)); debugInst($display(\u0026#34;DEBUG CAP COREID %d\u0026#34;, coreId)); debugInst($display(\u0026#34;DEBUG CAP PCC t:%d s:%d perms:0x%x type:0x%x offset:0x%x base:0x%x length:0x%x\u0026#34;, pcc.isCapability, pcc.sealed, pcc.perms, pcc.otype, pcc.offset-pcc.base, pcc.base, getLength(pcc))); for (Integer i = 0; i\u0026lt;32; i=i+1) begin Capability dc = debugCaps[i]; debugInst($display(\u0026#34;DEBUG CAP REG %d t:%d s:%d perms:0x%x type:0x%x offset:0x%x base:0x%x length:0x%x\u0026#34;, i, dc.isCapability, dc.sealed, dc.perms, dc.otype, dc.offset-dc.base, dc.base, getLength(dc))); end debugInst(reportCapRegs.deq()); end `endif if (!exception.notEmpty()) pcc \u0026lt;= newPcc; debug2(\u0026#34;cap\u0026#34;, $display(\u0026#34;CapCop Writeback, instID:%d==capWBTags.id:%d, capWBTags.valid:%d, capWB.first.instID:%d\u0026#34;, wbReq.instId, ct.instId, ct.doWrite, ct.instId)); return ct.writeCap; endmethod    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/beri-isa/",
	"title": "Beri ISA",
	"tags": [],
	"description": "",
	"content": " Reference 1\nCoprocessor 0: system control, MMU\nCoprocessor 1: FPU.\nCoprocessor 2: CHERI capability feature.\nSmaller caches motivated by the performance trade-offs in the FPGA substrate, which provides comparatively high-speed main memory, as well as a desire for simpilicity.\nFeatures omitted from MIPS 4000 ISA:\n only 64-bit, no 32-bit addressing support; only big endian support; no variable-endian features; BERI is usually configured as a single-core, single-threaded processor; Multiprocessor (BERI1) and multithreading (BERI2) are experimental.  Modifications to the MIPS TLB model Memory Caches L1 cache\n separate instruction and data; not coherent in BERI1 (BERI2 has coherent).\n explicit CACHE instructions are needed to synchronize the instruction and data caches.\n each L1 cache is 16K, direct-mapped, write-through, and physically indexed.\n  L2 cache\n shared between instruction and data; 64K, 4-way set associative, write-back, and physically indexed.  Reset Exception BERI start from 0x9000,0000,4000,0000 on reset, pointing to the miniboot ROM.\nFPU Some MIPS R4000 instructions are omitted; some instructions from MIPS IV are added.\nSelected additions from later MIPS ISA required by common compiler toolchains and operating systems.\nCP0 shadow registers: config1, config2, config3\n config1, allows queries of cache layout properties; used by FreeBSD during CPU discovery to select cache management routines; config2, ? config3, used by FreeBSD to detect that the processor supports the \u0026ldquo;user local\u0026rdquo; register, which is used by the C runtime to hold a pointer to thread-local storage.  RDHWR instruction, read hardware register.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/cheri-mips/",
	"title": "Cheri Source Code reading",
	"tags": [],
	"description": "",
	"content": " TODOs  cpu instructions; l2cache; icache; dcache; tagCache; init done; compilation passed.  Q\u0026amp;A Memory partitioned in ?  see MultiLevelTagLookup.bsv.  Possible bugs Bursts is 8 or 4?\n From TagController.bsv: peekMemResponse: one tagCache response is used for all bursts (frame as index), but the tagCache response only contain tags for 4 flits data\u0026rsquo;s tags. But somewhere says burst can be up to 8?  Does dCache/iCache calls the tag controller? If so, how? No. TagController is below L2Cache, and has an L3-like tag cache, See TagController\nReference 1\nKey files cheri/trunk/ Root of BERI1 source tree\n boards/ FPGA board projects sw/ integrated software component source code ip/ destination of generated Verilog files  In BERI1 source code:\n MIPS.bsv: Types and shared functions for the design MIPSTop.bsv: Top-level module implementing instruction and register fetch, which instantiates all other modules Scheduler.bsv: Pre-decode stage of the pipeline Decode.bsv Execute.bsv MemAccess.bsv: Memory access and writeback stage of the pipeline Memory.bsv: Memory subsystem, which instantiates the caches, merging logic, and memory interface ICache.bsv: Instruction level 1 cache DCache.bsv: Data level 1 cache Interconnect.bsv: Package including busses for implementing the memory heirachy L2Cache.bsv CoreCache.bsv: Core cache module used in all caches TopAxi.bsv: Top-level module adapting BERI\u0026rsquo;s memory interface to an AXI bus interface TopSimAxi.bsv: Top-level module interfacing BERI\u0026rsquo;s memory interface with the PISM bus for C peripheral models ForwardingPipelineRegFile.bsv: forwarding register file CP0.bsv: Coprocessor 0 containing all configuration registers TLB.bsv: 40-entry TLB with three cached interfaces CapCop.bsv: Module implementing the capability coprocessor  Macros for conditional compiling  CAP: include capability coprocessor COP1: Include floating point unit COP3: include experimental CP3 DCACHECORE: Use alternative DCache implementation ICACHECORE: Use alternative ICache impl. MULTI: number of cores MICRO: do not include the TLB and L2 cache NOBRANCHPREDICTION: wait for committed branch targets NOT_FLAT: build with all possible synthesis boundaries NOTAG: Bypass tag cache for capabilities (return True???)  Testing Run test suite\ncd cheritest/trunk/ make test\nPython Nose Framework Tagged Memory and Data Paths Two stages, Memory access and Instruction fetch, to access the memory with tags.\nData: Memory Access TODO: make clear how data is access from CPU to memory, and how tag is access in this process.\nsee Memory Access\nThe data path until TLB: MemoryAccess.bsv: issue memory request: module mkMemoryAccess: method Action enq() -\u0026gt; m.StartMem(addr, size,...)\n-\u0026gt; Memory.bsv: receive memory request from CPU: module mkMIPSMemory: (interface DataMemory) method Action startMem(addr, size,...):\n-\u0026gt; Memory.bsv: send request to TLB and get response. 1) prepare CacheRequest{size, TlbResponse{addr,\u0026hellip;},\u0026hellip;}, TlbRequest{addr,\u0026hellip;}, ; 2) send requests and get response from TLB: req.tr \u0026lt;- tlb.tlbLookupData.request(tlbReq);\n-\u0026gt; If TLB hit: send request to cache: dCache.put(req);\n-\u0026gt; If TLB miss: dCacheFetch \u0026lt;= req; dCacheDelayed \u0026lt;= True;\nThe Data path within DataCache (after TLB hit): The Data path when TLB Miss: query the TLB response again with req.tr \u0026lt;- tlb.tlbLookupData.response();\nThen do dCache.put(req), same when we have TLB hit.\nrule feedDCache(dCacheDelayed); CacheRequestDataT req = dCacheFetch; req.tr \u0026lt;- tlb.tlbLookupData.response(); dCache.put(req); dCacheDelayed \u0026lt;= False; endrule  MIPSTop.bsv  Q\u0026amp;A What is the specification of memory interface ? No mater what the capability width is, the MIPS processor has a memory interface of 256-bit data width (WORD width), 35-bit WORD address width. As there are 2^5 = 32 bytes = 256 bits per word, this is equivalent to a 35 + 5 = 40 byte address. ==\u0026gt; Memory interface is not byte addressable, but only world addressable; But processor could address in bytes inside itself.\n Example CSC  Q\u0026amp;A How a store cap via cap instruction got implemented in a processor? ISAv7 CSC: Store Capability via Capability CSC cs,rt,offset(cb) CSCR cs,rt(cb) CSCI cs,offset(cb) Cap register cs is stored at the memory location of cb.base + cb.offset + rt + 16*offset | Bit | size | value | |\u0026mdash;\u0026mdash;-|\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026ndash;| | 31-26 | 6 | 0x3e | | 25-21 | 5 | cs | | 20-16 | 5 | cb | | 15-11 | 5 | rt | | 10-0 | 11 | offset |\n Writeback   Q\u0026amp;A Who calls this module and what is the input? The final pipeline stage, previous one is MemAccess connected via FIFO of ControlToken. update register file. Where does it go? Reference 1 reference ↩  MIPS.bsv  Reference 1 reference ↩  ICache  Todones CacheInstIfc (in MIPS.bsv) - put() -\u0026gt; rule doPut() // - getRead() - invalidate() - getConfig() - getResponse() // - interface Master# Q\u0026amp;A Who calls this module and what is the input? called from Memory.bsv: rule feedICache, after TLB translation. iCache.put(req); The input is the physical memory access request req of type CacheRequestInstT. see Memory.bsv. Where does it go? it send a memory request to CacheCore, iCache.\n Test  Reference 1 Files in test suite cheritest/trunk. root of test suite gxemul_log/ output of gxemul test log/ holds output of test obj/ holds obj files, memory images, and assembly dumps. tests/ Individual tests and their matching Python Nose classes tools/ Utility functions to perform common functions such as interpreting BERI simulator and gxemul output fuzzing/ Scripts for fuzz testing the TLB init.s A thin loader to set up various aspects of CPU and memory configuration.\n tagsparams.py  file cherilibs/trunks/tagsparams.py Parameters: -c, \u0026ndash;cap-size, default=256, capability size in bits; -s, \u0026ndash;structure, default=[0], list from leaf to root of branching factors describing the tags tree; -t, \u0026ndash;top-addr, default=0x4000_0000, memory address the tag should start growing down from; -a, \u0026ndash;addr-align, default=32, alignment requirement (in bytes) for table levels addresses; -m, \u0026ndash;mem-size, default=(2^32 + 2^20), size of the memory to be covered by the tags; -b, \u0026ndash;bsv-inc-output, const=\u0026ldquo;TagTableStructure.bsv\u0026rdquo;, default = None; -l, \u0026ndash;linker-inc-output, const=\u0026ldquo;tags-params.\n Expand Bits  \n Tag Lookup  Q\u0026amp;A How many tags it caches for physical memory access request? Overview Get a physical addr access request, and return a tag associated with this physical address. This is a cache impl based on CacheCore, similar to D/ICache, L2Cache. One Covered Region is a cached tag region. It is of type LineTags, which is a vector (of size 4) of tags, each vector element contains the tags for one flit (i.\n MultiLevelTagLookup.bsv  Todones rules/functions processing different states: - Init: - doLookup condition !Init - Idle: - Slave cache.request.canPut(), put(), - doLookup condition !Idle - ReadTag, SetTag, ClearTag: - used in doLookup - set in Slave cache.request.put(req) - FoldZeroes: - used in doLookup - set in doLookup, rules triggered by getReq.send(): -\u0026gt; rule drainMemRsp: // done rule doLookup: -\u0026gt; ClearTags: -\u0026gt; getOldTagsEntry() // done // do nothing if flat table. -\u0026gt; getReq.send() // done -\u0026gt; doTransition() // done Slave: -\u0026gt; request.\n Master Slave  Q\u0026amp;A Master Slave: how do they communicate? ModuleA (master)\u0026lt;\u0026mdash;-\u0026gt; (slave) ModuleB (master) \u0026lt;\u0026mdash;-\u0026gt; (slave) ModuleC Master controls the communication: do the put/get things by calling slave\u0026rsquo;s interface method. Slave will be waiting for being called and receive the data; One has Slave interface will also have a Master interface in order to pass this data to the Slave interface of next module. Right? See Bluespec basics for connectable interfaces [/en/arch/basics/bluespec/packages/connectable/client-server/]\n L2Cache  Q\u0026amp;A Who calls it and what is the input? Where does it go? hand over the request to tagControllers Calls tagController to get response How is it related tagged memory? The master interface memory is re-used by TagController file: cherilibs/trunk/L2Cache.bsv Interface L2CacheIfc Master is memory; Slave is cache; mkConnection(l2CacheMemory, tagController.cache); means Master is l2CacheMemory and slave is tagController.cache, that is tag controller is being called by l2Cache; and l2Cache send request and get response from tagController.\n Merge.bsv  Q\u0026amp;A Who calls this and what is the input? i/dcache requests goes through here and being forwarded to l2cache; l2cache response being sent back here and forwarded to i/dcache; Where does this go? forward request to l2cache memory; Memory.bsv: mkConnection(theMemMerge.merged, l2Cache.cache) return response to icache/dcache via slaves[i] file: cheri/trunk/Merge.bsv module mkMergeFast module mkMergeFast(MergeIfc#(numIfc)); numIfc = 2 in Memory.bsv Connections: // Memory.bsv mkConnection(iCache.memory, theMemMerge.slave[0]); mkConnection(dCache.\n CacheCore.bsv  Q\u0026amp;A Does it treat the memory tags read/write request differently? no. tag read/write can only be distinguished by masterID. However, master ID does not change the logic routines in CacheCore. CacheCore only transfer this master ID from request to response. Who calls this and what is the input? DCache calls this to send request and get response via core.put(CheriMemRequest reqIn) and core.response.get init: CacheCore#(4, TSub#(Indices,1), 1) core \u0026lt;- mkCacheCore(cacheId, wmb, RespondAll, InOrder, DCache, zeroExtend(memReqs.\n CP0  Todos tracking tlbLookupData.request/response for TLB hit/miss handling MIPS.bsv: CP0Ifc declaration, contains subinterface of TranslationIfc tlbLookupData; COP0.bsv: mkCP0: definition of TranslationIfc tlbLookupData: .request(reqIn) and .response() invokes tlb.lookup[1/2].request(reqIn) and .response(), which is defined in mkTLB module in TLB.bsv: lookup = lookups. see [../tlb], Do TLB search tracking cache for hit/miss handling Reference 1 File: cheri/trunk/CP0.bsv Module mkCP0 mkCP0#(Bit#(16) coreId)(CP0Ifc) Interfaces interface CP0Ifc, in cheri/trunk/MIPS.bsv: methods: method for register read: readReq method for register writePending bool flag writePending; method for register write: writeReg; \u0026hellip; method for reading current address space identifier: getAsid // a method to get current code/data page tags?\n MemTypes.bsv  Data Reference 1 The type of Data#, CapTags, CapsPerFlit, and BytesPerFlit. See CheriBusBytes in MemTypes Data It contains both data and capability tag. TODO: What is the data_width? and the relationship between number of tag bits and this data_width, and the CHERI bits? Data# definition: // Data type typedef struct { `ifdef USECAP // is this frame has capabilities CapTags cap; `endif // actual data Bit#(width) data; } Data#(numeric type width) deriving (Bits, Eq, FShow); CapTags definition\n Tag Controller  Todones peekMemResponse(): when grab the tag response from tagCache: lookupRsp.first: need to review it to match the CheriTagResponse returned in MultiLevelTagLookup.bsv Q\u0026amp;A Who calls this and what is the input? see Input/Output How does it get feedback from memory? via function peekMemResponse(): mRsps.first. See section helper function Where does this being connected? Connect to l2 cache; and connect to memory to provide proxied memory interface.\n DCache.bsv  Todones CacheDataIfc - put() -\u0026gt; rule doPut() // - getResponse() // done. Q\u0026amp;A Who calls this module and what is the input? called from Memory.bsv: interface DataMemory:startMem, after TLB translation. dCache.put(req); The input is the physical memory access request req of type CacheRequestDataT. see Memory.bsv. Where does it go? it send a memory request to CacheCore, see CacheCore. it returns the response back to Memory.\n TLB.bsv  Q\u0026amp;A How does TLB read/write permissions on page table? Can we add more bits for permission/types? Reference 1 2 MIPS R4000 Basics 48 TLB entries, each can map variable-sized pages from 4Kb to 16Mb. Address translation value is tagged with the most-significant bits of its virtual address, and a per-process identifier. Instruction TLB: a two-entry instruction TLB.s Joint TLB: upon TLB miss, software will refill the JTLB from a page table resident in memory.\n TagCache.bsv   Q\u0026amp;A Who calls this and what is the input? ??? No one calls mkTagCache?! Where does this go? Reference 1 cherilibs/trunk/TagCache.bsv reference ↩  Memory.bsv  Q\u0026amp;A Who calls this and what is the input? Where does it go? it sends a cache memory request to DCache: dCache.put(req);, see DCache.bsv Reference 1 MIPS memory module file cheri/trunk/Memory.bsv module mkMIPSMemory#(Bit#(16) coreId, CP0Ifc tlb)(MIPSMemory); MIPS memory interfaces MIPSMemory DataMemory InstructionMemory MemConfiguration Server#(CoProMemAccess, CoProRegs) // cheri/trunk/Memory.bsv interface MIPSMemory; interface DataMemory dataMemory; interface InstructionMemory instructionMemory; interface MemConfiguration configuration; `ifdef COP1 interface Server#(CoProMemAccess, CoProReg) cop1Memory; `endif `ifdef MULTI method Action invalidateICache(PhyAddress addr); method Action invalidateDCache(PhyAddress addr); method ActionValue#(Bool) getInvalidateDone; interface Master#(CheriMemRequest, CheriMemResponse) dmemory; interface Master#(CheriMemRequest, CheriMemResponse) imemory; `else interface Master#(CheriMemRequest, CheriMemResponse) memory; // the generic main memory interface as a client.\n Execute.bsv  Q\u0026amp;A How does it caculate the memory access address? where does it access TLB? Global Functions: function Bit#(a) arithmeticShift(Bit#(a) toShift, Bit#(b) shiftAmount) function Bit#(a) arithmeticShift2(Bit#(a) toShift, Bit#(b) shiftAmount) mkExecute module s Input: MIPSRegFileIfc rf WritebackIfc writeback CP0Ifc cp0 CoProIfc cop1 CapCopIfc capCop FIFO#(ControlTokenT) inQ Rules: finishMultiplyOrDivide deliverPendingOp Methods: enq first deq clear States: FIFO#(ControlTokenT) outQ \u0026lt;- mkFIFO; MulDivIfc mul \u0026lt;- mkMulDiv; Reg#(MIPSReg) hi \u0026lt;- mkReg(64\u0026rsquo;b0); Reg#(MIPSReg) lo \u0026lt;- mkReg(64\u0026rsquo;b0); FIFOF#(Bool) hiLoPending \u0026lt;- mkFIFOF1; FIFOF#(ControlTokenT) pendingOps \u0026lt;- mkFIFOF1; Reg#(Bit#(16)) coreid \u0026lt;- mkConfigReg(0); method Action enq(ControlTokenT di) Condition:\n CoProConversionFunctions.bsv  // cheri/trunk/FPU/CoProFPConversionFunctions.bsv function Bit#(m) truncateLSB(Bit#(n) value); return value[valueOf(n)-1:valueOf(n)-valueOf(m)]; endfunction  Scheduler.bsv  Q\u0026amp;A Who calls this module and what is the input? Where does it go? Reference 1 //cheri/trunk/Scheduler.bsv // The mkScheduler module does a \u0026#34;pre-decode\u0026#34; of the instruction to find which // register numbers may be fetched and to classify the branch behaviour of the // instruction for the branch predictor. module mkScheduler#( // The scheduler needs the branch interface so that it can report the branch type // for the next prediction.\n MemAccess.bsv  Reference 1 Memory access stage of the pipeline //cheri/trunk/MemAccess.bsv module mkMemAccess#( DataMemory m `ifdef USECAP , CapCopIfc capCop `endif )(PipeStageIfc); Overview Input: DataMemory m. The memory hierachy which needs the system control processor for TLB integration CapCopIfc capCop. Methods: enq (ControlTokenT er) first deq clear // should never be called method Action enq(ControlTokenT er) Input: ControlTokenT er Output: ControlTokenT mi. // outQ.enq(mi) // mi has the updated\n CapCop.bsv  Reference 1 CapCop.bsv cheri/trunk/CapCop.bsv Overview Interface: CapCopIfc Module: mkCapCop#(Bit#(16) coreId) (CapCopIfc) Functions: getBase(cap), getLength(cap), getOffset(cap), getType(cap), getSealed(cap), checkRegAccess(Perms, CapReg), privileged(Perms), getPerms(CapFat). mkCapCop States: Reg#(Capability) pcc \u0026lt;- mkConfigReg(defaultCap); FIFOF#((BufferedPCC)) pccUpdate \u0026lt;- mkUGFIFOF1(); FIFO#(CapControlToken) inQ FIFO#(CapControlToken) dec2exeQ FIFO#(CapControlToken) exe2memQ FIFO#(CapControlToken) mem2wbkQ FIFOF#(ExceptionEvent) exception Reg#(CapCause) causeReg FIFOF#(CapCause) causeUpdate FIFO#(LenCheck) lenChecks FIFO#(CapCause) lenCause Reg#(Bool) capBranchDelay Reg#(CapState) capState Reg#(UInt#(5)) count Rules: initialize: regFile.writeRaw for 32 times and set capState from Init to Ready.\n  BERI HW reference. 2015. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/seminars/2020-asplos/",
	"title": "2020 Asplos",
	"tags": [],
	"description": "",
	"content": " Reference 1\nMost influential: Africa(Kenya) zebra tracking; peer-to-peer epidemic propagation; energy saving.\nBetteryless in IoT: Intermittent Timekeeping in Intermittent Computing RC circuits: capacitor discharged time.\nThis work: a sequential discharged chain of RC circuits instead of one.\nTotalRecall Avoid all NVM-writes by taking checkpoints that reside entirely in SRAM.\nSRAM volatility: ~5 minutes (20 C)\nLong time off times: predictable; irrelavant;\nTICS: Batteryless on legacy software Time annotated C source.\n64 KB FRAM\nCyber attacks Egalito: binary recompiler 50 software bugs per 1k lines!\nbinary level transformation\nPIC by default (ASLR):\n base address in register -\u0026gt; expensive on 32 bit; good on 64 bit x86, etc.  Three categories of binary transformation Binary patching: jmp detour;; e.g. DyInst\nProcess virtualization: switch address space during exe; e.g. DynamoRIO, PIN\nBinary recompilation: shifting everything up/down;\n e.g. Ramblr, McSema Difficult to perform: require precise pointer, function, jump table analysis has same power as the original linker/compiler backend  Binary disassembly is undecidable Dynamics techniques to conquer :\n DynamoRIO, PIN (Dynamic binary translation) Valgrind, Dyninst, Qemu  Or, statically with sacrifices:\n Under-approximate code, preserve layout. (most binary rewriting)\n Use heuristics and speculative disassembly. (e.g., Ramblr)\n Over-approximate code and pointers. (e.g., superset disassembly)\n  Egalito (layout agnostic) bin -\u0026gt; IR -\u0026gt; bin\nrecompiler passes\nfewer heuristics\nEgalitarian: binary transformation more equal with source level transformation; compile and defend itself.\nMachine code \u0026lt;-\u0026gt; Egalito IR (=~ Machine specific IR) \u0026lt;-\u0026gt; Higher-level representation (=~ LLVM IR)\n Find all pointers. via heuristics; PIC code;  Evaluation near zero overhead.\nX86_64, ARM64, partial RISC-V support.\nSource code https://egalito.org/\nhttps://github.com/columbia/egalito\n  talks ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/tools/make/",
	"title": "Make",
	"tags": [],
	"description": "",
	"content": "Reference 1\n%: one or more chars. used in matching patterns of targets, prerequests.\n$@: the target of the rule.\n$^: a list of the dependence files with their full paths.\n$\u0026lt;: the first dependence file.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/bluespec/types/",
	"title": "Types",
	"tags": [],
	"description": "",
	"content": " Reference 1\nStrong, static type-checking.\nEvery variable and every expression in BSV has a type.\nConvention: first char uppercase. (except for int and bit for backward compatibility with Verilog)\nType expression Type expression/paramterized types: X#(t1,\u0026hellip;,tn). X is the type constructor and x1,\u0026hellip;,xn are parameters of X.\n// Type Expression Examples Tuple2#(int, Bool) // pair of items, an int and a Bool Tuple3#(int, Bool, String) List#(Bool) List#(List#(Bool)) RegFile#(Integer, String) //paraeter can be natural numbers (numeric types) Bit#(16) // 16-bit wide bit-vector (16 is a numeric type) bit[15:0] // synonym for Bit#(16) Vector#(16, Int#(29)) // Vector of size 16, containing Int#(29)\u0026#39;s bit[m:n] \u0026ndash;\u0026gt; n must be 0.\nTypes in libraries Prelude package.\nBit types: Bit#(n), UInt#(n), Int#(n), Bool, Maybe, Tuples;\nNon-bit types: Integer, Real, String, Char, Fmt.\n Maybe: used to tag values as Valid or Invalid, where valid values contain data. Fmt: representation of arguments to the $display familiy of tasks.  Interface types: Reg, FIFO, Clock, Reset, Inout.\nTypes used by compiler:\n Action. An expression intended to acto on the state of the circuit. equal to ActionValue#(void). ActionValue#(a). An expression intended to act on the state of the cirtuit. a is the type of return value. Rules. Used to represent one or more rules as a first class type.\nmethod Action grab(Bit#(8) value); last_value \u0026lt;= value; endmethod interface IntStack; method Action push (int x); method ActionValue#(int) pop(); endinterface: IntStack seq noAction; endseq  Type synonyms:\n typedef Bits#(8) Byte; typedef Tuple2#(a, a) Pair#(type(a)); typedef 32 DataSize; typedef Bit#(DataSize) Data;  Enumerated types: typedef enum(Red, Blue, Green) Color deriving(Bits, Eq)\nPolymorphism: List#(a) List#(List#(b)) RegFile#(i,List#(x)) // Type variables, a, b, x, represent unknown (but specific) types. Type Functions used when defining variable size for types:\n TAadd#(n1, n2): Calculate n1 + n2 // example: Int#(TAdd#(5,n)): define a signed integer n+5 bits wide, n must be in scope somewhere\n TSub#(n1,n2)\n TMul#(n1,n2)\n TDiv#(n1,n2) // ceiling n1/n2\n TLog#(n) // ceiling log_2(n)\n TExp#(n) // 2^{n}\n TMax#(n1,n2)\n TMin#(n1,n2)\n  Provisos (brief intro) A proviso is a static condition attached to certain constructs, to impose certain restrictions on the types involve in the construct. The restrictions are of two kinds:\n Require instance of a type class (overloading group): this kind of proviso states that certain types must be instances of certain type classes, i.e., that certain overloaded functions are defined on this type.\n Require size relationships: this kind of proviso expresses certain constraints between the size of certain types.\n  Common overloading provisos:\nBits#(t,n) // Type class (overloading group) Bits // Meaning: overloaded operators pack/unpack are defined // on type t to convert to/from Bit#(n) // pack/unpack: {1,0,1} \u0026lt;-\u0026gt; 101 Eq#(t) // Type class (overloading group) Eq // Meaning: overloaded operators == and != are defined on type t Literal#(t) // Meaning: Overloaded function fromInteger() defined on type t // to convert an integer literal to type t. Also overloaded // function inLiteralRange to determine if an Integer // is in the range of the target type t. Ord#(t) // Meaning: Overloaded order-comparison operators \u0026lt;, \u0026lt;=, \u0026gt; and \u0026gt;= // are defined on type t Bounded // Meaning: Overloaded identifiers minBound and maxBound // are defined for type t Bitwise#(t) // Meaning: Overloaded operators \u0026amp;, |, ^, ~^, ^~, ~, \u0026lt;\u0026lt;, \u0026gt;\u0026gt; // and overloaded function invert are defined on type t BitReduction#(t) // Meaning: Overloaded prefix operators \u0026amp;, |, ^, ~\u0026amp;, ~|, // ~^, ^~ are defined on type t BitExtend#(t) // Meaning: Overloaded functions extend, zeroExtend, signExtend and truncate are defined on type t Arith#(t) // Meaning: Overloaded operators +, -, *, overloaded prefix operator - (same as function negate), negate, defined on type t Size relationship provisos are:\nAdd#(n1,n2,n3) // Meaning: assert n1 + n2 = n3 Mul#(n1,n2,n3) // Meaning: assert n1 * n2 = n3 Div#(n1,n2,n3) // Meaning: assert ceiling n1 / n2 = n3 Max#(n1,n2,n3) // Meaning: assert max(n1,n2) = n3 Log#(n1,n2) // Meaning: assert ceiling(log(n1)) = n2 // The logarithm is base 2 Example of using provisos:\nmodule mkExample (ProvideCurrent#(a)) provisos(Bits#(a,sa), Arith#(a)); Reg#(a) value_reg \u0026lt;- mkReg(?); // requires that type \u0026#34;a\u0026#34; be in the Bits typeclass. rule every; value_reg \u0026lt;= value_reg + 1; // requires that type \u0026#34;a\u0026#34; be in the Arith type class. endrulefunction Bit#(m) pad0101 (Bit#(n) x) provisos (Add#(n,4,m)); // m is 4 bits longer than n pad0101 = {x, 0b0101}; endfunction: pad0101 deriving clauses directing the compiler to define automatically certain overloaded functions for that type.\nderiving(Eq) // Meaning: automatically define == and != // for equality and inequality comparisons deriving(Bits) // Meaning: automatically define pack and unpack // for converting to/from bits deriving(FShow) // define fshow to convert to a Fmt representation for $display functions deriving (Bounded) // automatically define minBound and maxBound Example:\ntypedef enum {LOW, NORMAL, URGENT} Severity deriving(Eq, Bits); // == and != are defined for variables of type Severity // pack and unpack are defined for variables of type Severity module mkSeverityProcessor (SeverityProcessor); method Action process (Severity value); // value is a variable of type Severity if (value == URGENT) $display(\u0026#34;WARNING: Urgent severity encountered.\u0026#34;); // Since value is of the type Severity, == is defined endmethod endmodule   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/bluespec/type-classes/",
	"title": "Type Classes",
	"tags": [],
	"description": "",
	"content": " Reference 1\nType classes (overloading groups) and provisos predefined type classes: Bits, Eq.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/iot/5g/",
	"title": "5g",
	"tags": [],
	"description": "",
	"content": " Reference 1\nITU (International Telecommunications Union)\nApplications Internet,\naugmented, virtual reality..\nwearable devices with integrated mobile communication system (smart watch),\ncar communication system,\nhousehold applicances, utility meters\nrobotics, self-driving cars.\nmassive IoT: one million devices per square km.\nSecurity Traditional mobiles: SIM(Subscriber Identity Module), Universal Integrated Circuit Card (UIUC)\nCloud: tokenization, host card emulation(HCE), Trusted Execution Environment (TEE).\n  5G Explained. by Jyrki T. J. Penttinen. 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/attacks/sgx/",
	"title": "Sgx",
	"tags": [],
	"description": "",
	"content": "Reference 1\n2010-03-10 unfixable flaw\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/systemv/verilog/",
	"title": "Verilog",
	"tags": [],
	"description": "",
	"content": " Reference 1\nPort vs Parameters Port: arguments/interfaces to other modules, contains input/output.\nParameter: constants. Typically used to specify the width of variables and time delays; has default value; can be overwritten during module instantiation.\nVerilog Functions https://www.chipverify.com/verilog/verilog-functions\nFor certain pieces of code to be repetitive and called multiple times within the RTL.\nfunction [automatic] [return_type] name ([port_list]); [statements] endfunction  Starts with function, ends with endfunction.\nShould have at least one input.\nReturn could be void (return nothing)\nautomatic will make the functino reentrant and items declared within the task are dynamically allocated rather than shared between different invocations of the task.\n Useful for recursive functions Useful when the same function is executed concurrently by N Processes when forked.  Function declarations  Verilog Modules A Verilog module is a building block. It defines a design or testbench component. It does so by defining the building block\u0026rsquo;s ports and internal behaviour.\nA module can be embedded into another module, creating hierachical designs.\nModule \u0026amp; Components:\n Starts with module and ends with endmodule Identifier that is the name of the module Optional list of parameters Optional list of ports Module item  Parameters Allows a single piece of Verilog module code to be extensible and reusable.\nEach instantiation of a Verilog module can supply different values to the parameters, creating different variations of the same base Verilog module.\nFor example, a FIFO Verilog module may have a Verilog parameter to adjust its data width (or even data type, in SystemVerilog).\nVerilog Port A list of Verilog port (port list).\nTo communicate with other modules.\nWays to communicate other than ports: backdoors.\nModule item Item is essentially the code inside a module.\nAfter port declaration.\nDefines what constitutes the module, and can include many different types of declarations and definitions.\n nets, variable declarations, always blocks, initial blocks, \u0026hellip;  Example module my_module #( parameter WIDTH = 1 ) ( input wire clk, input wire rst_n, input wire [WIDTH-1:0] in_a, in_b, output reg [WIDTH-1:0] out_c ); always @(posedge clk or negedge rst_n) out_c \u0026lt;= in_a \u0026amp; in_b; endmodule  Modue Instantiation More   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/bluespec/modules/",
	"title": "Modules",
	"tags": [],
	"description": "",
	"content": " Reference 1\nOverview Modules and interfaces form the heart of BSV.\nModules and interfaces turn into actual hardware.\nAn interface for a module m mediates between m and other, external modules that use the facilities of m, i.e. clients of m.\nModule definition vs instantiation A single module definition of a FIFO, and multiple instantiations of this FIFOs in a design.\nPure hierarchy. In a module definition, mkM, one can specify instantiations of other modules. Every module instance unambiguously has a single parent module instance. The top of the hierarchy as the root module. Every module instance has a unique set of child module instances. If no children, we refer to it as a leaf module.\nInterface declarations and instances A design will contain interface declarations, and each of these ma have multiple instances.\nExample: an interface declaration I may have one instance $i_1$ for communication between module instances $a_1$ and $b_1$, and another instance $i_2$ for communication between module instances $a_2$ and $b_2$.\nModule in Three Parts Three parts: state, rules, interface.\n state elements in hardware, rules that operate on the state of the module. Fundamental means to express behavior in BSV (instead of always blocks in Verilog) interface to the outside world (surrounding hierarchy). Consists of methods that encapsulate the possible transactions that clients can perform. When compiled into RTL, an interface becomes a collection of wires.  Explicit state via module instantiation, not variables Ambiguity in Verilog/SystemVerilog RTL state elements by variables: variable can be mapped into various kind of state elements by a synthesis tool: a bus, a latch, a flip-flop, or even nothing at all.\nBSV removes the ambiguity:\n all state instances are specified explicitly using module instantiation.\n an ordinary declared variable in BSV never implies state, i.e. it never holds a value over time.\n just convenient names for intermiediate values in a computation. variables declared in blocks, formal parameters, pattern variables, loop iterators, and so on.   Interface Declaration An interface contains methods and subinterfaces as its members.\nEach method represents one kind of transaction between a module and its clients. Will be wires in RTL.\nDifference between a method and a function: method also carries implicit condition.\nImplicit condition: each method has an implicit ready wire, which governs when it is legal to use it.\none of the major advantages of BSV is that the compiler automatically generates all the control circuitry needed to ensure that a method (transaction) is only used when it is legal to use it. \u0026ndash;\u0026gt; any hints to system security forging languages/os/hardware???\nA stack of integers:\ninterface IntStack; method Action push (int x); method Action pop; method int top; endinterface: IntStack A stack with polymorphic type:\ninterface Stack#(type a); method Action push (a x); method Action pop; method a top; endinterface: Stack // to use: typedef Stack#(int) IntStack; Subinterfaces interface ILookup; interface Server#( RequestType, ResponseType ) mif; interface RAMclient#( AddrType, DataType ) ram; method Bool initialized; endinterface: ILookup Methods of subinterfaces are accessed using dot notation to select the desired component, e.g.,\nilookup.mif.request.put(...); Module definition mk convention: make, suggesting a module definition is not a module instance. When the module is instantiated, one invokes mkFoo to actually create a module instance.\nParameters \u0026ndash;\u0026gt; constants, same as verilog/systemverilog. parameter to generate Verilog parameter; without parameter, a Verilog port is generated.\nInterfaces \u0026ndash;\u0026gt; argument/port; input/output;\nProvisos \u0026ndash;\u0026gt; type classes (overloading groups).\nExamples:\nA module with parameter a and an interface Fifo:\nmodule mkFifo#(Int#(8) a) (Fifo); ... endmodule A module with arguments and an interface, but no parameters:\nmodule mkSyncPulse (Clock sClkIn, Reset sRstIn, Clock dClkIn, SyncPulseIfc ifc); ... endmodule A module definition with parameters, arguments, and provisos:\nmodule mkSyncReg#(a_type initValue) (Clock sClkIn, Reset sRstIn, Clock dClkIn, Reg#(a_type) ifc) provisos (Bits#(a_type, sa)); ... endmodule Can also be written as Parameters and Arguments be combined:\nmodule mkSyncReg (a_type initValue, Clock sClkIn, Reset sRstIn, Clock dClkIn, Reg#(a_type) ifc) provisos (Bits#(a_type, sa)); ... endmodule Module and interface instantiation Short form instantiation one line form\n[attributeInstances] type identifier \u0026lt;- identifier ( [moduleActualParameterArg {, \u0026hellip;}]);\n parameters listed first, argument next, combined within a single set of parentheses; no # before the list. each module has an implicit clock and reset. can be changed by explicitly specifying a clocked_by or reset_by argument.\ninterface ArithIO#(type a); //interface type called ArithIO method Action input (a x, a y); //parameterized by type a method a output; //contains 2 methods, input and output endinterface: ArithIO module mkGCD#(int n) (ArithIO#(bit [31:0])); ... //module definition for mkGCD ... //one parameter, an integer n endmodule: mkGCD //presents interface of type ArithIO#(bit{31:0]) //declare the interface instance gcdIFC, instantiate the module mkGCD, set n=5 module mkTest (); ... ArithIO#(bit [31:0]) gcdIfc \u0026lt;- mkGCD (5, clocked_by dClkIn); ... endmodule: mkTest  module instantiation using a clocked_by statement:\ninterface Design_IFC; method Action start(Bit#(3) in_data1, Bit#(3) in_data2, Bool select); interface Clock clk_out; method Bit#(4) out_data(); endinterface : Design_IFC module mkDesign(Clock prim_clk, Clock sec_clk, Design_IFC ifc); ... RWire#(Bool) select \u0026lt;- mkRWire (select, clocked_by sec_clk); ... endmodule:mkDesign Long form instantiation full form on two consecutive lines, similar to SystemVerilog.\nFirst line: identifier with an interface type.\nSecond line: instantiates the module and defines the interface.\nmodule mkTest (); //declares a module mkTest ... // ArithIO#(bit [31:0]) gcdIfc(); //declares the interface instance mkGCD#(5) a_GCD (gcdIfc); //instantiates module mkGCD ... //sets N=5, names module instance a_GCD endmodule: mkTest //and interface instance gcdIfc module mkDesign(Clock prim_clk, Clock sec_clk, Design_IFC ifc); ... RWire#(Bool) select(); // declare mkRWire t_select(select, clocked_by sec_clk); // instantiate module ... endmodule:mkDesign Interface/methods definition Definition of methods.\nInside a module definition.\nmethod [type] identifier ( methodFormals ) [implicitCond]; functionBody endmethod [: identifier]\n Methods must be from an interface of the module. Each methods in the interface must be defined exactly once. Return type and arguments are optional, since compiler knows them from the declaration;  Implicit condition:\n Every method is ultimately invoked from a rule (might be indirectly invoked through other methods) A method\u0026rsquo;s implicit condition controls wether the invoking rule is enabled. implicit condition precedes the semicolon that terminates the method definition header.\n// the implicite condition // if false, any rule invokes the method will not be fired. method ... foo (...) if (expr); ... endmethod // a conditonal statement inside the method. // condition does no prevent the rule being fired. // method ... foo (...); if (expr) ... endmethod  Method body is exactly like a function body.\nExample:\ninterface GrabAndGive; // interface is declared method Action grab(Bit#(8) value); // method grab is declared method Bit#(8) give(); // method give is declared endinterface module mkExample (GrabAndGive); Reg#(Bit#(8)) value_reg \u0026lt;- mkReg(?); Reg#(Bool) not_yet \u0026lt;- mkReg(True); // method grab is defined method Action grab(Bit#(8) value) if (not_yet); value_reg \u0026lt;= value; not_yet \u0026lt;= False; endmethod //method give is defined method Bit#(8) give() if (!not_yet); return value_reg; endmethod endmodule   Bluespec SystemVerilog Reference Guide. July 2017. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/iot/env/aleaves/",
	"title": "Artificial Leaves",
	"tags": [],
	"description": "",
	"content": "Reference 12\n  \u0026lsquo;Artificial leaf\u0026rsquo; successfully produces clean gas ↩ Virgil Andrei , Bertrand Reuillard and Erwin Reisner. ‘Bias-free solar syngas production by integrating a molecular cobalt catalyst with perovskite-BiVO4 tandems.’ Nature Materials (2019). DOI: 10.1038/s41563-019-0501-6 ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/finegrain/2020-sec-firefox/",
	"title": "2020 Sec Firefox",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Shravan Narayan, Craig Disselkoen, Tal Garfinkel, Nathan Froyd, Eric Rahm, Sorin Lerner, Hovav Shacham, and Deian Stefan.RLBox: Retrofitting Fine Grain Isolation in the Firefox Renderer. In Proceedings of USENIX Security Symposium. August, 2020 ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/overflow/hbleed/",
	"title": "Heart Bleed",
	"tags": [],
	"description": "",
	"content": "CVE-2014-0160\nOpenSSL 1.0.1f, Fixed in 1.0.1g\ntlsl_process_heartbeat() in t1_lib.c\n // 2553 int tls1_process_heartbeat(SSL *s){ unsigned char *p = \u0026amp;s-\u0026gt;s3-\u0026gt;rrec.data[0], *pl; unsigned short hbtype; unsigned int payload; unsigned int padding = 16; /* Use minimum padding */ /* Read type and payload length first */ hbtype = *p++; n2s(p, payload); pl = p; if (s-\u0026gt;msg_callback) s-\u0026gt;msg_callback(0, s-\u0026gt;version, TLS1_RT_HEARTBEAT, \u0026amp;s-\u0026gt;s3-\u0026gt;rrec.data[0], s-\u0026gt;s3-\u0026gt;rrec.length, s, s-\u0026gt;msg_callback_arg); if (hbtype == TLS1_HB_REQUEST) { unsigned char *buffer, *bp; int r; /* Allocate memory for the response, size is 1 bytes * message type, plus 2 bytes payload length, plus * payload, plus padding */ buffer = OPENSSL_malloc(1 + 2 + payload + padding); bp = buffer; /* Enter response type, length and copy payload */ *bp++ = TLS1_HB_RESPONSE; s2n(payload, bp); memcpy(bp, pl, payload); bp += payload; /* Random padding */ RAND_pseudo_bytes(bp, padding); r = ssl3_write_bytes(s, TLS1_RT_HEARTBEAT, buffer, 3 + payload + padding); ... }  Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/overflow/",
	"title": "Overflow",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Heart Bleed  CVE-2014-0160 OpenSSL 1.0.1f, Fixed in 1.0.1g tlsl_process_heartbeat() in t1_lib.c // 2553 int tls1_process_heartbeat(SSL *s){ unsigned char *p = \u0026amp;s-\u0026gt;s3-\u0026gt;rrec.data[0], *pl; unsigned short hbtype; unsigned int payload; unsigned int padding = 16; /* Use minimum padding */ /* Read type and payload length first */ hbtype = *p++; n2s(p, payload); pl = p; if (s-\u0026gt;msg_callback) s-\u0026gt;msg_callback(0, s-\u0026gt;version, TLS1_RT_HEARTBEAT, \u0026amp;s-\u0026gt;s3-\u0026gt;rrec.data[0], s-\u0026gt;s3-\u0026gt;rrec.length, s, s-\u0026gt;msg_callback_arg); if (hbtype == TLS1_HB_REQUEST) { unsigned char *buffer, *bp; int r; /* Allocate memory for the response, size is 1 bytes * message type, plus 2 bytes payload length, plus * payload, plus padding */ buffer = OPENSSL_malloc(1 + 2 + payload + padding); bp = buffer; /* Enter response type, length and copy payload */ *bp++ = TLS1_HB_RESPONSE; s2n(payload, bp); memcpy(bp, pl, payload); bp += payload; /* Random padding */ RAND_pseudo_bytes(bp, padding); r = ssl3_write_bytes(s, TLS1_RT_HEARTBEAT, buffer, 3 + payload + padding); .\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/bluespec/tlm/",
	"title": "TLM",
	"tags": [],
	"description": "",
	"content": "The TLM library package allows users to create bus-based protocol-independent designs. This package is provided as part of the Bluespec Foundation library, and is available to all users 1.\n  FoundationIP Lib ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/conf/edgeiot/",
	"title": "EdgeIoT",
	"tags": [],
	"description": "",
	"content": " Internet of Things, Edge Computing, Cloud Computing Conferences.\nTraditions Deadlines: conferences +/- 1 month\nJanuary- March:\nApril-June:\nJuly-September:\nOctober-December:\nUpcoming | Conference | Paper/notifcn | Date \u0026amp; Location | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; |\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | SEC\u0026rsquo;20 | May 29, 2020 | November 12-14, 2020 San Jose CA, USA | Ubicomp\u0026rsquo;21 | May 15, 2020\u0026frasl;8 weeks| | MobiCom\u0026rsquo;20 | Mar 07, 2020/ May 19, 2020| | Ubicomp\u0026rsquo;21 | Feb 15, 2020\u0026frasl;8 weeks| | ACMsocc\u0026rsquo;19 | Jun 03, 2019 | Nov 20-23, 2019. Chaminade, Santa Cruz, CA, USA\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Memory Management  Reference 1 Layout of FreeBSD process in memory and on disk: ![figure-3-3. Layout of FreeBSD process in memory and on disk] To begin execution of a binary file, kernel: Text portion of the binary is mapped into the low part of the process\u0026rsquo;s address space. (The first page of the address space is marked as invalid, so that attempts to read or write through a null pointer will fault) Initilized data portion of the file is mapped into the address space following the text.\n Dinosaur  Reference:  Real Time Operating System (Basics)  References: RTOS Fundamentals RTOS Fundamentals Reference: RTOS Fundamentals Multitasking Mutitasking can simply file the system design by partition complex application into smaller tasks easier testing, code reuse, task breakdown (better team collaboration), os dedicated for timing and sequencing. Scheduling Non real time: \u0026ldquo;fair\u0026rdquo; proportion of processor time among tasks; Real Time: Context Switching Context: processor registers, stack, etc. Real Time Applications Timely response to real world events; A priority to each task assigned by the developers; RTOS ensures that the highest priority task that is able to execute is the task given processing time; Real Time Scheduling Priority based scheduling.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-linkers-loaders/",
	"title": "Linkers Loaders",
	"tags": [],
	"description": "",
	"content": " References:\n Assemblers, Linkers, and Loaders, slides from Hakim Weatherspoon, Cornell, 2013. linkers and loaders, blog post. How to add a new target to LLD, slides from Peter Smith, Linaro, 2016.  a figure of calling dynamic libraries over PLT/GOT   Linker/Loader: binds more abstract names to more concrete names.\nExample:\ngetline \u0026ndash;\u0026gt; \u0026ldquo;the location 612 bytes from the beginning of the executable code in module iosys\u0026rdquo;.\n\u0026ldquo;the location 450 bytes beyond the beginning of the static data from this module\u0026rdquo; \u0026ndash;\u0026gt; numberic address.\nHistory of address binding Overlays by linker: different part of a program to share the same memory, with each overlay loaded on demand when another part of the program called into it.\nOverlays faded as virtual memory spreaded.\nAssembler Object file\n   section description     Header size and positions   Text Segment instructions   Data Segment static data: local/globals, strings, constants   Debugging Information line -\u0026gt; code   Symbol Table external (exported) \u0026amp; unresolve (imported) refs    objdump --disassemble/-d --syms/-t\nHandling forward references\n Can be in two passes.\n pass 1: scan whole program, allocate instructions and lay out data, determine addresses; pass 2: emitting instructions and data, with determined label offsets.  Can also in one pass:\n emitting instructions. Emit a 0 for jumps to labels not yet determined, keep track of where these instructions are; Backpatch. Fill in 0 offsets as labels are defined.   Handling external references\nOutput object files:\n binary machine code, but not executable may refer to external symbols each object has its own address space  Linkers: binding some symbols to a relative addresses inside a program;\nLoaders: binding symbols to actual address (non-relative).\nStatic Linker  Assign addresses to everything: determine the starting address of a subroutine and update all relative addresses. A linked excutable contains code to initialize memory prior to running a program: the subroutines all have addresses, the data all has addresses, the subroutines know about each other and the data they use, and there are instructions for the loader.  Dynamic linking Dynamic linking, or resolving an address for a procedure call can happen:\n upon program start. upon the procedure is called for the first time.  For shared libraries:\n when linking, linker does not link anything into the program, instead, it make a note in the output file the names of the libraries in which the symbols were found, so that when program is loaded, the shared libary can be bound in.   Loader Reads an executable and runs the program: setting up memory, as well as re-doing the linker\u0026rsquo;s job for some dynamic libraries.\nDynamic libararies are linked when you run the program instead of when you compile the program.\nLoaders can map a shared library into the same physical address but with different virtual addresses for different applications that use this library, to save physical memory space.\nRun-time loading: link the program to the loader itself and invoker loader\u0026rsquo;s \u0026ldquo;load this subroutine from this dynamic library\u0026rdquo; subroutine as it runs. The mechanics of such run-time loading are the same as execution-time loading. Benefit: can react to missing libs; Penalty: lib is not listed in the binary, thus hard to tell in advance what lib are needed. Common in Windows, almost universal in OS X, and unusual in Linux. Why???\n Linker Scripts  Reference SECTIONS Command Output Section description: section [address] [(type)] : [AT(lma)] [ALIGN(section_align) | ALIGN_WITH_INPUT] [SUBALIGN(subsection_align)] [constraint] { output-section-command output-section-command ... } [\u0026gt;region] [AT\u0026gt;lma_region] [:phdr :phdr ...] [=fillexp] [,] VMA and LMA Every section has a virtual memory address (VMA) and a load memory address (LMA), see baseic script concepts. The address in a linker script is virtual address (VMA). This address is optional, but if it is provided then the output address will be set exactly as specified.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-compart-papers/2010-capsicum/",
	"title": "Capsicum",
	"tags": [],
	"description": "",
	"content": "References:\n Capsicum: practical capabilities for UNIX\n Capsicum for Linux\n   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/smart-sep/2015-soaap/",
	"title": "2015 SOAAP",
	"tags": [],
	"description": "",
	"content": " Security-Oriented Analysis of Application Programs (SOAAP)[^c1].\n LLVM-based tool; uses source code annotations for compartmentalization hypotheses.  Able to help with:\n creating new compartmentalizations for complex applications; discover design faults in existing compartmentalized applications.  Challenges Reasoning about the compartmentalization tradeoffs is difficult:\n Information about past vulnerabilities is not easily accessible; Call graphs of compartmentalized applications are extremely complex; Simple control-flow analysis cannot follow manually encoded cross-domain actions \u0026ndash; such as those via IPC; reasoning about information flow; failures caused by compartmentalization are hard to debug and testing; performance impacts are difficult to predict and control.  Identifying a spot in the compartmentalization space is difficult:\n Knowing compartmentalization effects without implementation is difficult: performance, security.  This work:\n a security profiling tool, e.g. help to determine whether a particular compartmentalization was \u0026lsquo;worth it\u0026rsquo;. a security evaluation tool, e.g. ensure refactorings do not move vulnerable code to a more privileged context.  Contribution  framework: isolation + controlled communication; compart, spaces; design patterns; SOAAP: LLVM-based tool; annotated compart. hypotheses; Evaluation: OpenSSH, Chromium; fetch, Okular;  History of Compartmentalization Karger 1: access control, trojan horse, capability systems;\nProvos 2: OpenSSH; Kilpatrick 3: Chromium;\nCompartmentalization threat model:\n attackers gain total control of compromised compartments as a result of poorly crafted C code (or other program weaknesses) being exposed to malicious input; ADDED: software supplychain vulnerabilities involving explicitly trojaned software without the need for malicious input \u0026ndash; e.g., back doors.  Three Underpinnings  a strong TCB, able to protect compartmentalization itself; compartment isolation (implemented by TCB), provides strong prevention of interference between isolated program instances; controlled communication, allows safe communication between compartments \u0026ndash; subject to suitable policies;  Isolation:\nOS Process model + MMU; + access controls (chroot, Linux seccomp, SELinux, Mac OS X, Capsicum)\nWorkflow Boundaries by annotation Reusable/persistent sandbox:\n__soaap_sandbox_persistent(\u0026#34;dec2\u0026#34;) void dec2(int ifd, int ofd){ // secret key  char key[256]; read_stdin(\u0026#34;password\u0026#34;, key); // ...  char *tmp = tmp_file(); int tfd = open(tmp, O_RDWR); // ...  read(ifd, buffer, buffer_size); // ...  if(l_flag){ // list contents  // ...  }else{ // ... // decompress tmp to output file  } } // + annotate to create compartment at the start of main(), via fork() Data access analysis Sandbox access global variables -\u0026gt; report to human\nto allow, use __soaap_var_read(\u0026quot;dec2\u0026quot;) iint l_flag = 0;\n data consistency bug can be discovered. (such as l_flag being written after compartment is created.)  Information leak detection Annotate the private information:\nchar key[256] __soaap_private;\nSOAAP will detect if this can leak from any external library functions.\nDiscover privilege usage use platform descriptors to reason about sandbox restrictions.\n chroot() \u0026ndash;\u0026gt; allow all system calls\n seccomp \u0026ndash;\u0026gt; only read(), write(), sigreturn(), exit();\n file descriptors \u0026ndash;\u0026gt; Capsicum enforce capability on them;\n  SOAAP able to model Capsicum behavior.\nuse __soaap_fd_permit(read) to annotate the file descriptor to grant read permission.\nIncoperate known vulnerabilities Annotate the known CVE, SOAAP will evaluate the security risk (privileges being held by attackers) if got exploited.\n__soaap_vuln_pt(\u0026ldquo;CVE-xxx-xxxx\u0026rdquo;)\nData flow analysis may, must, flow sensitive, flow insensitive. different precisions.\ntracking sensitive data/file descriptors: define-use chains.\nSandbox sensitive: data-flow within sandbox and between sandbox are distinguished, even if they contain overlapping code.\nFunction call target: function pointers, polymorphism, in C/C++. Infer targets by tracking assignments, also explicit annotate callees.\nC++: AST \u0026amp; vtable in IR \u0026ndash;\u0026gt; class hierarchy analysis (CHA) \u0026ndash;\u0026gt; targets of virtual method call: all method definitions in the class hierachy rooted at the receiver object\u0026rsquo;s static type. (Receiver: callee object)\nEvaluation FreeBSD 10.1. Intel 4-core Xenon E5-1620 3.6GHz CPU, 64GB of RAM, 500GB SSD. Hyper-threading disabled. (?)\nUse Capsicum as sandboxing platform.\n Fetch in two parts: URL/HTTP header parsing; TLS via OpenSSL.\n URL parsing. Annotate fetchParseURL() with __soaap_sandbox_persistent; password filed in url struct with __soaap_classify.\n Networking\n code: fetch_c\n code: libfetch_c\n  Okular: 80KLoC separated + 4MLoC external libraries analyzed.\n modular structure with rendering plugins (renders) for each doc format; plugin interface as compartment boundary; code on [github]()  OpenSSH: maintance is hard for the style of separation in OpenSSH\n code: openssh 6.5 code: openssh-portable  Chromium: scalability of SOAAP is good.\n  Related work least privilege, Saltzer and Schroeder\u0026rsquo;s 1975 article, The Protection of Information in Computer Systems[^c38saltzer].\nprivilege separation. Trojan horse mitigation 1, Karger\u0026rsquo;s 1987 article. lays the conceptual groundwork for privilege separation.\nOpenSSH2, Kilpatrick\u0026rsquo;s Privman3\nUser-level application compartmentalization in Java 4, Chromium 5, Capsicum6. Focus on intra-application security concerns rather than system privileges.\nInterfaces between separated components. Cryptographic security APIs7,\ncompositional vulnerabilities among server and client sides of OpenSSL and JSSE. Beurdouche et al. 8\nAssisted compartmentalization Privtrans9, code oriented view, program annotation, dividing operation between privileged and unprivileged.\nWedge10, programmer provided memory type information.\nHarris et al.\u0026rsquo;s secure programming by parity games 11 reasons about the defense characteristics of Capsicum compartmentalization, representing policies as automata.\nprograms in modern browser architectures. In EuroSys ’09: Proceedings of the 4th ACM European Conference on Computer Systems (2009), ACM.\nand Schemers, R. Going beyond the sandbox: An overview of the new security architecture in the Java Development Kit 1.2. In Proceedings of the Symposium on Internet Technologies and Systems (1997), USENIX.\n  Karger, P. A. Limiting the damage potential of discretionary trojan horses. In Proceedings of the IEEE Symposium on Security and Privacy (1987), IEEE. ↩ Provos, N., Friedl, M., and Honeyman, P. Preventing privilege escalation. In Proceedings of the 12th USENIX Security Symposium (2003), USENIX. ↩ Kilpatrick, D. Privman: A Library for Partitioning Applications. In Proceedings of USENIX Annual Technical Conference (2003), USENIX. ↩ Gong, L., Mueller, M., Prafullchandra, H., ↩ Reis, C., and Gribble, S. D. Isolating web ↩ Watson, R. N. M., Anderson, J., Laurie, B., and Kennaway, K. Capsicum: Practical capabilities for UNIX. In Proceedings of the 19th USENIX Security Symposium (2010), USENIX. ↩ Anderson, R., Bond, M., Clulow, J., and Skorobogatov, S. Cryptographic processors-a survey. Proceedings of the IEEE 94, 2 (Feb 2006), 357–369. ↩ Beurdouche, B., Bhargavan, K., Delignat-Lavaud, A., Fournet, C., Kohlweiss, M., Pironti, A., Strub, P.-Y., and Zinzindohoue, J. K. A Messy State of the Union: Taming the Composite State Machines of TLS. In Proceedings of the IEEE Symposium on Security and Privacy (2015). ↩ Brumley, D., and Song, D. Privtrans: automatically partitioning programs for privilege separation. Usenix SP, 2014. ↩ Bittau, A., Marchenko, P., Handley, M., and Karp, B. Wedge: Splitting Applications into Reduced-Privilege Compartments. Usenix NSDI. 2008. ↩ Harris, W. R., Farley, B., Jha, S., and Reps, T. Secure Programming as a Parity Game. Tech. Rep. 1694, University of Wisconsin Madison, July 2011. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/papers/cspec/",
	"title": "CSpec",
	"tags": [],
	"description": "",
	"content": "Reference 1\n201901 note.\n  Verifying concurrent software using movers in CSPEC. OSDI, 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/iot/env/",
	"title": "How can IoT help us to save the planet?",
	"tags": [],
	"description": "",
	"content": " Rising Sea Level Fact: Sea-Level Report Cards and full report\nReference 1\n Artificial Leaves  Reference 12 \u0026lsquo;Artificial leaf\u0026rsquo; successfully produces clean gas ↩ Virgil Andrei , Bertrand Reuillard and Erwin Reisner. ‘Bias-free solar syngas production by integrating a molecular cobalt catalyst with perovskite-BiVO4 tandems.’ Nature Materials (2019). DOI: 10.1038/s41563-019-0501-6 ↩   Unresolved. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/seminars/ur/",
	"title": "Ur",
	"tags": [],
	"description": "",
	"content": " Seminars/Lectures\nDecember 02 Nathan Beckmann From CMU.\nPushing the limits of online and offline caching.\nMarry thery and practice\n computing tight bounds on OPT even when is NP-hard.  E.G. Mysql, cache can be 100x faster.\nCaches: Think smarter, not larger: a better cache policy. LRU, ++.\nCaching: theory questions; practical questions; online \u0026amp; offline policies. ==\u0026gt; an intersection of these.\nBeckmann, NSDI\u0026rsquo;18. LHD, AdaptSize, Hyperbolic, GDSF, LRU. Figure.\nCaches have performance Cliffs.\nLRU: cliffs. 31GB/32GB -\u0026gt; miss 100% until 32/32GB.\nTalus: random sampling.\nMetric: Hit density: (hit probability)/(expected lifetime)\nLeast Hit density eviction.\nOpen problems:\n metrics that really matters. object features.  OPT:\n if objects have different sizes, then NP-hard. (adapting (farach-colton and liberatore, \u0026lsquo;2000)) if writebacks cost \u0026gt; 0 , then Max-SNP-hard. (hard to approximate, reduction from hypergraph matching, )  OPT in practices:\nNP-hardness is \u0026lsquo;artificial\u0026rsquo;, and real traces are \u0026lsquo;easy\u0026rsquo;.\n==\u0026gt; FOO: computing OPT in real traces efficiently. Map LP to mini-cost flow.O(N^2log^2(N))\n==\u0026gt; PFOO: O(Nlog^2N)\n coupon collector problem.  Write back matters. Write-back aware caching.\nOPT: intractable, (not uncomputable).\nNov 18 Shaoshan Liu From PerceptIn\nR-CNN\nObject Tracking: MDP POMDP (deep learning)\nStereo (content CNN , ELAS) and Optical Flow (\u0026amp; FlowNet)\ntraffic prediction.\nlane routing\nbehavioral decisions: for neighbor vehicle.\nmotion planning. path planning.\nfeedback control.\nA heavyweight approach  A robust OS. Linux?WIndows? No. but A middleware that combines each component together.  -\u0026gt; Robotic OS. ROS: Topic and Topic.\n Problems of ROS:  not efficient: communication not secure: ? not scalable: central control node not reliable: crash   Cloud: spark* in autonomous driving\nHD Map: Raw data -\u0026gt; point cloud -\u0026gt; alignment -\u0026gt; 2d reflectance map -\u0026gt; HD Map labeling -\u0026gt; high precision map\n==\u0026gt; very expensive; e.g. Google map update once a year.\n\u0026ndash;\u0026gt; but we need update at least once a week. ==\u0026gt; who pays for it?\nProblem: heavyweight\nLightweight approach to automonous driving \u0026ndash;\u0026gt; we are doing  Computer vision based sensor fusion GNSS radar sonar Chasis  ** Edge computing\nEdge Client KITTI data set (but we still need benchmarks).\nRTOS -\u0026gt; VX QNX, space machines.\nMiddleware -\u0026gt; ROS: not stable.\n** Potential cyber attacks on Automated Vehicles. IEEE journal **\nBundle adjustment ROS replacement Nanomsg + ROS reimplementation\nnanomsg: 50% more performance.\nNov 15 Ruiqin Ruiqin: Value-set Analysis.\nCC\u0026rsquo;04.\nPage 10. Read examples.\nGive examples; what is a a-loc.\n\u0026ldquo;i don\u0026rsquo;t have a complete example\u0026rdquo; \u0026ndash; Sree\nMicheal:\nNov 01 Micheal locks: when application can fails, others cannot proceed.\n preemption at unexpected times; priority inversion;  Hardware primitives: for load and stores.\n compare and swap(a,e,n); load and store conditional; do load and tagged L1 cache; store when tag still valid;\n write with same old value. ==\u0026gt; CAS cannot fail; SC will fail.\n  A hardware swap: always a success; unconditional.\nsequential consistency: global visible way; but no hardware behaves that way;\n store release; load acquire;  ABA problem ABA problem: same address got freed and reallocated to the same address; but CAS regard as same before;\n counted pointers;  Correctness of non-blocking structures  safety: bad things never happen; e.g. dead-lock freedom; liveness: good things eventually happen; e.g. starvation problem.  dead-lock free is necessary for starvation free; but not sufficient.\nLinearizability (Herlihy \u0026amp; Wing 1987)\nExe hisotry H is linearizable, n threads, each sequential, exe in parallel; the result is the same as never overlapped (but different order is allowed).\nLinearization point: points that takes effect and visible to others;\nLiveness wait-free (starvation-free): there is a bound of instructions to finish; e.g. fetch_and_add based counter;\nlock-free (=livelock-free): a bounded number of instructions for others to finish; itself might be starved; e.g. CAS-based counter;\nobstruction-free (=merely nonblocking): my ops is guaranteed to complete in a bounded number of steps if I get to run all myself; external monitor/scheduler will take control if passed limited steps; e.g. deqeue of Herlihy.\nTreiber stack\nReplicated counter example: array of counters, one counter for each thread to update;\nscan array and add to total counts;\nBUT no static linearization point: the each count being added might not be exist simultaneously at any time point;\nMicheal \u0026amp; Scott queue [1996]\nA -\u0026gt; B -\u0026gt; D Insert C and delete B at same time; C got lost\nHarris\u0026rsquo;s insight: tag next pointer (D); lazy xxx using gc\nMicheal\u0026rsquo;s idea: no gc\nFavorate non-block data structure: Extensible hash table by S \u0026amp;Shavit\nOct 18 Jie Checked C compatible with legacy code.\nweb servers do not have much use of alloca/dealloca;\nuse after free: elevation from application to kernel. CVE examples.\nExisting works MMU page invalidate on free. (Adve: 2006 DSN, etc.) invalidating dangling: tracking point-to relations; (DangNULL; FreeSentry; DangSan) Dynamic checking on pointer dereference  Key-lock based dynamic checking: CETS @ ISMM\u0026rsquo;10 Tumstones.  Checked C solution Carry metadata with pointers: \u0026lsquo;safe-ptr\u0026rsquo; Time of Check to Time of Use: multi-threading: probabilistic use-after-free bugs.  retire immediately, but free it later.  Sep 27 from Wenhao Group  Tigris: 3D perception. Point Cloud. -\u0026gt; KD search. Energy efficient \u0026amp; real-time registration pipeline. Huge design space. Frontier points in design space. Bottleneck: KD-tree search. \u0026ndash;\u0026gt; optimize it. KD-tree search: sequential nature. \u0026ndash;\u0026gt; two-stage KD. \u0026ndash;\u0026gt; leaf nodes (unordered set, can be paralled). QLP: query level para; NLP: node-level para.  ??\nSep 20 ONR/Adve  machine learning to detect vulnerabilities in LLVM IR. Few millions of functions in BCDB.\n reduce code size improves security: in Geogia Tech. ROP/ret-libc/ Is less really more.\n SafeCode:\n TU overhead.\n Souper (Sclang)\n  Sandeep.\nX86-64 Semantics: formal user level\ngithb: kframework/ - 3155 instructions - 3135\u0026frasl;3736. - K framework. - BVL: 2016. Strata BVL Semantics.\n?- Chelly related work?\nONR:VENKMAN.\n Retpolines: jmp -\u0026gt; return: BTB -\u0026gt; RSB.\n BCDB: Bit code database; one module per function;\n software multiplexing:  Busybox: manually multiplexing Allmux: automatically, OOPSLA 2018   SoC mobile.\n  Binocular Depth sensing.\nKVell @ SOSP\u0026rsquo;19: CPU is bottleneck. ==\u0026gt; a new paradigm for persistent KVs to use new SSDs;\nLog-Structred merge tree: LSM. B Tree: good for read intensive load; in MongoDB\nSolution: multi-threading -\u0026gt; each thread for subset of keys.\nSep 13 Professors Intro Chen: Memory problems, Locality. - is there a difference of locality between languages? What is the best language to leverage/create best locality for algorithms.\nMicheal: - Persistent memory. Denser, cheaper, \u0026ndash;\u0026gt; fufuture: use pm to replace disk? - OS structure: fast devices, OS interaction, context switch expensive. - IO device direct with APP, but cannot be monitored by OS. - Communicate just enough to stay fair. Data structure - Hodor: shared library. PKU, MPK. - Move entire os to a library: libOS. - a wall in Rust and C for OS kernel;\nJohn: build systems that is resilient to attack. - harden it. - isolate malicious - security metrics - IskiOS, Silhouette, Apparition, PrivAnalyzer, - what is security: secure state defined by user.\nSandya: - The hardware-software interface - shared mem in hw and sw: DDCache. - adaptive cache granularity\nYuhao: - sw-hw co-design - point cloud, 2d, 3d, no images transfered, just point cloud.\nSree: - heterogenouts - domain specific langs - automate all the things - graph analytics - on CPUs? - accelerating general purpose data structures. - matrices. - Thur 3:30 - 5pm; 2506.\nAug 30 Isaac Sparse objects; a fast ccall or a traditional ccall; recognize the boundaries; encapsulate different data into same object type?\nContinuous data; but mini protection for code: legal ccall; but all other illegal jumps are allowed, but will trap.\nAug 30 Jie \u0026amp; Ethan Who is my audience, and what do I need to say in order to let them understand my research.\nSMAP: Supervisor Mode Access Prevention from Intel.\nEthan: reading notes; should control words condense.\nJuly 26 Edward: Yufei Du. ARM project. Silhouette.  Threat model Why do we need separate domains if only one application? C language for embedded system? Still true?  -O3 opt: caches. Why use O3?\n#July 19 Lele: CheriABI\nJuly 15, Xiaowan: efficient and protected address translation in memory management  in core: TLB, PTW, page table walker. Eurosys\u0026rsquo;16: sharing address translation info. \u0026ndash;\u0026gt; share them all: -\u0026gt; single address space.  sharing pagetable and TLB. android, zygote-preloaded shared lib; 88 to 107 shared lib loaded; used 24-68. instruction traces: 98% from shared; 70% from zygote; page traces: 46% pages from shared lib translation: 35% duplicate translation.  Android process model:  all are children of zygote  TLB: global bit, overwrites the ASID in TLB; primarily used for kernel pages.  zygote, set global bit to avoid kernel service to change shared lib: domain field.  domain protection model   zygote fork: x2.1 speedup application: launch: 10% exe: 38% fewer page faults. 35% fewer pt pages android ipc: last level TLB stall. reduced.\n super page promotion:\n for code: linux vs freebsd relaxing the policy of automatic superpage promotion. up to 8.5% memory consumption. sometimes can load large page, but most not used.  padding residual code:\n 18% improve   Side-channel attacks  os removed from TCB \u0026ndash;\u0026gt; still have side channel attacks. apparition page table side channel\n direct map: virtual - physicall for kernel to access. lazy allocation in malloc disabled.  last level cache side channel\n apparition VM, prevent OS from reconfiguring the cache partition.  bound check bypass attacks\n spectre separate addr space MPX SFI with lfence Bit masking sfi   July 12, Chen: timescale function  APF: allocation per fetch. lifetime: average time between two page faults.  Timescale functions:\n thread local reserve. central reserve. empty page pool.  sree: jemalloc.\nmemory reuse in a window.\nJune 28, 2019: MPK/PKU intra-address space isolation i/o op as libraries, out of kernel.\nHodor loader: assign key to diff domains.\n-challenge 1: pkru register mod instructions: not privileged. - sol; scan binary executable pages, undecidable, not disassemb. in loader. use debug registers: watch points: pkru instructions at runtime. 4 registers: 4 watch points: as the cache for illegal sequences. P15.\n use trampoline to switch between page tables.\n questions:\n the slow down of \u0026gt; 4 debug registers.\n how many isolated domains at maximum? \u0026gt; 16 domains\n how to avoid hijacking the trampoline? Not Atomic. A final check on registers.\n implicit pkru instructions?\n   Sandiya: use the 5 minutes QA to get yourself back to highlight your work.\nJun 21, 2019 PrivAnalyzer. bounded model checking: ROSA, in Maude (term rewriting logic). limit the number of times each process can call a sys call. INSECURE state? \u0026ndash; undecidable or not; DAC undecidable. \u0026ndash; number of system call the process can use. \u0026ndash;\nAutoPriv: Src \u0026ndash; static analysis\nChronoPriv: binary \u0026ndash; dyn priv analysis \u0026ndash; provides input to model checker. processes + privileges + user ids.\ncredentials?\nlinux privileges: permitted priv set effective priv set.\nEvaluation: /dev/mem, open r/w, priv port. send sigkill\n security analysis passed, ping, su, thttpd \u0026ndash; root has everything.\n solution:\n saved id has root different users for diff files, instead of all are root as owner.    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/constructive-logic/",
	"title": "Constructive Logic",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  CMU Undergraduate Class ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/closure/",
	"title": "Closure",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/lambda/lambda-lifting/",
	"title": "Lambda Lifting",
	"tags": [],
	"description": "",
	"content": " Reference [^wiki-lambda-lifting]\n1982 by Thomas Johnsson.\nrestructures a computer program so that functions are defined independently of each other in a global scope.\ntwo step process:\n eliminating free variables in the function by adding parameters; moving functions from a restricted scope to broader or global scope.  Different with Closure Conversion [^wiki-lambda-lifting] Lambda Lifting\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/lambda/",
	"title": "Lambda",
	"tags": [],
	"description": "",
	"content": " Reference 1\nLambda: Syntactically, lambda refers to a form for describing anonymous functions.\nBut a lambda does not become a function pointer.\nIt becomes a closure.\nClosures are data structures with both a code and a data component.\n Two strategies to compile lambdas into closures:\n Flat closures Linked (or shared) Closures  Closure Conversion: flat closure is top-down compilation; and linked(or shared) closure is bottom-up compilation.\n Lambda Lifting   Reference [^wiki-lambda-lifting] 1982 by Thomas Johnsson. restructures a computer program so that functions are defined independently of each other in a global scope. two step process: eliminating free variables in the function by adding parameters; moving functions from a restricted scope to broader or global scope. Different with Closure Conversion [^wiki-lambda-lifting] Lambda Lifting   Closure Conversion: How to compile lambda ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/",
	"title": "Langs",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Sequoia  Reference 1 http://web.stanford.edu/group/sequoia/ http://web.stanford.edu/group/sequoia/cgi-bin/ reference ↩  C \u0026amp; C\u0026#43;\u0026#43;   Reference 1 Copy Elision when return a struct. Mesh: Fragmentation in C/C\u0026#43;\u0026#43; Reference 1 MESH: Compacting Memory Management for C/C++ Applications, PLDI, 2019. ↩ reference ↩  NesC  Reference:  Go  Reference: Concurrency Setup Environment Variables Reference: GOPATH: environment variable that specifies the location of your workspace. If no GOPATH is set, it is assumed to be $HOME/go on Unix systems and %USERPROFILE%\\go on Windows. more Binary Package Download Getting Started with Go Build from Source Install Go from Source Uninstalling Go delete go directory. usually /usr/local/go under Unix or c:\\Go on Windows. remove Go bin directory from the $PATH environment variable.\n Rust  Reference: Oxide: The Essence of Rust Reference 1 at its heart lies a novel approach to ownership that balances type system expressively with usability. Rust integrates decades of programming languages research into a production system. Oxide: The Essence of Rust. 2019. ↩  Proof Carrying Code   Q\u0026amp;A What is the threat model in PCC? What if the proof and binary are changed at the same time by malicious compiler? PCC @ POPL\u0026rsquo;97 1, Necula Thesis\u0026rsquo;98 2. Proof-Carrying Code. George C. Necula. POPL, 1997. ↩ Compiling with Proofs. PhD thesis by George Ciprian Necula. 1998. ↩  Ada   References: reference More  C   References: reference Setjump/Longjump https://www.embecosm.com/appnotes/ean9/html/ch04s01s02.html https://developer.51cto.com/article/643833.html More   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-compart-papers/2018-reason-local/",
	"title": "Reasoning About a Machine with Local Capabilities: Provably Safe Stack and Return Pointer Management",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Reasoning About a Machine with Local Capabilities: Provably Safe Stack and Return Pointer Management. By Lau Skorstengaard, Dominique Devriese, and Lars Birkedal. ESOP 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/asm/mc-toll/",
	"title": "Mc Toll",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/pointer-ana/mlta/crix/",
	"title": "Crix: Detecting Missing-Check Bugs via Semantic- and Context-Aware Criticalness and Constraints Inferences",
	"tags": [],
	"description": "",
	"content": " Reference 1\nInter-procedural, semantic- and context-aware analysis.\nModeling and cross-checking of the semantics of conditional statements in the peer slices of critical variables infer their criticalness.\nUse criticalness to detect missing-check bugs.\n278 new missing-check bugs in Linux kernel that can cause security issues. 151 accepted by Linux maintainers.\nMissing Check Example /* Linux: net/smc/smc_ib.c */ static void smc_ib_remove_dev(struct ib_device *ibdev...) { struct smc_ib_device *smcibdev; /* ib_get_client_data may fail and return NULL */ smcibdev = ib_get_client_data(ibdev, \u0026amp;smc_ib_client); // ERROR1: NULL-pointer deference  list_del_init(\u0026amp;smcibdev-\u0026gt;list); /* ERROR2: device cannot be removed or unregistered */ smc_pnet_remove_by_ibdev(smcibdev); ib_unregister_event_handler(\u0026amp;smcibdev-\u0026gt;event_handler); /* ERROR3: memory leak */ kfree(smcibdev); /* No return value: caller cannot know the errors */ } From NVD: 59.5% stem from missing-check bugs; 52% (excluding DoS) of them will cause severe security impacts such as permission bypass, memory corruption, system crashes/hangs.\nExisting work Vanguard 2: detects only four specified critical operations such as arithmetical division and array indexing.\nChuncky3, Juxta4, Kremenek et al. 5, Dillig et al. 6.\n Manual specificatin of critical variables. cover only a small set of critical variables. \u0026ndash;\u0026gt; false negatives. Most are not semantic- or context-aware. E.g treating any if/switch statement as security check. Only by the variable\u0026rsquo;s semantics and context, should we reduce the false negatives and false positive.s  Challenges  critical variables take diverse forms. Can be a parameter, a global, a return value. Can and can not be used in arithmetic operations. identifying security checks requires semantic understanding. A variable in conditional statement does not necessarily mean the variable is security critical (70% not, see chapter 6), can also be normal selectors where all branches are normal execution. missing check bugs are context dependent. Eg. No need to check when var used in a debugging function. OS kernel is large. Checking every variable will not scale; corner cases such as hand-written assembly will make the analysis error-prone.  Crix  auto identify critical variables.  a two-layer type analysis to identify indirect-call targets. Function-type analysis in traditional CFI 7 8 9 + struct-type analysis 10. data flow analysis. Inter-procedural, flow-, context-, field-sensitive. identify security checked variables by automatic analysis.  peer slices that share similar semantics and contexts.  peer-slice construction to collect slices (code paths) of a critical variable that share similar semantics and contexts. For detection of missing checks.  model constraints.  Modeled constraints from the conditional statements and their semantics (e.g., the condition type). Semantic aware. Improves the precision of detection.  cross-checks the modeled constrain of the perr slices -\u0026gt; identifies deviations and reports. 804 cases found \u0026ndash;\u0026gt; manual confirmed 278 cases, patched, submitted to Linux \u0026ndash;\u0026gt; 151 accepted (134 applied + 17 confirmed).  General Techniques Two-layer type analysis for indirect-calls Similar to Ge et al.10.\n majority of taken addresses of functions are first stored to a function-pointer field of a struct. dereference of the addresses in indirect calls, they must be loaded from the struct. Function addresses that are never stored in the specific struct will not be valid targets of the indirect calls that load the function addresses from the struct.  ** 12% of function addresses in Linux kernel are not stored to struct. e.g. function pointer variable passed as an argument of another function: These does not have second layer struct-type, thus will not benefit from two-layer type matching. ==\u0026gt; falls back to one-layer.\n Field-sensitive: a struct may have multiple fields that hold function pointers. When offset is undecidable because indices are non-constant, we roll back the analysis to be field-insensitive.  Type-Escaping Analysis for False Negatives Escape: a function address stored to a different struct, say structB, can be loaded from memory with structA.\nIn this case, the function address will be missed by the type analysis because we cannot find that the function address is ever stored to structA but only structB.\nSuch escaping cases exist when:\n the struct holding the function addresses is cast to or from a different type; the function-pointer field of struct is stored to with a value of a different type (e.g. unsigned long).  ==\u0026gt; Crix: conservative: find all store and casts. When an escaped type is found, discard type during analysis, use only one-layer type analysis for this indirect call.\n==\u0026gt; two layer type analysis does not introduce extra false negatives to existing one-layer type analysis.\nComparison to Ge et al.10  elastic: can fall back to first-layer type analysis. escaping analysis: conservative to ensure soundness.  Critical-variable inference Identify Security Check by failure handling code pattern.\n Check failure pattern:  return error code, similar to LRSan11; calling an error-handling function.  In Linux, limited number of basic error-handling functions are critical functions and often in assembly: BUG(), panic(), dump_stack(), pr_err(), dev_err(); severity level: KERN_ERR, KERN_CRIT, KERN_EMERG. variable num of parameter. Detection is straightforward for a static analysis tool. Manually investigated the results and filter out false-positive cases: 531 error handling functions found.   security check by if statement:  one branch handles a check failure, and the other continues normal execution.   an if statement whose two branches both handle checking failures is not a security check.\nLRSan reports 131K security checks; CRIX reports 308K security checks.\nOnce security checks identified, the checked variables are regarded as critical variables.\nPeer-slice Source and Use Def and use in LLVM?\nFind Source (not exactly def):\nOnly for identified critical variables, do interprocedural backward data-flow analysis, to collect:\n Constants (such as error codes); Return values and parameters of certain functions: Input functions; assembly functions. Global variables. Others: when CRIX cannot find a predecessor instruction, the current values are marked as sources.  Find Use:\n Pointer dereference. Indexing in memory accesses. Binary operations. Function call parameter. None. if none of above, deem as no use. (diff with llvm def/use) common for error codes.  Construct Peer Slice Wiki: Program slicing\nNaive slice from use to source or source to use:\n path explosion 12. different semantic and contexts can make slice different and unrelated.  Goal of solution: for a source or use, need to construct its peer slices: should be sufficient to enable cross-checking; peer slices should share similar semantics and contexts.\nObservation: in a CFG: call and return often generate peer paths.\nE.G. a dispatcher indirect call: pad-\u0026gt;var-\u0026gt;reg()\n can target multiple semantically similar callee functions (e.g. adp5589_reg and adp5585_reg); arguments passed in by same caller: callee share similar contexts.  E.G. critical variable as parameter:\n direct calls to function: different callers to same callee: callee\u0026rsquo;s arguments are used as similar semantics in similar contexts.  Forward data-flow analysis: for each critical variable source:\n if indirect call take c.v. as paramter: collect all callees as a set of peer paths; if c.v. is returned or written to memory pointed to by an argument: collect callers as a set of peer paths; recursive until a use is found or propagation ends.  Backward data-flow analysis: for each use:\n if c.v. comes from an argument of the current function: all callers are collected as peer paths; recursive until a source is found.  Slicing peer paths:\n Slicing ends at a conditional statement or the end of the path. ==\u0026gt; each slice has at most one conditional statement.  Four classes of slices:\n Source-Ret: c.v. is returned as return value to multiple peer callers. Source-Param: c.v. is returned as output to peer callers. Source-Arg: c.v. is passed to peer callees through an indirect call. Use-Param: c.v. is passed in from peer callers.  Cross-Checking Check Constraints   Usenix Security, 2019. ↩ L. Situ, L. Wang, Y. Liu, B. Mao, and X. Li. Vanguard: Detecting missing checks for prognosing potential vulnerabilities. In Proceedings of the Tenth Asia-Pacific Symposium on Internetware, page 5. ACM, 2018. ↩ F. Yamaguchi, C. Wressnegger, H. Gascon, and K. Rieck. Chucky: Exposing missing checks in source code for vulnerability discovery. In Proceedings of the 2013 ACM SIGSAC conference on Computer \u0026amp; communications security, pages 499–510. ACM, 2013. ↩ C. Min, S. Kashyap, B. Lee, C. Song, and T. Kim. Cross-checking semantic correctness: The case of finding file system bugs. In Proceedings of the 25th ACM Symposium on Operating Systems Principles (SOSP), Monterey, CA, Oct. 2015. ↩ T. Kremenek, P. Twohey, G. Back, A. Ng, and D. Engler. From uncertainty to belief: Inferring the specification within. In Proceedings of the 7th Symposium on Operating Systems Design and Implementation, OSDI ’06, 2006. ↩ I. Dillig, T. Dillig, and A. Aiken. Static error detection using semantic inconsistency inference. In Proceedings of the 2007 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), San Diego, CA, June 2007. ↩ ↩ ↩ ↩ ↩ W. Wang, K. Lu, and P. Yew. Check It Again: Detecting Lacking-Recheck Bugs in OS Kernels. In Proceedings of the 25th ACM Conference on Computer and Communications Security (CCS), Toronto, ON,Canada, Oct. 2018. ↩ J. Jaffar, V. Murali, J. A. Navas, and A. E. Santosa. Path-sensitive backward slicing. In International Static Analysis Symposium, pages 231–247. Springer, 2012. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/class-pldi/concurrent-langs/",
	"title": "Concurrent Langs",
	"tags": [],
	"description": "",
	"content": "Reference 1\nWidely used parallel programming systems:\n    Shared Memory Message Passing Distributed Computing     Language Java, C#     Extension OpenMP  Remote Procedure Call   Library pthreads, Win32 threads MPI Internet libraries    Library augmentation for legacy languages still dominate today.\nWhile the library approach requires no changes to the syntax of languages that use it, compilers must refrain from performing optimizations that may introduce races into programs with multiple threads.\nIn comparision to libaray packages, an explicitly concurrent programming language has the advantage of compiler support. It can make use of syntax other than subroutine calls, and can integrate communication and thread management more tightly with such concepts as type checking, scoping, and exceptions.\nAt the same time, since most programs have historically been sequential, concurrent languages have been slow to gain widespread acceptance, particularly given that the presence of concurrent feature can sometime make the sequential case more difficult to understand.\nLLM: the three design patterna should also be applicable to securiy solution designs: do we need new language, new library, or language extension? I vote new language in the long term, new library for short term compatibility, and new language extension as buffer-period solution. Compiler-awared security engineering plays an important part here.\n  Pragmatics, 3rd Ed. Chapter 12. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/rings/",
	"title": "Rings",
	"tags": [],
	"description": "",
	"content": "Reference 1\n(From v7 2.3.14) Use of privileged features within privileged rings, depends on the program-counter capability having a suitable hardware permission set, rather than the traditional permissions in virtual memory as the supervisor.\nThis feature allows code within kernels, microkernels, and hypervisors to be compartmentalized, preventing bypass of the capability model within the kernel virtual address space through control of virtual memory features.\nThe feature also allows vulnerability mitigation by allowing only explicit use of privileged features: kernel code can be compiled and linked so that most code executes with a program-counter capability that does not authorize use of privilege, and only by jumping to selected program-counter capabilities can that privilege be exercised, preventing accidental use.\nFinally, this feature paves the way for process and object models in which the capability model is used without resource to rings.\n  CHERI ISAv7. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mc/",
	"title": "The `MC` Layer in LLVM",
	"tags": [],
	"description": "",
	"content": " Q \u0026amp; A  Where is the symbol table section being composed and written to the object file?  References:\n llvm-mc\n LLVM the x86 disassembler\n LLVM CodeGen\n  The LLVM MC Project This section is mostly from: llvm-mc, with partial info from LLVM CodeGen.\n Instruction Printer.  MCInstPrint: MCInst -\u0026gt; textual representation. Not aware of sections/directives, so independent of object file format. A new lowering pass: MachineInstr -\u0026gt; MCInst.  Instruction Encoder.  MCCodeEmitter: MCInst -\u0026gt; bytes \u0026amp; relocations. Same lowering code as MachineInstr -\u0026gt; MCInst.  Instruction Parser.  TargetAsmParser: parse .s file. lexer is largely shared/reused code. parser is all target-specific. Via Opcode \u0026amp; operand matching to determine concrete instruction. more abstract-than-MCInst.  Instruction Decoder.  MCDisassembler: turns an abstract series of bytes (implemented with the MemoryObject API, to handle remote disassembly) into MCInst and a size.  Assembly Parser.\n MCStreamer interface: take MemoryBuffer object as input. handle all the directives and other gunk that is in an .s file but not an instruction.  MCStreamer. an assembler API.\n one virtual method per directive, such as  EmitLable, EmtSymbolAttribute, SwitchSection, EmitValue, for .byte, .word EmitInstruction, output an MCInst to the streamer.  One implementation by MCAsmStreamer assembly printer.  This implements support for printing to .s file. It uses Instruction Printer to format the MCInsts. It simply prints out a directive for each method (e.g. EmitValue -\u0026gt; .byte).  Another implementation by MCObjectStreamer (or `)  writes out a .o file. It implements a full assembler.  For target specific directives, the MCStreamer has a MCTargetStreamer class instance.  Each target that needs it defines a class FooTargetStreamer that inherits from this MCTargetStreamer and is a lot like MCStreamer itself. it will have one method per directive, and two classes that inherit from FooTargetStreamer:  FooTargetAsmStreamer : public FooTargetStreamer: a target asm streamer just prints it (emitFnStart -\u0026gt; .fnstart), and FooTargetELFStreamer : public FooTargetStreamer: the object streamer implements the assembler logic for it.  see code here   Assembler Backend.\n Compiler Integration.\n Compiler backend now invokes the same MCStreamer interface to emit code; can read code back with the asmparser and results in the same MCStreamer calls as when the code generator directly invokes them.  Classes: MCInst, MCSymbol (a label in .s), MCSection, MCExpr.\n Usage 01: disassembler library\n llvm/include/llvm-c/Disassembler.h  Usage 02: standalone assembler\n Usage 03: Compiler-integrated assembler\n Compiler -\u0026gt; MCStreamer -\u0026gt; MCInsts -\u0026gt; assembler backend. inline assembly: a new temporary assembly parser to handle the inline asm, and talk with MCStreamer instance.   To Add a new Target in MC Reference\n add a subclass of AsmPrinter for your target, converting MachineFunctions into MC label constructs.  For ELF, COFF, or MachO target, many reusable functions available, defined in TargetLoweringObjectFile class.  add a instruction printer for your target. Converts MCInst to your ISA instruction as raw_ostream text.  Most of this is automatically generated from the .td file (when you specify something like add $dst, $src1, $src2 in the file), but you need to implement routines to print operands.  add code to lower MachineInstr to an MCInst.  ususally implemented in \u0026lt;Target\u0026gt;MCInstLower.cpp. responsible for translating into corresponding MCLabels from:  jump table entries constant pool indices global variable addresses  responsible for expanding pseudo ops used by the code generator into the actual machine instructions. The MCInst then is fed into the instruction printer or encoder.  Optionally, add a subclass of MCCodeEmitter, to lower MCInsts into machine code bytes and relocations.  This is important if you want to support direct .o file emission, or would like to implement an assembler for your target.   Emitting function stack size information Reference\nA section containing metadata on functino stack sizes will be emitted when TargetLoweringObjectFile::StackSizeSection is not null and TargetOptions::EmitSstackSizeSection is set (via -stack-size-section).\nThe section will contain an array of pairs of function symbol values (pointer size) and stack size (unsigned LEB128). The stack size values only include the space allocated in the function prologue. Functions with dynamic stack allocations are not included.\nHandling Sections Reference: The LLVM Target-Independent Code Generator\nMCStreamer API that can be implemented to output an ELF .o file (or .s file, etc). Its API correspond directly to what you see in a .s file.\nThe MCContext class: the owener of a variety of uniqued data structures at the MC Layer, including symbols, sections, etc.\nThe MCSymbol class: represents a symbol (aka label) in the assembly file. Created by MCContext and uniqued there. Can be compared for pointer equivalence to find out if they are the same symbol. (But pointer equivalence does not mean two label will end up in two differen address; since two different label can be used to point to the same address). Two kinds of symbols:\n assembler temporary symbols. These are used and processed by the assembler but are discarded when the object file is produced.  Usually distincted by adding a prefix to the lable, for example L labels in MachO.  normal symbols.  The MCSection class. It represents an object-file specific section.\n It is subclassed by object file specific implementations: MCSectionMachO, MCSectionCOFF, MCSectionELF) and these are created and uniqued by MCContext. MCStreamer has a notion of current section SectionStack.back().first or MCSectionSubPair(), which can be changed via SwitchToSection() method (which corresponds to a .section directive in a .s file). See more .section directive  The MCInst class. A target-independent representation of an instruction.\n Elf Writer  References: reference // class .member struct ELFWriter{ ELFObjectWriter \u0026amp;OWriter; } // parent --\u0026gt; child MCObjectWriter -\u0026gt; ELFObjectWriter States: ELFObjectWriter \u0026amp;OWriter support::endian::Writer W. An adapter to write values to a stream in a particular byte order. unsigned LastLocalSymbolIndex. This holds the symbol table index of the last local symbol. unsigned StringTableIndex. This holds the .strtab section index. unsigned SymbolTableIndex. This holds the .symtabl section index. std::vector\u0026lt;const MCSectionELF *\u0026gt; SectionTable.\n New Section  Reference reference To emit a new section, e.g. .newsection, to an object (ELF) file: add an option to clang to enable options. need to pass option from clang frontend to backend. Option finally goes to TargetOptions::EmitNewSection Option access in different classes: via TargetMachine instance: TM.Options.EmitNewSection Can be used in AsmPrinter, etc. via MachineFunction instance: MF.getTarget().Options.EmitNewSection update AsmPrinter class in LLVM CodeGen to emit the new section.\n Asm Printer  Reference reference llvm/include/llvm/CodeGen/AsmPrinter.h llvm/lib/CodeGen/AsmPrinter/AsmPrinter.cpp AsmPrinter is a pass at MachineFunction level: class AsmPrinter : public MachineFunctionPass. It acts as a driver for the MC layer streamers. It defines the MachineFunction pass that calls OutStreamer-\u0026gt;emitXXX() to emit all the stuff to the binary or assembly files. The (misnamed) target-independent AsmPrinter class implements the general lowering process converting MachineFunction\u0026rsquo;s into MC label constructs. target-specific subclasses of AsmPrinter, such as SparcAsmPrinter, MipsAsmPrinter target specific functions such as emitFunctionBodyStart()/End() Additionally, for other code generation other than MachineFunction labels:\n Mc Assembler  Reference reference // lib/MC/MCAssembler.cpp bool MCAssembler::registerSection(MCSection \u0026amp;Section) { if (Section.isRegistered()) return false; Sections.push_back(\u0026amp;Section); Section.setIsRegistered(true); return true; } // include/llvm/MC/MCAssembler.h /// \\name Section List Access /// @{ iterator begin() { return Sections.begin(); } const_iterator begin() const { return Sections.begin(); } iterator end() { return Sections.end(); } const_iterator end() const { return Sections.end(); } size_t size() const { return Sections.size(); }  MCContext  Reference include/llvm/MC/MCContext.h lib/MC/MCContext.cpp Context object for machine code objects. This class owns all the sections that it creates. MCSectionELF *MCContext::getELFSection() Search ELFUniquingMap return if hit create new section using createELFSectionImp() if miss. MCSectionELF *MCContext::createELFSectionImpl() get existing or create a new MCSymbolELF *R set binding ELF::STB_LOCAL set type ELF::STT_SECTION create a new MCSectionELF *Ret create new MCDataFragment() *F insert F to Ret-\u0026gt;getFragmentList() F-\u0026gt;setParent(Ret) R-\u0026gt;setFragment(F) return R, the MCSectionELF  Object File  Reference LLVM Source code Parent -\u0026gt; Child: MCObjectFileInfo -\u0026gt; TargetLoweringObjectFile -\u0026gt; TargetLoweringObjectFileELF -\u0026gt; MipsTargetObjectFile MCObjectFileInfo SourceCode of class MCObjectFileInfo llvm/MC/MCObjectFileInfo.h llvm/lib/MC/MCObjectFileInfo.cpp States: MCSection *TextSection, *DataSection, *BSSSection MCSection *ReadOnlySection. Not required. MCSection *LSDASection. Section of Language Specific Data Area (LSDA). To support languages with exception handling. DWARF sections DwarfLineSection DwarfLineStrSection DwarfStrSection \u0026hellip; Sections Initialization Initialized in function MCObjectFileInfo::initELFMCObjectFileInfo(const Triple \u0026amp;T, bool Large). code // lib/MC/MCObjectFileInfo.\n MCStreamer  References: LLVM MCStreamer Class Reference llvm/include/llvm/MCStreamer.h llvm/lib/MC/MCStreamer.cpp MCStreamer class is an abstract API that is implemented in different ways (e.g. to output a .s file, output an ELF .o file, etc). It is effectively an “assembler API”. MCStreamer has one method per directive, such as EmitLabel, EmitSymbolAttribute, SwitchSection, etc, which directly correspond to assembly level directives. Two implementations of MCStreamer: MCAsmStreamer is a straightforward impl that prints out a directive for each method.\n ELF (LLVM Side)  ELF Basics llvm-objcopy: object copy and editing tool Relocation wiki Object File Editing llvm-objcopy [options] input [output]: --add-section \u0026lt;section=file\u0026gt;, add a section named \u0026lt;section\u0026gt; with the content of \u0026lt;file\u0026gt; to the output. --dump-section \u0026lt;section\u0026gt;=\u0026lt;file\u0026gt;, dump the content of section \u0026lt;section\u0026gt; into the file \u0026lt;file\u0026gt; --discard-all, -x, remove most local symbols from the output. ELF Section Flags // include/llvm/BinaryFormat/ELF.h // Section flags. enum : unsigned { // Section data should be writable during execution.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/pointer-ana/mlta/read/",
	"title": "Read",
	"tags": [],
	"description": "",
	"content": "Reference 1\nGraph in GlobalContext:\n// file: // crix/analyzer/src/lib/Analyzer.h  typedef DenseMap\u0026lt;Function*, CallInstSet\u0026gt; CallerMap; typedef DenseMap\u0026lt;CallInst *, FuncSet\u0026gt; CalleeMap; struct GlobalContext { // ... \t// Map a callsite to all potential callee functions. \tCalleeMap Callees; // Map a function to all potential caller instructions. \tCallerMap Callers; // ... }    Github ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/pointer-ana/mlta/",
	"title": "Multi-layer Type Analysis",
	"tags": [],
	"description": "",
	"content": " Reference 1\nC++ and Casting Pointer to virtual function tables is frequently cast to general types such as char*, rendering the type match ineffective.\nMLTA: a mechanism to precisely connect VTables to the corresponding classes and to keep track of class casting.\nSimilar work 2 3: a virtual function call can only invoke the virtual functions implemented in the current class or its derived class, but not others. Use an expanded single-layer type for finding targets.\nMLTA outperforms them:\n when an object pointer is recursively stored into an object of a different class; precisely tracks type casting.  ==\u0026gt; virtual functions of a derived class become valid icall targets of a base class only when an actual cast exists.\nLLM: why only when an actual cast exists? Will it improve the precision? does it mean if function not called, then MLTA will not include into CFG but other will?\nFormal proof Goal: no more false negatives than FLTA (first-layer type analysis).\nAssembly code Chapter 8: Supporting MLTA in assembly or binary is out of the scope of this work.\n Crix: Detecting Missing-Check Bugs via Semantic- and Context-Aware Criticalness and Constraints Inferences  Reference 1 Inter-procedural, semantic- and context-aware analysis. Modeling and cross-checking of the semantics of conditional statements in the peer slices of critical variables infer their criticalness. Use criticalness to detect missing-check bugs. 278 new missing-check bugs in Linux kernel that can cause security issues. 151 accepted by Linux maintainers. Missing Check Example /* Linux: net/smc/smc_ib.c */ static void smc_ib_remove_dev(struct ib_device *ibdev...) { struct smc_ib_device *smcibdev; /* ib_get_client_data may fail and return NULL */ smcibdev = ib_get_client_data(ibdev, \u0026amp;smc_ib_client); // ERROR1: NULL-pointer deference list_del_init(\u0026amp;smcibdev-\u0026gt;list); /* ERROR2: device cannot be removed or unregistered */ smc_pnet_remove_by_ibdev(smcibdev); ib_unregister_event_handler(\u0026amp;smcibdev-\u0026gt;event_handler); /* ERROR3: memory leak */ kfree(smcibdev); /* No return value: caller cannot know the errors */ } From NVD: 59.\n Read  Reference 1 Graph in GlobalContext: // file: // crix/analyzer/src/lib/Analyzer.h typedef DenseMap\u0026lt;Function*, CallInstSet\u0026gt; CallerMap; typedef DenseMap\u0026lt;CallInst *, FuncSet\u0026gt; CalleeMap; struct GlobalContext { // ... // Map a callsite to all potential callee functions. CalleeMap Callees; // Map a function to all potential caller instructions. CallerMap Callers; // ... } Github ↩   Where Does it Go? Refining Indirect-Call Targets with Multi-layer Type Analysis. By Kangjie Lu, Hong Hu. CCS (Best Paper). 2019. ↩ SafeDispatch: Securing C++ Virtual Calls from Memory Corruption Attacks. By D. Jang, Z. Tatlock, and S. Lerner. In Proceedings of the 2014 Annual Network and Distributed System Security Symposium (NDSS), San Diego, CA, Feb. 2014. ↩ VTrust: Regaining Trust on Virtual Calls. C. Zhang, D. Song, S. A. Carr, M. Payer, T. Li, Y. Ding, and C. Song. In Proceedings of the 2016 Annual Network andDistributed System Security Symposium (NDSS), San Diego, CA, Feb. 2016. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/deep/",
	"title": "Deep Learning",
	"tags": [],
	"description": "",
	"content": " Top Wondering  Besides deep learning, many other solutions exists for computers to discover informal knowledge by itself. How many do we know and how they are catergorized?\n Until now, is there any new knowledge have been discovered by deep learning?\n Ones in traditional style: any new mathematical/physical theories discovered yet? Ones in non-traditional style?  For image-processing based AIs such as object detection: is the image a good source for feature extracting? (It works for human but we know it is not optimal since our eyes and brain usually make mistakes on this) Is there any other sources we can get more useful features for the same purpose?\n There must be some other form of information media be used together with images to finish a trustworthy task.  In which way does Deep Neural Network looks similar to human Brain?\n multi-level inter-connected neuron networks. neurons contain information.  In which way DNN does not works similar to human brain?\n we don\u0026rsquo;t know how brain train itself inside. Hidden network in DNN is one of guess that works. Brain has an area for comparison and pattern matching[cite?]. DNN does not explicitly have one. Brain can learn to recognize a cat with \u0026lt;10 times of training with just 1 cat. It will be able to recognize more cats, even ones it has never seen (a correct guess).   Q\u0026amp;A  What are the algorithms in deep learning?\n How much cost to train a neural network?\n can be very expensive: To train a model, can cost 5x the carbin footprint of a car over its lifetime1.   What is neural network?   Gradient Descent   Backpropagation   Backpropagation calculus\n  More Contents  Intro: Artificial Intelligence and Deep Learning  Reference 1 Artificial Intelligence Early stage of AI: problems can be described by a list of formal, mathematical rules: Relatively easy for computers but hard for humans. Now Challenging Task: that are easy for people to perform but hard for people to describe formally. ==\u0026gt; LLM: but not impossible to describe formally, yes??? Deep Learning: a solution to solve tasks that easy for people but hard to describe formally. This\n Horovod  References: Meet Horovod: Uber’s Open Source Distributed Deep Learning Framework for TensorFlow Motivation Problems in the standard distributed TensorFlow technique: not always clear which code modifications needed to be made to distribute the model training code; Many new concepts introduced hard-to-diagnose bugs that slowed training. The standard distributed TensorFlow package introduces many new concepts: workers, parameter servers, tf.Server(), tf.ClusterSpec(), tf.train.SyncReplicasOptimizer(), and tf.train.replicas_device_setter() to name a few.\n Distributed  References: reference More 2018 Horovod References: Horovod: fast and easy distributed deep learning in TensorFlow. code Overview Uber: deep learning for self-driving, trip forecasting, fraud prevention. Michelangelo[c3], an internal ML-as-a-service platform, deploying ML systems at scale. Horovod, an open-source component of Michelangelo\u0026rsquo;s deep learning toolkit which makes it easier to start \u0026ndash; and speed up \u0026ndash; distributed deep learning projects with TensorFlow. Motivation As datasets grew, so did the training times, which sometimes took a week or longer to complete.\n 6s191  Q\u0026amp;A How many ways to split training process into multiple steps, where each step can be done at different place. Reference 1 Intro - Perceptron Perceptron, 1985. Activation Functions: non-linearity two input, 1 output. multi output. Traning init weight. \u0026ndash;\u0026gt; wrong prediction \u0026ndash;\u0026gt; big loss multiple data \u0026ndash;\u0026gt; loss of all predictions Loss function Binary Cross Entropy Loss: for output to be 0 or 1. Mean Squared Error Loss: for\n Fedarated DLearning   Q\u0026amp;A/Top Wonderings/Todones Can docker migration assist the fedarated learning? Reference 1 reference ↩  Tensorflow   Q\u0026amp;A What is tensor? see tensors Reference 1 TensorFlow Tensors ↩   Energy and Policy Considerations for Deep Learning in NLP. arXiv, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/pointer-ana/andersen/",
	"title": "Andersen",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/pointer-ana/steensgaard/",
	"title": "Steensgaard",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/mir/",
	"title": "Machine IR",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How does it handle .got addressing?  References:\n Machine IR Language Reference Welcome to the back end: the LLVM Machine Representation  Tasks for LLVM Machine Representation:\n Resource Allocation: registers, stack space, \u0026hellip; Lowering: ABI, Exception Handling, Debug Info, \u0026hellip; Optimization: Peephole, Instruction/Block Scheduling, ..  Basics Pass Manage Setup Pass manager pipeline is setup in TargetPassConfig.\n Target overrides methods to add, remove or replace passes. There is also insertPass and subtitutePass.  MachineInstruction  class MachineInstruction MI Opcode Pointer to Machine Basic Block Operand Array; Memory Operand Array Debugging Location  Operands  class MachineOperand MOP Register, RegisterMask Immediates Indexes: Frame, ConstantPool, Target\u0026hellip; Addresses: ExternalSymbol, BlockAddress, \u0026hellip; Predicate, Metadata, \u0026hellip;  Instruction Description  class MCInstrDesc: Opcode/Instruction Description Describes operands types, register classes Flags describing instruction:  Format Semantic Filter for target callbacks Side Effects Transformation Hints/Constraints   Basic Blocks  class MachineBasicBlock (MBB) double linked list of instructions ??? Pointer to Machine Function and IR Basic Block  Functions  class MachineFunction (MF) Double linked list of basic blocks Poniters to IR Function, TargetMachine, TargetSubtargetInfo, MCContext, \u0026hellip; State: MachineRegisterInfo, MachineFrameInfo, MachineConstantPool, MachineJumpTableInfo, \u0026hellip;  MachineConstantPool Register Allocation Physical Registers  MachineRegisterInfo maintains list of uses and definitions per register.  Virtual Registers  MachineRegisterInfo  differentiate virtual/physical: .isVirtualRegister(Reg), .isPhysicalRegister(Reg) Register == 0: no register used.   Prolog Epilog Insertion Pass  Setup call frames, setup stack frame Save/Restore callee saved registers Resolve frame indexes Register scavenging  TargetFrameLowering class\nclassTargetFrameLowering { // ...  /// emitProlog/emitEpilog - These methods insert prolog and epilog code into  /// the function.  virtual void emitPrologue(MachineFunction \u0026amp;MF, MachineBasicBlock \u0026amp;MBB) const = 0; virtual void emitEpilogue(MachineFunction \u0026amp;MF, MachineBasicBlock \u0026amp;MBB) const = 0; virtual void determineCalleeSaves(MachineFunction \u0026amp;MF, BitVector /*...*/); virtual void processFunctionBeforeFrameFinalized(MachineFunction /*...*/); }   MachineFunctionPass  References: llvm/lib/CodeGen/MachineFunctionPass.cpp llvm/include/llvm/CodeGen/MachineFunctionPass.h Pass definition and creation /// MachineFunctionPass - This class adapts the FunctionPass interface to /// allow convenient creation of passes that operate on the MachineFunction /// representation. Instead of overriding runOnFunction, subclasses /// override runOnMachineFunction. classMachineFunctionPass : public FunctionPass { public: bool doInitialization(Module\u0026amp;) override { // Cache the properties info at module-init time so we don\u0026#39;t have to // construct them for every function.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/basics/reach-def/",
	"title": "Reaching Def",
	"tags": [],
	"description": "",
	"content": "Reference 1\nReaching Definition Analysis, (reaching assignment analysis):\nAn assignment (called a definition in classical literature) of the form $[x:=a]^l$ may reach a certain program point (typically the entry or exit of an elementary block) if there is an execution of the program where $x$ was last assigned a value at $l$ when the program point is reached.\nFor example, for the factorial program below:\n$[y:=x]^1; [z:=1]^2; while [y\u0026gt;1]^3 do ([z:=z*y]^4; [y:=y-1]^5); [y:=0]^6$\nwe have the following reaching definition analysis result:\n$[y:=x]^1$, or $(y,1)$, reaches the program point 2-6.\n  PPA. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/2019ccs-layer-type/",
	"title": "2019CCS Multi-Layer Type Analysis",
	"tags": [],
	"description": "",
	"content": " Reference 1\nGeorgiaTech SS Lab: https://gts3.org/pages/projects.html\n System software commonly uses indirect calls to realize dynamic program behaviors. However, indirect-calls also bring challenges to constructing a precise control-flow graph that is a standard prerequisite for many static program-analysis and system-hardening techniques. Unfortunately, indentifying indirect-call targets is a hard problem. In particular, modern compilers do not identify indirect-call targets by default. Existing approaches identify indirect-call targets based on type analysis that matches the type of function pointers and the ones of address-taken functions. Such approaches, however, suffer from hight false-positive rate as many irrelevant functions may share the same types.\n MLTA: Multi-Layer Type Analysis.\n function pointers are commonly stored into objects whose types have a multi-layer type hierarchy. ==\u0026gt; By matching the multi-layer types of function pointers and functions, MLTA can dramatically refine indirect-call targets.  MLTA implementation: TYPEDIVE, based on LLVM.\nEvaluation  LLVM 8.0 FreeBSD 12.0, Linux 5.1.0, Firefox. -O0 -g -fno-inlining  ![reduction of icall targets]()\nCollecting Traces  Intel PT QEMU    Where Does It Go? Refining Indirect-Call Targets with Multi-Layer Type Analysis. Kangjie Lu, Hong Hu. CCS 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/reg-alloc/",
	"title": "Reg Alloc",
	"tags": [],
	"description": "",
	"content": "Reference 1\nhttps://web.stanford.edu/class/archive/cs/cs143/cs143.1128/lectures/17/Slides17.pdf\nSilhouette:\n https://github.com/jzhou76/Silhouette/blob/silhouette_llvm9/lib/Target/ARM/ARMSilhouetteLabelCFI.cpp#L59\n https://github.com/jzhou76/Silhouette/blob/silhouette_llvm9/lib/Target/ARM/ARMSilhouetteSFI.cpp#L148\n https://github.com/jzhou76/Silhouette/blob/silhouette_llvm9/lib/Target/ARM/ARMSilhouetteSTR2STRT.cpp#L65\n    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/sequoia/",
	"title": "Sequoia",
	"tags": [],
	"description": "",
	"content": "Reference 1\nhttp://web.stanford.edu/group/sequoia/\nhttp://web.stanford.edu/group/sequoia/cgi-bin/\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-inst-iso/2017-dac-arm-inst-iso/",
	"title": "Arm Inst Iso",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Instruction-Level Data Isolation for the Kernel on ARM. DAC\u0026rsquo;17. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-inst-iso/",
	"title": "Isolation at instruction level",
	"tags": [],
	"description": "",
	"content": "Reference [^1]\nUserspace store/load on ARM.\n Arm Inst Iso  Reference 1 Instruction-Level Data Isolation for the Kernel on ARM. DAC\u0026rsquo;17. ↩  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/asm/remill/",
	"title": "Remill",
	"tags": [],
	"description": "",
	"content": "Reference 1\nTo add new instructions to Remill: https://github.com/lifting-bits/remill/blob/master/docs/ADD_AN_INSTRUCTION.md\nSEM: semantic of an instruction.\nISEL: An instruction \u0026lsquo;selection\u0026rsquo;.\nXED:\nImplementation\n lift instruction to basic block: https://github.com/lifting-bits/remill/blob/master/remill/BC/Lifter.h\n function lift: https://github.com/lifting-bits/remill/tree/master/tools/lift/Lift.cpp\n    Remill ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/asm/mcsema/",
	"title": "McSema",
	"tags": [],
	"description": "",
	"content": " Thesis: https://is.muni.cz/th/pxe1j/thesis.pdf\nMcSema\n use [Remill] to lift x86/amd64/aarch64 instructions to LLVM bitcode; the only option that separates control flow recovery from translation, permitting the use of custom control flow recovery front-ends; based on LLVM 3.5 (in 2014-2016), LLVM 3.8 (in 2017),  Modules:\n mcsema-disass disassembles binaries; only use IDA Pro as disassembly engine; mcsema-lift converts the disassembly into LLVM bitcode;  Add new instructions use mcsema-lift --list-supported to see supported instructions.\nAdd new instructions to remill\nUsage McSema Walkthrough\nReference 1\nRemill\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/asm/s2e/",
	"title": "S2e",
	"tags": [],
	"description": "",
	"content": "S2E\nBuilt upon KLEE symbolic execution engine and the QEMU virtual machine.\nGood:\n works at any level of the stack: applications, libraries, kernel drivers, and device firmware. generates test cases to prove the existence of vul; Supports Windows \u0026amp; Linux: exe tracing, code coverage, profiling. Explore thousands of paths automatically.  Modular/Extensible:\n use its multi-path analysis (symbolic execution). use as single-path instrumentation platform. can be used without overhead of VM: S2E emulates KVM interfaces.  Program analysis capability:\n navigate large state spaces with concolic and symbolic execution, state merging, static analysis, function summaries, incremental constraint solving. Security checking, test, verification, reverse engineering, performance profiling, etc. Quickly prototype your research ideas by combining existing plugins or writing your own.  Implementation:\nPapers: 1 2 3 4 5 6\n  Selective Symbolic Execution. Vitaly Chipounov, Vlad Georgescu, Cristian Zamfir, George Candea. 5th Workshop on Hot Topics in System Dependability (HotDep), Lisbon, Portugal, June 2009. ↩ Reverse Engineering of Binary Device Drivers with RevNIC. Vitaly Chipounov and George Candea. 5th ACM SIGOPS/EuroSys European Conference on Computer Systems (EuroSys), Paris, France, April 2010. ↩ Testing Closed-Source Binary Device Drivers with DDT. Volodymyr Kuznetsov, Vitaly Chipounov, George Candea. USENIX Annual Technical Conference (USENIX), Boston, MA, June 2010. DDT tool won the Silver Prize at the 2012 World Open-Source Software Challenge. ↩ S2E: A Platform for In Vivo Multi-Path Analysis of Software Systems. Vitaly Chipounov, Volodymyr Kuznetsov, George Candea. 16th Intl. Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), Newport Beach, CA, March 2011. BEST PAPER AWARD. ↩ Enabling Sophisticated Analysis of x86 Binaries with RevGen. Vitaly Chipounov and George Candea. 7th Workshop on Hot Topics in System Dependability (HotDep), Hong Kong, China, June 2011. ↩ The S2E Platform: Design, Implementation, and Applications. Vitaly Chipounov, Volodymyr Kuznetsov, and George Candea. ACM Transactions on Computer Systems (TOCS) Special issue: Best papers of ASPLOS, February 2012. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/asm/revgen/",
	"title": "Revgen",
	"tags": [],
	"description": "",
	"content": "Paper: Enabling sophisticated analyses of ×86 binaries with RevGen 1.\nDocument: Revgen 1\n Disassemble the binary using IDA Pro; Recover the control flow graph (CFG) using McSema; Translate each basic block in the CFG into a chunk of LLVM bitcode by using QEMU\u0026rsquo;s translator; Stitch together translated basic block into LLVM functions.  Note:\n use old version of McSema (from 2016. not the lastest McSema2); binary is statically linked; calling conventions not parsed for dynamic calls; only on x86? not self-modifying code (but QEMU supports them, and re-translating on the fly). translated binary that is 15-30x bigger than the orignal. Overhead from:  no optimizations; wraps each memory access to a function call; embeds the original binary in the translated binary; in order to translate data memory access at run time; those above should be done statically during translation. BUT this requires more complex lifting as in McSema; tasks include:  lifting local/global variables; recover library function calls; support multi-threading, signals, exceptions, long jumps, and many more.      Enabling sophisticated analyses of ×86 binaries with RevGen. DSN-W, 2011. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/unikernels/demikernel/",
	"title": "Demikernel",
	"tags": [],
	"description": "",
	"content": "Reference 1\nThe Demikernel is a library operating system architecture designed for use with kernel-bypass I/O devices. The Demikernel architecture offers a uniform system call API across kernel-bypass technologies (e.g., RDMA, DPDK) and OS functionality (e.g., a user-level networking stack for DPDK).\nDemikernel: kernel-bypass IO abstraction for data centers.\n  Github: Demikernel ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/unikernels/",
	"title": "Unikernels",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Demikernel  Reference 1 The Demikernel is a library operating system architecture designed for use with kernel-bypass I/O devices. The Demikernel architecture offers a uniform system call API across kernel-bypass technologies (e.g., RDMA, DPDK) and OS functionality (e.g., a user-level networking stack for DPDK). Demikernel: kernel-bypass IO abstraction for data centers. Github: Demikernel ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/calendar/",
	"title": "Calendar",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/deep/tensorflow/",
	"title": "Tensorflow",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  What is tensor? see tensors  Reference 1\n  TensorFlow Tensors ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/tensors/",
	"title": "Tensors",
	"tags": [],
	"description": "",
	"content": " Reference 1\nWhy tensor?   What is a tensor? From datacamp:\n Vectors: ordered collection of numbers; one column matrices; a scalar magnitudes that have been given a direction, where direction is relative to the reference direction. Vector space: two-space: (x,y); three space (x,y,z); Unit Vectors: $\\hat x$, a magnitude of one.\n Tensor: a mathematical representation of a physical entity that may be characterized by magnitude and multiple directions.\n Rank: In a N-dimensional space, scalar has one number, vector will require N numbers, and R-rank tensor require N^R numbers.\n Scalar is tensors of rank 0; Vector is rank 1. 3 dimensional space: 2-rank tensor will have 9 numbers.  Component + Basic vectors:\n  More:\n   Basic vectors (unit vectors): magnitude of 1. Vector component: project the vector into axis, we get a component.  Tensor:\n 1-rank in 3-dimension space: 3 1-rank basis, 3 components each vector; 2-rank in 3-dimension space: 9 2-rank basis, 9 components each vector; each component has two indices.  Forces inside a solid object: for one point in the solid object, one surface can be defined by vector (xSurface,ySurface,zSurface), and the force can be defined as (xForce,yForce,zForce). Therefore, for this point, to represent all possible surfaces and all possible forces, we need a new coordinator system by combining all 3 axis of surfaces and 3 axis of forces. This results in a 9 axis space, each axis contain 1 surface axis and 1 force axis.     Tensor in greek: to stretch.\nStress tensor. rank-2 tensor.\ncan be written as 3x3 matrix, each represents a direction.\nIndex notation: rack n: need n indices for each vector component.\nCoordinates transformation.\n real vector: vector itself does not change in different coordinates. pseudovector: angular momentum.     Tensors of rank one: (A_x, A_y, A_z): one index, or one basic vector per component. There is only one index for each of the vector component, because there is only one basis vector, (or directional indicator) for each compnent element.\n Tensors of rank zero: need no index, because no directional indicator. The scalars.\n    reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/abs-algebra/groups/",
	"title": "Groups",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/abs-algebra/",
	"title": "Abstract Algebra",
	"tags": [],
	"description": "",
	"content": " Reference 1\nThe Group    Groups  Reference 1 reference ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/galois/",
	"title": "Galois",
	"tags": [],
	"description": "",
	"content": "Reference 1\n --    \u0026gt; Listen Galois pronunciation from 4:30\n  Galois Connection ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/abs-int/",
	"title": "Abs Int",
	"tags": [],
	"description": "",
	"content": " PPA version Reference 1\nThe theory of Abstract Interpretation is a general methodology for calculating analyses rather than just specifying them and then rely on a posteriori validation.\nCollecting Semantics records the set of traces $tr$ that can reach a given program point:\n$tr \\in Trace = (Var \\times Lab)^*$\ne.g:\n$((x, ?), (y, ?), (z, ?), (y, 1), (z, 2), (z, 4), (y, 5), (z, 4), (y, 5), (y, 6))$\nis the trace to run the while loop twice in the example factorial program:\n$[y:=x]^1; [z:=1]^2; while [y\u0026gt;1]^3 do ([z:=z*y]^4; [y:=y-1]^5); [y:=0]^6$\nSemantic reaching definitions.\nDefined as:\n$SRD(tr)(x) = l $, iff (x,l) is the rightmost pair for $x$ in $tr$.\ncan be used to test the result of the Reaching Definition Analysis. To be corrent, we should have:\n$\\forall x \\in Var: (x, SRD(tr)(x)) \\in RD_{entry}(l)$.\nNote that this only requires all correct reaching defs should be included in the result, and does not exclude false reaching defs from the result. This property is defined as \u0026lsquo;safe\u0026rsquo; or \u0026lsquo;correct\u0026rsquo; property of the analysis (in PPA context).\nCollecting Semantics.\nCollecting semantics:\na superset of the possible traces at the various program points.\nFor example:\n$ CS_{exit} (1) = \\{ tr: (y,1) | tr \\in CS\\_entry(1) \\} $\n$ CS_{exit} (2) = \\{ tr: (z,2) | tr \\in CS\\_entry(2) \\} $\n$ CS_{exit} (5) = \\{ tr: (y,5) | tr \\in CS\\_entry(5) \\} $\n\u0026hellip; total 6.\nWhere $tr: (x,l)$ is to append an element (x,l) to a trace $tr$. For example, $(x_1, l_1), \u0026hellip; , (x_n,l_n): (x,l)$ equals $(x_1, l_1), \u0026hellip;, (x_n, l_n), (x,l).$\n$ CS_{entry} (3) = CS\\_exit (2) \\cup CS\\_exit (5) $\n$ CS_{entry} (4) = CS\\_exit (3) $\n$ CS_{entry} (6) = CS\\_exit (3) $\n\u0026hellip; total 6.\nInformation about value of $y$: make $CS{entry}(4)$ and $CS{entry} (6)$ more precise.\nRewrite the above system of equations:\n$\\vec{CS}$ = $G(\\vec{CS})$\nwhere $\\vec{CS}$ is a 12-tuple containing the $CS$ for all 12 program points. $G$ is monotone function2:\nG: $(P(Trace))^{12} \\rightarrow (P(Trace))^{12}$\nSolutions of the equation system: set of reaching definitions for each statement/label.\nA theory: has a least solution, as $lfp(G)$\nProblem: $(P(Trace))^{12}$ is not finite.\nGalois Connections Collecting semantics: operates on set of traces.\nReaching definition analysis: operates on set of pairs of variables and lables.\nUse one abstract functions $\\alpha$ and one concretisation function $\\gamma$ to relate these two \u0026ldquo;worlds\u0026rdquo;:\n$ \\alpha : P(Trace) \\rightarrow P(Var \\times Lab) $\n$ \\gamma : P(Var \\times Lab) \\rightarrow P(Trace) $\n$\\alpha$: extracts the reachability information present in a set of traces;\n$\\alpha(X) = \\{(x,SRD(tr)(x)) | x \\in Var \\wedge tr \\in X \\}$\n$\\gamma$, the concretisation function, produces all traces $tr$ that are consistent with the given reachability information:\n$\\gamma(Y) = \\{ tr | \\forall x \\in Var: (x, SRD(tr)(x)) \\in Y \\} $\nOften: $\\alpha(X) \\subseteq Y \\Leftrightarrow X \\subseteq \\gamma(Y)$, then $(\\alpha, \\gamma)$ is an adjunction, or a Galois connection.\nInduced Analysis   PPA. chapter 1.5, 4. ↩ A monotone function F: $\\vec{RD} \\sqsubseteq \\vec{RD\u0026rsquo;}$ implies $F(\\vec{FD}) \\sqsubseteq F(\\vec{RD\u0026rsquo;})$ ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/asm/",
	"title": "Asm",
	"tags": [],
	"description": "",
	"content": " Q \u0026amp; A  Can assembly language being compiled to LLVM IR so that it can be analysed?  Yes, lots of tools can do this \u0026lsquo;lifting\u0026rsquo;. see assembly to llvm IR translators   Assembly to LLVM IR llvm-mctoll\nremill\nlibqemu\nllvm-qemu\n Mc Toll  Reference 1 reference ↩  Remill  Reference 1 To add new instructions to Remill: https://github.com/lifting-bits/remill/blob/master/docs/ADD_AN_INSTRUCTION.md SEM: semantic of an instruction. ISEL: An instruction \u0026lsquo;selection\u0026rsquo;. XED: Implementation lift instruction to basic block: https://github.com/lifting-bits/remill/blob/master/remill/BC/Lifter.h function lift: https://github.com/lifting-bits/remill/tree/master/tools/lift/Lift.cpp Remill ↩  McSema  Thesis: https://is.muni.cz/th/pxe1j/thesis.pdf McSema use [Remill] to lift x86/amd64/aarch64 instructions to LLVM bitcode; the only option that separates control flow recovery from translation, permitting the use of custom control flow recovery front-ends; based on LLVM 3.5 (in 2014-2016), LLVM 3.8 (in 2017), Modules: mcsema-disass disassembles binaries; only use IDA Pro as disassembly engine; mcsema-lift converts the disassembly into LLVM bitcode; Add new instructions use mcsema-lift --list-supported to see supported instructions.\n S2e  S2E Built upon KLEE symbolic execution engine and the QEMU virtual machine. Good: works at any level of the stack: applications, libraries, kernel drivers, and device firmware. generates test cases to prove the existence of vul; Supports Windows \u0026amp; Linux: exe tracing, code coverage, profiling. Explore thousands of paths automatically. Modular/Extensible: use its multi-path analysis (symbolic execution). use as single-path instrumentation platform. can be used without overhead of VM: S2E emulates KVM interfaces.\n Revgen  Paper: Enabling sophisticated analyses of ×86 binaries with RevGen 1. Document: Revgen 1 Disassemble the binary using IDA Pro; Recover the control flow graph (CFG) using McSema; Translate each basic block in the CFG into a chunk of LLVM bitcode by using QEMU\u0026rsquo;s translator; Stitch together translated basic block into LLVM functions. Note: use old version of McSema (from 2016. not the lastest McSema2); binary is statically linked; calling conventions not parsed for dynamic calls; only on x86?\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/proj/",
	"title": "Proj",
	"tags": [],
	"description": "",
	"content": "Reference 1\n root dir Makefile\n Variables PROJECT_NAME LLVM_SRC_ROOT LLVM_OBJ_ROOT PROJ_SRC_ROOT PROJ_OBJ_ROOT PROJ_INSTALL_ROOT LEVEL include Makefile.config from $(LLVM_OBJ_ROOT) include Makefile.rules from $(LLVM_SRC_ROOT) two ways to set all these variables write your own Makefiles pre-made LLVM sample project  Source Tree Layout\n lib/ include/ tools/ test/  Variables in subdir Makefile\n LEVEL DIRS PARALLEL_DIRS OPTIONAL_DIRS  Variables for Building Libraries (lib/)\n LIBRARYNAME BUILD_ARCHIVE SHARED_LIBRARY   Variables for Building Programs (tool/)\n TOOLNAME USEDLIBS LLVMLIBS LINK_COMPONENTS LIBS  Miscellaneous Variables\n CFLAGS \u0026amp; CPPFLAGS     Creating an LLVM Project ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/hacking/types/",
	"title": "Types",
	"tags": [],
	"description": "",
	"content": "Reference 1\nTo Print type info:\nuse dump()\n  Type ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/hacking/",
	"title": "Hacking",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Types  Reference 1 To Print type info: use dump() Type ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/201904-secswift/",
	"title": "201904 Secswift",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  A compiler approach to cyber-security ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/attr/",
	"title": "Attr",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to add new attributes and propagate it using LLVM?\n How about attributes in assembly language?\n  LLVM References:\n How to use attributes\n Adding an annotation that gets to the backend\n How to add an attribute\n  An attribute can be a single “enum” value (the enum being the [Attribute::AttrKind] enum), a string representing a target-dependent attribute, or an attribute-value pair. Some examples:\n Target-independent: noinline, zext Target-dependent: \u0026ldquo;no-sse\u0026rdquo;, \u0026ldquo;thumb2\u0026rdquo; Attribute-value pair: \u0026ldquo;cpu\u0026rdquo; = \u0026ldquo;cortex-a8\u0026rdquo;, align = 4  Note: for an attribute value pair, we expect a target-dependent attribute to have a string for the value.\nAttribute An Attribute object is passed by value.\n[Attribute::get] to create a new Attribute object\nAttribute::get:\n[Attribute::AttrKind] enum. This enumeration lists the attributes that can be associated with parameters, function results, or the function itself.\nAttribute::AttrKind\nllvm/IR/Attributes.inc\nAttributeList stores a collection of Attribute objects for each kind of object that may have an attribute associated with it:\n the function as a whole, the return type, or the function’s parameters.  A function’s attributes are at index AttributeList::FunctionIndex;\nthe return type’s attributes are at index AttributeList::ReturnIndex;\nthe function’s parameters’ attributes are at indices 1, …, n (where ‘n’ is the number of parameters). Most methods on the AttributeList class take an index parameter.\nAttrBuilder A builder class to create AttributeList object;\nadd and remove attributes;\nAn AttrBuilder should be passed by reference.\nDO NOT USE AttrBuilder::addRawValue(), or AttrBuilder(uint64_t Val); will be remove in the future.\nClang Reference 1 2\nParsed representation of an attribute is an \u0026lsquo;PassedAttr\u0026rsquo; object.\nkeywords attribute vs non-keywords attribute.\n keywords attribute. The parsing of the keyword and creation of the ParseAttr object must be done manually. non-keywords attribute. The parsing of attributes is handled automatically by Clang.  Sema::ProcessDeclAttributeList() is called with Decl and an ParsedAttr, transform a parsed attribute into a semantic attribute. The semantic attribute object is attached to Decl, can be obtained by Decl::getAttr\u0026lt;T\u0026gt;(). The process of the attribute is determined by the attribute definition and semantic requirements of the attribute.\nAttribute definition in file include/clang/Basic/Attr.td. This definition is used to\n automatically generate functionality used for the implementation of the attribute, such as  a class derived from clang::Attr, information for the parser to use, automated semantic checking for some attributes, etc.   Add an attribute To add an attribute:\nIn include/clang/Basic/Attr.td, add a new attribute definition. The attribute must derive from an Attr (tablegen, not semantic) type, or one of its derivatives:\n InheritableAttr: most derive from the InheritableAttr type; An InheritableAttr specifies that the attribute can be inherited by later redeclarations of the Decl it is associated with; InheritableParamAttr is similar to InheritableAttr, except that the attribute is written on a parameter instead of a declaration; TypeAttr: the attribute is intended to apply to the type instead of the declarationi; such attribute will generally not be given an AST representation. IgnoredAttr: parsed but will generate an ignored attribute diagnostic when used; may be useful when an attr is supported by another vendor but not supported by clang.  The attr definition contains:\n semantic name; a spelling list: the spellings the attribute supports; a subject list: a documentation list. can be \u0026lsquo;Undocumented\u0026rsquo;. the arguments the attribute expects; and more.  Argument If Args is [StringArgument\u0026lt;\u0026quot;Arg1\u0026quot;\u0026gt;, IntArgument\u0026lt;\u0026quot;Arg2\u0026quot;\u0026gt;], then __attribute__((myattribute(\u0026quot;Hello\u0026quot;, 3))) will be a valid use.\nArguments can be flagged optional.\nSteps to change Clang/LLVM Add attributes for functions in both clang/llvm see 1.\n clang/include/clang/Basic/Attr.td: add definition of attribute for clang; llvm/include/llvm/IR/Attributes.td: add def for llvm; llvm/lib/IR/Attributes.cpp: change getAsString(), which convert attributes to a string; llvm/lib/IR/Verifier.cpp: add Attribute::YourAttrbute in isFunctionOnlyAttr; clang/lib/Sema/SemaDeclAttr.cpp: Process the attribute; in ProcessDeclAttribute(), either by new function or just call handleSimpleAttribute. clang/lib/CodeGen/CodeGenModule.cpp: attach attribute to function when generate code in CodeGenModule::SetLLVMFunctionAttributesForDefinition().\n// LLM: privilege tracking attributes for functions if (D-\u0026gt;hasAttr\u0026lt;PrivilegeFunctionAttr\u0026gt;()){ B.addAttribute(llvm::Attribute::PrivilegeFunction); } if (D-\u0026gt;hasAttr\u0026lt;PrivilegeLevelAttr\u0026gt;()){ B.addAttribute(llvm::Attribute::PrivilegeLevel); }  Add LLVM support to write/read bitcode with attributes.\n llvm/lib/AsmParser/LLToken.h: add kw_yourAttribute to llvm::lltok::Kind. llvm/lib/AsmParser/LLLexer.cpp add KEYWORD(yourAttribute);to lltok::Kind LLLexer::LexIdentifier. llvm/lib/AsmParser/LLParser.cpp: add code to turn keyword into the IR attribute in LLParser::ParseFnAttributeValuePairs. case lltok::kw_yourAttribute: B.addAttribute(Attribute::YourAttribute); break; llvm/include/llvm/Bitcode/LLVMBitCodes.h: add a new entry to end of AttributeKindCodes. ATTR_KIND_YourAttribute = 55, llvm/lib/Bitcode/Writer/BitcodeWriter.cpp:\ncase Attribute::YourAttribute: return bitc::ATTR_KIND_YourAttribute;  llvm/include/llvm/Bitcode/BitCodeReader.cpp: in getAttrFromCode:\ncase bitc::ATTR_KIND_YourAttribute: return Attribute::YourAttribute;    Add attributes for global variables in clang/llvm: little change for step 6, change function SetCommonAttributes() and convert the attribute in clang (attached with clang::GlobalDecal) to llvm (attached to llvm::GlobalVariable)\n// file: clang/lib/CodeGen/CodeGenModule.cpp // add priv attribute to global variables if (llvm::GlobalVariable *GVar= dyn_cast\u0026lt;llvm::GlobalVariable\u0026gt;(GV)){ if (auto *PAttr = D-\u0026gt;getAttr\u0026lt;PrivilegeDataAttr\u0026gt;()){ GVar-\u0026gt;addAttribute(\u0026#34;privilege_data\u0026#34;); } if ( auto *PAttr = D-\u0026gt;getAttr\u0026lt;PrivilegeLevelAttr\u0026gt;()){ GVar-\u0026gt;addAttribute(\u0026#34;privilege_level\u0026#34;, std::to_string(PAttr-\u0026gt;getPrivilegeLevel())); } }  Attributes for function arguments: clang/lib/CodeGen/CGDecl.cpp: EmitParmDecl(): parse the attribute and add it for bit code code generation.\n if (D.hasAttr\u0026lt;PrivilegeDataAttr\u0026gt;()){ llvm::Argument *LLVMArg = dyn_cast\u0026lt;llvm::Argument\u0026gt;(Arg.getAnyValue()); LLVMArg-\u0026gt;addAttr(llvm::Attribute::PrivilegeData); }  llvm/lib/AsmParser/LLParser.cpp: ParseOptionalParamAttrs(): parse the bit code and convert attribute to LLVM Attribute object. add one line:\ncase lltok::kw_privilege_data: B.addAttribute(Attribute::PrivilegeData); break;\nAttributes for local (non-static) variables: Clang detected the attribute of local (non-static) variable at clang/lib/CodeGen/CGDecl.cpp: EmitAutoVarAlloca();\nAttributes for local static variables: Clang detected static local variable at clang/lib/CodeGen/CGDecl.cpp: EmitStaticVarDecl();\n// LLM: add privilege_data attribute if (auto *PA = D.getAttr\u0026lt;PrivilegeDataAttr\u0026gt;()){ llvm::errs() \u0026lt;\u0026lt; \u0026#34;LLM: \u0026#34; \u0026lt;\u0026lt; __FILE__ \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; __FUNCTION__ \u0026lt;\u0026lt; \u0026#34;: found priv data attr on static var: \u0026#34; \u0026lt;\u0026lt; D.getName() \u0026lt;\u0026lt; \u0026#34;. Added to llvm::GlobalVariable\\n\u0026#34;; var-\u0026gt;addAttribute(llvm::Attribute::PrivilegeData); }  Debugging Warning:\n/root/cheri/llvm-project/clang/lib/AST/TypePrinter.cpp:1514:11: warning: enumeration values 'PrivilegeData', 'PrivilegeFunction', and 'PrivilegeLevel' not handled in switch [-Wswitch] switch (T-\u0026gt;getAttrKind()) {  solution: added switch cases (commit):\n // file: clang/lib/AST/TypePrinter.cpp // LLM: added to avoid warning case attr::PrivilegeData: OS \u0026lt;\u0026lt; \u0026quot;privilege_data\u0026quot;; break; case attr::PrivilegeFunction: OS \u0026lt;\u0026lt; \u0026quot;privilege_function\u0026quot;; break; case attr::PrivilegeLevel: OS \u0026lt;\u0026lt; \u0026quot;privilege_level(\u0026quot; \u0026lt;\u0026lt; \u0026quot;???\u0026quot; \u0026lt;\u0026lt; \u0026quot;)\u0026quot;; break;  Warning:\n [537/3555] Building CXX object lib/Bitcode/Reader/CMakeFiles/LLVMBitReader.dir/BitcodeReader.cpp.o /root/cheri/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp:1216:11: warning: enumeration values 'PrivilegeData', 'PrivilegeFunction', and 'PrivilegeLevel' not handled in switch [-Wswitch] switch (Val) { ^ 1 warning generated. [555/3555] Building CXX object lib/Transforms/Utils/CMakeFiles/LLVMTransformUtils.dir/CodeExtractor.cpp.o /root/cheri/llvm-project/llvm/lib/Transforms/Utils/CodeExtractor.cpp:789:15: warning: enumeration values 'PrivilegeData', 'PrivilegeFunction', and 'PrivilegeLevel' not handled in switch [-Wswitch] switch (Attr.getKindAsEnum()) { ^ 1 warning generated.    Adding an annotation that gets to the backend ↩ How to add an attribute ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-llvm/fatptr/",
	"title": "Fatptr",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to distinguish capabilities? How does it parse __capability qualifier?  Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-llvm/passes/range-checker/",
	"title": "CheriRangeChecker Pass",
	"tags": [],
	"description": "",
	"content": " References:\n llvm/lib/Target/Mips/CheriRangeChecker.cpp Add LLVM pass to the pipeline  Overview Only in Mips, not in RISCV.\nA function pass with instruction visitor: class CheriRangeChecker : public FunctionPass, public InstVisitor\u0026lt;CheriRangeChecker\u0026gt;;\nPass is initialized at\nvoid initializeCheriRangeCheckerPass(PassRegistry \u0026amp;); in llvm/lib/Target/Mips/Mips.h (LLM: this init func\u0026rsquo;s implementation will be automatically generated by LLVM using macro INITIALIZE_PASS_BEGIN).\n\u0026lt;\u0026ndash;\nllvm/lib/Target/Mips/MipsTargetMachine.cpp: LLVMInitializeMipsTarget(): initializeCheriRangeCheckerPass(*PR);\nPass is invoked at\nllvm/lib/Target/Mips/MipsTargetMachine.cpp: void MipsPassConfig::addIRPasses(): addPass(createCheriRangeChecker());\nFunctions/Steps:\n runOnFunction():\n visit(F): collect pairs of range info and correspondign cast instruction in vectors: \u0026lt;AllocaOperands, xxxCastInst\u0026gt; in Casts and \u0026lt;AllocaOperands, ConstantCast\u0026gt; in ConstantCasts: visitAddrSpaceCast(): get ValueSource of the cast operand: auto Src = getValueSource(ASC.getOperand(0));  If ValueSource is GlobalVariable and has external linkage, ignore If ValueSource is Not AllocaInst, or is a call site, ignore Otherwise, get the range of the operand: AllocOperands AO = getRangeForAllocation(Src); getRangeForAllocation(ValueSource Src), see below. Store the pair of range info and instruction in Casts  visitIntToPtrInst(IntToPtrInst \u0026amp;I2P):  User *P2I = testI2P(I2P): get the operand(0) as PtrToInt instruction. get ValueSource of the operands of P2I get the range of the operand and store the pair in Casts  visitRet(ReturnInst \u0026amp;RI)  get return value of the instruction: Value *RV = RI.getReturnValue() If return value is a ConstantExpr: get the origin of the return value: testI2P(*cast\u0026lt;User\u0026gt;(RV))  testI2P(): get the operand(0) as PtrToInt instruction.  get the range and put it in ConstantCasts  visitCall(CallInst \u0026amp;CI): for each operands of the CallInst  If the operand is a ConstantExpr: get the origin of the operand:  testI2P(*cast\u0026lt;User\u0026gt;(AV)): get the operand(0) as PtrToInt instruction.  get the range of the operand and put is in ConstantCasts  Create function based on intrinsic cheri_cap_bounds_set: SetLengthFn = Intrinsic::getDeclaration(M, SetLength, SizeTy); For each pair stored inCasts and ConstantCasts get instruction and store as I2P  Instruction in Casts Instruction operand in ConstantCasts  determine insert point.  The instruction after the I2P in Casts The Instruction in ConstantCast in ConstantCasts  call RangCheckedValue() to inert bound check instruction and get the new instruction contain the casted object pointer New  see below.  In all uses of I2P, replace I2P with New (Now all users are refering New)   User *testI2P(User \u0026amp;I2P): Return Operand(0) as P2I, if it is Instruction::PtrToInt and is {non-extenal global || AllocaInst || CallSite}.\n If I2P is pointer type (dyn_cast\u0026lt;PointerType\u0026gt;(I2P.getType())), and Pointer is CheriPointer (isCheriPointer(DestTy, TD.get())), and Operand 0 has the opcode of Instruction::PtrToInt do the following: Cast the operand 0 to User and store as P2I; if Operand 0 is pointer type and address space of the type is 0:  strip off the pointer casts of the Operand 0: Value *Src = P2I-\u0026gt;getOperand(0)-\u0026gt;stripPointerCasts() If Src is Global Variable and not external linkage, return P2I; If Src is AllocaInst or CallSite, return P2I; Otherwise, return 0.   RangeCheckedValue(): add cheri_cap_bounds_set instruction and return a set of new instructions (IRBuilder)\n compute the bound size of the object under cast I2P. insert call to the cheri_cap_bounds_set intrinsic, set as result. if offset is non-zero, insert GEP instruction, and set as result. insert BitCast instruction, casting Result -\u0026gt; I2P, and return.  getRangeForAllocation():\n recognize Heap or Stack object malloc/valloc/realloc/aligned_alloc/reallocf/calloc for Heap object AllocaInst for stack object, get the size argument of the object, save it in AllocOperands() instance.   Main funcs  getRangeForAllocation(ValueSource Src)  get the range of the malloc\u0026rsquo;d and alloca\u0026rsquo;d object.\nCallSite Malloc = CallSite(Src.Base); // initialize a CallSite instance to get the call instruction information. Function * Fn = Malloc.getCalledFunction; // get function information.runOnFunction Fn-\u0026gt;getName(); // get the function name in string. can be malloc, valloc, realloc, aligned_alloc, reallocf, calloc. Malloc.getArgument(0); // first argument // a special switch statement in C++ switch (StringSwitch\u0026lt;int\u0026gt;(Fn-\u0026gt;getName()) .Case(\u0026quot;malloc\u0026quot;, 1) .Case(\u0026quot;valloc\u0026quot;, 1) .Case(\u0026quot;realloc\u0026quot;, 2) .Case(\u0026quot;aligned_alloc\u0026quot;, 2) .Case(\u0026quot;reallocf\u0026quot;, 2) .Case(\u0026quot;calloc\u0026quot;, 3) .Default(-1)) { default: return AllocOperands(); case 1: return AllocOperands{Malloc.getArgument(0), nullptr, Src, cheri::SetBoundsPointerSource::Heap}; case 2: return AllocOperands{Malloc.getArgument(1), nullptr, Src, cheri::SetBoundsPointerSource::Heap}; case 3: return AllocOperands{Malloc.getArgument(0), Malloc.getArgument(1), Src, cheri::SetBoundsPointerSource::Heap}; }  Summary Get and set bound for heap and stack objects.\nFirst, tracking the operands of different instructions, collect the object size and source instruction:\n AddrSpaceCast, tracking object at operand 0. IntToPtrInst, tracking object at operand 0. Ret, tracking object at return value. Call, tracking object operand i, that is a ConstantExpr whose operand(0) has operand PtrToInt.  Second, insert instruction after the object allocation site to set the bounds to the pointer.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/addrspace/",
	"title": "Addrspace",
	"tags": [],
	"description": "",
	"content": "Cite: relation between address spaces and physical memory locations\n On Wed, Mar 23, 2016 at 8:01 PM, David Chisnall via llvm-dev \u0026lt; llvm-dev at lists.llvm.org\u0026gt; wrote:\nOn 23 Mar 2016, at 11:35, Mohammad Norouzi wrote: \u0026gt; \u0026gt; Thanks for the reply. \u0026gt; \u0026gt; On Wed, Mar 23, 2016 at 10:43 AM, James Molloy wrote: \u0026gt; Hi, \u0026gt; \u0026gt; Address spaces in LLVM are an abstract concept and LLVM attaches no internal meaning to address spaces, apart from: \u0026gt; \u0026gt; - Location 0 in address space 0 is \u0026lsquo;nullptr\u0026rsquo; and a pointer to this cannot be dereferenced in a well formed program. \u0026gt; \u0026gt; - pointers in different address spaces cannot alias. \u0026gt; \u0026gt; Different backends attach different meanings. So for example an OpenCL backend might interpret address space 1 as local memory, 2 as private memory etc (in fact for OpenCL, these mappings are defined in the Clang frontend, if I recall correctly) \u0026gt; \u0026gt; When are the meanings attached? After or before register allocation?\nThe meanings are target specific. They are assigned by the targets. Note that the C address space and the LLVM IR address space do not always correspond - Clang’s OpenCL mode, for example, maps OpenCL address spaces to different IR address spaces depending on the target.\n This is important as register allocation can use this information to allocate registers to variables. For example, in a parallel code we have shared and private variables. Shared variables should not go into registers. This alleviates register pressure.\n I think that you are talking about something different to what I understand register allocation to mean. For most targets, values must be in registers (or, at least, one of a pair of values must be) to be used by instructions. If they reach the back end without a canonical memory location then they are not referenced by address and so may end up solely in registers, or on the stack. If they are referenced by address, then they must be loaded before being computed on and assignments will require a store.\nFor parallel code, this may make a difference to instruction selection (for example, you don’t need atomic operations on private variables), but shouldn’t make a different to register allocation.\nDavid\n Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/instvisitor/",
	"title": "Instvisitor",
	"tags": [],
	"description": "",
	"content": "Reference 1\nClass InstVisitor:\nBase class for instruction visitors\nInstruction visitors are used when you want to perform different actions for different kinds of instructions without having to use lots of casts and a big switch statement (in your code, that is).\nTo define your own visitor, inherit from this class, specifying your new type for the \u0026lsquo;SubClass\u0026rsquo; template parameter, and \u0026ldquo;override\u0026rdquo; visitXXX functions in your class. I say \u0026ldquo;override\u0026rdquo; because this class is defined in terms of statically resolved overloading, not virtual functions.\nFor example, here is a visitor that counts the number of malloc instructions processed:\nDeclare the class. Note that we derive from InstVisitor instantiated with our new subclasses type.\n struct CountAllocaVisitor : public InstVisitor\u0026lt;CountAllocaVisitor\u0026gt; { unsigned Count; CountAllocaVisitor() : Count(0) {} void visitAllocaInst(AllocaInst \u0026amp;AI) { ++Count; } }; And this class would be used like this: CountAllocaVisitor CAV; CAV.visit(function); NumAllocas = CAV.Count;  The defined has \u0026lsquo;visit\u0026rsquo; methods for Instruction, and also for BasicBlock, Function, and Module, which recursively process all contained instructions.\nNote that if you don\u0026rsquo;t implement visitXXX for some instruction type, the visitXXX method for instruction superclass will be invoked. So if instructions are added in the future, they will be automatically supported, if you handle one of their superclasses.\nThe optional second template argument specifies the type that instruction visitation functions should return. If you specify this, you MUST provide an implementation of visitInstruction though!.\nNote that this class is specifically designed as a template to avoid virtual function call overhead. Defining and using an InstVisitor is just as efficient as having your own switch statement over the instruction opcode.\n  InstVistor Class ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/boot/",
	"title": "Boot",
	"tags": [],
	"description": "",
	"content": " x86: BIOS -\u0026gt; boot0 -\u0026gt; boot1 -\u0026gt; BTX -\u0026gt; boot2 -\u0026gt;\nBIOS  early hw init, POST MBR(boot0) loaded from absolute disk sector to 0x7c00  boot0 stage Master Boot Record (MBR)\nNote:\n The first piece of code under FreeBSD control. Must fit into 512 bytes. boot0.S is assembled \u0026ldquo;as is\u0026rdquo;: one-to-one asm to binary; no ELF format; see sys/boot/i386/boo0/Makefile or stand/i386/boo0/boot0.S, the special LDFLAG to strip out any file formating (-oformat,binary)  Function: Scan the partition table and let the user choose which partition to boot from.\n relocate itself from 0x7c00 to the location it was linked to execute (0x600) load the first disk sector from the FreeBSD slice to address 0x7c00  boot1 stage sys/boot/i386/boot2/boot1.S or stand/i386/boot2/boot1.S\nNote:\n First of 3 booting stages; boot1 is 512 bytes; boot2 is much larger. boot1 and boot2 (which contains Boot Extender, BTX, and boot2 client) are both included in a single file /boot/boot on disk (cat boot1 boot2 \u0026gt; boot) BTX execute in kernel mode; boot2 client execute in user mode.  Function: load the next boot stage: a server called BTX, a client called boot2.\n start -\u0026gt; main relocate itself from 0x7c00 to 0x700, but does not jump to 0x700. (It was linked to execute at 0x7c00). rescan the partition table to find where the FreeBSD slice starts(Rereads the MBR). load fist 16 sectors (the all-in-one boot file, contains boot1, boot2, and BTX) to 0x8c00; BTX loaded to 0x9000; (execution at main.5), enable access to memory above 1MB jump to the BTX server  BTX server (x86) cite: https://www.freebsd.org/doc/en_US.ISO8859-1/books/arch-handbook/btx-server.html\nsys/boot/i386/btx/btx.S\nFunction:\n switches from 16-bit real mode to 32-bit protected mode  modifies interrupt vector table (IVT), providing exception and interrupt handlers for real-mode code; create the Interrupt Descriptor Table(IDT), providing exception and interrupt handlers for protected-mode code: processor exceptions hardware interrupts two system calls V86 interfaces Create a Task-State Segment (TSS), holding information about a task for context-switching between the user mode boot2 client and kernel mode BTX server; Set up Global Descriptor Table(GDT). Entries are provided for supervisor code and data, user code and data, and real-mode code and data.  passing control to the client boot2\n/* stand/i386/btx/btx/btx.S */ start:\t# Start of code /* * BTX header. */ btx_hdr:\t.byte 0xeb\t# Machine ID \t.byte 0xe\t# Header size \t.ascii \u0026#34;BTX\u0026#34;\t# Magic \t.byte 0x1\t# Major version \t.byte 0x2\t# Minor version \t.byte BTX_FLAGS\t# Flags \t.word PAG_CNT-MEM_ORG\u0026gt;\u0026gt;0xc\t# Paging control \t.word break-start\t# Text size \t.long 0x0\t# Entry address  The last field of the header is entry point to the client boot2. This field is patched at link time.\nNext is the BTX entry point:\n/* stand/i386/btx/btx/btx.S */ /* * Initialization routine. */ init:\tcli\t# Disable interrupts \txor %ax,%ax\t# Zero/segment \tmov %ax,%ss\t# Set up \tmov $0x1800,%sp\t# stack \tmov %ax,%es\t# Address \tmov %ax,%ds\t# data \tpushl $0x2\t# Clear \tpopfl\t# flags It\n disables interrupts, set up a working stack (starting at address 0x1800), and clears the flags in the EFLAGS register. (EFLAGS = 0x2 is clearing because IA-32 requires bit 2 always be 1)  Next is the memory initialization code:\n/* stand/i386/btx/btx/btx.S */ /* * Initialize memory. */ mov $0x5e00,%di\t# Memory to initialize \tmov $(0x9000-0x5e00)/2,%cx\t# Words to zero \trep\t# Zero-fill \tstosw\t# memory It clears memory range 0x5e00 - 0x8fff.\nThen the real-mode IVT is updated:\n/* stand/i386/btx/btx/btx.S */ /* * Update real mode IDT for reflecting hardware interrupts. */ mov $intr20,%bx\t# Address first handler \tmov $0x10,%cx\t# Number of handlers \tmov $0x20*4,%di\t# First real mode IDT entry init.0:\tmov %bx,(%di)\t# Store IP \tinc %di\t# Address next \tinc %di\t# entry \tstosw\t# Store CS \tadd $4,%bx\t# Next handler \tloop init.0\t# Next IRQ Next creating the IDT:\n/* stand/i386/btx/btx/btx.S */ /* * Create IDT. */ mov $0x5e00,%di\t# IDT\u0026#39;s address \tmov $idtctl,%si\t# Control string init.1:\tlodsb\t# Get entry \tcbw\t# count \txchg %ax,%cx\t# as word \tjcxz init.4\t# If done \tlodsb\t# Get segment \txchg %ax,%dx\t# P:DPL:type \tlodsw\t# Get control \txchg %ax,%bx\t# set \tlodsw\t# Get handler offset \tmov $SEL_SCODE,%dh\t# Segment selector init.2:\tshr %bx\t# Handle this int? \tjnc init.3\t# No \tmov %ax,(%di)\t# Set handler offset \tmov %dh,0x2(%di)\t# and selector \tmov %dl,0x5(%di)\t# Set P:DPL:type \tadd $0x4,%ax\t# Next handler init.3:\tlea 0x8(%di),%di\t# Next entry \tloop init.2\t# Till set done \tjmp init.1\t# Continue Each entry is 8 bytes long. contains\n segment/offset information segment type privilege level whether the segment is present in memory or not.  Interrupt numbers:\n 0x0 to 0xf (exceptions) handled by function intx00 0x10 (also an exception) handled by intx10 0x20 - 0x2f (hardware interrupts), handled by intx20 0x30 (system calls), handled by intx30 0x31 - 0x32, handled by intx31  Note:\n Only interrupt vectors 0x30, 0x31, 0x32 are given privilege level 3, same as boot2 client. Thus user mode client can use services provided by BTX. Hardware interrupts and processor exceptions are always handled regardless of privileges involved.  Next is to initialize TSS:\n/* stand/i386/btx/btx/btx.S */ /* * Initialize TSS. */ init.4:\tmovb $_ESP0H,TSS_ESP0+1(%di)\t# Set ESP0 \tmovb $SEL_SDATA,TSS_SS0(%di)\t# Set SS0 \tmovb $_TSSIO,TSS_MAP(%di)\t# Set I/O bit map base A hardcode value is given to stack pointer and stack segment for privilege level 0 in the TSS.\nA value is also given to the I/O Map base address field of the TSS.\nNext is the allow the processor to switch to protected mode:\n/* stand/i386/btx/btx/btx.S */ /* * Bring up the system. */ mov $0x2820,%bx\t# Set protected mode \tcallw setpic\t# IRQ offsets \tlidt idtdesc\t# Set IDT \tlgdt gdtdesc\t# Set GDT \tmov %cr0,%eax\t# Switch to protected \tinc %ax\t# mode \tmov %eax,%cr0\t# \tljmp $SEL_SCODE,$init.8\t# To 32-bit code \t.code32 init.8:\txorl %ecx,%ecx\t# Zero \tmovb $SEL_SDATA,%cl\t# To 32-bit \tmovw %cx,%ss\t# stack locore.S Reference 1\nsys/mips/mips/locore.S\nCHERI specific\n create CHERI kernel sealing cap, store as kernel_sealcap; create a universal user cap covering all userspace, store as userspace_cap; create CHERI user sealing cap, user_sealcap; swap cap swap_restore_cap more at cheribsd booting\nGLOBAL(btext) ASM_ENTRY(_start) VECTOR(_locore, unknown) ... /* * Initialize stack and call machine startup. */ PTR_LA\tsp, _C_LABEL(pcpu_space) PTR_ADDU\tsp, (PAGE_SIZE * 2) - CALLFRAME_SIZ REG_S\tzero, CALLFRAME_RA(sp)\t# Zero out old ra for debugger REG_S\tzero, CALLFRAME_SP(sp)\t# Zero out old fp for debugger  PTR_LA\tgp, _C_LABEL(_gp) /* Call the platform-specific startup code. */ PTR_LA\tt9, _C_LABEL(platform_start) jalr\tt9 nop PTR_LA\tsp, _C_LABEL(thread0_st) PTR_L\ta0, TD_PCB(sp) REG_LI\tt0, ~7 and\ta0, a0, t0 PTR_SUBU\tsp, a0, CALLFRAME_SIZ PTR_LA\tt9, _C_LABEL(mi_startup) jalr\tt9\t# mi_startup(frame) \tsw\tzero, (CALLFRAME_SIZ - 8)(sp)\t# Zero out old fp for debugger  PANIC(\u0026#34;Startup failed!\u0026#34;)  platform_start stack pointer: pcpu_space + (page size * 2) - callframe_size\nmi_startup   Cheribsd github ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/sysinit/",
	"title": "Sysinit",
	"tags": [],
	"description": "",
	"content": " Reference 1\ngeneric call sort and dispatch mechanism;\ndynamic initialization of kernel;\nallows kernel subsystems to be reordered, and added, removed, and replaced at kernel link time when kernel or one of its module is loaded;\nwithout having to edit a statically ordered initialization routing and recompile the kernel;\nkernel linker\nLinker: take static data declared at multiple locations throughout a program\u0026rsquo;s source and group it together as a single contiguous chunk of data. This linker technique is called a \u0026ldquo;linker set\u0026rdquo;.\nSYSINIT uses two linker sets to maintain two data sets containing each consumer\u0026rsquo;s call order, function, and a pointer to the data to pass to that function. Startup and shutdown data sets.\nTwo priorities:\n subsystem ID, predcalared orders insys/kernel.h: sysinit_sub_id; secondary priority within a subsystem, predcalared orders in sys/kernel.h:sysinit_elem_order;  Two Uses of SYSINIT:\n function dispatch at system startup and kernel module loads; function dispatch at system shutdown and kernel module unload.\n system startup SYSINIT to initialize data structures. e.g. process scheduling subsystem uses a SYSINIT to initialize the run queue data structure.\n  Definition in sys/kernel.h\nSYSINIT(uniquifier, subsystem, order, func, ident) // for startup data set SYSUNINIT(uniquifier, subsystem, order, func, ident) // for shutdown data set\nSYSINIT() macro: takes a uniquifier (that SYSINIT uses to identify the particular function dispatch data), the subsystem order, the subsystem element order, the function to call, and the data to pass the function. All functions must take a constant pointer argument.\nExample:\n#include \u0026lt;sys/kernel.h\u0026gt; void foo_null(void *unused) { foo_doo(); } SYSINIT(foo, SI_SUB_FOO, SI_ORDER_FOO, foo_null, NULL); struct foo foo_voodoo = { FOO_VOODOO; } void foo_arg(void *vdata) { struct foo *foo = (struct foo *)vdata; foo_data(foo); } SYSINIT(bar, SI_SUB_FOO, SI_ORDER_FOO, foo_arg, \u0026amp;foo_voodoo); SI_SUB_FOO and SI_ORDER_FOO defined in sysinit_sub_id and sysinit_elem_order enum\u0026rsquo;s.\n  The SYSINIT Framework ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/info-flow/2009-micro-cfo/",
	"title": "2009 Micro Cfo",
	"tags": [],
	"description": "",
	"content": " Reference 1\nDeferred exception Itanium: deferred exception tracking. can be used to support for information flow tracking.\nDeferred exception for speculatively executed instructions. An exception is deferred for later handling instead of being thrown out immediately.\nEach general purpose register is extended with an additional deferred exception token (NaT, Not a Thing) to keep track of exceptions.\nToken is propagated along with the executing instructions.\nInstruction to tnat check the existence of exceptions. chk.s jumps to some recovery code if the register is with an exception token.\nChanges to GCC: add passes\n  Control Flow Obfuscation with Information Flow Tracking. By Haibo Chen, et al. MICRO, 2009. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Escape Capture  References: Escape Analysis \u0026amp; Capture Tracking in LLVM Pointer Capture: A pointer value is captured if the function makes a copy of any part of the pointer that outlives the call. Pinter Escape: A pointer value escapes if it is accessible from outside the current function or thread. The latter case is sometimes considered separate and called thread-escape. Capture and Escape are not opposites: Informally, escaping is concerned with the contents of the pointer, while capturing is concerned with the pointer itself 1.\n Reaching Def  Reference 1 Reaching Definition Analysis, (reaching assignment analysis): An assignment (called a definition in classical literature) of the form $[x:=a]^l$ may reach a certain program point (typically the entry or exit of an elementary block) if there is an execution of the program where $x$ was last assigned a value at $l$ when the program point is reached. For example, for the factorial program below: $[y:=x]^1; [z:=1]^2; while [y\u0026gt;1]^3 do ([z:=z*y]^4; [y:=y-1]^5); [y:=0]^6$\n Interprocedural  References: Ch12 of Dragon Book1. Static Program Analysis: Part 7 \u0026ndash; Interprocedural analysis Intra-procedural Analysis Most compiler optimizations are performed on procedures one at a time. We refer to such analyses as intraprocedural. These analyses conservatively assume that procedures invoked may alter the state of all the variables visible to the procedures and that they may create all possible side effects, such as modifying any of the variables visible to the procedure or generating exceptions that cause the unwinding of the call stack.\n Complexity  Reference: References: [1] Static Program Analysis, Anders Moller, and Micheal I. Schwartzbach, 2018. Questions/Proposals To decide whether any given a program will halt or not is undecidable. However, there are many programs (probably small or large) that we already know it will halt, or will never halt. How many are there? What is the common feature of these programs? Could we statically describe some (not all) of them? Undecidability of Program Correctness\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/papers/19-arm-os/",
	"title": "2019 Arm Os",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Scalable Translation Validation of Unverified Legacy OS Code. FMCAD, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/diff-good-bad/",
	"title": "Diff Good Bad",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context. ICSE. 2015. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/papers/",
	"title": "Papers",
	"tags": [],
	"description": "",
	"content": "Reference 1\n CSpec  Reference 1 201901 note. Verifying concurrent software using movers in CSPEC. OSDI, 2018. ↩  2019 Arm Os  Reference 1 Scalable Translation Validation of Unverified Legacy OS Code. FMCAD, 2019. ↩  Intscope   Reference 1 Decompiler: Bestar, IDA Pro as front-end. translates x86 assembl into PANDA IR (freshly designed). Symbolic execution engine: leverage framework of GiNac[^c8]. Path Validator and Integer Overflow Checker: STP, a decision procedure for bit-vectors and arrays. Evaluation 20 zero-day integer overflows in QEMU, Xen, Xine, MPlayer, VLC. [^c8] IntScope: Automatically Detecting Integer Overflow Vulnerability in X86 Binary Using Symbolic Execution. NDSS. 2009. ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/papers/intscope/",
	"title": "Intscope",
	"tags": [],
	"description": "",
	"content": " Reference 1\nDecompiler: Bestar, IDA Pro as front-end.\ntranslates x86 assembl into PANDA IR (freshly designed).\nSymbolic execution engine: leverage framework of GiNac[^c8].\nPath Validator and Integer Overflow Checker: STP, a decision procedure for bit-vectors and arrays.\nEvaluation 20 zero-day integer overflows in QEMU, Xen, Xine, MPlayer, VLC.\n[^c8]\n  IntScope: Automatically Detecting Integer Overflow Vulnerability in X86 Binary Using Symbolic Execution. NDSS. 2009. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/temporal-logic/",
	"title": "Temporal Logic",
	"tags": [],
	"description": "",
	"content": "Reference 1\n CTL   References: Lecture 7, Computation Tree Logics Path Quantifier $A$: for every path. $E$: there exists a path. Linear-time operators $\\boldsymbol{X}_p$: $p$ holds next time. $\\boldsymbol{F}_p$: $p$ holds sometime in the future. $\\boldsymbol{G}_p$: $p$ holds globally in the future. $p\\boldsymbol{U}q$: $p$ holds until $q$ holds. Path Formulas and State Formulas More   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/mc/",
	"title": "Model Checking",
	"tags": [],
	"description": "",
	"content": "References:\n Model Checking @CMU \n Model Checking Code @CMU Specification and Verification Center @CMU  wiki: Model Checking, contains a list of model checking tools.\n Model Checking简述\n   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/tools/isabelle/",
	"title": "Isabelle",
	"tags": [],
	"description": "",
	"content": "References:\nHigher order logic (HOL)\n Isar - Intelligible semi-automated reasoning.\n Concrete Semantics\n Video: Haskell for imperative programmers\n Video: Math 220, Pepperdine.edu\n  Structured Proof Language.\nArithmetic Expressions:\n   Concrete Abstract     5 N 5 (constants)   x V \u0026ldquo;x\u0026rdquo; (variables)   x + y Plus (V \u0026ldquo;x\u0026rdquo;) (V \u0026ldquo;y\u0026rdquo;)   2 + (z + 3) Plus (N 2) (Plus (V \u0026ldquo;z\u0026rdquo;) (N 3))     "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/idt/",
	"title": "IDT: interrupt descriptor table",
	"tags": [],
	"description": "",
	"content": " Reference 1\nstatic void cpu_startup(void *); SYSINIT(cpu, SI_SUB_CPU, SI_ORDER_FIRST, cpu_startup, NULL);  The Table cpu_startup(void *dummy) in sys/mips/mips/machdep.c\n\u0026ndash;\u0026gt; cpu_init_interrupts();\ncpu_init_interrupts()[sys/mips/mips/intr_machdep.c]: perform initialization of interrupts prior to setting handlings.\n compose a name sintxx (2 soft_irqs), or intxx (6 hard_irqs); call mips_intrcnt_create() to name the intrnames; increase the global counter intrcnt_index;  void mips_vector_init(void)[sys/mips/mips/machdep.c]: initialize the hardware exception vectors, and the jump table used to call locore cache and TLB management functions, based on the kind of CPU the kernel is running on.\n copy TLB exception vector code to MIPS_UTLB_MISS_EXC_VEC(=0x8000,0000); copy TLB exception vector code to MIPS_XTLB_MISS_EXC_VEC(=0x8000,0080); copy MIPS exception vector code to MIPS_GEN_EXC_VEC (=0x8000,0180); copy MIPS Cache vector code to MIPS_CACHE_ERR_EXC_VEC (=0x8000,0100); (CHERI) copy MIPS exception vector code to CHERI_CCALL_EXC_VEC (=0x8000,0280);  The Trap Gates sys/mips/mips/exception.S\nMipsException: handles all exceptions except RESET and TLBMiss.\nRESET\nMipsTLBMiss: vector address 0x8000,0000\n  FreeBSD kernel source. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/silhouette/cves/",
	"title": "Cves",
	"tags": [],
	"description": "",
	"content": "Reference 1\nTwo CVEs on FreeRTOS:\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/silhouette/",
	"title": "Silhouette",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Cves  Reference 1 Two CVEs on FreeRTOS: reference ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/ccxx/mesh/",
	"title": "Mesh: Fragmentation in C/C++",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  MESH: Compacting Memory Management for C/C++ Applications, PLDI, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/ccxx/",
	"title": "C &amp; C++",
	"tags": [],
	"description": "",
	"content": " Reference 1\nCopy Elision when return a struct.\n Mesh: Fragmentation in C/C\u0026#43;\u0026#43;  Reference 1 MESH: Compacting Memory Management for C/C++ Applications, PLDI, 2019. ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": " Reference 1\nTwo Types of Logic Blocks Combinational Logic Blocks without memory are called combinational; the output of a combinational block depends only on the current input.\nCan be defined by truth table, boolean algebra.\nDecoders: n-bit input -\u0026gt; 2^n outputs\nMultiplexors: a selector: output is one of the inputs that is selected by a control.\nSequential Logic Sequential logic is logic including state. In blocks with memory, the outputs can depends on both the inputs and the value stored in memory, which is called the state of the logic block.\nTwo level representation Any logic can be implemented with only AND, OR, and NOT functions.\nAny logic function can be written in a canonical form, where every input is either a true or complemented variable and there are only two levels of gates \u0026ndash; one being AND and the other OR \u0026ndash; with a possible inversion on the final output. ==\u0026gt; such a representation is called a two level representation.\nTwo forms:\nSum-of-products: a logical sum (OR) of products (AND)\nProducts-of-sums: the opposite.\nRegister Transfer Level cite: https://www.sciencedirect.com/topics/computer-science/register-transfer-level\n \u0026ldquo;The register transfer level of modeling circuits in VHDL for use with register transfer level synthesis. Register transfer level is a level of description of a digital design in which the clocked behavior of the design is expressly described in terms of data transfers between storage elements in sequential logic, which may be implied, and combinatorial logic, which may represent any computing or arithmetic-logic-unit logic. RTL modeling allows design hierarchy that represents a structural description of other RTL models.”\n  Gem5  Q\u0026amp;A How does the simulator load the binary into the memory for execution? Reference 1 A memory object: Example system configurations in gem5/configs/: gem5/configs/boot/: for Full-System mode. rcS files. These files will be loaded by the simulator after Linux boots and are executed by the shell. gem5/configs/common/: Caches.py: example cache configuration. Options.py: a script to set a variety of options, such as number of CPUs system clock \u0026hellip; CacheConfig.\n Class: Adv  Aug 29 ECE 401\u0026frasl;201. Prof. Engin Ipek, Cornell from High school to Ph.D. Text book: Computer Arch: a quantitative approach, 6th ed. by John L. Hennessy, David A. Patterson. Org: building computer works; Arch: works faster; FSM design: finite state machine. TA: Ryan Wong; Muhammad Mehdi; 527 CSB office hr. Blackboard. Midterm Oct 29. Final Dec 19. Three verilog projects. Verilog design projects. expand on basic MIPS R3000 processor.\n Arm  ARM on Gem5 References: Extending gem5 for ARM Run FreeBSD on gem5 ARM More Trustzone References: Intro to TrustZone Difference between SGX and TrustZone TrustZone Explained Dan Rosenberg, Reflections on Trusting TrustZone Normal world vs Secure World: Embeded OS vs Secure OS Context Switch normal world use SMC (secure monitor call) instruction to call secure world. ==\u0026gt; exception into the monitor mode (TrustZone kernel) Non-secure bit in Secure Configuration Register; Non-secure bit in the main memory;\n X86   References: reference More  Mips  Reference: MIPS directives. Directives .set pop/push The directives .set push and .set pop may be used to save and restore the current settings for all the options which are controlled by .set. The .set push directive saves the current settings on a stack. The .set pop directive pops the stack and restores the settings. These directives can be useful inside an macro which must change an option such as the ISA level or instruction reordering but does not want to change the state of the code which invoked the macro.\n RISC-V  References: [1] TIMBER-V: Tag-Isolated Memory Bringing Fine-grained Enclaves to RISC-V. NDSS, 201902. paper [2] XuanTie 910, Pingtouge (Honey Badger), 20190725. RISCV Terms Hart: Hardware thread. Spec 20191213, Page 2. More Attacks Reference1 A2: Analog Malicious Hardware Reference1 \u0026ldquo;In the open spaces of an already placed and routed design, we contruct a circuit that use capacitors to siphon charge from nearby wires as they transition between digital values.\n Bluespec  Reference 1 Packages Reference 1 Connectable The Connectable type class defines the module mkConnection, which is used to connect a pair of related types. typeclass Connectable#(type a, type b); module mkConnection#(a x1, b x2)(Empty); endtypeclass Instances of typeclass to be connectable Get and Put instance Connectable#(Get#(a), Put#(a)); One put and another will get the element. Tuples instance Connectable#(Tuple2#(a, c), Tuple2#(b, d)) provisos (Connectable#(a, b), Connectable#(c, d)); This is used by ClientServer to connect the Get of Client to the Put of the Server and visa-versa.\n System Verilog  Reference 1 HDL Languages Hardware description languages. Three elements seldom present in a PL: Concurrency. Representation of time. Representation of structure. Gate and hardware structure persist and have a state even if they are doing nothing. Verilog (1980s) -\u0026gt; Verilog 1.0 (1995) -\u0026gt; Verilog 2.0 (2001) -\u0026gt; Verilog 3.1a (System Verilog, 2005) Extended Verilog to system-level modeling. VHDL (Very High Speed Integrated Circuit) System C Usage: OVM, VMM, UVM System Verilog Object Oriented Programming\n C910   References: reference More  Chisel  References: Chisel Bootcamp Chisel教程汇总 Verilog vs Chisel Comparison Scala Based on Java Virtual Machine (JVM). Scala \u0026ndash; .class \u0026ndash; JVM Scala designed for Domain-Specific Language developers: can build your own language based on Scala. Chisel Type parameters class or function definition can have type paramters, in order to define class/functions with arbitrary types. e.g. the following defines a function myMux which\n  \u0026ldquo;Computer Organization and Design, The Hardware/Software Interface\u0026rdquo;. By David A. Patterson, and John L. Hennessy. 5th ed. 2014. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freertos/",
	"title": "Freertos",
	"tags": [],
	"description": "",
	"content": " References:\n FreeRTOS Implementation  FreeRTOS Implementation  Building Blocks Detailed Example\nMore   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/basics/dominator-tree/",
	"title": "Dominator Tree",
	"tags": [],
	"description": "",
	"content": " In Java GC From Reference 1: Dominator tree of object graph in Java heap analyzer.\nAn object x dominates an object y if every path in the object graph from the start (or the root) node to y must go through x.\nThe immediate dominator x of some object y is the dominator closest to the object y.\nA dominator tree is built out of the object graph. In the dominator tree, each object is the immediate dominator of its children, so dependencies between the objects are easily identified.\n If x is the immediate dominator of y, then the immediate dominator of x also dominates y, and so on. The edges in the dominator tree do not directly correspond to object references from object graph. The objects belonging to the sub-tree of x (i.e. the objects dominated by x) represent the retained set of x ;  In LLVM In LLVM: DominatorTreeWrapperPass is a function pass that will compute and give you the dominator tree for a function.\nDominator tree in the [LLVM DominatorTree Class]:\n A block is said to be forward statically reachable if there is a path from the entry of the function to the block. A statically reachable block may become statically unreachable during optimization. A forward unreachable block may appear in the dominator tree, or it may not. If it does, dominance queries will return results as if all reachable blocks dominate it. When asking for a Node corresponding to a potentially unreachable block, calling code must handle the case where the block was unreachable and the result of getNode() is nullptr. Generally, a block known to be unreachable when the dominator tree is constructed will not be in the tree. One which becomes unreachable after the dominator tree is initially constructed may still exist in the tree, even if the tree is properly updated. Calling code should not rely on the preceding statements; this is stated only to assist human understanding.    Dominator Tree ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": "Reference 1\n DAG - Directed Acyclic Graph  Directed Acyclic Graph (DAG) is a tool that depicts the structure of basic blocks, helps to see the flow of values flowing among the basic blocks, and offers optimizatino too. 1 A directed acyclic graph (DAG) for a basic block: Leaf nodes represent identifiers, names or constants. Interior nodes are labeled by an operator symbol. Nodes are also given a sequence of identifiers for labels to store the computed value.\n Name Mangling  Reference 1 A technique to resolve unique names for programming entities in many modern programming languages. Provides a way of encoding additional information in the name of a function, structure, class or another datatype in order to pass more semantic information from compilers to linkers. Linker: To link different object code together, linker needs a great deal of information on each program entity. For example, to correctly link a function, it needs the function name, the number of arguments and their types, and so on.\n Dominator Tree  In Java GC From Reference 1: Dominator tree of object graph in Java heap analyzer. An object x dominates an object y if every path in the object graph from the start (or the root) node to y must go through x. The immediate dominator x of some object y is the dominator closest to the object y. A dominator tree is built out of the object graph. In the dominator tree, each object is the immediate dominator of its children, so dependencies between the objects are easily identified.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-llvm/passes/",
	"title": "Passes",
	"tags": [],
	"description": "",
	"content": " llvm/lib/Target/Mips/Mips.h\nCheri(Stack)InvalidatePass llvm/lib/Target/Mips/CheriStackInvalidatePass.cpp\nPass Invoked at:\nllvm/lib/Target/Mips/MipsTargetMachine.cpp: void addPostRegAlloc() overide.\nMachine Function Pass: class CheriInvalidatePass : public MachineFunctionPass.\nEvery function do:\n nothing; // all function code is disabled by #if 0  If enabled, for every function do:\n check if a sensitive function with metadata cheri.sensitive.functions; if current function is sensitive:  get the set of storeToStackSlot(LLM: what is this mean) and return instructions for this function (by runOnMachineBasicBlock) if store set is empty, return; if have store instructions: enumerate all return instructions, for each return: zero all capability and non-capability spills.   CheriLoopPointerDecanonicalize Cheri128FailHardPass CheriAddressingModeFolderPass CHERICapFoldIntrinsicsPass CHERICapDirectCallsPass CheriBoundAllocas Add bound information to alloca instructions.\nTracking by commit: 2bda57cca54edb8e928de715bfcb6638ea3e1210\nllvm/lib/CodeGen/CheriBoundAllocas.cpp: class CheriBoundAllocas:\na module pass:\n get data layout; get address space for the data layout; check the capability in data layout \u0026amp; address space: if (!DL.isFatPointer(AllocaAS)); get I8CapTy and SizeTy using context(M-\u0026gt;getContext()), data layout and address space; For every function F in the module M:  get optimization attribute: IsOptNone; get TargetMachine and TargetLowering from TargetPassConfig; get set of allocas in the function: Allocas.clear(); visit(F); choose proper intrinsic ID, BoundedStackCap, according to UseRematerilizableIntrinsic; Get the intrinsic function BoundedStackFn according to the intrinsic ID: Intrinsic::getDeclaration(M, BoundedStackCap, SizeTy); IRBuilder\u0026lt;\u0026gt; B\u0026copy;; // C is LLVMContext; For every AllocaInst *AI in Allocas:  get total uses: AI-\u0026gt;getNumUses(); set insert point: B.setInsertPoint(\u0026hellip;); get alloca type: PointerType *AllocaTy = AI-\u0026gt;getType(); // AllocaTy is here a CheriCap get Type *AllocationTy = AllocaTy -\u0026gt; getElementType(); get Value *ArraySize = AI-\u0026gt;getArraySize(); create a new AS 0 alloca  set alignment find uses of allocas that needs to be bounded: (all or only escaped): BoundsChecker.findUsesThatNeedBounds() : now all or nothing for each use that needs bounds: get instruction of the user; find a proper insert point (PHI or not); insert intrinsics:   code   // We need to convert it to an i8* for the intrinisic. Note: we must  // not reuse a bitcast since otherwise that results in spilling the  // register that was incremented and doing a setbounds in a different  // basic block. This is stupid and we should be either using the  // bounded capability everywhere or be doing inc+setoffset in the  // other block.  Instruction *AllocaI8 = cast\u0026lt;Instruction\u0026gt;(B.CreateBitCast(AI, I8CapTy)); auto WithBounds = B.CreateCall(SetBoundsIntrin, {AllocaI8, Size}); const_cast\u0026lt;Use *\u0026gt;(U)-\u0026gt;set(B.CreateBitCast(WithBounds, AllocaTy));        llvm/lib/CodeGen/CodeGen.cpp: call initializeCheriBoundAllocasPass(Registry); in llvm::initializeCodeGen(...)\nllvm/include/llvm/initializePasses.h: void initializeCheriBoundAllocasPass(PassRegistry \u0026amp;);\nllvm/include/llvm/Passes.h:   code   /// List of target independent CodeGen pass IDs. namespace llvm { ///...  /// Create CHERI pass to bound alloca.s  ModulePass *createCheriBoundAllocasPass(); } // End llvm namespace   \nFoldCapIntrinsics file: llvm/lib/Transforms/CHERICap/FoldCapIntrinsics.cpp\nFold Capability Intrinsics.\n depends on TargetLibraryInfoWrapperPass  runOnModule:\n  code: CHERICapFoldIntrinsics.runOnModule   bool runOnModule(Module \u0026amp;M) override { if (skipModule(M)) return false; TLI = \u0026amp;getAnalysis\u0026lt;TargetLibraryInfoWrapperPass\u0026gt;().getTLI(); Modified = false; DL = \u0026amp;M.getDataLayout(); LLVMContext \u0026amp;C = M.getContext(); I8CapTy = Type::getInt8PtrTy(C, 200); CapAddrTy = Type::getIntNTy(C, DL-\u0026gt;getPointerBaseSizeInBits(200)); CapSizeTy = Type::getIntNTy(C, DL-\u0026gt;getIndexSizeInBits(200)); // Don\u0026#39;t add these intrinsics to the module if none of them are used:  IncOffset = M.getFunction( Intrinsic::getName(Intrinsic::cheri_cap_offset_increment, CapSizeTy)); SetOffset = M.getFunction(Intrinsic::getName(Intrinsic::cheri_cap_offset_set, CapSizeTy)); GetOffset = M.getFunction(Intrinsic::getName(Intrinsic::cheri_cap_offset_get, CapSizeTy)); SetAddr = M.getFunction(Intrinsic::getName(Intrinsic::cheri_cap_address_set, CapAddrTy)); GetAddr = M.getFunction(Intrinsic::getName(Intrinsic::cheri_cap_address_get, CapAddrTy)); // at least one intrinsic was used -\u0026gt; we need to run the fold  // setoffset/incoffset pass  if (IncOffset || SetOffset || GetOffset) { // Ensure that all the intrinsics exist in the module  if (!IncOffset) IncOffset = Intrinsic::getDeclaration( \u0026amp;M, Intrinsic::cheri_cap_offset_increment, CapSizeTy); if (!SetOffset) SetOffset = Intrinsic::getDeclaration( \u0026amp;M, Intrinsic::cheri_cap_offset_set, CapSizeTy); if (!GetOffset) GetOffset = Intrinsic::getDeclaration( \u0026amp;M, Intrinsic::cheri_cap_offset_get, CapSizeTy); // TODO: does the order here matter?  foldIncOffset(); foldSetOffset(\u0026amp;M); } if (SetAddr || GetAddr) { // Ensure that all the intrinsics exist in the module  if (!SetAddr) SetAddr = Intrinsic::getDeclaration( \u0026amp;M, Intrinsic::cheri_cap_address_set, CapAddrTy); if (!GetAddr) GetAddr = Intrinsic::getDeclaration( \u0026amp;M, Intrinsic::cheri_cap_address_get, CapAddrTy); if (!IncOffset) IncOffset = Intrinsic::getDeclaration( \u0026amp;M, Intrinsic::cheri_cap_offset_increment, CapSizeTy); // TODO: does the order here matter?  foldSetAddress(\u0026amp;M); } foldGetIntrinisics(\u0026amp;M); return Modified; }    PureCapABICalls file: llvm/lib/Transforms/CHERICap/PureCapABICalls.cpp\nThe pass that transform PCC-relative calls into direct calls (so that they can be inlined) and then back again (so that we generate the correct code).\nclass: CheriCapDirectCalls\n  code: CheriCapDirectCalls.runOnFunction   bool runOnFunction(Function \u0026amp;F) override { Modified = false; DeadInstructions.clear(); visit(F); for (auto *V : DeadInstructions) RecursivelyDeleteTriviallyDeadInstructions(V); return Modified; }    CheriLogSetBoundPass A util Function pass; every instruction:\n only applies to call instruction  or invoke instruction  first get the CalledFunc and attribute list AL for this instruction. get the attribute from CalledFunc. logging the allocation size from the attribute using a $\\lambda$ func: LogAllocSize: a)  The function of LogAllocSize:\n Input: std::pair\u0026lt;unsigned Optional\u0026lt;unsigned\u0026gt;\u0026gt; AllocSize; Output: by side effects of cheri::CSetBoundsStats-\u0026gt;add(Alignment, KnownSize, \u0026quot;function with alloc_size\u0026quot;, cheri::SetBoundsPointerSource::Heap, \u0026quot;call to \u0026quot; + (CalledFunc ? CalledFunc-\u0026gt;getName() : \u0026quot;function pointer\u0026quot;), cheri::inferSourceLocation(\u0026amp;I), SizeMultipleOf)  Pointer Type Impl. file: llvm/lib/IR/Type.cpp\n PointerType *PointerType::get(Type *EltTy, unsigned AddressSpace)    code   PointerType *PointerType::get(Type *EltTy, unsigned AddressSpace) { assert(EltTy \u0026amp;\u0026amp; \u0026#34;Can\u0026#39;t get a pointer to \u0026lt;null\u0026gt; type!\u0026#34;); assert(isValidElementType(EltTy) \u0026amp;\u0026amp; \u0026#34;Invalid type for pointer element!\u0026#34;); LLVMContextImpl *CImpl = EltTy-\u0026gt;getContext().pImpl; // Since AddressSpace #0 is the common case, we special case it.  PointerType *\u0026amp;Entry = AddressSpace == 0 ? CImpl-\u0026gt;PointerTypes[EltTy] : CImpl-\u0026gt;ASPointerTypes[std::make_pair(EltTy, AddressSpace)]; if (!Entry) Entry = new (CImpl-\u0026gt;Alloc) PointerType(EltTy, AddressSpace); return Entry; }    All Passes llvm/include/llvm/initializePasses.h:\n  passes       llvm/include/llvm/Passes.h:\n  passes       llvm/lib/Target/Mips/MipsTargetMachine.cpp:\n initializeCHERICapDirectCallsPass(*PR); initializeCHERICapFoldIntrinsicsPass(*PR); initializeCheriAddressingModeFolderPass(*PR); initializeCheriRangeCheckerPass(*PR); void addPostRegAlloc() override { if (getMipsSubtarget().isCheri()) addPass(createCheriInvalidatePass()); } void MipsPassConfig::addIRPasses() { ... if (getMipsSubtarget().isCheri()) { if (getOptLevel() != CodeGenOpt::Level::None) { addPass(createCHERICapFoldIntrinsicsPass()); } addPass(createCheriLoopPointerDecanonicalize()); addPass(createAggressiveDCEPass()); addPass(createCheriRangeChecker()); addPass(createCheriBoundAllocasPass()); } } void MipsPassConfig::addPreRegAlloc() { if (getMipsSubtarget().isCheri()) { addPass(createCheriAddressingModeFolder()); // The CheriAddressingModeFolder can sometimes produce new dead instructions // be sure to clean them up: if (getOptLevel() != CodeGenOpt::Level::None) addPass(\u0026amp;DeadMachineInstructionElimID); addPass(createCheri128FailHardPass()); } }    complete passes init/invoke   extern \u0026#34;C\u0026#34; void LLVMInitializeMipsTarget() { // Register the target.  RegisterTargetMachine\u0026lt;MipsebTargetMachine\u0026gt; X(getTheMipsTarget()); RegisterTargetMachine\u0026lt;MipselTargetMachine\u0026gt; Y(getTheMipselTarget()); RegisterTargetMachine\u0026lt;MipsebTargetMachine\u0026gt; A(getTheMips64Target()); RegisterTargetMachine\u0026lt;MipselTargetMachine\u0026gt; B(getTheMips64elTarget()); RegisterTargetMachine\u0026lt;MipsCheriTargetMachine\u0026gt; C(getTheMipsCheriTarget()); PassRegistry *PR = PassRegistry::getPassRegistry(); ... initializeCHERICapDirectCallsPass(*PR); initializeCHERICapFoldIntrinsicsPass(*PR); initializeCheriAddressingModeFolderPass(*PR); initializeCheriRangeCheckerPass(*PR); } void addPostRegAlloc() override { if (getMipsSubtarget().isCheri()) addPass(createCheriInvalidatePass()); } }; } // end anonymous namespace  void MipsPassConfig::addIRPasses() { TargetPassConfig::addIRPasses(); addPass(createAtomicExpandPass()); ... if (getMipsSubtarget().isCheri()) { if (getOptLevel() != CodeGenOpt::Level::None) { addPass(createCHERICapFoldIntrinsicsPass()); } addPass(createCheriLoopPointerDecanonicalize()); addPass(createAggressiveDCEPass()); addPass(createCheriRangeChecker()); addPass(createCheriBoundAllocasPass()); } } // Install an instruction selector pass using // the ISelDag to gen Mips code. bool MipsPassConfig::addInstSelector() { addPass(createMipsModuleISelDagPass()); addPass(createMips16ISelDag(getMipsTargetMachine(), getOptLevel())); addPass(createMipsSEISelDag(getMipsTargetMachine(), getOptLevel())); return false; } void MipsPassConfig::addPreRegAlloc() { addPass(createMipsOptimizePICCallPass()); if (getMipsSubtarget().isCheri()) { addPass(createCheriAddressingModeFolder()); // The CheriAddressingModeFolder can sometimes produce new dead instructions  // be sure to clean them up:  if (getOptLevel() != CodeGenOpt::Level::None) addPass(\u0026amp;DeadMachineInstructionElimID); addPass(createCheri128FailHardPass()); } } TargetTransformInfo MipsTargetMachine::getTargetTransformInfo(const Function \u0026amp;F) { if (Subtarget-\u0026gt;allowMixed16_32()) { LLVM_DEBUG(errs() \u0026lt;\u0026lt; \u0026#34;No Target Transform Info Pass Added\\n\u0026#34;); // FIXME: This is no longer necessary as the TTI returned is per-function.  return TargetTransformInfo(F.getParent()-\u0026gt;getDataLayout()); } LLVM_DEBUG(errs() \u0026lt;\u0026lt; \u0026#34;Target Transform Info Pass Added\\n\u0026#34;); return TargetTransformInfo(BasicTTIImpl(this, F)); } // Implemented by targets that want to run passes immediately before // machine code is emitted. return true if -print-machineinstrs should // print out the code after the passes. void MipsPassConfig::addPreEmitPass() { // Expand pseudo instructions that are sensitive to register allocation.  addPass(createMipsExpandPseudoPass()); // The microMIPS size reduction pass performs instruction reselection for  // instructions which can be remapped to a 16 bit instruction.  addPass(createMicroMipsSizeReducePass()); // The delay slot filler pass can potientially create forbidden slot hazards  // for MIPSR6 and therefore it should go before MipsBranchExpansion pass.  addPass(createMipsDelaySlotFillerPass()); // This pass expands branches and takes care about the forbidden slot hazards.  // Expanding branches may potentially create forbidden slot hazards for  // MIPSR6, and fixing such hazard may potentially break a branch by extending  // its offset out of range. That\u0026#39;s why this pass combine these two tasks, and  // runs them alternately until one of them finishes without any changes. Only  // then we can be sure that all branches are expanded properly and no hazards  // exists.  // Any new pass should go before this pass.  addPass(createMipsBranchExpansion()); addPass(createMipsConstantIslandPass()); } bool MipsPassConfig::addIRTranslator() { addPass(new IRTranslator()); return false; } void MipsPassConfig::addPreLegalizeMachineIR() { addPass(createMipsPreLegalizeCombiner()); } bool MipsPassConfig::addLegalizeMachineIR() { addPass(new Legalizer()); return false; } bool MipsPassConfig::addRegBankSelect() { addPass(new RegBankSelect()); return false; } bool MipsPassConfig::addGlobalInstructionSelect() { addPass(new InstructionSelect()); return false; }    Reference 1\n Bound Allocas  References: llvm/lib/CodeGen/CheriBoundAllocas.cpp Overview A Module pass with instruction visitor: class CheriBoundAllocas : public ModulePass, public InstVisitor\u0026lt;CheriBoundAllocas\u0026gt; Initialization: initializeCheriBoundAllocaPass() declared in llvm/include/llvm/InitializePasses.h impl in llvm/lib/CodeGen/CheriBoundAllocas.cpp: INITIALIZE_PASS(\u0026hellip;) called in: llvm/lib/CodeGen/CheriBoundAllocas.cpp: CheriBoundAllocas() llvm/lib/CodeGen/CodeGen.cpp: initializeCodeGen() llvm/tools/opt/opt.cpp: main() Pass Creation: createCheriBoundAllocasPass() declared in llvm/include/llvm/CodeGen/Passes.h called in Mips: llvm/lib/Target/Mips/MipsTargetMachine.cpp: MipsPassConfig::addIRPasses() RISCV: llvm/lib/Target/RISCV/RISCVTargetMachine.cpp: RISCVPassConfig::addIRPasses() Adding bound instruction: Get intrinsic: Intrinsic::getDeclaration(M, Intrinsic::cheri_cap_bounds_set, SizeTy); // llvm/lib/CodeGen/CheriBoundAllocas.cpp // Intrinsic handle as function Function *SetBoundsIntrin = Intrinsic::getDeclaration(M, Intrinsic::cheri_cap_bounds_set, SizeTy); Intrinsic::ID BoundedStackCap = UseRematerializableIntrinsic ?\n CheriRangeChecker Pass  References: llvm/lib/Target/Mips/CheriRangeChecker.cpp Add LLVM pass to the pipeline Overview Only in Mips, not in RISCV. A function pass with instruction visitor: class CheriRangeChecker : public FunctionPass, public InstVisitor\u0026lt;CheriRangeChecker\u0026gt;; Pass is initialized at void initializeCheriRangeCheckerPass(PassRegistry \u0026amp;); in llvm/lib/Target/Mips/Mips.h (LLM: this init func\u0026rsquo;s implementation will be automatically generated by LLVM using macro INITIALIZE_PASS_BEGIN). \u0026lt;\u0026ndash; llvm/lib/Target/Mips/MipsTargetMachine.cpp: LLVMInitializeMipsTarget(): initializeCheriRangeCheckerPass(*PR); Pass is invoked at llvm/lib/Target/Mips/MipsTargetMachine.cpp: void MipsPassConfig::addIRPasses(): addPass(createCheriRangeChecker()); Functions/Steps: runOnFunction(): visit(F): collect pairs of range info and correspondign cast instruction in vectors: \u0026lt;AllocaOperands, xxxCastInst\u0026gt; in Casts and \u0026lt;AllocaOperands, ConstantCast\u0026gt; in ConstantCasts: visitAddrSpaceCast(): get ValueSource of the cast operand: auto Src = getValueSource(ASC.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/paperwriting/discussions/",
	"title": "Limitations",
	"tags": [],
	"description": "",
	"content": " Limitation Every work has limitations. Some inherits from the design; Some exist because they are just obvious but complex to implement. Reviewers might be interested in this to see how you understand the solution by yourself. Some reviewers will reject you if they pointed out some limitations that you haven\u0026rsquo;t discussed in the paper. However, if you can discuss the limitation of your work thoroughly, this will show the depth of your understanding in the field and will get your work be understood better.\nAs a security solution for a computer system, here are some factors can be easily forgotten but might be important to discuss:\n Is this solution compatible with other similar security solutions?  Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/pagebits/pool-dangling/",
	"title": "Dang",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to detect there is still reference pointing to a pool?\n What if there is a buffer overflow to the freed variable on the same page?\n  Reference 1\nProblem:\nAllocate only one object per physical page would be quickly exhaust physical memory. Changing the allocation in this way would potentially lead to poor cache performance in physically indexed cache.\nOverview:\n Use a new virtual page for each allocation of the program but map it to the same physical page as the original allocator.\n after malloc returns with address a, remap this address from a to new_a. E.g. via mremap(old_address, old_size, new_size, flags); This way, we get a new virtual address for the physical address; keep old virt address for deallocatio later;  Implemented without any changes to the underlying memory allocator.\n with a small addition to the metadata for the allocator; no change to the allocation algorithm.  Use automatic pool allocation to reuse virtual pages. Partition memory into pools according to their lifetimes and allows us to reuse virtual pages.\n    Efficiently Detecting All Dangling Pointer Uses in Prodction Servers. DSN, 2006. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/modern89/",
	"title": "Modern Logic 89",
	"tags": [],
	"description": "",
	"content": " Top Wonderings  Formal logic vs informal logic, how can they assist the artificial intelligence/life in general?  The representation of the knowledge(model, data, algorithms, problems, etc)? What kind of representations under the hood?   Reference 1： 逻辑学从哲学中独立出来的趋势以后便被人们发现是属于数学。因此当把作为数学的逻辑学同传统逻辑学突出地区分开来的时候，人们就将其成为符号逻辑（symbolic logic）或者数理逻辑（mathematical logic）。当然也是有许多人只称其为逻辑学或现代逻辑学的。\n然而逻辑学并不是全部成了数学，它尽管限制在符号逻辑里，也还是有不能归入数学的哲学方面。\n辩证法（dialectic）\n非形式逻辑（informal logic），日常语言学派，日常语言分析；\n形式逻辑（formal logic），人工语言学派，对人工语言的分析，采用符号逻辑方法构成人工语言；\n形式科学与经验科学 形式科学，论证，理论内完成的证明。\n经验科学，实证，以对经验事实观察为必要条件的证明。\n归根到底，最终决定真假的必须是实证。\n对象科学与元科学 一切学问都使用语言来构成理论，而在理论中又有对象理论（object theory）和元理论（metatheory）的区分。即一切学问都具有对象理论和元理论两个方面。\n对象科学，主要着重于对象理论；元科学，主要着重于元理论。\n对象科学例子：\n 自然科学：主要着重于以自然为对象的对象理论。 人文·社会科学：以将人类·社会为对象的对象理论作为主要观点的对象科学。 普通数学：以数、集合等等为对象的对象科学。  元科学例子：\n 数学基础论（the foundations of mathematics）：以数学的元理论为主要观点的元科学；关于数学的数学，元数学（metamathematics）。 逻辑学：以元理论为主要观点的元科学。用元逻辑学（metalogic）以强调逻辑学的元科学性。比如，逻辑学最基础的部分是关于语句的研究，称为语句逻辑（sentential logic），相继部分是关于谓词的研究，成为谓词逻辑（predicate logic）。 哲学：比如，认识论，是对于以表现知识为主要内容的理论之反思式的研究，它是关于知识的知识，所以是元科学。存在论和价值论也都明显的是元科学。  对象理论，是关于语言之外的对象的理论；元理论，是关于语言的理论。所以在元科学中使用的方法主要是语言分析（linguistic analysis）。\n Logic Methods  Q\u0026amp;A 什么是语形论/语义论/语用论方法？ 什么是应用逻辑？ Reference 1 （前言） 对逻辑方法的大致划分，三个方面： 语形论方法 语义论方法 语用论方法 纯逻辑（不包括\n  现代逻辑方法论，永井成男，1989. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/ir/",
	"title": "LLVM IR",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A Reference 1\nExample: class A { public: int f; } A* __capability a = new A; a-\u0026gt;f = 42;%call = tail call i8 addrspace(200)* @operator new(unsigned long)(i64 zeroext 4) %f = bitcast i8 addrspace(200)* %call to i32 addrspace(200)* store i32 42, i32 addrspace(200)* %f   LLVM Language Reference Manual ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/tag-ptr/",
	"title": "Tagged Pointer",
	"tags": [],
	"description": "",
	"content": " Reference 1\nFolding tags into the pointer By alignment: Certain types of data will be aligned to the size of data, often a word or multiple thereof. This discrepancy leaves a few of the least significant bits of the pointer unused, which can be used for tags \u0026ndash; most often as a bit field (each bit a separate tag) \u0026ndash; as long as code that uses the pointer masks out these bits before accessing memory.\nFor example, 32-bit architecture, word size is 32bits = 4 bytes; thus word-aligned addresses are always a multiple of 4, hence end in 00, leaving the last 2 bits available. On 64-bit architecture, a word is 64 bits word = 8 bytes; so word aligned addresses end in 000, leaving last 3 bits available. For word-addressable architectures, word-aligned data does not leave any bits available.\nIn some operating systems, virtual addresses are narrower than the overall architecture width, which leaves the most significant bits available for tags. On 64-bit architectures, many practical 64-bit processors have narrower addresses. Note that the virtual address width may be narrower than the physical address width, which in turn may be narrower than the architectural width; for tagging of pointers in user space, the virtual address space provided by the operating system (in turn provided by the memory management unit) is the relevant width.\nMore  ARM MTE. ARM pointer authentication\n CHERI Tagged Memory\n Intel MPX\n   In-Fat Pointer   References: In-Fat Pointer: Hardware-Assisted Tagged-Pointer Spatial Memory Safety Defense with Subobject Granularity Protection More   wiki: Tagged Pointer ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/vghost/svamem/",
	"title": ".svamem",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Why not all sva code be put into svamem section, instead, just a selected portion of data structures in libsva?  Linker Script   .svamem section   // file // sys/conf/ldscript.amd64 /* Create the SVA data section */ _svastart = ALIGN(0x1000); .svamem ALIGN(0x1000) : { SVAPTPages = .; . = . + 4194304; *(svamem) _svaend = .; }   Variables: _svastart, _svaend, SVAPTPages, Used in\n SVA/SVA/lib/checks.c: to compute svamemlen and being checked against.   code: svamemlen check   // file // SVA/SVA/lib/checks.c void sva_check_buffer (uintptr_t start, uintptr_t len) { ... uintptr_t nstart = start - SECMEMSTART; uintptr_t nend = end - SECMEMSTART; if ((nstart \u0026lt;= secmemlen) || (nend \u0026lt;= secmemlen)) { panic (\u0026#34;SVA: Invalid buffer access: %lx %lx\\n\u0026#34;, start, end); } }    Section Attribute __attribute__ ((section (\u0026quot;svamem\u0026quot;))), used in\nSVA/SVA/lib/\n init.c:  static struct gate_descriptor sva_idt[256]  interrupt.c:  static struct CPUState realCPUState[numProcessors] static int nextIndex; // ???? LLM: thus not all sva code/data are stored in svamem.  keys.c:  struct translation translations [4096];  mmu.c:  struct PTInfo PTPages[1024] __attribute__ ((section (\u0026quot;svamem\u0026quot;))); extern unsigned char SVAPTPages[1024][X86_PAGE_SIZE]__attribute__ ((section (\u0026quot;svamem\u0026quot;)));  thread_stack.c: __attribute__ ((aligned (16)))  static struct SVAThread Threads[THREAD_STACK_SIZE] static struct FT_stack_fthreads   Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/iot/batteryless/",
	"title": "Batteryless Computing",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Devices that survive using harvested enegy, store that energy in small cpacitors, and work opportunistically maintenance-free for decades. Devices that make the most of energy when it is available and get useful work done in the face of frequent power failures.\n Computational RFIDs2.\n  Batteries Not Included. pdf ↩ A. N. Parks, A. P. Sample, Y. Zhao, and J. R. Smith. A wireless sensing platform utilizing ambient RF energy. In Proceedings of the 2013 IEEE Radio and Wireless Symposium. IEEE, 2013, 331–333. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-compart-papers/2017-fm-compart/",
	"title": "Beyond Good and Evil: Formalizing the Security Guarantees of Compartmentalizing Compilation",
	"tags": [],
	"description": "",
	"content": " Reference 1\nA new security property, secure compartmentalizing compilation (SCC), that formally characterizes the guarantees provided by compartmentalizing compilation and clarifies its attacker model.\n Starting from the fully abstract compilation; Identify three important limitations that make full abstract compilation unsuitable for compartmentalization; Lifting the three limitations; ??? How Illustrate this with a compiler from a simple unsafe imperative language with procedures to a compartmentalized abstract machine;  Fully Abstract Compilation Notion of fully abstract compilation: 2 3 4 5 6 7 8 9 10 11 12.\nA fully abstract compiler toolchain contains compiler, linker, loader, and underlying architecture with its security mechanism. The toolchain protects the interactions between a compiled program and its low-level environment, allowing programmers to reason soundly about the behavior of their code when it is placed in an arbitrary target-language context, by considering only its behavior in arbitrary source-language contexts.\nIn particular, if we link the code produced by such a compiler against arbitrary low-level libraries \u0026ndash; perhaps compiled from an unsafe language or even written directly in assembly \u0026ndash; the resulting execution will not be any less secure than if we had restricted ourselves to library code written in the same high-level language as the calling program.\n  Beyond Good and Evil: Formalizing the Security Guarantees of Compartmentalizing Compilation. 29th IEEE Symposium on Computer Security Foundations (CSF), 2016. arXiv 2017 v6. ↩ M. Abadi. Protection in programming-language translations. Research Report 154. 1998. ↩ M. Abadi and J. Planul. On layout randomization for arrays and functions. POST. 2013. ↩ M. Abadi, J. Planul, and G. D. Plotkin. Layout randomization and nondeterminism. MFPS, 298:29–50, 2013. ↩ M. Abadi and G. D. Plotkin. On protection by layout randomization. TISSEC, 15(2):8, 2012. ↩ P. Agten, R. Strackx, B. Jacobs, and F. Piessens. Secure compilation to modern processors. CSF. 2012. ↩ A. Ahmed and M. Blume. Typed closure conversion preserves observational equivalence. ICFP. 2008 ↩ A. Ahmed and M. Blume. An equivalence-preserving CPS translation via multi-language semantics. ICFP. 2011. ↩ C. Fournet, N. Swamy, J. Chen, P.-É. Dagand, P.-Y. Strub, and B. Livshits. Fully abstract compilation to JavaScript. POPL. 2013. ↩ R. Jagadeesan, C. Pitcher, J. Rathke, and J. Riely. Local memory via layout randomization. CSF. 2011. ↩ M. New, W. J. Bowman, and A. Ahmed. Fully abstract compilation via universal embedding. To appear in 21st International Conference on Functional Programming (ICFP 2016). ↩ M. Patrignani, P. Agten, R. Strackx, B. Jacobs, D. Clarke, and F. Piessens. Secure compilation to protected module architectures. TOPLAS, 2015. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/iot/edge/migration/",
	"title": "Migration",
	"tags": [],
	"description": "",
	"content": "Science Fiction 1:\n 瞬间移动装置将他的大脑和身体逐个细胞地进行扫描并摧毁了他们，然后将信息传到火星，在火星上重新构建人体。\n   《一头想要被吃掉的猪》引自德里克·帕菲特，《理与人》第十章。 ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/iot/edge/",
	"title": "Edge",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Migration  Science Fiction 1: 瞬间移动装置将他的大脑和身体逐个细胞地进行扫描并摧毁了他们，然后将信息传到火星，在火星上重新构建人体。 《一头想要被吃掉的猪》引自德里克\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/2019-enclavedom/",
	"title": "2019 EnclaveDom: Privilege Separation for Large-TCB Applications in Trusted Execution Environments",
	"tags": [],
	"description": "",
	"content": " EnclaveDom: Privilege Separation for Large-TCB Applications in Trusted Execution Environments. arXiv, 2019 v1, 2020 v2.\nOverview Problem: unmodified application in a library OS container (TEE libOS) is a large in-enclave TCB, can introduce bugs or vulnerabilities from third party codes.\nSolution: A privilege separation system for large-TCB TEE applications.\n Partitions an enclave into multiple regions, and enforce per-region access rules; Partition at the granularity of individual in-enclave functions. Using Intel SGX for enclave, using Intel MPK for memory tagging. Protect internal libOS management data structures against tampering by application-level code.  At every libOS system call, EnclaveDom then only grant access to those internal data structures which the syscall needs to perform its task.   Challenges:\n Privilege separation using enclave is hard to be made efficient; Partition an enclave is also not easy;  EnclaveDom: do not split one enclave into two enclaves; but use MPX to control the access to different memory regions in a single enclave;  Challenging to share sensitive data between regions with different privileges;  EnclaveDom: use hardware-assisted memory tagging \u0026ndash; assigning tags to enclave pages.   Key Techniques  Combination of Intel SGX and Intel MPX.  Evaluation Using Graphene-SGX library OS;\nMicrobenchmarks: LMBench.\nExecution Performance on lat_syscall benchmark.\nMemory overhead.\nSome thoughts Can we do the same thing?\n Yes. we can do the same thing. seems straight forward to build this prototype.  Any questions?\n How about two functions occupy a same page but these two have different privilege?   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxsw/box-lang-sep/2018-unsafe-rust/",
	"title": "Fidelius Charm: Isolating Unsafe Rust Code",
	"tags": [],
	"description": "",
	"content": " Reference 1\nRust: memory safety is lost when any unsafe blocks are used.\nFedelius Charm(FC): limiting access to the program\u0026rsquo;s memory while executing unsafe libraries:\n move sensitive program data to protected pages before entering unsafe code;  call userspace lib e.g. fc_immutable in which call system call mprotect to change page permission bits and switch to isolated mode;  allow unsafe code to run normally without modifications; restore visibility of the protected state when unsafe code completes;  call userspace lib e.g. fc_normal to restore page permissions;  kernel-level monitor to ensure unsafe code cannot circumvent protections;  written in Rust; maintain the secure compartments; mediates page permission; separating user code section into two groups: 1. app code in Rust; 2. non-rust app code ; app code in Rust can make mprotect calls to change page permissions; non-Rust app code cannot change page perms of secure compartment pages via mprotect; separating data section into two groups: 1. secure compartment; 2. exposed pages with r/w access.   Related work:\nShredsc7, lwCc14, SpaceJMPc12, provide thread-like abstractions for isolating memory. ==\u0026gt; requires some static analysis or special abstractions;\nCodejailc29, provides a sandbox for unsafe libraries.\nFC: reverse the sandbox model: isolating the a subset of the trusted region and providing the rest of the memory to the unsafe libraries.\nEvaluation Microbenchmarks Rust\u0026rsquo;s benchmarking interface, plain openssl request \u0026amp; FC-ified openssl request.\nTime to lanuch an openssl-based HTTP server and processing single client.\nvmware Workstation VM, Ubuntu 15, four cores, 2 GB memory.\nSystem Benchmarks unsafe operations in TLS-based HTTP servers: use unsafe operations for invoking openssl operations, or make calls to Rust\u0026rsquo;s ring library, which in turn makes unsafe calls to cryptographic functions.\nHTTP server. Four compartments.\n128 simultaneous request threads; 5% decrease of number of requests processed in 60 seconds; 13.69% decrease if 50 calls to ring\n16 simultaneous requests in 10 milliseconds, the average decrease is 8.30%.\n  Hussain M.J. Almohri, and David Evans. Fidelius Charm: Isolating Unsafe Rust Code. CODASPY, 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/ptr-auth/",
	"title": "Ptr Auth",
	"tags": [],
	"description": "",
	"content": " References:\n ARM Pointer Authentication. LWN.net. April 2017.\n PAC it up: Towards Pointer Integrity using ARM Pointer Authentication.. USENIX Security, 2019.\n ARMv8-A Architecture Reference Manual\n Qualcomm Technologies, Inc. Pointer Authentication on ARMv8.3. 2017\n  Pointer Authentication (PA)\nAdded in ARMv8-A.\nPurpose is to detect pointers created by an external entity.\nPA uses cryptographic message authentication codes (MACs) to protect the integrity of pointers.\n It attaches a cryptographic signature to pointer values;  unused uppermost bits [62:48/42/39] of the address, could be used to hold auth code. Calculated from three values: the pointer itself, a secret key hidden in the process context, a third value (e.g., the current stack pointer). PAC instruction can be used to calculate the auth code and insert into a pointer value.  Those signatures can be verified before a pointer is used.  signed pointers cannot be directly dereferenced. (without the sign-extension bits, no longer recognized as valid address) AUT instruction need to be used. auth recalculated and compared. if auth match, auth code will be removed; if does not match, invalid pointer, will crash/exceptions.  An attacker lacking the key used to create the signatures, is unlikely to be able to create valid pointers for use in an exploit.  ARM address space layout Reference: lwn.net: documentation/arm64/memory.txt\nARM64 Linux, up to three level page tables for 64KB page size; up to 4 levels for 4KB page size;\n 4KB page size:  4 levels: only bottom 48 bits (256TB) + bit[63] of the virtual address are used 3 levels: only bottom 39 bits (512GB) + bit[63]  64KB page size:\n 3 levels: 48 bits (256TB) + bit[63] 2 levels: 42 bits (4TB) + bit[63]  bit [63] is always used to determine the choice between TTBR0 and TTBR1.\n TTBR: Translation Table Base Register.   Pointer Reuse Attacks Reference:\n Qualcomm Technologies, Inc. Pointer Authentication on ARMv8.3. 2017  PA is vulnerable to pointer reuse attacks where an authenticated pointer is substituted with another.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxsw/byte-sfi/",
	"title": "Byte Sfi",
	"tags": [],
	"description": "",
	"content": " Reference:\n Fast Byte-Granularity Software Fault Isolation. SOSP, 2009.  Byte Granularity Isolation (BGI) is implemented as a compiler plug-in that genrates instrumented code for kernel extenstions, and an interposition library that mediates communication between the extensions and the kernel.\n BGI runs extensions in separate protection domains that share the same address space. It associates an access control list (ACL) with each byte of virtual memory that lists the domains that can access the byte and how they can access it. Access rights are granted and invoked by code inserted by our compiler and by the interposition library according to the semantics of the operation being invoked. Protection is enforced by inline checks inserted by our compiler and by checks performed by the interposition library.\n BGI also ensures type safety for kernel objects and it can detect common types of errors inside domains.\n  Evaluation  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/sok-stack/",
	"title": "Sok: Shining Light on Shadow Stacks",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  SoK: Shining Light on Shadow Stacks. arXiv, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-lang/ccured/",
	"title": "CCured",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  CCured: Type-Safe Retrofitting of Legacy Software. ACM Transactions on PL and Systems. 2005. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/hwstack/",
	"title": "Defending Embedded Systems Against Control Flow Attacks",
	"tags": [],
	"description": "",
	"content": "A hardware controlled stack split: one for data, one for return;\nReference 1\n  Defending Embedded Systems Against Control Flow Attacks. SecuCode, 2009. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/1994pldi-translator/",
	"title": "Efficient Detection of All Pointer and Array Access Errors",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Efficient Detection of All Pointer and Array Access Errors. PLDI, 1994. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/mpx/bogo/",
	"title": "BOGO: Buy Spatial Memory Safety, Get Temporal Memory Safety (Almost) Free",
	"tags": [],
	"description": "",
	"content": "Reference 1\n LLVM MPX (BOGO)  Q\u0026amp;A How to determine the size of object? How to store the bound info in MPX? How to do bound checking? How to choose the instrumentation point? A Map from instruction to the pointer it want to access? Reference 1 Overview A module pass: class llmpx: public ModulePass runOnModule(Module \u0026amp;) Methods: mpxPass(Module \u0026amp;) harden_cfi(Module \u0026amp;) create_global_constants(Module \u0026amp;) collect_safe_access(Module \u0026amp;) transform_functions(Module \u0026amp;) transform_global(Module \u0026amp;)\n USENIX Security\u0026#39;19 ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK)  References: Vahldiek-Oberwagner, Anjo, Eslam Elnikety, Nuno O. Duarte, Michael Sammler, Peter Druschel, and Deepak Garg. \u0026ldquo;ERIM: Secure, efficient in-process isolation with protection keys (MPK).\u0026rdquo; In 28th USENIX Security Symposium (USENIX Security 19), pp. 1221-1238. 2019. Background Intel MPK: 4-bits permission bits in page table entry; 16 disjoint domains. PKRU: 32-bit registers; 2-bits perms for each region. 11-260 cycles to update PKRU. 0.07 to 1.0% overhead per 100,000 switches/s on a 2.\n  BOGO: Buy Spatial Memory Safety, Get Temporal Memory Safety (Almost) Free. ASPLOS, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxhw/rings/lord-x86/",
	"title": "Lord X86",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Lord of the x86 Rings: A Portable User Mode Privilege Separation Architecture on x86. CCS, 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxhw/rings/",
	"title": "Rings",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Lord X86  Reference 1 Lord of the x86 Rings: A Portable User Mode Privilege Separation Architecture on x86. CCS, 2018. ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/epoxy/",
	"title": "Protecting Bare-metal Embedded Systems With Privilege Overlays",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Protecting Bare-metal Embedded Systems With Privilege Overlays. SP. 2017. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/pagebits/hypersafe/",
	"title": "HyperSafe: A Lightweight Approach to Provide Lifetime Hypervisor Control-Flow Integrity",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-lang/nesc/",
	"title": "nesC",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/attack-rop/2014ndds-persistent/",
	"title": "Persistent Data-only Malware: Function Hooks without Code",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Persistent Data-only Malware: Function Hooks without Code. NDSS, 2014. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/attacks/rop/",
	"title": "Rop",
	"tags": [],
	"description": "",
	"content": "Reference 1\nReturn Oriented Programming Attacks\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/mix-langs/fun-tal/",
	"title": "FunTal",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  FunTAL: Reasonably Mixing a Functional Language with Assembly ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/verify/sec-gap/",
	"title": "Sec Gap",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  The correctness-security gap in compiler optimization. By Vija D\u0026rsquo;Silva, Mathias Payer, Dawn Song. LangSec, 2015. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/verify/next700/",
	"title": "Next700",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  The Next 700 Compiler Correctness Theorems (Functional Pearl). By Daniel Patterson, Amal Ahmed. ICFP, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/mix-langs/",
	"title": "Mix Langs",
	"tags": [],
	"description": "",
	"content": "Reference 1\n   FunTal  Reference 1 FunTAL: Reasonably Mixing a Functional Language with Assembly ↩   All the languages together ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/types/gradual-typing/",
	"title": "Gradual Typing",
	"tags": [],
	"description": "",
	"content": " Reference 1\nRUST \u0026mdash;\u0026mdash;\u0026ndash;buffer\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt; Ocaml \u0026lt;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nEscape Hatches:\nML:C FFI Rust:unsafe Java: JNI\nAll type soundness(safety) guarranttes are gone.\nInstead, use Principled FFIs:\n ML: linear types.  Linking types: support safe initeroperability with other languages.\n Only need linking types extensions to interact with behavior/features inexpressible in your language. SNAPL\u0026rsquo;172: Linking Types for Multi-language Software: Have your cake eat it too. Teach Ocaml with ownership in Rust:  Linking Type: linear type: cannot keep it and give it away at the same time. Ownership in Rust.   Pure vs Stateful languages Semantic Foundations for Gradual Typing Slow migration from dynamic typing to static typing.\nMixed with dynamic \u0026amp; static types. EG: C#, Typescript, Hack, Flow, Dart.\nCast Calculus: cast dynamic type to static type.\nWhat is Semantics of Casts?: What a cast should be checking or not checking is the heart of where the research area is. Three main questions:\n Gradual Typing Criteria: How do you set up the semantics of casts. Frameworks for Gradualizing: AGT framework Performance Overhead. (sound gradual typing dead? )  relational reasoning. soundness.\nCriteria  Gradual: precision: make the types more precise; change to more precise: either error or behave the same. Soundness:  Milner: \u0026ldquo;Well typed programs cannot go wrong\u0026rdquo; Equational Reasoning Priciples      FM 2019, PPDP Invited Talk: Semantic Foundations for Gradual Typing.video ↩ SNAPL\u0026rsquo;17: Linking Types for Multi-language Software: Have your cake eat it too. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/security-pol/bell-lapadula/",
	"title": "Bell LaPadula",
	"tags": [],
	"description": "",
	"content": "Reference:\n Computer Security, Art and Science/ By Matt Bishop, 2nd edition.  The simplest type of confidentiality classification is a set of security clearance, or security classification arranged in a linear (total) ordering. For example, the set below is {TS, S, C, UC}:\n------------------------------------- TOP SECRET (TS) Tamara, Thomas Personal Files SECRET (S) Sally, Samuel Electronic Mail Files CONFIDENTIAL (C) Claire, Clarence Activity Log Files UNCLASSIFIED (UC) Ulaley, Ursula Telephone List Files --------------------------------------  The goal of Bell-LaPadula model:\nPrevent information flowing from object with higher security classification to subject with lower security clearance.\nBell-LaPadula security model combines mandatory and discretionary access controls. Were the mandatory controls not present, discretionary ones will take effect.\nLet L(S) = l_s be the security clearance of subject S, and let L(O) = l_o be the security classification of object O.\n READ: from high to low. S can read O if and only if l_o \u0026lt;= l_s and S has discretionary read access to O. Write: from low to high. S can write O if and only if l_o \u0026gt;= l_s and S has discretionary write access to O.   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/tapl/",
	"title": "Tapl",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Semantic Style  Semantic Styles (chapter 3.4 in 1) There are three basic approaches to formalizing semantics: Operational semantics. Specifies the behavior of a programming language by defining a simple abstract machine on it. For simple languages, a state of the machine is just a term, and the machine\u0026rsquo;s behavior is defined by a transition function that, for each state, either gives the next state by performing a step of simplification on the term or declares that the machine has halted.\n  TAPL: Types and Programming Languages. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/tapl/semantic-style/",
	"title": "Semantic Style",
	"tags": [],
	"description": "",
	"content": " Semantic Styles  (chapter 3.4 in 1) There are three basic approaches to formalizing semantics:\n Operational semantics. Specifies the behavior of a programming language by defining a simple abstract machine on it. For simple languages, a state of the machine is just a term, and the machine\u0026rsquo;s behavior is defined by a transition function that, for each state, either gives the next state by performing a step of simplification on the term or declares that the machine has halted. he meaning of a term t can be taken to be the final state that the machine reaches when started with t as its initial state 2.  It is sometimes useful to give two or more different operational semantics for a single language \u0026ndash; some more abstract, with machine states that look similar to the terms that the programmer writes, others closer to the structures manipulated by an actual interpreter or compiler for the language. Proving that the behaviors of these different machines correspond in some suitable sense when executing the same program amounts to proving the correctness of an implementation of the language.\n Denotational semantics. Takes a more abstract view of meaning: instead of just a sequence of machien states, the meaning of a term is taken to be some mathematical object such as a number or a function. Giving denotational semantics for a language consists of finding a collection of semantic domains and then defining an interpretation function mapping terms into elements of these domains. The search for appropriate semantic domains for modeling various language features has given rise to a rich and elegant research area known as domain theory.  One major advantage of dnotational semantics is that it abstracts from the gritty details of evaluation and highlights the essential concepts of the language. Also, the properties of the chosen collection of semantic domain can be used to derive powerful laws for reasoning about program behaviors \u0026ndash; laws for proving that two programs have exactly the same behavior, for example, or that a program\u0026rsquo;s behavior satisfies some specification. Finally, from the properties of the chosen collectin of semantic domains, it is often immediately evident that various (desirable or undesirable) things are impossible in a language.\n Axiomatic semantics. Takes a more direct approach to these laws: instead of first defining the behaviors of programs (by giving some operational or denotational semantics) and then deriving laws from this definition, axiomatic methods take the laws themselves as the definition of the language. The meaning of a term is just what can be proved about it.  The beauty of axiomatic methods is that they focus attention on the process of reasoning about programs. It is this line of thought that has given computer science such powerful ideas as invariants.\n The bete noire of denotational semantics turned out to be the treatment of nondeterminism and concurrency; for axiomatic semantics, it was procedures.\nProgramming Models (From 3 Chapter 10.1) The imperative and functional models grew out of work undertaken by mathematicians Alan Turing, Alonzo Church, Stephen Kleene, Emil Post, and others in the 1930s. Different formalizations of the notion of an algorithm, or effective procedure, based on automata, symbolic manipulation, recursive function definition, and combinatorics. Over time, these various formalization were shown to be equally powerful: anything that could be computed in one could be computed in the others. This result led Church to conjecture that any intuitively appealing model of computing would be equally powerfull as well; this conjecture is known as Church\u0026rsquo;s thesis.\nTuring Machine. An automaton reminiscent of a finite or pushdown automaton, but with the ability to access arbitrary cells of an unbounded storage \u0026ldquo;tape\u0026rdquo;. The Turing machine computes in an imperative way, by changing the values in cells of its tape, just as a high-level imperative program computes by change the values of variables.\nLambda Calculus. Church\u0026rsquo;s model of computing. It is based on the notion of parameterized experssions(which each parameter introduced by an occurence of the letter $\\lambda$ ). Lambda calculus was the inspiration for functional programming: one uses it to compute by substituting parameters into expressions, just as one computes in a high level functional program by passing arguments to functions. The computing models of Kleene and Post are more abstract, and do not lend themselves directly to implementation as a programming language.\nConstructive proof vs non-constructive proof. The goal of early work in computability was not to understand computers (aside from purely mechanical devices, computers did not exist) but rather to formalize the notion of an effective procedure. Over time, this work allowed mathematicians to formalize the distinction between a constructive proof (one that shows how to obtain a mathematical object with some desired property) and a non-constructive proof(one that merely shows that such an object must exist, perhaps by contradiction, or counting arguments, or reduction to some other theorem whose proof is nonconstructive).\nIn effect, a program can be seen as a constructive proof of the proposition that, given any appropriate inputs, there exists outputs that are related to the inputs in a particular, desired way. Euclid\u0026rsquo;s algorithm, for example, can be thought of as a constructive proof of the proposition that every pair of non-negative integers has a greatest common divisor.\nLogic programming is also intimately tied to the notion of constructive proofs, but a more abstract level. Rather than write a general constructive proof that works for all appropriate inputs, the logic programmer writes a set of axioms that allow the computer to discover a constructive proof for each particular set of inputs.\n  TAPL: Types and Programming Languages. ↩ Strictly speaking, what we are describing here is the so-called small-step style of operational semantics, sometimes called structural operational semantics (Poltkin, 1981). An alternative is big-step style, sometimes called natural semantics (Kahn, 1987), in which a single transition of the abstract machine evaluates a term to its final result. ↩ Programming Language Pragmatics, 3rd Ed. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/vg_code/",
	"title": "FreeBSD Refactor in Virtual Ghost",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A Todos  Classify all code changes in SVA (combine paper and actual code)  Userspace libc (malloc) File: lib/libc/stdlib/malloc.c\n disable sbrk() by undefine MALLOC_DSS macro. LLM: What is this mean?   code   /* * MALLOC_DSS enables use of sbrk(2) to allocate chunks from the data storage * segment (DSS). In an ideal world, this functionality would be completely * unnecessary, but we are burdened by history and the lack of resource limits * for anonymous mapped memory. */ #if 0/* SVA: No sbrk()! */ #define\tMALLOC_DSS #endif  \n Add ghost_sbrk(intptr_t incr) and use it to replace sbrk. ghost_sbrk use secmemalloc when GHOSTING. secmemalloc(uintptr_t size) is implemented as an interrupt (number 0x7f.   code   /* * Function: secmemalloc() * * Description: * Ask the SVA VM to allocate some ghost memory. */ static inline void * secmemalloc (uintptr_t size) { void * ptr; __asm__ __volatile__ (\u0026#34;int $0x7f\\n\u0026#34; : \u0026#34;=a\u0026#34; (ptr) : \u0026#34;D\u0026#34; (size)); return ptr; } /* SVA: ghost sbrk() */ void * ghost_sbrk (intptr_t incr) { static uintptr_t totalAllocated = 0; static uintptr_t currentSize = 0; static uintptr_t start = 0xffffff0000000000u; void * oldBrk = (void *)(start + currentSize); if (getenv (\u0026#34;GHOSTING\u0026#34;) == NULL) return sbrk (incr); //  // If this is the first time we\u0026#39;ve been called, allocate some ghost  // memory so that we have something with which to start.  //  if (!start) { start = (uintptr_t) secmemalloc (0x400000); totalAllocated = 0x400000; currentSize = 0; } // Caller is asking to increase the allocation space  if (incr \u0026gt; 0) { //  // If we have enough space remaining, simply increase the current size.  // Otherwise, go allocate more secure memory.  //  if ((totalAllocated - currentSize) \u0026gt;= incr) { currentSize += incr; } else { secmemalloc (incr - (totalAllocated - currentSize)); currentSize += incr; } } // Caller is asking to decrease the allocation space  if (incr \u0026lt; 0) { currentSize += incr; } //  // Return the previous break value: note that an input increment of zero  // returns the current (unchanged) break value.  //  return oldBrk; }  \n disable TLS. define \u0026lsquo;NO_TLS\u0026rsquo; macro.\n  Kernel Structures LLM: Will kernel\u0026rsquo;s errorneously change to these SVA related fields invalidate SVA protection???\npcpu  5 More fields are added to kernel\u0026rsquo;s pcpu struct.   code   // file // sys/sys/pcpu.h /* * This structure maps out the global data that needs to be kept on a * per-cpu basis. The members are accessed via the PCPU_GET/SET/PTR * macros defined in \u0026lt;machine/pcpu.h\u0026gt;. Machine dependent fields are * defined in the PCPU_MD_FIELDS macro defined in \u0026lt;machine/pcpu.h\u0026gt;. */ struct pcpu { struct thread\t*pc_curthread;\t/* Current thread */ struct thread\t*pc_idlethread;\t/* Idle thread */ struct thread\t*pc_fpcurthread;\t/* Fp state owner */ struct thread\t*pc_deadthread;\t/* Zombie thread or NULL */ struct pcb\t*pc_curpcb;\t/* Current pcb */ uint64_t\tpc_switchtime;\t/* cpu_ticks() at last csw */ int\tpc_switchticks;\t/* `ticks' at last csw */ u_int\tpc_cpuid;\t/* This cpu number */ STAILQ_ENTRY(pcpu) pc_allcpu; struct lock_list_entry *pc_spinlocks; struct vmmeter\tpc_cnt;\t/* VM stats counters */ long\tpc_cp_time[CPUSTATES];\t/* statclock ticks */ struct device\t*pc_device; void\t*pc_netisr;\t/* netisr SWI cookie */ int\tpc_dnweight;\t/* vm_page_dontneed() */ int\tpc_domain;\t/* Memory domain. */ /* * Stuff for read mostly lock * * XXXUPS remove as soon as we have per cpu variable * linker sets. */ struct rm_queue\tpc_rm_queue; uintptr_t\tpc_dynamic;\t/* Dynamic per-cpu data area */ /* * Keep MD fields last, so that CPU-specific variations on a * single architecture don't result in offset variations of * the machine-independent fields of the pcpu. Even though * the pcpu structure is private to the kernel, some ports * (e.g., lsof, part of gtop) define _KERNEL and include this * header. While strictly speaking this is wrong, there's no * reason not to keep the offsets of the MI fields constant * if only to make kernel debugging easier. */ PCPU_MD_FIELDS; /* * Fields added to support SVA. Normally, SVA would control the PCPU * data structure, but we allow FreeBSD to maintain control to make * porting simpler. */ void *\tsvaIContext;\t/* Pointer to SVA CPUState */ uint64_t\tsvaRSP;\t/* Saved RSP on system call */ uint64_t\tsvaRBP;\t/* Saved RBP on system call */ uint64_t\tsvaRDI;\t/* Saved RDI on system call */ uint64_t\tsvaRSI;\t/* Saved RSI on system call */ } __aligned(CACHE_LINE_SIZE);     thread struct  sva added 6 more elements:   code   // file // sys/sys/proc.h struct thread{ ... #if 1  /* The thread that swapped out so this thread could swap on */ struct thread * prev; struct mtx * mtx; uintptr_t svaID; /* Thread ID for SVA Thread */ unsigned char sva; /* Flag whether SVA saved state on context switch */ void (*callout)(void *, struct trapframe *); /* Thread startup function */ void * callarg; /* Thread startup argument */ #endif }    Interrupt sys/sys/amd64/amd64/\n trap.c\n add void fr_sva_trap(unsigned trapno, void * trapAddr) to replace void trap(struct trapframe *frame)  enable interrupts; convert SVA trap frame freebsd frame; call trap_pfault_sva instead of trap_pfault no fpu support in sva; run ast(frame);  add trap_fault_sva add trap_pfault_sva void amd64_syscall(struct thread *td, int traced): void sva_syscall(struct thread *td, int traced):  enable interrupt; sva_syscall_trapframe(\u0026amp;localframe): convert sva trap frame to freebsd trap frame. ast(\u0026amp;localframe)  void trap(struct trapframe *frame):  add checking on trap type, panic if not T_BPTFLT nor T_NMI:   code   if ((type != T_BPTFLT) \u0026amp;\u0026amp; (type != T_NMI)) panic (\u0026quot;SVA: trap: %lx: %d\\n\u0026quot;, frame-\u0026gt;tf_rip, type);      mp_machdep.c\n init_secondary() keep common_tss[cpu].tss_ist3 that is SVA IST configuration   code   #if 0common_tss[cpu] = common_tss[0]; #else  /* * SVA: Don\u0026#39;t reconfigure the SVA IST configuration. */ { uintptr_t ist = common_tss[cpu].tss_ist3; common_tss[cpu] = common_tss[0]; common_tss[cpu].tss_ist3 = ist; } #endif   disable lidt($r_idt); call sva_init_secondary() to initialize the processor. call sva_load_cr0(cr0) instead of load_cr0(cr0).  machdep.c\n setidt(idx,func,typ,dpl,ist): check to disable changes to the 0x7f interrupt (SVA) spurious_handler(unsigned intNum, sva_icontext *p): new func hammer_time(u_int64_t modulep, u_int64_t physfree): changed: KGSBASE set to pcpu[0] instead of 0: wrmsr(MSR_KGSBASE, (u_int64_t)pc) added: initialize pcpu[i].svaIContext from sva_getCPUState(\u0026amp;common_tss[i]). added: initial SVA VM on the primary processor: sva_init_primary(); changed: call SVA to initialize exception.  sva_register_general_exception(IDT_DE,fr_sva_trap) to replace setidt(IDT_DE,\u0026amp;IDTVEC(div)); sva_register_general_exception(IDT_OF, fr_sva_trap); sva_register_general_exception(IDT_BR, fr_sva_trap); sva_register_general_exception(IDT_UD, fr_sva_trap); \u0026hellip;  added: thread0.svaID = 0; added: cpu_switch_sva(old,new,mtx) to replace cpu_switch() in cpu_switch.S.  exception.S\n add SVAsyscall, call this during IDTVEC(fast_syscall) Orignal fast_syscall: add SVAsysret add RETTARGET label.  locore.S \u0026amp; apic_vector.S \u0026amp; atpic_vector.S \u0026amp; cpu_switch.S: sva/cfi.h:\n RETTARGET after every call: label of every return target. RETQ to replace ret: first check label of return address, then return.  APIC sys/x86/x86/local_apic.c\n use apic_isr_svax instead of apic_isrx; use sva_reg: spurious_handler instead of setidt: spuriousint; use sva_reg: lapic_handle_timer instead of setidt: timerint; use sva_reg: lapic_handle_error instead of setidt: errorint; \u0026hellip; add lapic_handle_intr_sva(int vector) add apic_isr_sva1(unsigned int vector) add apic_isr_sva2(..) \u0026hellip; use lapic_handle_timer(int type) instead of lapic_handle_timer(struct trapframe *frame); // defined in include/apicvar.h \u0026hellip;  sys/kern/subr_trap.c:\n ast(struct trapframe *framep): enable_intr() at beginning;   Process management sys/sys/amd64/amd64/vm_machdep.c\n add void kernel_thread_trampoline (struct thread * td): call fork_exit with td-\u0026gt; callout, and td-\u0026gt;callarg;   code   #if 1 void kernel_thread_trampoline (struct thread * td) { extern void fork_exit(void (*callout)(void *, struct trapframe *), void *arg, struct trapframe *frame); /* * Call the specified function. */ fork_exit (td-\u0026gt;callout, td-\u0026gt;callarg, 0); return; } #endif  \n cpu_fork(\u0026hellip;): init thread struct: .sva/.callout/.callarg/.svaID;\n call sva_init_stack: to initialize the thread state in SVA; paramters:  kernel stack pointer: td2-\u0026gt;td_kstack; // TODO: stacklen; new thread struct: td2; kernel_thread_trampoline is passed in for proper start of a process (fork_exit()).  td2-\u0026gt;callout = fork_return; //TODO: td2-\u0026gt;callarg = td2; td2-\u0026gt;sva = 1;  cpu_set_fork_handler(td,func,arg):\n td-\u0026gt;callout = func; td-\u0026gt;callarg = arg;   code   /* * Intercept the return address from a freshly forked process that has NOT * been scheduled yet. * * This is needed to make kernel threads stay in kernel mode. */ void cpu_set_fork_handler(td, func, arg) struct thread *td; void (*func)(void *); void *arg; { /* * Note that the trap frame follows the args, so the function * is really called like this: func(arg, frame); */ td-\u0026gt;td_pcb-\u0026gt;pcb_r12 = (long) func;\t/* function */ td-\u0026gt;td_pcb-\u0026gt;pcb_rbx = (long) arg;\t/* first arg */ #if 1  td-\u0026gt;callout = func; td-\u0026gt;callarg = arg; #endif }    cpu_exit(struct thread *td)\n sva_release_stack(td-\u0026gt;svaID)  cpu_set_syscall_retval(struct thread *td, int error)\n use sva_icontext_setretval (td-\u0026gt;td_retval[1], td-\u0026gt;td_retval[0], 0); to replace the assignment to td-\u0026gt;td_frame-\u0026gt;tf_rax/rdx/rflags use sva_icontext_restart(0,0).  cpu_set_upcall (struct thread *td, struct thread *td0)\n use sva_init_stack() to initialize the new thread state in SVA;  add cpu_create_upcall(td,td0,func,arg)\n  sys/sys/amd64/amd64/machdep.c\n exec_setregs(td, image_params *imgp, u_long stack) /* reset registers on default values on exec */\n disable pcb fsbase/gsbase/clear_pcb_flags; disable regs init; add sva_translate(imgp-\u0026gt;entry_addr); add `sva_reinit_icontext(handle,0,((stack - 8) \u0026amp; ~-xFul) + 8, stack);  sys/vm/vm_glue.c\n vm_thread_new(td,pages): init: td-\u0026gt;svaID/mtx/sva/prev/callout/callarg;  sys/kern/kern_kthread.c\n kthread_add(..) : use \u0026lsquo;cpu_create_upcall(newtd,oldtd,func,arg);\u0026rsquo; to replace \u0026lsquo;cpu_set_upcall(newtd,oldtd); cpu_set_fork_handler(newtd,func,arg)\u0026rsquo;  sys/kern/kern_fork.c\n fork_return(): set td-\u0026gt;td_retval[0/1] = 0; call td-\u0026gt;td_proc-\u0026gt;p_sysent-\u0026gt;sv_set_syscall_retval(td,0);  context switch: sys/kern/sched_ule|4bsd.c:\n cpu_switch -\u0026gt; cpu_switch_sva cpu_throw -\u0026gt; cpu_throw_sva   Signal sys/amd64/amd64/sigtramp.S\n NON_GPROF_ENTRY(sigcode): callq *%r8 (5th argument) instead of call *SIGF_HANDLER(%rsp) LLM: why this change?  sys/sys/amd64/amd64/machdep.c\n sendsig (sig_t catcher, ksiginfo_t *ksi, sigset_t *mask):\n disable assignment to sf.sf_uc.uc_mcontext.*; disable assignment to regs-\u0026gt; rdi,rdx,rsi,rcx ; disable copyout of sigfram to user stack; disable reset of regs rsp,rip,rflags,cs,ds,es,fs,gs,flags,pcb_flags; add sva_save_icontext() add sva_ialloca(sigframe,..) add sva_ipush_function5 ;  sys_sigreturn(td, struct sigreturn_args *uap):\n disable load user context from ucp-\u0026gt;uc_mcontext diable set pcb flags; add sva_load_icontext();    SVA memory management sys/conf/ldscript.amd64\n add .savmem section. _svastart, _svaend, SVAPTPages exported  sys/sys/amd64/amd64/\n pmap.c:\n create_pagetables(vm_paddr_t * firstaddr): disable AMDID_PAGE1GB. pmap_bootstrap(vm_paddr_t * firstaddr): call sva_mmu_init(): set static address for kernel MMU initialization; init CR3;   code   #if 1  /* * Set the static address locations in the struct here to aid in kernel MMU * initialization. Note that we pass in the page mapping for the pml4 page. * This function will also initialize the cr3. */ sva_mmu_init (\u0026amp;((pdp_entry_t *)KPML4phys)[PML4PML4I], NPDEPG, firstaddr, (uintptr_t)btext, (uintptr_t)etext); #endif  \n pmap_init_pat(): use sva_load_cr0 instead of load_cr0   code   /* Disable PGE. */ cr4 = rcr4(); load_cr4(cr4 \u0026amp; ~CR4_PGE); /* Disable caches (CD = 1, NW = 0). */ cr0 = rcr0(); #ifdef SVA_MMU \tsva_load_cr0((cr0 \u0026amp; ~CR0_NW) | CR0_CD); #else \tload_cr0((cr0 \u0026amp; ~CR0_NW) | CR0_CD); #endif  /* Flushes caches and TLBs. */ wbinvd(); invltlb(); /* Update PAT and index table. */ wrmsr(MSR_PAT, pat_msr); for (i = 0; i \u0026lt; PAT_INDEX_SIZE; i++) pat_index[i] = pat_table[i]; /* Flush caches and TLBs again. */ wbinvd(); invltlb(); /* Restore caches and PGE. */ #ifdef SVA_MMU \tsva_load_cr0(cr0); #else \tload_cr0(cr0); #endif \tload_cr4(cr4);  \n use sva_update_l2_mapping instead of pde_store(). same parameters.\n in fuctions: pmap_update_pde_action(void *arg) / pmap_update_pde(\u0026hellip;) / pmap_demote_pde(\u0026hellip;) / pmap_protect_pde / pmap_promote_pde/ pmap_enter_pde / pmap_object_init_pt / pmap_pde_attr /  use sva_update_l1_mapping instead of pte_store. same parameters. in functions:\n pmap_kenter(vm_offset_t va, vm_paddr_t pa) / pmap_kenter_attr(\u0026hellip;) / pmap_qenter(\u0026hellip;) / pmap_fill_ptp(\u0026hellip;) / pmap_protect / pmap_enter_quick_locked / pmap_promote_pde / pmap_enter / pmap_change_wiring / pmap_remove_write / pmap_ts_referenced / pmap_clear_modify/ pmap_clear_reference / pmap_pte_attr /  use sva_remove_mapping(pte/ptq) instead of pte_clear(pte) pte_load_clear(ptq)\n in fuctions: pmap_kremove(vm_offset_t va) / pmap_remove_pde / pmap_remove_pte / pmap_remove_all(vm_page_t m) / pmap_remove_pages /  add sva_remove_page in pmap_add_delayed_free_list.\n _pmap_unwire_pte_hold(...): use sva_update_l2/l3/l4_mapping.\n pmap_pinit(pmap_t pmap): update l4 mappings;\n demote the PD Page and declare it to SVA: pmap_demote_DMAP(VM_PAGE_TO_PHYS(pml4pg))) update l4 mappings sva_update_l4_mappings instead of `pmap-\u0026gt;pm_pml4[KPML4I + i] = \u0026hellip;;  pmap_allocpde -\u0026gt; _pmap_allocpte(\u0026hellip;): update l4, l2, l3, l1 mappings.\n pmap_release(): update l4;\n pmap_growkernel(): l2/l3/l1\n pmap_collect(): remove mapping\n pmap_demote_pde(\u0026hellip;): declare l1. update l2.\n pmap_demote_pdpe: declare l2; up l2/l3.\n pmap_promote_pde: update l2,l1\n pmap_protect_pde: update l2\n pmap_protect: update l1\n pmap_enter: update l1,\n pmap_enter_pde: up l2;\n pmap_enter_quick_locked: up l1.\n pmap_object_init_pt: up l2;\n pmap_change_wiring: up l1.\n pmap_copy: up l1/l2\n pmap_remove_pages: rm mapping;\n  machdep.c: cpu_setregs():\n disable load_cr0(cr0); add sva_load_cr0(cr0).  amd64_mem.c: sva_load_cr0 ((cr0)) instead of load_cr0((cr0)) ==\u0026gt; LLM: cr0 must come from privileged sandbox. CR0 cannot be a global/shared variable.\n sys/kern/kern_sva.c\n provideSVAMemory(size): OS allocate memory and pass it to SVA to use. releaseSVAMemory(paddr,size): SVA call this to release memory back to OS testSVAMemory(unsigned char *p): try to access secure memory from OS: should fail.   IO sys/amd64/amd64/sys_machdep.c\n \u0026ldquo;SVA: no support for I/O permissions!\u0026rdquo;  FPU sys/sys/amd64/amd64/\n fpu.c  empty fpuexit(struct thread *td) empty fpudna(void) empty fpugetregs(struct thread *td) empty fpusetregs(struct thread *td, struct savefpu *addr)   Support funcs sys/amd64/amd64/\n support.S  copyin/out changed to real_copyin/out casuword/32 -\u0026gt; real_casuword/32 fuword/32/16 -\u0026gt; real_fuword64/32/16 fubyte -\u0026gt; real_fubyte suword/32/16 -\u0026gt; real_suword64/32/16 RETQ instead of ret;  sva_support.c  copyinstr(\u0026hellip;): sva_invokestrncpy(\u0026hellip;) copyin/out(\u0026hellip;): sva_invoke(\u0026hellip;,real_copyin/out) fuword64/32/16/fuword: sva_invoke(\u0026hellip;,real_fuword64/32/16) fubyte/subyte/suword/16/32/64, casuword/32 -\u0026gt; svainvoke*   Configurations sys/conf/\n files: add kern/kern_sva.c files.amd64: add amd64/amd64/sva_support.c kern.mk: turn on CFI and SFI for clang and SVA: CFLAGS+= -mllvm -add-sfi -mllvm -enable-sfi-loadchecks -Xclang -backend-option -Xclang -x86-add-cfi kern.post.mk: compile libsva.a into full kernel binary:   code   ${FULLKERNEL}: ${SYSTEM_DEP} vers.o $S/../../../SVA/lib/libsva.a @rm -f ${.TARGET} @echo linking SVA ${.TARGET} ${SYSTEM_LD} -L$S/../../../SVA/lib -lsva @${SYSTEM_CTFMERGE}   \n ldscript.amd64: add \u0026lsquo;svamem\u0026rsquo; section:   code   /* Create the SVA data section */ _svastart = ALIGN(0x1000); .svamem ALIGN(0x1000) : { SVAPTPages = .; . = . + 4194304; *(svamem) _svaend = .; }  \n NOTES: add makeoptions CONF_CFLAGS=-fno-builtin -I/usr/home/criswell/src/sva/SVA/include\n options: add SVA_MMU opt_sva_mmu.h\n  sys/dev/aic7xxx/aicasm/Makefile: add CC=gcc\nTODONES TODO: []\nDONE:\nsys/dev/aic7xxx/aicasm/Makefile\nsys/conf/\nsys/amd64/amd64/\n vm_machdep.c trap.c sigtramp.S support.S sva_support.c sys_machdep.c pmap.c mp_machdep.c machdep.c fpu.c apic_vector.S; atpic_vector.S; cpu_switch.S; exception.S; locore.S; amd64_mem.c  sys/amd64\n-/conf/{SVA, SVAMAC}; -/ia32/ia32_syscall.c; -/include/ {apicvar.h, asm.h, asmacros.h, cpufunc.h, pmap.h}; -/linux32/linux32_locore.S;\nsys/kern/; sys/sys/; sys/vm/; sys/x86/x86/local_apic.c;\nReference 1\n  SVA: github.com/jtcriswell/SVA.git; or tupipa/sva_freebsd90 ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/vmi/hwvmi/",
	"title": "Hwvmi",
	"tags": [],
	"description": "",
	"content": " Reference 1\nIntrospection in hardware.\nTo match network connections to the application-layer while being isolated and undetected from the operating system or the hypervisor.\nMotivation Firewalls:\n external firewall: external device only connected to network  cannot see the content of the target computer\u0026rsquo;s physical memory, thus cannot make decision based on what code is accessing the traffic;  software-based firewall: installed on a target computer.\n can be the target of attacks themselves.  This paper: external firewalls with added ability to analyze memory of the target.\n  Challenge \u0026amp; Solution  DMA to transparently read memory via hardware, bypassing the operating system.   2016 Flexcore  Reference 1 D. Y. Deng, Flexible and efficient accelerator architecture for runtime monitoring. Cornell University, 2016. ↩   SystemWall: An Isolated Firewall using Hardware-based Memory Introspection. by Sebastian Biedermann, Jakub Szefer. ISC (Proceedings of the International Security Conference), 2014. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/verify/compcert/",
	"title": "CompCert",
	"tags": [],
	"description": "",
	"content": " Reference 1\nCompCert: A realistic, verified compiler.\n By verified, we mean a compiler that is accompanied by a machine-checked proof of a semantic preservation property: the generated machine code behaves as prescribed by the semantics of the source program.\nBy realistic, we mean a compiler that could realistically be used in the context of production of critical software.\n Background The first compiler proof in 19672, for the compilation of arithmetic expressions down to stack machine code; and mechanically verified in 19723.\nA survey of compiler verification 4.\n  Formal verification of a realistic compiler. by Xavier Leroy. 2008. ↩ Correctness of a compiler for arithmetical expressions. J. McCarthy and J. Painter. Mathematical Aspects of Computer Science. 1967. ↩ Proving Compiler correctness in a mechanized logic. By R. Milner and R. Weyhrauch. 1972. ↩ Compiler verification: a bibliography. M. A. Dave. SIGSOFT Softw. Eng. 2003. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/types/sec-type/",
	"title": "Sec Type",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  A type system for expressive security policies. POPL, 2000. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/types/info-flow-type/",
	"title": "Info Flow Type",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Language-based information-flow security. IEEE journal on selected areas in comm. 2003. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/detection/hw-monitor/",
	"title": "Hw Monitor",
	"tags": [],
	"description": "",
	"content": " Reference 1\nHardware-based monitoring technique that can detect if the system calls of sophisticated embedded operating systems (e.g. Linux) deviate from the originally programmed behavior due to an attack.\n By Verifying operation at the level of an individual processor instruction, we can detect any deviation almost instantaneously. By limiting the monitoring to a fraction of the operating system code (i.e. system calls) and not the entire code base, we can achieve low overhead compared to other hardware monitoring approaches.  This combination of sensitivity to attacks on vulnerable code and low hardware overhead (and no modification to any software) provides a promising approach to protecting embedded systems in the IoT domain or anywhere else.\nMonitoring System Calls GOAL: prevent execution deviation from system calls to malicious code.\nBasic monitor operation Hardware monitors are components that are co-located with processor cores to track the processing of software on that core. The objective is to assess the operation of the processor and determine when incorrect behavior is detected (which can be due to benign faults or malicious attacks).\nIn this work, hardware monitor receives information about every instruction executed on the processor core and compares it to a \u0026ldquo;monitoring graph\u0026rdquo; that is generated from the processing binary.\nA monitoring graph is generated during compilation [^6] for selected system calls. Each instruction in the system call is encoded as an entry in the graph that includes the valid has value(s) of the next instruction (or instructions in the case of a branch) and the next graph state(s).\nLinux (4.13.15) contains 337 system calls.\nAttacking database analysis  Between 1999 and 2017, 1931 vulnerabilities in the Linux kernel were reported to the CVE database. Of those, 45 vulnerabilities (2.3%) directly relate to system calls. This may seem like a small percentage. However, the existence of a vulnerability is particularly problematic if an exploit exists that can let an attacker use the vulnerability in a practical manner. Of 148 publicly available exploits (listed in Exploit Database maintained by Offensive Security) that lead to privilege escalation attacks (which gives the attacker full control over the system), 25 exploits (16.9%) are based on vulnerabilities in system calls.\n Related work Hardware monitoring from basic block level to instruction level Hardware monitoring system at the granularity of basic block[^c2]. Then was extended by Mao et al. in verifying individual processor instructions[^c3]. Pouraghily et al. further expanded the previous work to not only monitor monolithic applications, but the underlying operating system [^c4].\nThis work also on monitoring operating system, but aim to work with a real Linux, not a light, embedded variant of a simplistic operating system.\n  A Hardware Monitor to Protect Linux System Calls, IEEE Computer Society Annual Symposium on VLSI, 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/verify/binary-verify/",
	"title": "Binary Verify",
	"tags": [],
	"description": "",
	"content": "Reference 1\nSVA: type checking in LLVM IR, ensure there is no type violation in the binary (IR form) code. However, backdoor style malicious compiler is out of the security model, thus will not be able to be detected.\n SVA is also designed to ensure that the (relatively complex) safety checking compiler does not need to be a part of the trusted computing base. The compiler can generate code in the SVA virtual instruction set, and a simple type checker can ensure that the code meets the safety requirements of SVA. This provides a robust implementation strategy for enforcing the safety properties of SVA. Furthermore, higher-level security properties (e.g. information flow, or security automata, expressible as types can be encoded compactly in SVA code, enabling robust implementations of sophisticated security-checking strategies.)\n   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/verify/",
	"title": "Verify",
	"tags": [],
	"description": "",
	"content": "Reference:\nFully Abstract Compilation. a little bit\n Sec Gap  Reference 1 The correctness-security gap in compiler optimization. By Vija D\u0026rsquo;Silva, Mathias Payer, Dawn Song. LangSec, 2015. ↩  Next700  Reference 1 The Next 700 Compiler Correctness Theorems (Functional Pearl). By Daniel Patterson, Amal Ahmed. ICFP, 2019. ↩  CompCert  Reference 1 CompCert: A realistic, verified compiler. By verified, we mean a compiler that is accompanied by a machine-checked proof of a semantic preservation property: the generated machine code behaves as prescribed by the semantics of the source program. By realistic, we mean a compiler that could realistically be used in the context of production of critical software. Background The first compiler proof in 19672, for the compilation of arithmetic expressions down to stack machine code; and mechanically verified in 19723.\n Binary Verify  Reference 1 SVA: type checking in LLVM IR, ensure there is no type violation in the binary (IR form) code. However, backdoor style malicious compiler is out of the security model, thus will not be able to be detected. SVA is also designed to ensure that the (relatively complex) safety checking compiler does not need to be a part of the trusted computing base. The compiler can generate code in the SVA virtual instruction set, and a simple type checker can ensure that the code meets the safety requirements of SVA.\n 1967 Correctness of a Compiler for Arithmetic Expressions  Q\u0026amp;A What is the tool used to verify the correctness? A proof of the correctness of a simple compiling algorithm for compiling arithmetic expressions into machine language. The definition of correctness. The formalism used to express the description of source language, object language, and compiler. The methods of proof. Ultimate goal, is to make it possible to use a computer to check proofs that compilers are correct.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/kernel-cap/grep-cap/",
	"title": "Grep Cap",
	"tags": [],
	"description": "",
	"content": "Reference: 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/arm/trustzone/",
	"title": "Trustzone",
	"tags": [],
	"description": "",
	"content": " References:\n Intro to TrustZone\n Difference between SGX and TrustZone\n TrustZone Explained\n Dan Rosenberg, Reflections on Trusting TrustZone\n  Normal world vs Secure World:\n Embeded OS vs Secure OS Context Switch\n normal world use SMC (secure monitor call) instruction to call secure world. ==\u0026gt; exception into the monitor mode (TrustZone kernel)  Non-secure bit in Secure Configuration Register;\n Non-secure bit in the main memory;\n  To use  re-implement a secure world.  Usage examples References:\n Dan Rosenberg, Reflections on Trusting TrustZone\n DRM (WideVine, PlayReady, DTCP-IP)\n Secure key storage (dm-verify)\n Mobile payments\n Protected hardware (framebuffer, PIN entry)\n Management of secure boot (via QFuses)\n Kernel integrity monitoring (TIMA)\n  Single point failure in QSEE In Qualcomm implementation, Qualcomm Secure Execution Environment (QSEE), to leverage TrustZone vulnerabilities:\n By Gal Beniamini, several vulnerabilities were found.  \u0026ldquo;Code execution in Secure World userland privilege escalation (CVE-2015-6639) to gain code execution in Secure World kernel via SMC handler or via SVC handler (CVE-2016-2431) allowing KeyMaster Keys extraction, Linux Kernel hijacking from TrustZone, and bootloader unlocking\u0026rdquo;  By Azimuth Security, two vulnerabilities were found.\n write primitive and arbitrary code execution in Qualcomm Trustzone. blackhat representation  A vulnerability allows to write a zero dword to any address in the TrustZone Kernel. It can be used to disable memory boundary validation on TrustZone memcpy function, crafting an arbitrary write primitive.\n Using signed comparison instead of unsigned comparison leads to leaking information from Secure World to Normal World.\n  Trustonic TrustZone The Trustonic implementation, t-base, or Kinibi.\nIt has a micro-kernel, thus no single point of failure.\n t-base internals:  part 1, part 2, part 3  Attacks on github   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/data-layout/",
	"title": "Data Layout",
	"tags": [],
	"description": "",
	"content": "(From 1) layout specification: A module may specify a target specific data layout string that specifies how data is to be laid out in memory. The IR syntax for the data layout is simply:\ntarget datalayout = \u0026quot;layout specification\u0026quot;\n(From 2) The XXXTargetMachine constructor will specify a TargetDescription string that determines the data layout for the target machine, including characteristics such as pointer size, alignment, and endianness. For example, the constructor for SparcTargetMachine contains the following:\nSparcTargetMachine::SparcTargetMachine(const Module \u0026amp;M, const std::string \u0026amp;FS) : DataLayout(\u0026#34;E-p:32:32-f128:128:128\u0026#34;), Subtarget(M, FS), InstrInfo(Subtarget), FrameInfo(TargetFrameInfo::StackGrowsDown, 8, 0) { } In this example, the layout specification string is \u0026quot;E-p:32:32-f128:128:128\u0026quot;:\n \u0026ldquo;E\u0026rdquo; indicates big-endian target data model. \u0026ldquo;p:\u0026rdquo; is followed by pointer information: size, ABI alignment, and preferred alignment. If only two figures follow \u0026ldquo;p:\u0026ldquo;, then the first value is pointer size, and the second value is both ABI and preferred alignment; \u0026ldquo;i\u0026rdquo;, \u0026ldquo;f\u0026rdquo;, \u0026ldquo;v\u0026rdquo;, or \u0026ldquo;a\u0026rdquo; are letters for numeric type alignment (integer, floating point, vector, aggregate). \u0026ldquo;i\u0026rdquo;, \u0026ldquo;v\u0026rdquo;, \u0026ldquo;a\u0026rdquo; are followed by ABI alignment and preferred alignment; \u0026ldquo;f\u0026rdquo; is followed by three values: the first indicates the size of a long double, then ABI alignment, then ABI preferred alignment.  Class definition: DataLayout\nCite: relation between address spaces and physical memory locations\nDavid Chisnall via llvm-dev llvm-dev at lists.llvm.org Wed Mar 23 05:34:32 PDT 2016\nOn 23 Mar 2016, at 12:33, Hongbin Zheng wrote: \u0026gt; \u0026gt; Hi, \u0026gt; \u0026gt; Is it feasible to assign different DataLayout to different address space in the same LLVM IR module?\nDataLayout is per module and describes, among other things, the different size and alignment requirements of pointers to different address spaces.\nDavid\n  LLVM DOC: Data Layout. ↩ Wrting an LLVM Backend. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-seal/",
	"title": "Cheri Seal",
	"tags": [],
	"description": "",
	"content": " Questions  How can Java/C++ benefit from CHERI\u0026rsquo;s sealed caps? Can Rust ownership benefit from CHERI\u0026rsquo;s sealed caps?  Why explicit unseal/ccall (ISAv71 Ch 8.18): Unseal is an explicit operation. In CHERI, it requires explicit operation to convert an undereferenceable object into a pointer. CUnseal or CCall.\nAn alternative architecture would have been one with implicit* unsealing, where a sealed capability could be dereferenced without explicitly unsealing it first, provided that the subsystem attempting the dereference had some kind of ambient authority that permitted it to dereference sealed capabilities of that type. This ambient authority could have taken the form of a protection ring or the otype field of PCC.\nA disadvantage of an implicit unseal approach such as the one outlined above is that it is potentially vulnerable to the Confused deputy problem2: the attacker calls a protected subsystem, passing a sealed capability in a parameter that the called subsystem expects to be unsealed. If unsealing is implicit, the protected subsystem can be tricked by the attacker into using its privileges to read or write to memory to which the attacker does not have access.\n   LLM: how to solve? how about OO constraint? Limit the interfaces? Constrain the parameters?\n   The disadvantage of the CHERI choice is that protected subsystems need to be careful not to leak capabilities that they have unsealed, for example, by leaving them on the stack when they return to their caller. In an architecture with \u0026ldquo;implicit unseal\u0026rdquo;, protected subsystems would just need to delete their ambient authority for the type before returning, and would not need to explicity clean up all the unsealed capabilities that they had created.\nSealed Capabilities Reference: ISAv8\nTwo types:\n Sealed pairs:\n Primarily designed to support the linking of a pair of code and data capabilities for use together during domain transition; CInvoke, a jump-like instruction, allows the two sealed capabilities to be atomatically unsealed as control flow transfers to the code pointed to by the code capability, if their object types match; Can be used to implement controlled privilege escalation for the purposes of domain transition; Sealed capabilities sharing a common object type are the foundation for building the CheriBSD object-capability model supporting in-address-space compartmentalization.  Sealed entry capabilities:\n a single sealed code capability; Can be jumped to, leading to an atomic unsealing and control-flow transfer; to date has primarily been used to strength control-flow robustness within a single protection domain by preventing the undesired manipulation and use of code pointers; Jump-and-link instructions acting on sealed entry capabilities also generate a sealed return capability; Can also be used to implement domain transition with privilege escalation.   Usages:\n CHERI Domain isolation (in-address-space compartmentalization); Protect code pointers; Representing other sorts of delegated rights (non-hardware-defined); Ensuring that pointers are dereferenced only by suitable code (e.g., in support of language-level memory or type safety).  Capability Object Types  Allow multiple sealed capabilities to be indelibly and indivisibly linked;  the kernel or language runtime can avoid expensive checks (e.g., via table lookups) to confirm that they are intended to be used together; e.g., CheriBSD object-capability model: code capability + data capability;  Updates when a capability undergoes (un)sealing;  Sealing: object type is set when a capability is sealed based on a second input capability authorizing use of the type space; the second capability is simply a capability permission authorizing sealing within a range of values specified by the capability\u0026rsquo;s bounds; Unsealing: a sealed capability is restored to a mutable and dereferenceable state; a suitable capability that have sealed the cap must be held during unsealing; Non-unsealing: sealed capability inspection a suitably privileged component could rederive its unsealed contents by inspecting a sealed capability  e.g., kernel? However, authorizing both sealing and unsealing based on type capabilities allows the right to construct encapsulated pointers to be delegated, without requiring recourse to a privileged      CHERI ISAv7. ↩ ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/cheriops/",
	"title": "Cheriops",
	"tags": [],
	"description": "",
	"content": " ALL CHERI/MIPS Instructinos are declared as emulating functions in target/mips/helper.h, with macro DEF_HELPER_*. Implemented in target/mips/op_helper_cheri.c, using macro CHERI_HELPER_IMPL.\nFor example, cseal instruction is declared as DEF_HELPER_4(cseal, void, env, i32, i32, i32), and implemented as void CHERI_HELPER_IMPL(cseal)(CPUMIPSState *env, uint32_t cd, uint32_t cs, uint32_t ct).\ncapability runtime check instructions PCC check DEF_HELPER_2(ccheck_pc, void, env, i64)\nCHERI_HELPER_IMPL(ccheck_pc)(CPUMIPSState *env, uint64_t next_pc)\nDDC check will always be checked on ld/st without explicit instructions. see check_cap.\nLD/ST check Problem: could we do PCC/DDC and pointer checks on their types? assuming types are already available (even if they are not currently).\nDEF_HELPER_3(ccheck_store, tl, env, tl, i32) DEF_HELPER_3(ccheck_store_right, tl, env, tl, i32) DEF_HELPER_3(ccheck_load, tl, env, tl, i32) DEF_HELPER_3(ccheck_load_right, tl, env, tl, i32)  Branch check DEF_HELPER_1(ccheck_btarget, void, env)  type check DEF_HELPER_3(cchecktype, void, env, i32, i32)\nperm check DEF_HELPER_3(ccheckperm, void, env, i32, tl)\nNon-check ISA instructions perm op instructions DEF_HELPER_4(candperm, void, env, i32, i32, tl)  sealing/types op instructions DEF_HELPER_4(cseal, void, env, i32, i32, i32) DEF_HELPER_4(ccseal, void, env, i32, i32, i32) // ?????? DEF_HELPER_4(cunseal, void, env, i32, i32, i32) DEF_HELPER_4(ccopytype, void, env, i32, i32, i32) DEF_HELPER_3(csealentry, void, env, i32, i32) // ??????  ccall DEF_HELPER_3(ccall, void, env, i32, i32) DEF_HELPER_3(ccall_notrap, tl, env, i32, i32)  tag ops DEF_HELPER_5(cinvalidate_tag, void, env, tl, i32, i32, tl) DEF_HELPER_5(cinvalidate_tag_left_right, void, env, tl, i32, i32, tl) DEF_HELPER_5(cinvalidate_tag32, void, env, tl, i32, i32, i32) DEF_HELPER_3(ccleartag, void, env, i32, i32) DEF_HELPER_3(cloadtags, tl, env, i32, i64)  LD/ST ops DEF_HELPER_5(cload, tl, env, i32, tl, i32, i32) DEF_HELPER_5(cstore, tl, env, i32, tl, i32, i32) DEF_HELPER_3(cloadlinked, tl, env, i32, i32) DEF_HELPER_3(cstorecond, tl, env, i32, i32) DEF_HELPER_3(cscc_without_tcg, tl, env, i32, i32) DEF_HELPER_5(csc_without_tcg, void, env, i32, i32, tl, i32) DEF_HELPER_5(clc_without_tcg, void, env, i32, i32, tl, i32) DEF_HELPER_3(cllc_without_tcg, void, env, i32, i32)  EPC ops /* cannot access EPC directly since it is the offset of EPCC */ DEF_HELPER_1(mfc0_epc, tl, env) DEF_HELPER_2(mtc0_epc, void, env, tl) DEF_HELPER_1(mfc0_error_epc, tl, env) DEF_HELPER_2(mtc0_error_epc, void, env, tl)  misc DEF_HELPER_2(cclearreg, void, env, i32) DEF_HELPER_4(cfromptr, void, env, i32, i32, tl) DEF_HELPER_2(cgetaddr, tl, env, i32) DEF_HELPER_2(cgetbase, tl, env, i32) DEF_HELPER_1(cgetcause, tl, env) DEF_HELPER_2(cgetlen, tl, env, i32) DEF_HELPER_2(cgetoffset, tl, env, i32) DEF_HELPER_2(cgetpcc, void, env, i32) DEF_HELPER_3(cgetpccsetoffset, void, env, i32, tl) DEF_HELPER_2(cgetperm, tl, env, i32) DEF_HELPER_2(cgetsealed, tl, env, i32) DEF_HELPER_2(cgettag, tl, env, i32) DEF_HELPER_2(cgettype, tl, env, i32) DEF_HELPER_4(cincbase, void, env, i32, i32, tl) DEF_HELPER_4(cincoffset, void, env, i32, i32, tl) DEF_HELPER_3(cjalr, tl, env, i32, i32) DEF_HELPER_2(cjr, tl, env, i32) DEF_HELPER_1(creturn, void, env) DEF_HELPER_4(csetbounds, void, env, i32, i32, tl) DEF_HELPER_4(csetboundsexact, void, env, i32, i32, tl) DEF_HELPER_2(crap, tl, env, tl) // ??????? DEF_HELPER_2(cram, tl, env, tl) // ??????? DEF_HELPER_3(csub, tl, env, i32, i32) DEF_HELPER_2(csetcause, void, env, tl) DEF_HELPER_4(csetlen, void, env, i32, i32, tl) DEF_HELPER_4(csetoffset, void, env, i32, i32, tl) DEF_HELPER_3(ctoptr, tl, env, i32, i32) DEF_HELPER_4(cmovz, void, env, i32, i32, tl) DEF_HELPER_4(cmovn, void, env, i32, i32, tl) DEF_HELPER_3(ceq, tl, env, i32, i32) DEF_HELPER_3(cne, tl, env, i32, i32) DEF_HELPER_3(clt, tl, env, i32, i32) DEF_HELPER_3(cle, tl, env, i32, i32) DEF_HELPER_3(cltu, tl, env, i32, i32) DEF_HELPER_3(cleu, tl, env, i32, i32) DEF_HELPER_3(cexeq, tl, env, i32, i32) DEF_HELPER_3(cnexeq, tl, env, i32, i32) DEF_HELPER_4(csetaddr, void, env, i32, i32, tl) DEF_HELPER_3(cgetandaddr, tl, env, i32, tl) DEF_HELPER_4(candaddr, void, env, i32, i32, tl) DEF_HELPER_3(ctestsubset, tl, env, i32, i32) DEF_HELPER_2(rdhwr_statcounters_icount, tl, env, i32) DEF_HELPER_1(rdhwr_statcounters_reset, tl, env) DEF_HELPER_1(rdhwr_statcounters_itlb_miss, tl, env) DEF_HELPER_1(rdhwr_statcounters_dtlb_miss, tl, env) DEF_HELPER_2(rdhwr_statcounters_memory, tl, env, i32) DEF_HELPER_2(rdhwr_statcounters_ignored, tl, env, i32)  Capability check primitives check_cap check_cap() is called by:\n CHERI_HELPER_IMPL(ccheck_btarget): check whether the branch target is within $pcc void CHERI_HELPER_IMPL(ccheck_pc)(CPUMIPSState *env, uint64_t next_pc): check_ddc(CPUMIPSState *env, uint32_t perm, uint64_t ddc_offset, uint32_t len, bool instavail, uintptr_t retpc)\n// file // target/mips/op_helper_cheri.c  static inline void check_cap(CPUMIPSState *env, const cap_register_t *cr, uint32_t perm, uint64_t addr, uint16_t regnum, uint32_t len, bool instavail, uintptr_t pc) { uint16_t cause; /* * See section 5.6 in CHERI Architecture. * * Capability checks (in order of priority): * (1) \u0026lt;ctag\u0026gt; must be set (CP2Ca_TAG Violation). * (2) Seal bit must be unset (CP2Ca_SEAL Violation). * (3) \u0026lt;perm\u0026gt; permission must be set (CP2Ca_PERM_EXE, CP2Ca_PERM_LD, * or CP2Ca_PERM_ST Violation). * (4) \u0026lt;addr\u0026gt; must be within bounds (CP2Ca_LENGTH Violation). */ if (!cr-\u0026gt;cr_tag) { cause = CP2Ca_TAG; // fprintf(qemu_logfile, \u0026#34;CAP Tag VIOLATION: \u0026#34;);  goto do_exception; } if (is_cap_sealed(cr)) { cause = CP2Ca_SEAL; // fprintf(qemu_logfile, \u0026#34;CAP Seal VIOLATION: \u0026#34;);  goto do_exception; } if ((cr-\u0026gt;cr_perms \u0026amp; perm) != perm) { switch (perm) { case CAP_PERM_EXECUTE: cause = CP2Ca_PERM_EXE; // fprintf(qemu_logfile, \u0026#34;CAP Exe VIOLATION: \u0026#34;);  goto do_exception; case CAP_PERM_LOAD: cause = CP2Ca_PERM_LD; // fprintf(qemu_logfile, \u0026#34;CAP LD VIOLATION: \u0026#34;);  goto do_exception; case CAP_PERM_STORE: cause = CP2Ca_PERM_ST; // fprintf(qemu_logfile, \u0026#34;CAP ST VIOLATION: \u0026#34;);  goto do_exception; default: break; } } // fprintf(stderr, \u0026#34;addr=%zx, len=%zd, cr_base=%zx, cr_len=%zd\\n\u0026#34;, // (size_t)addr, (size_t)len, (size_t)cr-\u0026gt;cr_base, (size_t)cr-\u0026gt;cr_length); if (!cap_is_in_bounds(cr, addr, len)) { cause = CP2Ca_LENGTH; // fprintf(qemu_logfile, \u0026#34;CAP Len VIOLATION: \u0026#34;);  goto do_exception; } return; do_exception: env-\u0026gt;CP0_BadVAddr = addr; if (!instavail) env-\u0026gt;error_code |= EXCP_INST_NOTAVAIL; do_raise_c2_exception_impl(env, cause, regnum, pc); }  cap_is_in_bounds(), called by functions in target/mips/op_helper_cheri.c\n check_cap(), ccall_common(), cseal_common() CHERI_HELPER_IMPL(cjalr),  (cjr), (cunseal), (cload), (cloadlinked), (cstorecond), (cstore),  get_clc_addr(), get_cllc_addr(), get_csc_addr(), get_cscc_addr()\n// file // target/mips/cheri_util.h  // Check if num_bytes bytes at addr can be read using capability c static inline bool cap_is_in_bounds(const cap_register_t* c, uint64_t addr, uint64_t num_bytes) { if (addr \u0026lt; cap_get_base(c)) { return false; } // Use __builtin_add_overflow to avoid wrapping around the end of the addres space uint64_t access_end_addr = 0; if (__builtin_add_overflow(addr, num_bytes, \u0026amp;access_end_addr)) { warn_report(\u0026#34;Found capability access that wraps around: 0x%\u0026#34; PRIx64 \u0026#34; + %\u0026#34; PRId64 \u0026#34;. Authorizing cap: \u0026#34; PRINT_CAP_FMTSTR, addr, num_bytes, PRINT_CAP_ARGS(c)); return false; } if (access_end_addr \u0026gt; cap_get_top(c)) { return false; } return true; }  Unsealing in ccall TODO-1: enable _sbit_for_memory for 128 bit hybrid CHERI_128; including\n add it in the cap register struct representation; done. store it in the memory while store the capability; done. load it from the memory along with the capability load; done. change the bit when sealing/unsealing operation is being carried out; done. change the API of testing seal or unseal, use _sbit_for_memory only;  Things might need to change:\n target/mips/cpu.h\n struct cap_register ==\u0026gt; added the sbit field _sbit_for_memory.  target/mips/cheri-compressed-cap/cheri_compressed_cap.h\n enum: CC128_FILED(name, start, end): ==\u0026gt; added CC128_FIELD(SEALED_BIT, 109,109) compress_128cap_without_xor(): ==\u0026gt; store the sealed bit of the cap struct to the 128bit rep.\n// LLM: read seal bit from csp bool S_BIT = csp-\u0026gt;_sbit_for_memory \u0026gt; 0 ? true : false; uint64_t pesbt = CC128_ENCODE_FIELD(csp-\u0026gt;cr_uperms, UPERMS) | CC128_ENCODE_FIELD(csp-\u0026gt;cr_perms, HWPERMS) | CC128_ENCODE_FIELD(S_BIT, SEALED_BIT) | CC128_ENCODE_FIELD(csp-\u0026gt;cr_otype, OTYPE) | CC128_ENCODE_FIELD(IE, INTERNAL_EXPONENT) | CC128_ENCODE_FIELD(Te, TOP_ENCODED) | CC128_ENCODE_FIELD(Be, BOTTOM_ENCODED); decompress_128cap_already_xored(): ==\u0026gt; read sealed bit from 128 rep and stored in the cap struct.\n  target/mips/op_helper_cheri.c:\n store_cap_to_memory(); // L2197 CHERI_128; L2313 CHERI_MAGIC128; L2484: CHERI 256 compress_128cap(csp) -\u0026gt; compress_128cap_without_xor() -\u0026gt; add seal_bit\n load_cap_from_memory(); //\n decompress_128cap(pesbt, cursor, \u0026amp;ncd) -\u0026gt; decompress_128cap_already_xored()\n  sealing update in target/mips/cheri_utils.h:\n cap_set_sealed(); cap_set_unsealed(); set_max_perms_capability()  sealing test in target/mips/cheri_utils.h:\n cap_is_sealed_with_type(); cap_is_unsealed();   TODO-2: duing unsealing, do not reset the otype, keep it instead; things might need to change:\nMust change:\n cap_set_unsealed();  Functions might be affected:\n target/mips/op_helper_cheri.c: store_cap_to_memory(),\n target/mips/cheri_utils.h: CAP_OTYPE_UNSEALED;\n cap_set_sealed(); cap_get_otype(); cap_is_sealed_entry(); cap_unseal_entry(); cap_make_sealed_entry();\n// file // target/mips/op_helper_cheri.c  target_ulong CHERI_HELPER_IMPL(ccall_notrap)(CPUMIPSState *env, uint32_t cs, uint32_t cb) { return ccall_common(env, cs, cb, CCALL_SELECTOR_1, GETPC()); } static target_ulong ccall_common(CPUMIPSState *env, uint32_t cs, uint32_t cb, uint32_t selector, uintptr_t _host_return_address) { const cap_register_t *csp = get_readonly_capreg(\u0026amp;env-\u0026gt;active_tc, cs); const cap_register_t *cbp = get_readonly_capreg(\u0026amp;env-\u0026gt;active_tc, cb); /* * CCall: Call into a new security domain */ if (!csp-\u0026gt;cr_tag) { do_raise_c2_exception(env, CP2Ca_TAG, cs); } else if (!cbp-\u0026gt;cr_tag) { do_raise_c2_exception(env, CP2Ca_TAG, cb); } else if (!cap_is_sealed_with_type(cspRuntime check)) { do_raise_c2_exception(env, CP2Ca_SEAL, cs); } else if (!cap_is_sealed_with_type(cbp)) { do_raise_c2_exception(env, CP2Ca_SEAL, cb); } else if (csp-\u0026gt;cr_otype != cbp-\u0026gt;cr_otype || csp-\u0026gt;cr_otype \u0026gt; CAP_MAX_SEALED_OTYPE) { do_raise_c2_exception(env, CP2Ca_TYPE, cs); } else if (!(csp-\u0026gt;cr_perms \u0026amp; CAP_PERM_EXECUTE)) { do_raise_c2_exception(env, CP2Ca_PERM_EXE, cs); } else if (cbp-\u0026gt;cr_perms \u0026amp; CAP_PERM_EXECUTE) { do_raise_c2_exception(env, CP2Ca_PERM_EXE, cb); } else if (!cap_is_in_bounds(csp, cap_get_cursor(csp), 1)) { // TODO: check for at least one instruction worth of data? Like cjr/cjalr? do_raise_c2_exception(env, CP2Ca_LENGTH, cs); } else { if (selector == CCALL_SELECTOR_0) { do_raise_c2_exception(env, CP2Ca_CALL, cs); } else if (!(csp-\u0026gt;cr_perms \u0026amp; CAP_PERM_CCALL)){ do_raise_c2_exception(env, CP2Ca_PERM_CCALL, cs); } else if (!(cbp-\u0026gt;cr_perms \u0026amp; CAP_PERM_CCALL)){ do_raise_c2_exception(env, CP2Ca_PERM_CCALL, cb); } else { cap_register_t idc = *cbp; cap_set_unsealed(\u0026amp;idc); update_capreg(\u0026amp;env-\u0026gt;active_tc, CP2CAP_IDC, \u0026amp;idc); // The capability register is loaded into PCC during delay slot  env-\u0026gt;active_tc.CapBranchTarget = *csp; // XXXAR: clearing these fields is not strictly needed since they  // aren\u0026#39;t copied from the CapBranchTarget to $pcc but it does make  // the LOG_INSTR output less confusing.  cap_set_unsealed(\u0026amp;env-\u0026gt;active_tc.CapBranchTarget); // Return the branch target address  return cap_get_cursor(csp); } } return (target_ulong)0; }// file // target/mips/cheri_utils.h  static inline void cap_set_unsealed(cap_register_t* c) { assert(c-\u0026gt;cr_tag); assert(cap_is_sealed_with_type(c)); assert(c-\u0026gt;cr_otype \u0026lt;= CAP_MAX_SEALED_OTYPE \u0026amp;\u0026amp; \u0026#34;should not use this to unsealed reserved types\u0026#34;); c-\u0026gt;cr_otype = CAP_OTYPE_UNSEALED; #ifndef CHERI_128 assert(c-\u0026gt;_sbit_for_memory == true); c-\u0026gt;_sbit_for_memory = false; #endif }   cap_register There is no seal bit (for memory) in 256-bit cap\n// file // target/mips/cpu.h /* * Please note if this structure is changed then the TCG gen_branch() in * translate.c may need to be changed as well. */ struct cap_register { /* offset = cursor - base */ uint64_t cr_offset; /* Capability offset */ uint64_t cr_base; /* Capability base addr */ /* Length is actually 65 bits (TODO: should store top instead) */ unsigned __int128 _cr_top; /* Capability top */ uint32_t cr_perms; /* Permissions */ uint32_t cr_uperms; /* User Permissions */ #ifdef CHERI_128  uint64_t cr_pesbt_xored_for_mem; /* Perms, E, Sealed, Bot, \u0026amp; Top bits (128-bit) */ #endif  uint32_t cr_otype; /* Object Type, 24 bits */ uint8_t cr_tag; /* Tag */ #ifndef CHERI_128  bool _sbit_for_memory; #endif };// file // target/mips/cheri-compressed-cap/cheri_compressed_cap.h  // QEMU already provides cap_register_t but if used in other programs // we want to define it here: #ifndef HAVE_CAP_REGISTER_T struct cap_register { /* offset = cursor - base */ uint64_t cr_offset; /* Capability offset */ uint64_t cr_base; /* Capability base addr */ cc128_length_t _cr_top; /* Capability top */ uint32_t cr_perms; /* Permissions */ uint32_t cr_uperms; /* User Permissions */ uint64_t cr_pesbt_xored_for_mem; /* Perms, E, Sealed, Bot, \u0026amp; Top bits (128-bit) */ uint32_t cr_otype; /* Object Type, 24 bits */ uint8_t cr_tag; /* Tag */ uint8_t _sbit_for_memory; /* sealed flag */ #ifdef __cplusplus  inline uint64_t base() const { return cr_base; } inline uint64_t address() const { return cr_base + cr_offset; } inline cc128_length_t top() const { return _cr_top; } inline uint64_t top64() const { const cc128_length_t t = top(); return t \u0026gt; UINT64_MAX ? UINT64_MAX : (uint64_t)t; } inline cc128_length_t length() const { return _cr_top - cr_base; } inline uint64_t length64() const { const cc128_length_t l = length(); return l \u0026gt; UINT64_MAX ? UINT64_MAX : (uint64_t)l; } #endif }; typedef struct cap_register cap_register_t; #endif Reference:\n CLoadTags  Q\u0026amp;A How it is accessing the tag table without access data memory? call cheri_get_many Reference 1 // in disas/mips.c {\u0026#34;cloadtags\u0026#34;, \u0026#34;t,+b\u0026#34;, 0x4800.07bf, 0xffe0,07ff, 0, 0, I1}, Instruction ISA definition in C: // target/mips/helper.h DEF_HELPER_3(cloadtags, tl, env, i32, cap_checked_ptr) // target/mips/os_helper_cheri.c target_ulong CHERI_HELPER_IMPL(cloadtags(CPUArchState *env, uint32_t cb, uint64_t cbcursor)) Helper function to access tag table in memory. // in target/cheri-common/cheri_tagmem.c int cheri_tag_get_many(CPUArchState *env, target_ulong vaddr, int reg, hwaddr *ret_paddr, uintptr_t pc)// target/mips/translate_cheri.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": " TCG Frontend Ops1 implements supported operations for the targe CPU (what QEMU executes; not where QEMU executes).\n[tcg/tcg.h]() contains frontend helpers.\n// file // tcg/tcg.h\nALL CHERI/MIPS Instructinos are defined as emulating functions in target/mips/helper.h\n// file // target/mips/helper.h  // QEMU-CHERI extension: DEF_HELPER_1(mfc0_rtc64, i64, env) DEF_HELPER_2(mtc0_rtc64, void, env, i64) // BERI extension: DEF_HELPER_1(mfc0_coreid, tl, env) DEF_HELPER_2(cheri_debug_message, void, env, i64) #if defined(TARGET_CHERI) DEF_HELPER_2(mtc2_dumpcstate, void, env, tl) DEF_HELPER_1(ccheck_btarget, void, env) DEF_HELPER_2(ccheck_pc, void, env, i64) DEF_HELPER_3(ccheck_store, tl, env, tl, i32) DEF_HELPER_3(ccheck_store_right, tl, env, tl, i32) DEF_HELPER_3(ccheck_load, tl, env, tl, i32) DEF_HELPER_3(ccheck_load_right, tl, env, tl, i32) DEF_HELPER_5(cinvalidate_tag, void, env, tl, i32, i32, tl) DEF_HELPER_5(cinvalidate_tag_left_right, void, env, tl, i32, i32, tl) DEF_HELPER_5(cinvalidate_tag32, void, env, tl, i32, i32, i32) DEF_HELPER_4(candperm, void, env, i32, i32, tl) DEF_HELPER_3(cbez, tl, env, i32, i32) DEF_HELPER_3(cbnz, tl, env, i32, i32) DEF_HELPER_3(cbts, tl, env, i32, i32) DEF_HELPER_3(cbtu, tl, env, i32, i32) DEF_HELPER_3(ccall, void, env, i32, i32) DEF_HELPER_3(ccall_notrap, tl, env, i32, i32) DEF_HELPER_3(ccheckperm, void, env, i32, tl) DEF_HELPER_3(cchecktype, void, env, i32, i32) DEF_HELPER_2(cclearreg, void, env, i32) DEF_HELPER_3(ccleartag, void, env, i32, i32) DEF_HELPER_4(cfromptr, void, env, i32, i32, tl) DEF_HELPER_2(cgetaddr, tl, env, i32) DEF_HELPER_2(cgetbase, tl, env, i32) DEF_HELPER_1(cgetcause, tl, env) DEF_HELPER_2(cgetlen, tl, env, i32) DEF_HELPER_2(cgetoffset, tl, env, i32) DEF_HELPER_2(cgetpcc, void, env, i32) DEF_HELPER_3(cgetpccsetoffset, void, env, i32, tl) DEF_HELPER_2(cgetperm, tl, env, i32) DEF_HELPER_2(cgetsealed, tl, env, i32) DEF_HELPER_2(cgettag, tl, env, i32) DEF_HELPER_2(cgettype, tl, env, i32) DEF_HELPER_4(cincbase, void, env, i32, i32, tl) DEF_HELPER_4(cincoffset, void, env, i32, i32, tl) DEF_HELPER_3(cjalr, tl, env, i32, i32) DEF_HELPER_2(cjr, tl, env, i32) DEF_HELPER_1(creturn, void, env) DEF_HELPER_4(cseal, void, env, i32, i32, i32) DEF_HELPER_4(ccseal, void, env, i32, i32, i32) DEF_HELPER_4(csetbounds, void, env, i32, i32, tl) DEF_HELPER_4(csetboundsexact, void, env, i32, i32, tl) DEF_HELPER_2(crap, tl, env, tl) DEF_HELPER_2(cram, tl, env, tl) DEF_HELPER_3(csub, tl, env, i32, i32) DEF_HELPER_2(csetcause, void, env, tl) DEF_HELPER_4(csetlen, void, env, i32, i32, tl) DEF_HELPER_4(csetoffset, void, env, i32, i32, tl) DEF_HELPER_3(ctoptr, tl, env, i32, i32) DEF_HELPER_4(cunseal, void, env, i32, i32, i32) DEF_HELPER_4(cmovz, void, env, i32, i32, tl) DEF_HELPER_4(cmovn, void, env, i32, i32, tl) DEF_HELPER_4(cbuildcap, void, env, i32, i32, i32) DEF_HELPER_4(ccopytype, void, env, i32, i32, i32) DEF_HELPER_3(creadhwr, void, env, i32, i32) DEF_HELPER_3(cwritehwr, void, env, i32, i32) DEF_HELPER_3(csealentry, void, env, i32, i32) DEF_HELPER_3(cloadtags, tl, env, i32, i64) DEF_HELPER_3(ceq, tl, env, i32, i32) DEF_HELPER_3(cne, tl, env, i32, i32) DEF_HELPER_3(clt, tl, env, i32, i32) DEF_HELPER_3(cle, tl, env, i32, i32) DEF_HELPER_3(cltu, tl, env, i32, i32) DEF_HELPER_3(cleu, tl, env, i32, i32) DEF_HELPER_3(cexeq, tl, env, i32, i32) DEF_HELPER_3(cnexeq, tl, env, i32, i32) DEF_HELPER_4(csetaddr, void, env, i32, i32, tl) DEF_HELPER_3(cgetandaddr, tl, env, i32, tl) DEF_HELPER_4(candaddr, void, env, i32, i32, tl) DEF_HELPER_3(ctestsubset, tl, env, i32, i32) DEF_HELPER_5(cload, tl, env, i32, tl, i32, i32) DEF_HELPER_5(cstore, tl, env, i32, tl, i32, i32) DEF_HELPER_3(cloadlinked, tl, env, i32, i32) DEF_HELPER_3(cstorecond, tl, env, i32, i32) DEF_HELPER_3(cscc_without_tcg, tl, env, i32, i32) DEF_HELPER_5(csc_without_tcg, void, env, i32, i32, tl, i32) DEF_HELPER_5(clc_without_tcg, void, env, i32, i32, tl, i32) DEF_HELPER_3(cllc_without_tcg, void, env, i32, i32) #endif  #if defined(TARGET_CHERI) /* cannot access EPC directly since it is the offset of EPCC */ DEF_HELPER_1(mfc0_epc, tl, env) DEF_HELPER_2(mtc0_epc, void, env, tl) DEF_HELPER_1(mfc0_error_epc, tl, env) DEF_HELPER_2(mtc0_error_epc, void, env, tl) #endif  #if defined(TARGET_CHERI) DEF_HELPER_2(rdhwr_statcounters_icount, tl, env, i32) DEF_HELPER_1(rdhwr_statcounters_reset, tl, env) DEF_HELPER_1(rdhwr_statcounters_itlb_miss, tl, env) DEF_HELPER_1(rdhwr_statcounters_dtlb_miss, tl, env) DEF_HELPER_2(rdhwr_statcounters_memory, tl, env, i32) DEF_HELPER_2(rdhwr_statcounters_ignored, tl, env, i32) #endif New instruction TCG frontend.\nTCG Frontend\nTCG Basics\nDecodeTree Specification\n  QEMU TCG Frontend ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/build/",
	"title": "Build",
	"tags": [],
	"description": "",
	"content": " Isaac: Just a quick FYI, since I just noticed this problem: Apparently, cheribuild hardcodes the git branch to use when building qemu, regardless of the \u0026ndash;qemu/git-revision setting. A manual clone is needed to override. (I was wondering why my change to how $DDC was handled wasn\u0026rsquo;t reflected in the simulator. It turns out that I was building CTSRD\u0026rsquo;s branch, not my branch.)\n  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/hacking/sandbox_user/",
	"title": "Sandbox_user",
	"tags": [],
	"description": "",
	"content": " Error: seal violation when no ccall attributes Error: Could not print inside sandbox using default PCC/DCC Outside sandbox the printf function address is 0x4026,b0b0; Inside sandbox the printf function address is 0x401d,6ec0,0000,0000, which invalid address.\nProblem The problem comes out to be an issue of the calling convention. By default, functions are called by instruction jalr $t9, where t9 stores the entry address for the target function. When the target function is executed, the compiler still uses t9 to compute the address of variables and global functions, such as printf.\nSolution Possible solutions:\n manually reset t9 to be the target function address before ccall to the target function; manually reset t9 to be the function entry at the beginning of each target function; tell compiler to automatically do either of the above; tell compiler to recognize the ccall case and use a different manner to compute global variables and function addresses.  Outside the sandbox 0x20b58 \u0026lt;test_sandboxA+160\u0026gt;:\tnop 0x20b5c:\tnop =\u0026gt; 0x20b60 \u0026lt;main\u0026gt;:\tdaddiu\tsp,sp,-144 // t9: 0x20b60; sp = 0x7f,fffe,fa50 - 144 = 0x7f,fffe,f9c0 0x20b64 \u0026lt;main+4\u0026gt;:\tsd\tra,136(sp) // ra: 0x2010c 0x20b68 \u0026lt;main+8\u0026gt;:\tsd\ts8,128(sp) // s8: 0x7ffffefa50 0x20b6c \u0026lt;main+12\u0026gt;:\tsd\tgp,120(sp) // gp: 0x48010 0x20b70 \u0026lt;main+16\u0026gt;:\tmove\ts8,sp // s8 = 0x7f,fffe,f9c0 0x20b74 \u0026lt;main+20\u0026gt;:\tlui\tat,0x2 // at = 0x2,0000 0x20b78 \u0026lt;main+24\u0026gt;:\tdaddu\tat,at,t9 // t9: 0x2,0b60; at = 0x40b60; 0x20b7c \u0026lt;main+28\u0026gt;:\tdaddiu\tat,at,29872 // at = 0x48010 0x20b80 \u0026lt;main+32\u0026gt;:\tsw\tzero,116(s8) // [0x7ffffefa34] = 0 0x20b84 \u0026lt;main+36\u0026gt;:\tld\tv0,-32688(at) // v0 = [0x48010 - 32688] = [0x40060] = 0x1,0000 0x20b88 \u0026lt;main+40\u0026gt;:\tdaddiu\ta0,v0,2083 // a0 = 0x1,0000 + 2083 = 0x10823 0x20b8c \u0026lt;main+44\u0026gt;:\tld\tt9,-32424(at) // t9 = [0x48010 - 32424] = [0x40168] = 0x4026,b0b0 0x20b90 \u0026lt;main+48\u0026gt;:\tmove\tgp,at // gp = 0x48010 0x20b94 \u0026lt;main+52\u0026gt;:\tsd\tat,104(s8) // [stacktop] = 0x48010 0x20b98 \u0026lt;main+56\u0026gt;:\tjalr\tt9 // t9: 0x4026b0b0 0x20b9c \u0026lt;main+60\u0026gt;:\tnop Inside the sandbox With Wrong t9, which is not changed since updated when calling sandbox_invoke using jalr $t9; when function sandboxA_print is called via ccall and executed, compiler still generate code assuming t9 points to the function entry.\n0x20444 \u0026lt;sandbox_invoke\u0026gt;:\tccall\t$c1,$c2,1 // t9: 0x20444; at: 0x48010 0x20448 \u0026lt;sandbox_invoke+4\u0026gt;:\tnop 0x2044c \u0026lt;sandbox_invoke_end\u0026gt;:\t0x4170001 0x20450 \u0026lt;sandboxA_print\u0026gt;:\tdaddiu\tsp,sp,-32 // sp: 0x7f,fffe,f9a0; t9: 0x20444; at: 0x48010; 0x20454 \u0026lt;sandboxA_print+4\u0026gt;:\tsd\tra,24(sp) // sp: 0x7f,fffe,f980; ra: 0x20b48; 0x20458 \u0026lt;sandboxA_print+8\u0026gt;:\tsd\ts8,16(sp) // s8: 0x7f,fffe,f9a0; 0x2045c \u0026lt;sandboxA_print+12\u0026gt;:\tsd\tgp,8(sp) // gp: 0x48010; 0x20460 \u0026lt;sandboxA_print+16\u0026gt;:\tmove\ts8,sp // s8 = 0x7f,fffe,f980; 0x20464 \u0026lt;sandboxA_print+20\u0026gt;:\tlui\tat,0x2 // at = 0x2,0000 0x20468 \u0026lt;sandboxA_print+24\u0026gt;:\tdaddu\tat,at,t9 // at += 0x2,0444 = 0x4,0444 0x2046c \u0026lt;sandboxA_print+28\u0026gt;:\tdaddiu\tat,at,31680 // at = 0x48004 0x20470 \u0026lt;sandboxA_print+32\u0026gt;:\tld\tv0,-32688(at) // v0 = [0x40054] = 0x3,0000,0000,0000 0x20474 \u0026lt;sandboxA_print+36\u0026gt;:\tdaddiu\ta0,v0,2257 // a0 = 0x3,0000,0000,08d1 0x20478 \u0026lt;sandboxA_print+40\u0026gt;:\tld\tt9,-32424(at) // t9 = [0x48004 - 32424] = [0x4015c] = 0x401d,6ec0,0000,0000 0x2047c \u0026lt;sandboxA_print+44\u0026gt;:\tmove\tgp,at // gp = 0x48004 0x20480 \u0026lt;sandboxA_print+48\u0026gt;:\tjalr\tt9 // t9: this is supposed to be printf. but the address is 0x401d,6ec0,0000,0000, invalid. 0x20484 \u0026lt;sandboxA_print+52\u0026gt;:\tnop gdb commands:\nset mips abi cheri128\nb main, sandboxA_print, test_sandboxA\nx /30gi ($pc-0x10) x /20gx ($at - 32688)\ninfo reg v0\nsi 30 ni 20\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/tools/gdb/",
	"title": "Gdb",
	"tags": [],
	"description": "",
	"content": "CheatSheet\nReference:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/hacking/hello/",
	"title": "Hello",
	"tags": [],
	"description": "",
	"content": " Hello World Makefile for cross compiling\nExecution in CheriBSD\nError: relocation R_MIPS_HIGHEST cannot be used against local symbol; cheri-unknown-freebsd-ld: error: relocation R_MIPS_HIGHEST cannot be used against local symbol; recompile with -fPIC \u0026gt;\u0026gt;\u0026gt; defined in /root/cheri/output/rootfs-purecap128/usr/libcheri/libcheri.a(libcheri_invoke_cabi.o) \u0026gt;\u0026gt;\u0026gt; referenced by libcheri_invoke_cabi.S:156 (/root/cheri/cheribsd/lib/libcheri/mips/libcheri_invoke_cabi.S:156) \u0026gt;\u0026gt;\u0026gt; libcheri_invoke_cabi.o:(cheri_invoke) in archive /root/cheri/output/rootfs-purecap128/usr/libcheri/libcheri.a\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/class-pldi/workshops/",
	"title": "Workshops",
	"tags": [],
	"description": "",
	"content": "Reference:\n 09/08 Hello world from diff languages:\n Ada Haskell Ocaml Prolog Scheme \u0026hellip;  Interpreter: better error reports: have source code at runtime.\n09/22 FIRST(each_rightHS); Follow(LHS); PREDICT(production of each rules)\n11\u0026frasl;10  C#/Python/Ruby: iterator permutations.\ndef it(n) for i in 1 .. n yield i  Stack push and pop.\n Hash table.\n  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-sandbox/class-object/",
	"title": "Class Object",
	"tags": [],
	"description": "",
	"content": " Sandbox Class vs Object Class: \u0026lsquo;sandbox class\u0026rsquo; is an instance of code that may be sandboxed and invoked, along with statistics/monitoring information, etc. (see lib/libcheri/libcheri_sandbox_internal.h)\nObject: \u0026lsquo;sandbox object\u0026rsquo;, or sandbox instance, is an in-flight combination of code and data. Currently, due the compiler limitations, we must conflate the \u0026lsquo;code\u0026rsquo;, \u0026lsquo;heap\u0026rsquo;, and \u0026lsquo;stack\u0026rsquo;, but eventually would like to allow one VM mapping of code to serve many object instances. This would also ease supporting multithreaded objects. (see lib/libcheri/libcheri_sandbox_internal.h)\nImplementations A sandbox is composed of a sandbox class and an object:\n/* * A classic \u0026#39;sandbox\u0026#39; is actually a combination of a sandbox class and a * sandbox object. We continue to support this model as it is used in some * CHERI demo and test code. */ struct sandbox { struct sandbox_class *sb_sandbox_classp; struct sandbox_object *sb_sandbox_objectp; }; A sandbox class contains:\n its code and data map. class\u0026rsquo;s code cap: rtld, invoke; ccall classes/methods: provided, required statistics of the class.\n// file: // lib/libcheri/libcheri_sandbox_internal.h  #define SANDBOX_CLASS_METHOD_COUNT 32 struct sandbox_class { char *sbc_path; int sbc_fd; struct stat sbc_stat; #ifdef SPLIT_CODE_DATA  size_t sbc_codelen; void *sbc_codemem; struct sandbox_map *sbc_codemap; #endif  struct sandbox_map *sbc_datamap; #ifdef SPLIT_CODE_DATA  /* * The class\u0026#39;s code capabilities, in various incarnations required for * class creation. These will be used for all objects in the class. */ void * __capability sbc_classcap_rtld; /* Ctor/dtor */ void * __capability sbc_classcap_invoke; /* Object invoke */ #endif  /* * Class CCall methods. */ struct sandbox_provided_classes *sbc_provided_classes; struct sandbox_required_methods *sbc_required_methods; /* * Class and invoke() method statistics. */ struct sandbox_class_stat *sbc_sandbox_class_statp; struct sandbox_method_stat *sbc_sandbox_method_nonamep; struct sandbox_method_stat *sbc_sandbox_methods[ SANDBOX_CLASS_METHOD_COUNT]; };  A sandbox object includes:\n IDC, for both rtld and invocation entry, and entry vector code; PCC for rtld; PCC for invocation; vtable pointer, used for CHERI system classes; unused for loaded (confined) classes; DDC for invocation; libcheri_tls: base address for tls; CSP for invocation; class pointer; object pointer; data length; heap base, length; stack length; sandbox flags; sealed code/data capabilities for general object invocation and accessing the objects\u0026rsquo;s runtime linker methods (struct cheri_object sbo_cheri_object_rtld, sbo_cheri_object_invoke;) system object capabilities: sbo_cheri_object_system; stack capability; object statistics; private data for system objects;\nstruct #if _MIPS_SZCAP == 128 __attribute__ ((aligned(4096))) #endif sandbox_object { /* * IMPORTANT: These fields must be at the top of the sandbox_object, * and in this specific order, as corresponding offsets to them are * included in assembly domain-transition code in * cheri_ccall_trampoline.S. * * sbo_idc IDC to install for both rtld and invocation entry. * The entry vector code will also use this * capability, with offset set to zero, as the * installed DDC. * * sbo_rtld_pcc PCC to install for rtld operations. * * sbo_invoke_pcc PCC to install on invocation. * * sbo_vtable VTable pointer used for CHERI system classes; * unused for loaded (confined) classes. * * sbo_ddc DDC to install on invocation. * * sbo_csp CSP to install on invocation. * * These capabilities are used by libcheri itself when accessing data * from within the CCall trampoline, so that we don\u0026#39;t have to assume * that the sandbox_object pointer is DDC-relative: * * sbo_libcheri_tls Access TLS relative to this register. * * XXXRW: It would be nice if the offsets to these fields were in * shared headers, allowing compile-time asserts to be used to check * binary compatibility has not been broken. */ void * __capability sbo_idc; /* Capability offset 0. */ void * __capability sbo_rtld_pcc; /* Capability offset 1. */ void * __capability sbo_invoke_pcc;/* Capability offset 2. */ void * __capability sbo_vtable; /* Capability offset 3. */ void * __capability sbo_ddc; /* Capability offset 4. */ void * __capability sbo_libcheri_tls; /* Capability offset 5. */ void * __capability sbo_csp; /* Capability offset 6. */ union { int sbo_busy; /* Capability offset 7. */ void * __capability _sbo_reserved; /* Pad to capability size. */ }; /* * Further fields are unknown to the assembly domain-transition code. */ struct sandbox_class *sbo_sandbox_classp; struct sandbox_object *sbo_sandbox_system_objectp; void *sbo_datamem; void *sbo_stackmem; register_t sbo_datalen; register_t sbo_heapbase; register_t sbo_heaplen; register_t sbo_stacklen; uint sbo_flags; /* Sandbox flags. */ /* * Sealed code and data capabilities suitable to access the object\u0026#39;s * run-time linker methods and also general object-capability * invocation. */ struct cheri_object sbo_cheri_object_rtld; struct cheri_object sbo_cheri_object_invoke; /* * System-object capabilities that can be passed to the object via * sandbox metadata. */ struct cheri_object sbo_cheri_object_system; /* * Stack capability that will also be installed in the object during * domain transition. */ void * __capability sbo_stackcap; /* * Sandbox statistics. */ struct sandbox_object_stat *sbo_sandbox_object_statp; /* * Private data for system objects -- e.g., for cheri_fd, a pointer to * file-descriptor data. */ void * __capability sbo_private_data; };   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-sandbox/sandbox-methods/",
	"title": "Sandbox Methods",
	"tags": [],
	"description": "",
	"content": " sandbox_provided_classes\nNo two binaries can provide the same class as vtable offsets would be inconsistant.\n/* * List of classes provided by a sandbox binary. Each binary can * support one or more classes. No two binaries can provide the same * class as vtable offsets would be inconsistant. */ struct sandbox_provided_classes { struct sandbox_provided_methods\t**spcs_classes;\t/* Class pointers */ size_t\tspcs_nclasses; /* Number of methods */ size_t\tspcs_maxclasses; /* Array size */ size_t\tspcs_nmethods; /* Total methods */ vm_offset_t\tspcs_base;\t/* Base of vtable */ }; sandbox_required_method\n/* * Description of a method required by a sandbox to be called by ccall. */ struct sandbox_required_method { char\t*srm_class;\t/* Class name */ char\t*srm_method;\t/* Method name */ vm_offset_t\tsrm_index_offset;\t/* Offset of caller variable */ vm_offset_t\tsrm_vtable_offset;\t/* Method number */ bool\tsrm_resolved;\t/* Resolved? */ }; sandbox_make_vtable // file: // lib/libcheri/libcheri_sandbox_methods.c  vm_offset_t * __capability sandbox_make_vtable(void *dataptr, const char *class, struct sandbox_provided_classes *provided_classes) { vm_offset_t * __capability vtable; vm_offset_t *cheri_ccallee_base; size_t i, index, length, m; struct sandbox_provided_method *pm; struct sandbox_provided_methods *pms; if (provided_classes-\u0026gt;spcs_nclasses == 0) return (NULL); if ((vtable = calloc_c(provided_classes-\u0026gt;spcs_nmethods, sizeof(*vtable))) == NULL) { warnx(\u0026#34;%s: calloc\u0026#34;, __func__); return (NULL); } #ifdef __CHERI_PURE_CAPABILITY__  /* * XXXRW: For system classes, a NULL dataptr is passed in, signifying * that bases are relative to virtual address 0x0. This isn\u0026#39;t really * the right thing for CheriABI, where we should instead pass in the * default capability with an offset of zero. For now, handle that * here, but probably the caller should do that instead. */ if (dataptr == NULL) dataptr = cheri_clearperm( cheri_setoffset(cheri_getpcc(), 0), CHERI_PERM_EXECUTE); #endif  cheri_ccallee_base = (vm_offset_t *)dataptr + provided_classes-\u0026gt;spcs_base / sizeof(vm_offset_t); length = provided_classes-\u0026gt;spcs_nmethods * sizeof(*vtable); assert(cheri_getlen(vtable) \u0026gt;= length); #ifdef DEBUG  printf(\u0026#34;%s(%s): spcs_nmethods = %zd, length = %zd\\n\u0026#34;, __func__, class, provided_classes-\u0026gt;spcs_nmethods, length); #endif  if (class == NULL) { #ifdef DEBUG  printf(\u0026#34;%s: class == NULL -\u0026gt; copying whole table\\n\u0026#34;, __func__); #endif  memcpy_c_tocap(vtable, cheri_ccallee_base, length); return (cheri_andperm(vtable, CHERI_PERM_LOAD)); } for (i = 0; i \u0026lt; provided_classes-\u0026gt;spcs_nclasses; i++) { pms = provided_classes-\u0026gt;spcs_classes[i]; #ifdef DEBUG  printf(\u0026#34;%s: provided_classes[%zd]=\u0026#39;%s\u0026#39;, want \u0026#39;%s\u0026#39;\\n\u0026#34;, __func__, i, pms-\u0026gt;spms_class, class); #endif  if (strcmp(pms-\u0026gt;spms_class, class) != 0) continue; for (m = 0; m \u0026lt; pms-\u0026gt;spms_nmethods; m++) { pm = pms-\u0026gt;spms_methods + m; index = (pm-\u0026gt;spm_index_offset - provided_classes-\u0026gt;spcs_base) / sizeof(*vtable); #if defined(DEBUG) \u0026amp;\u0026amp; DEBUG \u0026gt; 1  printf(\u0026#34;%s: provided_classes[%zd] method[%zd] is \u0026#39;%s\u0026#39;.\u0026#34; \u0026#34; index = %zd\\n\u0026#34;, __func__, i, m, pm-\u0026gt;spm_method, index); #endif  assert(vtable[index] == 0); vtable[index] = cheri_ccallee_base[index]; } #ifdef DEBUG  printf(\u0026#34;%s: added [%zd] methods to vtable for %s\\n\u0026#34;, __func__, m, pms-\u0026gt;spms_class); #endif  /* TODO: set bounds on vtable up to last index? */ return (cheri_andperm(vtable, CHERI_PERM_LOAD)); } free_c(vtable); return (NULL); }  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/basics/dinosaur/",
	"title": "Dinosaur",
	"tags": [],
	"description": "",
	"content": "Reference:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheriabi/chericwrappers/",
	"title": "Chericwrappers",
	"tags": [],
	"description": "",
	"content": " File sys/cheri/cheric/h defines programmer-friendly macros for CHERI-aware C code. These pieces of code require use of CHERI-aware Clang/LLVM, and fully capability context switching.\ncheri_andperm // file: sys/cheri/cheric.h  #define\tcheri_andperm(x, y)\t__builtin_cheri_perms_and((x), (y)) cheri_seal() cheri_seal() takes two arguments: the capability to seal, and the sealing capability. It is a macro defined to be a builtin func:\n// file // sys/cheri/cheric.h  #define cheri_seal(x, y) __builtin_cheri_seal((x), (y))  cheri_andperm // file: sys/cheri/cheric.h // #if __has_feature(capabilities) || defined(__CHERI__) #define\tcheri_andperm(x, y)\t__builtin_cheri_perms_and((x), (y))  // file: lib/libc/gen/tls_malloc.c  // #ifndef __CHERI_PURE_CAPABILITY__ #define cheri_andperm(ptr, size) ((void *)(ptr)) __builtin_cheri_perms_and is compiler built in function to emit ??? instruction.\nLLVM builtins for Cheri\ncheri_codeptrperm // file: sys/cheri/cheric.h  static __inline void * __capability cheri_codeptrperm(const void *ptr, size_t len, register_t perm) { return (cheri_andperm(cheri_codeptr(ptr, len), perm | CHERI_PERM_GLOBAL)); } cheri_codeptr(ptr,len)\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/mips/instructions/",
	"title": "Instructions",
	"tags": [],
	"description": "",
	"content": "Reference: https://github.com/MIPT-ILab/mipt-mips/wiki/MIPS-Instruction-Set\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/mips/regs/",
	"title": "Regs",
	"tags": [],
	"description": "",
	"content": "Source:\n https://github.com/MIPT-ILab/mipt-mips/wiki/MIPS-registers http://www.cs.uwm.edu/classes/cs315/Bacon/Lecture/HTML/ch05s03.html     Number Name Use Preserved across function calls?     0 $zero constant 0 —   1 $at assembler temporary no   2, 3 $v0, $v1 function return values no   4 - 7 $a0 - $a3 function arguments no   8 - 15 $t0 - $t7 temporaries no   16 - 23 $s0 - $s7 temporaries yes   24, 25 $t8, $t9 temporaries no   26, 27 $k0, $k1 reserved for OS kernel —   28 $gp global pointer —   29 $sp stack pointer —   30 $s8 temporaries yes   31 $ra return address —     "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/arch-asm/",
	"title": "Arch - Basics - Assembly",
	"tags": [],
	"description": "",
	"content": " Assembler Directives Reference:\n GNU AS - assembler directives Pseudo Op-Codes  .cpload directives, etc.  CFI (Call Frame Information) directives  .cfi_personality directives, etc.  Exception Frames  .eh_frame section.  TI - MSP430 - Assembler Directives  Assembler directives supply data to the program and control the assembly process. Directives are commands that are part of the assmbler syntax but are not related to the processor ISA. Assembler directives enable you to do the following:\n Assemble code and data into specified sections Reserve space in memory for uninitialized variables Control the appearance of listings Initialize memory Assemble conditional blocks Define global variables Specify libraries from which the assembler can obtain macros Examine symbolic debugging information  Assembler directives have names that begins with a period (.). The rest of the name is letters, ususally in lower case.\nMore directives Call Frame Directives Refrence: CFI (Call Frame Information) directives\n .cfi_personality encoding [, exp] .cfi_signal_frame \u0026hellip;  .set symbol, expression .macro .macro and .endm together defines a macro, which generates assembly code blocks.\nExample:\n.macro sum from=0, to=5 .long \\from .if \\to-\\from sum \u0026quot;(\\from+1)\u0026quot;,\\to .endif .endm  will generate\n.long 0 .long 1 .long 2 .long 3 .long 4 .long 5  Machine dependent directives Machine Dependent directives for MIPS.\nExample: MSP430: Directives that define sections Reference: TI - MSP430 - Assembler Directives\nMSP430 is a mixed-signal microcontroller, built around a 16-bit RISC CPU.\n .bss directive reserves space in the .bss section for uninitialized variables. .data directive identifies portions of code in the .data section. The .data section usually contains initialized data. .intvec directive creates an interrupt vector entry that points to an interrupt routine name. .retain directive can be used to indicate that the current of specified section must be included in the linked output. Thus even if no other sections included in the link reference the current or specified section, it is still included in the link. .retainrefs directive can be used to force sections that refer to the specified section. This is useful in the case of interrupt vectors. How is it usefull ??? .sect directive defines an initialized named section and associates subsequent code or data with that section. A section defined with .sect can contain code or data. .text directive identifies portions of code in the .text section. The .text section usually contains executable code. .usect directive reserves space in an uninitialized named section. The .usect directive is similar to the .bss directive, but it allows you to reserve space separately from the .bss section.   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-ccall/trampolines/",
	"title": "Trampolines",
	"tags": [],
	"description": "",
	"content": " file: lib/libcheri/mips/libcheri_ccall_trampoline.S\nThis file contains \u0026ldquo;userspace implementation of libcheri invocation and return semantics\u0026rdquo;. \u0026ldquo;These vectors are intended to run on the inside of sealed call and return code capabilities, perform any necessary checks, transform the capability register file, and then jump into the target domain.\nOutline of trampolines Three types of objects and with corresponding three kinds of CCalls:\n for rtld init: libcheri_ccall_rtld_vector: is used for rtld initialization and destruction.\n for invoke: libcheri_ccall_invoke_vector: is used for general invocation.\n for return: libcheri_creturn_vector:\n  Note: “We would most ideally share an implementation, varying the target $pcc load based on sealed-capability object type \u0026ndash; but, unfortunately, the current userspace CCall instruction doesn\u0026rsquo;t [yet] provide reliable access to the operand sealed capabilities.”\nIn details rtld init to invoke to return trusted stack pointer Macro: compute_libcheri_trusted_stack dst_cap, sbop_cap, tmp_reg1, tmp_reg2. First get offset of stack and store it in tmp_reg1, then\nMacro: compute_libcheri_trusted_stack_tls_offset dst_reg, tmp_reg: Use thread-local storage to retrieve the trusted stack for the current pthread. (XXXRW: Clang appears to generate roughly this code across multiple ABIs and regardless of -fpic/-fno-pic, if -mno-abicalls is used. So, go with this in all cases, but much testing definitely required \u0026ndash; e.g., once we have dynamically linked pure-capability binaries using.)\n??? LLM: Why trusted stack pointer is stored via TLS? Is this a trustworthy place? Macro switch #ifdef __CHERI_CAPABILITY_TLS__ is used for ??? trusted stack in CheriBSD\nSimple usage examples libcheri ccall implementation\nMiscellaneous  NO multi-threading: We provide a simply lock around each object to prevent concurrent entry; an error is returned if this is attempted. In the future, we may instead want to support multiple stacks per sandbox as well as reentrance onto the stack\u0026rdquo;.\n Exception handlers abondoned: The design is similar to our earlier prototype based on a dedicated exception handler, in that we rely on hardware acceleration of certain checks, push and pop trusted stack frames, and clear the register file as required. There are some necessary differences:\n (1) We enter and end with a jump-like, rather than exception enter/return semantic. This means two different code capabilities pointing at the runtime, selecting call or return semantics. (2) We locate a trusted stack using the ambient environments compiler/linker-provided thread-local storage (TLS) rather than kernel per-thread state. (3) Error handling is quite different, as we can\u0026rsquo;t simply jump into the kernel\u0026rsquo;s exception handler. Instead we trigger a suitable signal, or return to the originating context. (XXXRW: More here?)  The implementation assumes that the architecture validates:\n cs and ds accessibility cs and ds tags cs and ds seals cs.otype == ds.otype cs and ds permissions cs.offset vs cs.length    "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/instructions/csc/",
	"title": "Csc",
	"tags": [],
	"description": "",
	"content": "(ISAv7: Ch 7, p240)\nFormat\nCSC cs, rt, offset(cb) CSCR cs, rt(cb) CSCI cs, offset(cb)  Capability register cs is stored at memory location [cb.base + cb.offset + rt + 16 * offset], and the bit in the tag memory associated with this address is set to the value of cs.tag.\nCapability cb must contain a capability that grants permission to store capabilities. The virtual address of [cb.base + cb.offset + rt + 16 * offset] must be capability_size aligned.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/regs/specialregs/",
	"title": "Specialregs",
	"tags": [],
	"description": "",
	"content": "Permissions is required to read special purpose capability registers, but CR3 is not included since it is not a capability register.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/instructions/cgetdefault/",
	"title": "CGet/SetDefault",
	"tags": [],
	"description": "",
	"content": "(ISAv7, ch7.5) CGetDefault and CSetDefault get and set the capability register that is implicitly employed by the legacy MIPS load and store instructions. In the current version of ISA, this register is special-purpose capability register 0.\n# The following are equivalent: CGetDDC $c1 CGetDefault $c1 CReadHWR $c1, $0 # The following are equivalent: CSetDDC $c1 CSetDefault $c1 CWriteHWR $c1, $0   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/class-adv/",
	"title": "Class: Adv",
	"tags": [],
	"description": "",
	"content": " Aug 29 ECE 401\u0026frasl;201. Prof. Engin Ipek, Cornell from High school to Ph.D.\nText book: Computer Arch: a quantitative approach, 6th ed. by John L. Hennessy, David A. Patterson.\n Org: building computer works; Arch: works faster;  FSM design: finite state machine.\nTA: Ryan Wong; Muhammad Mehdi; 527 CSB office hr.\nBlackboard.\nMidterm Oct 29. Final Dec 19.\nThree verilog projects.\n Verilog design projects. expand on basic MIPS R3000 processor.\n Final lab: choices.\n  Stories: Sleep bag, take turns.\nPollan; ECE; Pluses and Minus; when ug, parternes with Ph.D.\nFeatures: Award-winning publishs.\nVerilator: Verilog HDL to C/C++ source code;\nECE 461 (VLSI), 402 (memory), 404 (), 455 (compilers), 456 (OS)\nIntro Goals: multi-dimensional opt problem.\ncorrectness (verify), speed, power efficiently, energy, form factor, cost, usability, safety, security, modularity, compatibility, reliability, programmability, scalability,\nISAs: can only grow, cannot shrink: compatibility.\n what are the instructions # of registers addressing  If history teaches us anything, it is that man, in his quest for knowledge and progress, is determined and cannot be deterred. \u0026ndash; John F. Kennedy (1962)\nMoore\u0026rsquo;s Law.\nSep 3 ECE accounts. Simulators.\nstory of processors number of transistors. Moore\u0026rsquo;s law. recent, TSMC/Samsung.\nSoft errors:\nRAM: flip bits. noises, e.g. cosmic rays. 2018, NAND Flash. 11 nanoclous.\nMinicomputers/mainframes/supercomputers vs. Micro-processors.\nmicro-processors 50% perf increase per year. slowing: pwr + wire delays + soft errors.\n wire delays: 2000: Titan, 4 cycles half chip. now: local vs global wires on multi-cores.  CMOS metal layers. M1 pitch.\nsquare of 2 size of nm: 250, 180, 130, 90, 65, 45, \u0026hellip;., 14, \u0026hellip;, 11\nparallel more than pipelines, to reduces cycles per ins (CPI):\n super scalar: multi issue thread level para. SMT: simultaneous, CMT: multi-processor.  increate of freq pwr density: nuclear reactor, rocket nozzle, sun\u0026rsquo;s surface.\nnum of cores domain specific chips similar story of RAM parallelism and locality.\nVLSI Cost and performance die and round wafer/weife/.\ncost of IC: die, die test, package, package test, yield ratio.\ncost of die: $N{wafer}$ \\over ${N{die} x Y}$\nwhy not square wafer? way of making wafer, by spin during chemical solutions and cut horizontal.\nCost trends of RAM: 1978 \u0026mdash; 2001\ncost of same RAM goes down: yield ratio goes up. learn from failures.\nCost of each generation of RAM goes up.\nSep 05, 2019 Throughput vs. latency.\nCustomer\u0026rsquo;s workload:\n best option. Can build a hw has 1000x faster for a specific workload; not always available:  secrets cannot be shared; user has no idea about how the workload; who is the customer: millions of different customers; marvolous possibility of usages;   \u0026lsquo;Standard\u0026rsquo; workload:\n SPEC (real programs) kernels (livermore loops, linpack): common core of many algorithms. e.g. matrix vector multiplication, FFT, etc. synthetic benchmarks (Whetstone, Dhrystone); toy benchmarks (Quicksort, Towers of Hanoi).  Simulation at many levels\n ISA simulation: instruction stream + memory + reg file =\u0026gt; simulate computing on faked memory \u0026amp; reg file;  emulate software for correctness without an ISA implementation; dynamic instruction count; instructin mix; size of working set; cannot estimate cost, power, speed.  RTL (register transfer language) simulation:  cycle accurate (can count exactly how many cycles will cost) cannot give you cycle time (no frequency), no area, no power  gate-level, circuit level  Frequency area power   Architect: RTL level.\nAnalytical modeling (e.g. queuing theory): too complex\nHow is frequency determined?\n by changing the design. such that IPC goes down.  arithmetic mean vs. geometic mean\n Arithmetic mean. is bogus for normalized times. can make anyone faster. Geometric mean. consistent independent of reference; does not track execution time.  Amdahl\u0026rsquo;s law：  5 minute walk + 10 min bike + 5 min climb to classroom. A fantastic fast bike: 20min -\u0026gt; 10 min. Maximum 2x speedup. $Speedup = T_{old}/T_{new}$. $Fraction{enhanced}$: if 20 seconds of the exe time of a program that takes 60 seconds in total can use enhancement, the fraction is 20\u0026frasl;60. This value, which we call $Fraction{enhanced}$, which is always less than or equal to 1. $Speedup{enhanced}$: If the enhanced portion of program takes 2 seconds in enhanced mode while 5 seconds in original (non-enhanced) mode, the improvement is 5\u0026frasl;2. We will call this value, $Speedup{enhanced}$, which is always greater than 1.\n (0, $f_e$, 1): $f_e$ speed up is $S_e$, then total speed up is\n $S = 1/ ((1 - f_e) + f_e / S_e)$  If an infinite fast speedup of $f_e$\n $S_{max} = 1/(1- f_e)$  Always have big picture in mind\n Eg: 1 GHz to 2 GHz, but 10% cpu and 90% memory time. ==\u0026gt; 1/(0.95) speedup.   EG: multiprocessor scalability.\nCPU perf eval\n$ T=N_{clk}*T_{clk}=IC*CPI*T_{clk}$\nIC: instruction count; CPI: cycles per instruction.\nSep 10 ISA Principles ISA: SW/HW interface.\nISA vs Implementation.\nISA: defines the what.\n what is the programmer visable state what happens on each intruction e.g: num. of registers; types of instructions  Impl: defines the how.\n the sequence of steps; e.g.: the width of the data bus between processor and memory; \u0026ldquo;micro-architecture\u0026rdquo;  Classifying ISAs\ntype of internal storage: - stack abstraction of memory: add; \u0026ndash;\u0026gt; add two on the stack; - JVM. Java byte code ISA. - Internet: keep instruction small. - accumulator: add M; \u0026ndash;\u0026gt; add M with accumulator and store it in accumulator; - register-memory: add Rd, Rs, M; \u0026ndash;\u0026gt; (ALU) can operate both on memory/register; - register-register/load-store: add Rd, Rs, Rt; \u0026ndash;\u0026gt; (ALU) only operate on register; - much faster by avoiding corner cases; - easier.\nCompiler Effects/Wishlist\n number of general regs regularity, orthogonality  law of least surprise no strange side effects consistent addressing modes  Three more\n provide primitives, not solutions simplify trade-offs of alternatives make compile-time constants fast e.g. x = y + 5; // addi, 5 encoded in instruction.  Little/Big endian\n abcd -\u0026gt; mem[4]  Alignment\n aligned architecture: instructions no need to store 2 bits, 32bits aligned;  Addressing modes:\n Rs, #n immediate, (Rs), Register Indirect: Mem[Reg[s]]; (n), n(Rs) Displacement, (Rs+Rt) , @(Rs), Memory Indirect: Mem[Mem[Reg[s]]]; (Rs)+, Auto Increment: Mem[Reg[s]]; Reg[s] + d; ==\u0026gt; d is determined by data type during operation; -(Rs), Auto decrement; n(Rs)[Rt], Scaled: Mem[n+Reg[s]+Reg[t]*d]   VAX had them all. For ease of hand-writing assmebly codes.\n Conditional/unconditional branch  branch/jump distances. Jump register: register r31 for func returns.   Sep 12 Procedure calls\ncall a function written by somebody else: calling convention.\n Caller saved convention:\n save all registers contain live variables: data may be read again before program ends. Problem: some registers might not be used in callee, then the saving is unnecessary.  Callee saved convention:\n prior to overwriting any register, the callee saves and eventually restores that register\u0026rsquo;s content; Problem: some registers might not be used by the caller, then the saving is unnecessary.  MIPS:\n Split registers into 2 groups: callee saved \u0026amp; caller saved. caller or callee\u0026rsquo;s responsibility to save, can also no save for dead variables or not rewritten.   Instruction Set Encoding\nUnary number: 1 1 1 1. Know the instruction without decoding.\nbinary num: 0b100.\nVariable length instructions:\n efficient encoding: no bits wasted Problem: sequential determination of each operand  MIPS Arch\n load/store, or reg-reg instruction set R format: register instruction. ALUs I format: immediate instruction. load/stores J format: jump instructions: j, jal.\n branch delay slot: instruction after branch is always executed.\n load delay slot: value returned from load cannot be used the next cycle. unspecified result if not followed.\n  RISC: any isa defined after 1980.\nSep 17 Exe time = IC x CPI x $\\tao$\nPipeline:\nDatapath phases;\nPipeline: introducing latches between different stages.\nIPC better than CPI to compare ISA impl.;\nPipleline Hazards  dependence; slower phase; latches time \u0026hellip;  data hazards 3 kinds of data dependence in the original program:\n Read after write (RAW); not a problem if no pipeline; forwarding to solve; Write after write (WAW); cannot be reordered; reg rename in hardware; Write after read (WAR); cannot be reordered;  control hazards control dependences\n branches: which to fetch next;\n MIPS branch delay/wait slot: not good if large num of pipeline stages;   structural hazards content for same hw resource (eg. register, non-pipelined FU, divider): adding more hardware;\naccess the register file Read and Write of register file: RD in 2nd half clock cycle; WB in 1st half.\nTwo-phase non-overlapping clocks: $\\phi_1, \\phi_2$;\nnon-overlap: never high at the same time;\nLatches in pipeline latches vs. \u0026lsquo;foot blocks\u0026rsquo;.\nA D-latch: Din Dout Clk. Can be open, or close; when it is closed, it remembers last input; if clock high, the out equals in, \u0026lsquo;open\u0026rsquo;; if clock low, the out got stuck where it is, will not reflect input, \u0026lsquo;closed\u0026rsquo;;\ntwo D-latches forms \u0026lsquo;footblocks\u0026rsquo;\nhigh usually shorter than the low state in the timeline graph.\nIs there 2-D/3-D pipelines, for parallel: e.g. one input, 4x output\nSep 19 Instruction scheduling Basic Block scheduling\n Boosting: move instructions across basic blocks. Must maintain semantics.  Branch delay slot scheduling\nbeq.likely R4, R6, L : if not taken, squash the delay slot (turn it into nop)  Static branch prediction:\n Exceptions  Dynamic branch prediction.\nCommit: When does state change commit: An instruction is committed when it is guaranteed to complete. And the result will be visible to the programmer, either in register or memory.\nMIPS: WB stage is for committing.\nOOO pipelines Out-of-order pipeline: 5 stage, 4 load in 10 instructions ==\u0026gt; ~ 400 cycles.\n if out of order and parallel memory requests load ==\u0026gt; ~100 cycles.  Multicycle pipelines IF -\u0026gt; ID -\u0026gt; { EX | FP adder | FP mult | FP dividers } -\u0026gt; MEM -\u0026gt; WB\nProblems: Different pipleline can finish in different time (can cause out of order commit).\nAn implmentation problem.\n structrual hazards for entry into MEM RAW:\nfmult R1, R2, R3 fadd R4, R3, R5 WAW: fadd executes faster than fmult:\nfmult R1 \u0026lt;-- fadd R1 \u0026lt;-- WAR: not a problem. Since only in ID (decode) stage does the read.\nfmult \u0026lt;-- R1 fadd R1 \u0026lt;--  Sep 24 Multicycle pipelines(continued)  structural hazards: mem stage RAW. forward does not work with this. Stall@ID WAW. Possible. Stall@ID WAR. Not possible.  Reservation Shift Register (Left shift \u0026lt;\u0026ndash;): 0 the resource is free; 1 is not free; One shift register for one conflict parts\u0026rsquo; ID; one for \u0026lsquo;now\u0026rsquo;; \u0026lsquo;now\u0026rsquo; = OR of all resources.\nWhen to know mem op finishes: assume hit L1, or assume \u0026hellip;; if not do recover; \u0026ndash;\u0026gt; speculate.\n Shift Register: shift in a 0, or shift in a 1;\n Dynamic scheduling ILP: Instruction level parallelism\nEG:\nfdiv R5 \u0026lt;-- fadd R5 \u0026lt;-- // stall 2 cycles add R7 \u0026lt;-- // can be rescheduled to amortize the above stall sub R8 \u0026lt;-- xor R11 \u0026lt;-- ...  no ILP:\nadd r1, r2, r3 sub r4, r5, r1 xor r6, r7, r4   value speculate: 90s idea; not good for silicon.\n ILP:\nadd r1, r2, r3 sub r4, r5, r6 xor r7, r8, r9  Sep 26 Next time: Verilog by TA.\nCPU: Instr queue. Reg file. 0 0 1 1 -\u0026gt; RS0 2 2 fadd 3 3 fadd (clk2. ) 4 4 fmul (clk1. when r1 = RS0) 5 5 /\\ || issue (always in order) || \\/ || || Reservation station. |===============\u0026gt;|| ready,op1,1-rdy,op2,2-rdy || -\u0026gt; *ready* of means all operands of an inst are ready or operands has a value (not a pointer). RS0 ___1___r0___1___r2____1____fmul_ RS1 RS2 RS3 ___1___r6___1___r7____1____fadd_ RS4 ___0,__RS0__0___r3____1____fadd_ ___________________________________ | | | | || Multiplier Adder/Subtractor || | | || ----------------------------------- fmul r1, r0, r2 fadd r4, r1, r3 fsub r5, r6, r7 CLK: 0, start, fmul, fadd, fadd in queue 1, fmul out of queue; r0, r2: ready; fmul: ready; fmul, r1 \u0026lt;- RS0; 2, fadd, src reg: r1: pointer to RS0, not ready ; r3: value, ready; fadd ready = r1.rdy \u0026amp;\u0026amp; r3.rdy = no r4: RS4. fmul, executing, 3, fsub, r6, r7, instr: all ready; r5: RS3 4, fadd, r1: not ready fsub, r6: exe 1st cycle (only 1 cycle to finish). fmul, exe: 3rd cycle of exec (need 4 cycles to finish). 5, fmul, exe: 4th cycle fsub, r6: done. RS3 result. Finished execution stage, will WB in next stage. 6, fsub, r6: result -1, to write back: **broadcast**: \u0026lt;-1, r5, RS3\u0026gt;: to all RS and Reg files. all RS and register file **snooping** the common data bus to receive the broadcast - reg file get the broadcast and set r5 = -1; fmul: 5th cycle, done exe. 7, fmul, broadcast, \u0026lt;0, r1, RS0\u0026gt; RS4: see the broadcast, RS0 = 0 in its operands, and set it to ready; reg file: see r1, and set r1 = 0; 8, fadd, executing (1 cycle left) 9, fadd, broadcast: \u0026lt;3, r4, RS4\u0026gt; reg file: r4 = 3. EG2: fmul r4, r1, r2 fadd r4, r5, r6 CPU Instr queue. Reg file. 0 0 1 1 -\u0026gt; RS0 2 2 3 3 fadd (clk2. ) 4 4 fmul (clk1. when r1 = RS0) 5 5 /\\ || issue (always in order) || \\/ || || Reservation station. |===============\u0026gt;|| ready,op1,1-rdy,op2,2-rdy || -\u0026gt; *ready* of means all operands of an inst are ready or operands has a value (not a pointer). RS0 ___1___r0___1___r2____1____fmul_ RS1 RS2 RS3 ___1___r6___1___r7____1____fadd_ RS4 ___0,__RS0__0___r3____1____fadd_ ___________________________________ | | | | || Multiplier Adder/Subtractor || | | || ----------------------------------- cycle 1. issue: RS0 ready, r4 = RS0. 2. issue: RS3 ready, r4 = RS3. fmul: start exe 3. fmul: exe (2nd cycle, 3 left) fadd: exe (1st cycle, 1 left) 4. fadd: done, broadcast: \u0026lt;5, r4, RS3\u0026gt; - reg file: r4 points to RS3, and set r4 = 5. fmul exe (3rd cycle.) 5. fmul (4th cycle) 6. fmul: broadcast \u0026lt;0, r4, RS0\u0026gt; register file: **r4 does not points to RS0**, we dont apply 0 to r4.  Oct 01 Verilog HDL vs Prog. Lang\n NOT A PROGRAMMING LANGUAGE No variables (outlawed) \u0026ndash; signals!  registers (containers) wires (connections)  HDLs concurrent\n which happens first:\nassign a = ~b; assign c = d;    NAND/AND Gate:\nmodule NAND (a,b,out); input a; input b; output out; assign out = ~(a\u0026amp;b); // assign out = a\u0026amp;b; // AND gate endmodule module AND (x,y,out); input x; input y; output out; wire x; NAND MyNAND(.a(x), .b(y), out(z)); assign out = ~z; // AND gate from NAND // block statement: set out until ~z is true. endmodule  Combinational logic  using assign; evaluated every time RHS changes LHS must be declared wire (cannot feed into reg \u0026ndash; it is combinational!) Typical operators  \u0026amp; | ^ ~ == != physical data types: 0 1, x (dont care), x (high impedance)   Buses\nmodule AND8 (x,y,out); input [7:0] x; input [7:0] y; output [7:0] out; assign out = x\u0026amp;y; endmodule  Contatenation, Repetition\n Syntax: R{E1,E2,\u0026hellip;,En}. R repetitions (default 1) of the concatenation of E1, .. En 16{a[15],a} + b  Sequential Logic CLK\nD ~~~_\nQ\nmodule DFF (d,q,clk) input clk; input d; output q; reg q; always @(posedge clk) begin q \u0026lt;= d; end endmodule // can be negedge as well (and clk any other name)  nonblodkint assignment \u0026lsquo;\u0026lt;=\u0026rsquo; in sequential always blocks;\n Clock only signal in sensitivity list; (posedge clk) LHS must be declared reg  cannot use wire \u0026ndash; it is sequential logic  Hoist combinational logic outside of always blocks as much as possible  (slow down clock freq)\nControl flow\nalways @(posedge clk) begin if (r == 1'b1) begin // 1 bit signal 1'b1; n bits: n'b0000_n ; n'dxxx q \u0026lt;= 1'b0; end else begin q \u0026lt;= d; end end endmodule  Combinational always Blocks\n All RHS singals must appear on sensi list LHS must be assigned in every possible case\n otherwise implied sequential logic!\nalways @(sel or a) begin if (sel == 2'b0) begin z = 1'b0; end else if (sel == 2'b1) begin z = a; end end    Extra Hardware?\n watch out for too much hardware every if condition, every single operation you do will increase the hardware  Verilog is concurrent, C is not.\n differnet block code represent different hardware sequential block: can execute sequential objects block \u0026lsquo;=\u0026rsquo;, non-block \u0026lsquo;\u0026lt;=\u0026rsquo; combination block: concurrent.  reg[31:0] regfile [0:7] // num of bits; num of registers\nwire [31:0] reg2; wire b4r2;\nassign reg2 = regfile[2] // 2nd register assign b4r2 = reg2[4]; // 4th bit of reg2\n// tri-state devices assign reg2 = b4r2 ? regfile[2] : 32\u0026rsquo;bz;\n// z:\nVerilog Prog:\n draw hardware diagrams first; Textbook think about what hardware does read the manual exercise  Project 1 Branch predictor\ninitial 5 stage pipeline.\n always do not take branch  verilator 3.876\nverilog/ - ALU.v - Decoder.v - EXE.v - ID.v - MIPS.v\nmake ./VMIPS -f tests/cpp/class\n// enter -\u0026gt; next circle.\nOct 03 Tomasulo  instruction status reservation status: Busy bit, Op field, address field, V_j \u0026amp; V_k: source values of registers(if not in resevation station); Q_j \u0026amp; Q_k: pointers to source registers (reservation stations)  IBM 360\u0026frasl;91: Tomasulo\n update register in program order? NO: update as soon as it finishes. Problem: exceptions. Solution: out-of-order HW.  Out-of-order Single issue OOO processor.\nRegister renaming.\nMemory speculation.\nProblem:\n In a modern pipeline, there are many stages (cycles) between a branch is fetched and when its direction/target are known (i.e. when it resolves). worse in superscalar pipelines that process multiple instructions in each stage.  e.g 8-way superscalar (8 instructions processed in every pipeline stage); and 8 stages between fetch \u0026amp; execute ==\u0026gt; 64 instruction must be fetched in the shadow of unresolved branch.   Solution:\nDynamic branch prediction.\n Predict both the direction and target for the branch. Assume prediction is true. Fetch instructions from the predicted path. Do not allow either the branch or any subsequent instructions to commit (i.e. modify architectural states). Verify if the prediction was true when the branch executes. If misprediction, will squash the branch and all subsequent instructions; fetch from the corrent path. (Misprediction Recovery)  Note:\n Prediction does not have to be correct 100% of the time. precition is useful if it is correct most of the time. Accuracy of branch predictor = (#correct)/(#correct + #misprediction).  how much accuracy is \u0026lsquo;good enough\u0026rsquo;?   EX:\n what is the probability that we are still on the right path after speculating through N branches assuming accuracy of p? ==\u0026gt; p^N if 8 stages to EX stage, and 8-way superscalar, every 4th instruction branch -\u0026gt; N = 16  P = 0.9 =\u0026gt; p^N = 0.9^16 = 0.18\np = 0.99 =\u0026gt; 0.85.\n Fetch Decode Rename Dispatch Register Read EXE Memory Retire Commit pc --\u0026gt; i-$ i-TLB Front-end --\u0026gt; Issue Queue Physical ALU | L1 d-$ | |d-TLB reorder Register alias ------------ reg file |\\ buffer (ROB) Retirement table (F-RAT) | | | | | | |Miss states address register ------------ | |holding reg (MSHR) stack alias (OOO) |/ Table (R-RAT) branch Branch _FIFO_ --\u0026gt; Decoder --\u0026gt; _FIFO_ Free List direction Target |OOO load queue predictor Buffer Busy | | Bits | | |in-order store queue | | return Outstanding | Memory Dependence address branch | predictor stack queue  Oct 08 Branch predictors Categories of dynamic branch predictions:\n Always taken branch predictor:\n predict the branch will always be (not) taken. Problem: not accurate enough (~60%)  Backward-Taken, Forward Not Taken:\n predict that branches whose target PC is less than the branch PC (i.e. backward branches) are taken, others are not taken. Rational is loops. Insufficient accuracy (60-70%).   ==\u0026gt; problem: treat every branch instr equally. always make same prediction for the same instruction.\n Last Direction:  Table of branch directions(taken/not-taken) + use n bits of branch PC as index To predict: index into table; read the taken/not-taken bit, 0 not taken, 1 taken; Update table: Index into table; write 1 if the branch is actually taken, 0 if not; Accuracy: 80%. Aliasing possible in the prediction table (collisions). ==\u0026gt; can help each other \u0026amp; distructive aliasing if two aliase behaves differently.   EX:\n// assume the branch pattern: 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 x o o o x x o o o x x o o o x ==\u0026gt; problem: two mistaken at the end of every loop   Bimodal Predictor\n Table: two bits: saturating up/down counter (Finite State Machine) problem:\n// Two bit saturating up/down counter strong taken 11 weak taken 10 predict taken ------------------------------------------- weak n-taken 01 predict not-taken strong n-t 00 // transitions: 00 --1--\u0026gt; 01 01 --1--\u0026gt; 10 10 --1--\u0026gt; 11 11 --1--\u0026gt; 11 11 --0--\u0026gt; 10 10 --0--\u0026gt; 01 01 --0--\u0026gt; 00 // init: 10    Ex:\n10 11 11 11 11 10 11 11 11 11 10 11 11 11 11 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 o o o o x o o o o x o o o o x error: 3/15 accurary: 80%  Two-level Branch Predictors Goal: accurately predict repeating sequences of branch outcomes.\n Local Predictor Global Predictor  Local Predictor (SAg):  Branch PC [n-bits] -\u0026gt; index into first level table:  Branch History Table (BHT): each entry k-bits wide to log pattern of taken/not-taken; then goes into PHT. Pattern History Table (PHT); do predict; 2-bit saturating up/down counter.  Prediction:\n index into BHT; use BHT entry (row) as index into PHT; prediction is the value of PHT;  Update:\n shift the branch outcome into the indexed BHT entry; updating the corresponding PHT entry, the 2-bit saturating up/down counter.\n// k=4 in BHT; after training using pattern // assuming no aliasing, then predicts all repeating sequences // of length \u0026lt;= k with 100% accuracy. ... 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 ... ------------------------------ PHT 11 00 11 ------------------------------ 0 1 1 1 1 1 1 1 1 1 1 0   Problem of aliasing when indexing using BHT to PHT: a corner case that rarely happen dynamically.\n local predictor captures self-correlations\n 90-99% (99.99% on floating point)\n What about correlations among different branches?\n// an opportunity not exploited by the local predictor // but global predictor can. if (A \u0026amp; B){ } if (B){ }   Global predictor  Global history register (GHR): outcome of all branches. Store patterns, then used to index PHT; Prediction:  index into PHT using GHR; prediction in the msb read act  Updating:  shift in GHR Perform Saturating up/down in PHT 90-95% accurate on an integer code.   Oct 10. Hybrid branch prediction  local branch predictors capture self-corelations. global branch predictors capture correlations among different branches.\n Combine the two\n Predict:\n Local \u0026amp; global provide their predictions A selector (bimotdel predictor) picks which predictor to trust for the current branch\n// Meta-predictor //global // local // (selector) PC[n] PC[n] | ---\u0026gt; 00, GHR | ----\u0026gt; BHT 01 | | ---\u0026gt; PHT 10 11 || || || ------------------------------------------------------- || \\/ predict Branch- local(0) global(1) Meta- local- global- meta- outcome predictor training traning traning 0 0 0 0/1 down down no-change 0 0 1 0/1 down down down 0 1 0 0/1 down down up 0 1 1 0/1 down down no-change 1 0 0 0/1 up up no-change 1 0 1 0/1 up up up 1 1 0 0/1 up up down 1 1 1 0/1 up up no-change    Branch Target Prediction We need to predict two other pieces of information in addtion to direction\n what is the branch target (if taken)? whether this is branch instruction?  Answer: Branch Target Buffer.\nBTB: is a cache which is indexed and tagged using the branch PC, if holds the branch target for each cached branch. -\u0026gt; typically, block size = 1 branch.\n EG: 4-way set associative, 1024-entry is common. cache hit or miss. Reason of miss: 1. branch target not cached; 2. instruction is not a branch.\n Update: BTB is updated after decode;\n BTB and direction predictor are accessed in parallel.\n  LLM: BTB is accessed before decoding done: we don\u0026rsquo;t even know this is an branch or not, but will fetch only according to PC\u0026rsquo;s address. Is this safe in multi-process env? Why not just access BTB after decoding done?\nCall/Return sequences In MIPS, jal/jr\nBTB not useful in predicting target for return instructions. (because we have multiple call sites/multiple return site for a same function)\nInstead, use a structure called the Return Address Stack (RAS)\n on a call, push the return address onto RAS. on a return, we pop the top of the RAS. will forget something if overflows; LLM: how about saving the overflowed ones to memory? and use this hw stack instead of compiler managed stack?\nBTB direction- what to fetch next predictor hit 0 PC+4 hit 1 target from BTB miss 0 PC+4 miss 1 PC+4   Speculative updates Problem: information to update the direction predictor not known for many cycles. Makeing predictors of stable prediction results in inaccuracy.\nSolution: assuming that the prediction is correct \u0026amp; update the predictor state speculatively (i.e. update direction)\n before the update, save the existing predictor state in the outstanding branch queue (QBQ). on a misprediction, restore the relavent QBQ entry to predictor.  Oct 17 (A copy of cpu figure)\n Fetch Decode Rename Dispatch Register Read EXE Memory Retire Commit pc --\u0026gt; i-$ i-TLB Front-end --\u0026gt; Issue Queue Physical ALU | L1 d-$ | |d-TLB reorder Register alias ------------ reg file |\\ buffer (ROB) Retirement table (F-RAT) | | | | | | |Miss states address register ------------ r0 | |holding reg (MSHR) stack alias (OOO) r1 |/ Table ... (R-RAT) branch Branch _FIFO_ --\u0026gt; Decoder --\u0026gt; _FIFO_ Free List direction Target |OOO load queue predictor Buffer Busy | | Bits | | |in-order store queue | | return Outstanding | Memory Dependence address branch | predictor stack queue v v x: FIFO x: renaming x: issue queue x:phys x: ROB x:R-RAT  FIFO: FIFO allows disruptions in either the producer (cache) or the consumer (decoder) stage to be hidden.\n if instruction cache got a miss, decoder can go to next instruction instead of being stalled.  Renaming using a double RAT scheme Goal: rename false dependences (WAW, WAR)\n Architectural registers: specified by ISA (R0-R31) (typically big R)\n Physical registers: actually implemented in hardware (e.e. r0 - r511). (typically little r)\n Typically, # of r is much greater than # of R. (LLM: why: stores the results for speculatively executed instructions)\n Register renaming maps architectural registers to physical registers.\n F-RAT table (map: 1 --\u0026gt; 1) Phy Reg File (1 \u0026lt;-- 1) Retire-RAT entries: R0: r1 r0 R0 R1: r1 R1 R2: r100 ... R3: R4 R5 .. R31: r31 R31 ... r511 Free-List r400 r312 r5 ... ---------------------- ----------------------   F-RAT: points to \u0026ldquo;speculative state\u0026rdquo; \u0026ndash;\u0026gt; program cannot see. R-RAT: points to \u0026ldquo;architectual state\u0026rdquo; \u0026ndash;\u0026gt; program can see\nFree-list: holds list of physical reg IDs available to be written.\n Every operator using current mapped phy reg in F-RAT. Rename source registers by reading the F-RAT and mapping architectural source registers to physical registers. Every destination register got a new phy reg from free list (that register must not be used).  pick up a free register from the the free list. update the F-RAT with the new map.  Allocate a reorder buffer: ROB entry (FIFO) in program order. Instruction wait in the ROB until they are allowed to update arch state.  instructions must have executed. instruction must be free of misspeculation. all earlier instructions must have committed (updated architectural state). \u0026ndash;\u0026gt; instruction must be the ROB head in order to be committed.  Allocate on issue queue entry.\n similar to tomasulo\u0026rsquo;s reservation station.  If instruction is a load/store, allocate a load/store queue entry. (issue queue is not FIFO).\n If operands are results of some instructions in the issue queue? to distinguish whether or not: use busy bits for every physical register file.\n check the busy bits for the source physical registers: if any operands reg is busy, this instruction must wait in the issue queue for the producer to depart from issue queue. set busy for the destination physical register.  when the instruction commits, update the R-RAT with the architectural-\u0026gt;physical mapping of the instruction.\n R-RAT is updated in program order R-RAT reflects the arch state, which programmers can see.  when a branch resolves, and is found to be mispredicted, setting a bit in the branch\u0026rsquo;s ROB entry.\n when a mispredict branch reaches the ROB head, recover by:\n Flush the ROB starting from this branch instruction (by setting a single bit flagging \u0026lsquo;ignore these instructions\u0026rsquo;) \u0026amp; Flust the load/store queues. Copy R-RAT to the F-RAT. Start fetch from the correct path.   Stop rename  If we run out of any of the following, rename must stop:  Issue queue entries are run out ROB entries Free register unless: store/branch/jump instructions that do not use new registers. no instruction to rename load queue entry if load store queue entry if store Once stopped, no more instructions will be put into OOO execution.   Register recycling When is the earliest safe time to return a physical register to the free list?\nWhen the next instruction that renames the same destination register commits.\nOct 22 (A copy of cpu figure)\n Fetch Decode Rename Dispatch Register Read EXE Memory Retire Commit pc --\u0026gt; i-$ i-TLB Front-end --\u0026gt; Issue Queue Physical ALU | L1 d-$ | |d-TLB reorder Register alias ------------ reg file |\\ buffer (ROB) Retirement table (F-RAT) | | | | | | |Miss states address register ------------ r0 | |holding reg (MSHR) stack alias (OOO) r1 |/ Table ... (R-RAT) branch Branch _FIFO_ --\u0026gt; Decoder --\u0026gt; _FIFO_ Free List direction Target |OOO load queue predictor Buffer Busy | | Bits | | |in-order store queue | | return Outstanding | Memory Dependence address branch | predictor stack queue v v v: FIFO v: renaming x: issue queue v:phys x: ROB v:R-RAT  Issue queue  allows instructions to wait for their operands to become available; instructions are going to respect RAW dependences and structural hazards; but will issue as soon as possible; fullfils two critical functionalities: (this is the critical path, will determine clock speed)\n wake-up: instruction become ready to issue when all operands become available. (set instruction to \u0026lsquo;wakeup\u0026rsquo;) select: one among multiple ready instructions must be selected to issue. (be removed from the issue queue, called being \u0026lsquo;issued\u0026rsquo;) ** for high performance, wake up and select must be atomic (done in one cycle) ==\u0026gt; This typically determines the critical path that sets the clock speed.  instructions can be issued out of order.\n  Wake-up  issue queue entries: 0 1 2 3 4 5 ---------------------- ---------------------- | | | | | | ^^^^^^^^^^^^^^^^^^^^ (common data bus; broadcast)^^^^^^^^^^^^^^^^^^^^^^^^^^^^ one entry: {src1} | {src1.ready} | {src2} | {src2.ready} | {instr.ready} | ... | | /\\ | /\\ /\\ | \\/ | \\/ | | | | |or gate| | |or gate| |and gate| | -----| ---------\u0026gt;---------------|---------\u0026gt;-------| |compare|----- | unit | || ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ src1/2: physical register specifier; src1/2.ready: (physical registers the instruction needs) For the instructions that are 'born' to be ready: e.g. Jump instruction. src1 and src2.ready are initialized using busy bits of the physical registers when being put into the issue queue.  Select Use tree of arbitors to select the instructions that are ready.\n G2 = GG and {not R0/R1} and R2 issue queue entries: 0 1 2 3 4 5 6 7 8 9 10 11 -------------------------------------------- | | | | | | | | | | | | -------------------------------------------- read bits | | | | | | | | | | | | \\/ \\/ \\/ \\/ Arbitors: arb01 arb02 arb03 arb04 ..... (selection logic) arb11 arb12 (child) arb21 (parent) One arbitor: Request from child/queue entries: R0 R1 R2 R3 Response back to child: G0 G1 G2 G3 group request send to parent: GR Response from parent: GG (granted by parent) GR = or {R0, R1, R2, R3} G0= GG and R0 G1 = GG and {not R0} and R1 G2 = GG and {not R0/R1} and R2 G3 = GG and {not R0/R1/R2} and R3  // memory cell (what kind of info it stores??? opcode, src1, src2, dest, immediate, or issue queue index) - wordline(enables): when wordline is high, the cell drives bit line. - bitline (read): |M|-- wordline -------------- ------|-------------- bit line -------- Issue queue wired with memory cells: 0 1 2 3 4 5 6 7 8 9 10 11 ------------------------------------------------- | | | | | | | | | | | | ------------------------------------------------- | M | M | M | M | M | M | M | M | M | M | M | | | | | | | | | | | | | --------------------------------------------------- bit lines | M | M | M | M | M | M | M | M | M | M | M | | | | | | | | | | | | | -------------------------------------------- | M | M | M | M | M | M | M | M | M | M | M | | | | | | | | | | | | | -------------------------------------------- | M | M | M | M | M | M | M | M | M | M | M | | | | | | | | | | | | | -------------------------------------------- | M | M | M | M | M | M | M | M | M | M | M | | | | | | | | | | | | | | | | | | | | | | | | |word line G0 G1 G2 G3 G4 G5 G6 G7 G8 G9 G10 G11 0 0 0 1 0 0 0 0 0 0 0  Pipeline wakeup and select W\u0026amp;S = 1 cycle; IPC = 1\nW\u0026amp;S = 3 cycles; IPC = 1\u0026frasl;3 with one chain; = 1 is \u0026gt;= 3 chains\ninstruction dependence chains:\na -\u0026gt; b -\u0026gt; c -\u0026gt; d -\u0026gt; \u0026hellip;. -\u0026gt;\na -\u0026gt; b -\u0026gt; c -\u0026gt; d -\u0026gt; \u0026hellip; -\u0026gt;\na -\u0026gt; b -\u0026gt; c -\u0026gt; d -\u0026gt; \u0026hellip; -\u0026gt;\n==\u0026gt; the white spot in processor thermal die.\nQ\u0026amp;A: given Issue queue entries: 128; load queue: 64; store queue 64; reorder buffer size 512 (instructions);\nwhat is the max size of physical register file should be where performance cannot improve?\n 545 = 512 + 32 + 1.  RENAMING depends on the size of all, not single ones;\nOct 24 (missed) Oct 29 Lockup-free cache A lockup-free cache does not block future accesses on a miss immediately. By contrast, a blocking cache does.\n Hit-under-miss: continue to service hits in the shadow of ongoing miss.\n miss-under-miss: take a miss in the shadow of multiple outstanding misses.\n  ? What can go wrong?\n the request result can be resolved out of order (different with the issued order); different missing requests can be in the same cache block. ==\u0026gt; cause energy and performance overhead.  Two data structures:\n Miss status holding registers (MSHRs):  make sure we issue the same miss only once (avoid multiple outstanding misses to the same cache block); Allocated on a primary miss (no other outstanding misses to the same block); On a secondary miss (there is already a pending request for the block due to an earlier miss); got a hit in MSHRs. Search on a new miss: Do a broadcast to all MSHRs, then each MSHR will compare the address against its recorded address. (similar search in the issue queue, broadcasting for register updates) On an MSHR hit: secondary miss; wait for reply; On an MSHR miss: a primary miss; request the block; add address to MSHR.   when load executes, it first computes the address.\nMSHR: valide, address,   Address stack   wake up pending loads in the load queue when a block is returned. allocate on primary and secondary misses. when a block returns, check the address stack, index into the load queue, to set a bit, indicating the data is now arrived; the load will retry again (be replayed) and it will hit.\nOne entry: - instruction pointer - valid - address   Tests:\n # MSHRs \u0026gt; # address stack entries: does not make sense;  To increase MLP:\n Larget MSHRs and address stack Larger load queue Larger ROB (reorder buffer) Larger issue queue (load instruction would be issued (removed from issue queue), once the address is computed; but when dependencies exists, the load instruction must be in the issue queue) More physical registers Larger store queue (if there load in bewteen those stores)  Second level cache Local miss \u0026amp; global miss:\nlocal L2 miss rate = (# L2 misses)/(# L2 accesses); ==\u0026gt; usually \u0026ldquo;50% - 60%\u0026rdquo;; local l1 miss (5-6%); data accesses goes to L2 are much more random. ==\u0026gt; locality opt on L2 has opptunity!!!\nglobal L2 miss rate = (# L2 misses)/(# all memory accesses)\nUnified L2 cache: contains both data and code while L1 has L1-code/L1-data separated caches.\nWrite hits longer than read hits (why?)\n a write: first check tag; then write only if hit; a read: read the value while read the tag; if tag miss, discard;  Main memory Latency vs bandwidth.\nLatency:\n access time: read request, first word of data; cycle time: minimum time between success requests; cycle time is \u0026gt; than the access time;  Nov 05 (A copy of cpu figure)\n Fetch Decode Rename Dispatch Register Read EXE Memory Retire Commit pc --\u0026gt; i-$ i-TLB Front-end --\u0026gt; Issue Queue Physical ALU | L1 d-$ | |d-TLB reorder Register alias ------------ reg file |\\ buffer (ROB) Retirement table (F-RAT) | | | | | | |Miss states address register ------------ r0 | |holding reg (MSHR) stack alias (OOO) r1 |/ Table ... (R-RAT) branch Branch _FIFO_ --\u0026gt; Decoder --\u0026gt; _FIFO_ Free List direction Target |OOO load queue predictor Buffer Busy | | Bits | | |in-order store queue | | return Outstanding | Memory Dependence address branch | predictor stack queue v v v: FIFO v: renaming v: issue queue v:phys x ld/st queue v: ROB v:R-RAT depend pred.  Examples\nadd R1, R2, R3\nsub R4, R1, R5\nsw R1, 0(R7)\nlw R4, 8(R12)\n==\u0026gt; store and load address can change.\n Addr can be the same and can be different;\n This kind of dependence cannot be resolved in the issue queue (by simply inspecting register specifiers)\n  Out-of-order Loads  ** Process ld/st in prog order?   Place ld/st inst into a single FIFO l/s queue (LSQ) The load/store queue is signaled to access the L1 d-cache when the ld/st is read to consume. Problem: at most 1 miss; no MLP.   ** out of order loads: (no ooo stores, because you cannot undo it since memory renaming cost is high)   Separate load and store queue. Stores write to L1 in program order. Loads access data cache as soon as they calculate the effective address, but must make sure there is no older store with a partialy or completely matching effective address.  ==\u0026gt; load search the store queue with effective address (load also search issue queue with effective addr). If older matching store, the load stalls until the store commits.\n==\u0026gt; what if older store with unresolved effective address? load stall until resolves.\n ** Out of order loads with forwarding.   No need for load to wait for store to write to the cache. Instead, store forwards the valve to the load. Which store?\n The youngest older store. load search the store queue for the youngest older store with matching effective address.  load will access the data cache in parallel with store queue search:\n if store queue does not find a conflict and no unresolved address \u0026ndash;\u0026gt; use value loaded from data cache; if store queue forwards \u0026ndash;\u0026gt; use forwarded value, ignore ld from cache; unresolved addr in store(s) \u0026ndash;\u0026gt; ignore ld from cache;    ** Speculative loads:   Same as 3. except:  when there is an unresolved older store, the load will speculatively access the data cache and consume the fetched value. Later, we must check if the speculation failed, and if so, recover.  Store search the load queue.  for oldest younger load with a matching eff addr that has issued speculatively; if found, mark the load as misspeculated in the ROB; recover when load becomes ROB head by flushing the pipeline; and copying RRAT -\u0026gt; FRAT    ** Dependence prediction:   Always accessing the data cache speculatively may result in too many miss-predicates. Solution: predict if the load depends on an unresolved store using a dependence predictor.  A simple one: Load Wait Table (LWT)\n an array of one bit wide table index of the PC of load: |xxx| index |xx   Index into the LWT using load PC; if 1, do not speculate. When we misspredictable, index into the LWT, set entry to 1. Problem: before ??, LWT is filled with 1s (always) Solution: periodically (e.g. every 1 million cycles) erase the LWT to all 0s.  EA: effective addr (Generated at exe stage)\n |=\u0026gt; Instruction load: access, LWT, cache , Store Queue, | load wati 1 v older unresolved | use forward 1 v forwards | 1 value x ld use cache | 0 v older unres ld specc from cache | 0 v forwards use forward | 0 v x use cache Effective | addr ==\u0026gt; | | | | | | |=\u0026gt; Instruction store: search the load queue... ... update lwt.  Nov 07 Quiz:\nReduce cache associativity: reduce cold miss ratio.\nassociativity/ num of sets.\nMain memory  Dynamic Random Access Memory (DRAM), diffrences with SRAM ?\n Hierachy of channels, ranks ,bancks, rows, and columns. ==\u0026gt; both parallelism and locality at the same time\n Accessed using a command set.\n Command Set is implemented by a memory controller.\n A memory controller usually integrated on the same die as the processor.  Timing contraints dictate how soon different commands can be issued.\n Memory controllers reorders requests to optimize:\n throughput. power. quality of service.   DRAM Cells\n1T1C Cell (page 10\u0026frasl;19)\n access transistor ____ ----____----- | --- --- capacitor |   Information is representted by the absence/present of charge on the capacitor; The charge on the capacitor leaks over time;  The cell must be periodically refreshed (read and written back) to maitain state;  The period is called the refresh interval (64ms @ \u0026lt; 80 Celcius\u0026gt;)  Can refresh 30 minutes a time, but need to keep at 40 Celcius? Used in superconductor tech.\nReading the DRAM Cell\n![A DRAM Cell]()\nReads destroy the cell content (reads are distructive); content must be written back after a read.\nWriting the DRAM Cell to 1:\n Drive bitline to VDD; Drive the wordline high (switch close, charge from bitline to capacitor); capacitor is charged to VDD; Drive wordline low (switch open, no charge from bitline to capacitor);  DRAM Array ![figure of DRAM array]()\n Precharge all bitlines\n Precharge the bitlines destroys the contents of the sense amplifiers.  Activiting a row:\n Decoders drive one wordline high. An entire row of cells are sersed by the sense amplifiers.  Sense amplifiers holds the last sensed value.\n architecturally, architecturally like a buffer; called \u0026lsquo;Row Buffer\u0026rsquo;;   E.G.\n Assume it takes 30ns for precharge bitlines 40ns for activate 20ns to read from row buffer.  Type Row# Col# Rd 1 5 Rd 3 4 Rd 1 3 Rd 3 2 Rd 1 6 Rd 3 9\nFCFS (first come first served, in-order): 600ns\nOut-of-order:\n1,5 \u0026ndash;\u0026gt; 1,3 \u0026ndash;\u0026gt; 1,6 \u0026ndash;\u0026gt; 3,4 \u0026ndash;\u0026gt; 3,2 \u0026ndash;\u0026gt; 3,9\n100 20ns 20ns 100ns 20 20ns \u0026ndash;\u0026gt; 280ns\nExploits the row buffer locality:\n If a row is already stored at the sens amplifiers, we say row is \u0026lsquo;open\u0026rsquo;, otherwise \u0026lsquo;closed\u0026rsquo; If a request find the row open, it is called a row buffer hit. If a request find the row closed, and the bitlines are not precharged; we call it a \u0026lsquo;row buffer miss\u0026rsquo;; If the row is closed but the bitline is already precharged; we call it a \u0026lsquo;row empty\u0026rsquo;.  Nov 12 no class Nov 14 DRAM Memory\nDRAM Array + row buffer\nT = R C\nInvertors cannot be used in DRAM: bitline is not digital signal, but analog signal.\nUse array + buffer as basic building block.\nDRAM Bank Leverage the row buffer locality.\n1 bank:\ncache block: A B C D; // four arrays accessed in parallel\n4 * (DRAM array (1k*1k) + row buffer 1k) ===\u0026gt; a bank of 4 arrays: 1k * 4k + 4k\n each array provides a subset of the bits on every access; logically, the row buffer size is the array row buffer size * #arrays;  only exploit spatial locality; but no parallelism, so we have rank.\nDRAM Rank Leverage the bank parallelism\n1 Rank:\nBank 0\nBank 1 + Common Bus Bank 2 - commands: active, precharge, r/w, refresh Bank 3 - address: bank ID, row/col ID; A read: bank + col ID (assume already activated) - data: 64-bits wide;\nCache block size: 64 bytes.\n Data transmitted in \u0026lsquo;bursts\u0026rsquo;: after read commands, the data bus will starting to have data (after a TCL-xxx latency)  command bus: \u0026mdash;-RD\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-time data bus: \u0026mdash;\u0026mdash;\u0026ndash;bursts: d0 d1 dx \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 2 64-bits chunks per DRAM clock: one on positive edge, one on negative edge.   Assume 3 cache blocks: x, y, z. resp. in bank0/row1/col4, back1/r57/col8, back3/r1/col\nRead x Read y Read z\nHow to retrieve the data?\n(if only one back in rank: read one by one: pre-charge x, activate, read.)\nThe command schedule with 4 banks in a rank (assume pre-charge 8 cycles, act: 8 cycles, TCL: 4 cycles):\ncommand, time:\n pre B0, 0 pre B1, 1 pre B3, 2 \u0026hellip; act B0 row1, 8 act B1 r57, 9 act B3 r1, 10 \u0026hellip; rd B0 col4, 16 // when is next read? rd B1 col8, 20 rd B3 col20 24\n  Not RD every 8 cycles, but 4 cycles.\ncommand bus: ----RD-----------8cycle--------RD-------------8---------RD---------8------------RD----------time data bus: --------d0-4 data---------- 4 empty-----------d1-------------------dx ------------------------  Bank Conflict Problem:\n two request to different rows within same bank.\n three misses might be faster resolved than 2 misses: 3 misses in different banks can be paralleled; but 2 misses in the same bank cannot be paralleled.\n More banks could help as long as the bus is not too small to be the bottle neck.\n  DRAM Channels A Channle: contains one/more ranks;\nA Channel Figure: 4 channels around a processor:\nMemory controller0 \u0026ndash; Rank 0, 1\nMemory controller1 \u0026ndash; Rank 2, 3\nMemory controller2 \u0026ndash; Rank 4, 5\nMemory Controller3 \u0026ndash; Rank 6, 7\nExample: processor walks around an array.\nfor (i=0; i\u0026lt; 1 billion; i++){ sum += a[i]; // a byte array. } // miss rate: 1/cache block.  DRAM Address Mapping: Physical address -\u0026gt; DRAM coordinate (chnl, rank, bank, row, col)\ne.g 32-bit physical address, one method of mapping:\n0 -------------------------------------------------- 31 | Row | Col | Bank | Rank | Channel | offset | // this will keep all channels up.  // one XOR gate, improve performance by 2x.\nNov 19  Fetch Decode Rename Dispatch Register Read EXE Memory Retire Commit pc --\u0026gt; i-$ i-TLB Front-end --\u0026gt; Issue Queue Physical ALU | L1 d-$ | |d-TLB reorder Register alias ------------ reg file |\\ buffer (ROB) Retirement table (F-RAT) | | | | | | |Miss states address register ------------ r0 | |holding reg (MSHR) stack alias (OOO) r1 |/ Table ... (R-RAT) branch Branch _FIFO_ --\u0026gt; Decoder --\u0026gt; _FIFO_ Free List direction Target |OOO load queue predictor Buffer Busy | | Bits | | |in-order store queue | | return Outstanding | Memory Dependence address branch | predictor stack queue v v v: FIFO v: renaming v: issue queue v:phys x ld/st queue v: ROB v:R-RAT depend pred.  Two philosophies to multiple issue:\n VLIW.\n Superscalar.\n  Terminology: 4-way super scalar.\n4 inst issued every cycle ==\u0026gt; 4-issue superscalar.\n Sometimes, not all pipeline stage are symmetric, e.g. 4-way fetch, decode, issue, but 6-way commit.  Intel: design \u0026amp; debug(verification) team.\nSuperscalar, in-order, 5-stage pipeline.\ninstruction fetch | inst decode(ID) | Execute (exe) | Memory (MEM) | write back (WB) | | PC register file | ALU data-cache | | | Instruction cache decoder | forwarding data-TLB | --- \u0026lt;-------------------------------| instruction TLB  Two ways to increasing the bandwidth of memory structures.\n Multiporting. Allows simultaneous access to a memory cell from multiple ports.  two ports: add one more decoder, bitline, wordline, sense amplifier, for every cell. advantage: no matter addresses are, can always fetch in parallel. problem: not scalable. area grows n^2 for n ports. Used only when absolutely necessary.  Banking.  area grows as N. disadvantage: bank conflicts (access to same bank). increase # of banks.   i-cache or i-TLB/ d-cache or d-TLB: multiported or banked.\nMultiple PCs, latch, decoders, ALU, \u0026hellip;\nForwarding network: n^2 growth.\nregister file: greater degree of multiporting.\nControl logic to detect dependences (still in order core)\nCreate if condition for next instruction.\nProblem: it\u0026rsquo;s hard to find a dependent instruction one after another in one cycle.\nNov 21 To parallelize a processor  Fetch Decode Rename Dispatch Register Read EXE Memory Retire Commit pc --\u0026gt; i-$ i-TLB Front-end --\u0026gt; Issue Queue Physical ALU | L1 d-$ | |d-TLB reorder Register alias ------------ reg file |\\ buffer (ROB) Retirement table (F-RAT) | | | | | | |Miss states address register ------------ r0 | |holding reg (MSHR) stack alias (OOO) r1 |/ Table ... (R-RAT) branch Branch _FIFO_ --\u0026gt; Decoder --\u0026gt; _FIFO_ Free List direction Target |OOO load queue predictor Buffer Busy | | Bits | | |in-order store queue | | return Outstanding | Memory Dependence address branch | predictor stack queue v v v: FIFO v: renaming v: issue queue v:phys v ld/st queue v: ROB v:R-RAT depend pred.  pc: multiplex\ni-$, i-TLB, Branch Predictor, BTB, RAS, FIFO ==\u0026gt; bank or multiport.\nDecoder: multiple decoders.\nRename Rename Group\n1: in parallel\na) access free list the pick up physical reg specifier for destination.\nb) compose architectural save register to destination of addr ???. Find youngest addr match.\n2: in parallel\na) assign physical regs specifier picked in 1-a to multiple\nb) at the same time, write dest specifier to F-RAT\nIssue queue Common data bus (CDB) 1: \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\nissue queue: | | | | | | | |\narbitors: [] []\n []  Common data bus (CDB) 2: \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\nUnified vs Distributed Issue queues:\nUnified:\none queue + Two ALUs\nDistributed:\nTwo \u0026lt; one queues, one ALU \u0026gt; pairs\nReducing the number of register file ports:\nProblem: 8-way superscalar requires 24 RF ports\n-\u0026gt; Area (and latency, energy) sacle quadratically with # of ports.\nSolutions:\n(1) Replication: two (multiple) copies of same register file. Two copy of same register:\n both copies must be updated; it reduces only the # of read ports.  (2) how do we pipelining the register file accesses?\nMSHR: miss states holding register. Address stack:\n==\u0026gt; multi-parallel.\nNov 26  Fetch Decode Rename Dispatch Register Read EXE Memory Retire Commit pc --\u0026gt; i-$ i-TLB Front-end --\u0026gt; Issue Queue Physical ALU | L1 d-$ | |d-TLB reorder Register alias ------------ reg file |\\ buffer (ROB) Retirement table (F-RAT) | | | | | | |Miss states address register ------------ r0 | |holding reg stack alias (OOO) r1 |/ |(MSHR) Table ... (R-RAT) branch Branch _FIFO_ --\u0026gt; Decoder --\u0026gt; _FIFO_ Free List direction Target |OOO load queue predictor Buffer Busy | | Bits | | |in-order store queue | | return Outstanding | Memory Dependence address branch | predictor stack queue v v v: FIFO v: renaming v: issue queue v:phys v ld/st queue v: ROB v:R-RAT depend pred.  Miss prediction occurs for a br instruction:\n time point: when that br reaches the head of ROB: all inst before this branch have committed, all stuff in pipeline are garbage due to mis-prediction, so we can flash entire pipeline, easily by setting one bit.  Problem:\nA situation in ROB: garbage insts | br | ld with miss (500 cycles) | \u0026ndash;\u0026gt; head\n=\u0026gt; have to wait 500 cycles in order for br to be at the head of ROB and recover the misprediction.\n=\u0026gt; why not recover while ld is underway and br is not yet at the head? Then when is good to recover? ==\u0026gt; early recovery.\nEarly Recovery from branch misprediction as soon as branch executes:\n Flush the branch and all later instructions from ROB:  nullified bit in ROB entry: instruction has been turned into nop; in verilog: ROB index of the branch, \u0026lt;=, ROB index of this entry. ==\u0026gt; on every entry do such comparison.  Memory dependence predictor: no need to update, allows mis-prediction; Store/Load queue: use instruction ages/inst numbers/prog orders/rob index ==\u0026gt; flush all ld/st instructions that are younger than branch from ld/st queues. Issue queue: flush younger instructions. (e.g. mark them as ready, let them depart, do garbage calculation, and in ROB will be nop and commit nothing) Cannot replace F-RAT with R-RAT immediately; instead: Eliminate R-RAT, but take checkpoints of F-RAT by copying contents at every branch. Use checkpoints to recover that architectural values.  when we run out of checkpoints, rename stops at the next branch.   multi-core processors Exploit thread-level parallelism: TLP by simultoneously executing multiple threads. can be 1) threads of same processes; or 2) different processes all together.\nfuse multi-core. 50% of ipek\u0026rsquo;s Ph.D thesis.\nWhy not increase superscalar width instead of designing more cores?\n Power.  P_{dynamic}: due to switching. cause industry to use multicore. capacitor: wire + gate capacitor. $P = \\alpha C V^2 f$, $\\alpha$ activity factor; Valtage $V$ propotional to frequency $f$ in digital design. P_{static}: due to leakage google 16-issue superscalar, no 32-issue.   From 4-way superscalar: Power_4_way = $\\alpha C V^2 f$\n 8-way superscalar. two 4-way multi-core. Power_2 = 2 x Power_4_way two half-fast 4-way, with f/2. Speed same as 4-way. Power = $\\alpha C/2 * (V/2)^2 * f/2$ = 1\u0026frasl;4 Power_4_way.  Problem: How do we keep cores busy?\n execute multiple applications at the same time.\n users have limited tasks in parallel; single thread no benefit.  parallelize a single threaded application to take advantage of multiple cores.\n Intel\u0026rsquo;s commercial idea since 2005. minimal source code changes. algorithms change.   ==\u0026gt; Problem:\n Data dependences must be identified and program must be synchronized to respect the dependences. Certain codes are inheritly sequential. E.G Graph search. Amdahl\u0026rsquo;s Law: 20% sequential, 5x max speed up.   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/class-pldi/ch1/",
	"title": "Ch1",
	"tags": [],
	"description": "",
	"content": "  It is not yet clear to what extent, and in what problem domains, we can expect compilers to discover good algorithms for problems stated at a very high level of abstraction. In any domain in which the compiler cannot find a good algorithm, the programmer needs to be able to specify one explicitly.\n Q/A What distinguishes the front end of a compiler from the back end? What is the purpose of a compiler\u0026rsquo;s symbol table? What is the difference between static and dynamic semantics? Semantic Analysis Semantic analysis is the discovery of meaning in a program. The semantic analysis phase of compilation recognizes when multiple occurrences of the same identifier are meant to refer to the same program entity, and ensures that the uses are consistent.\nIn most languages, the semantic analyzer tracks the types of both identifiers and expressions, both to verify consistent usage and to guide the generation of code in later phases.\nTo assist in its work, the semantic analyzer typically builds and maintains a symbol table data structure that maps each identifier to the information known about it. Information such as identifier\u0026rsquo;s type, internal structure, and scope.\nStatic vs Dynamic Semantic Analysis semantic rules checked at compile time or runtime.\nExample rules checked at runtime:\n variables are never used in an expression unless they have been given a value. Pointers are never dereferenced unless they refer to a valid object. Array subscript expressions lie within the bounds of the array. Arithmetic operations do not overflow.  For dynamic semantic rules, compiler will often produce code to perform appropriate checks at run time, aborting the program or generating an exception if one of the checks then fails.\n(undefined behavior in C) Some rules, unfortunately may be unacceptably expensive or impossible to enforce, and the language implementation may simply fail to check them. In Ada, a program that breaks such a rule is said to be erroneous; in C its behavior is said to be undefined.\n(Annotations/Attributes): Nodes in AST are annotated with useful information, such as pointers from identifiers to their symbol table entries. The annotations attached to a particular node are known as its attributes.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/unrhdr/",
	"title": "Unit Number Allocation API",
	"tags": [],
	"description": "",
	"content": " Unit number API definitions sys/systm.h\nstruct unrhdr; 522 struct unrhdr *new_unrhdr(int low, int high, struct mtx *mutex); 523 void init_unrhdr(struct unrhdr *uh, int low, int high, struct mtx *mutex); 524 void delete_unrhdr(struct unrhdr *uh); 525 void clear_unrhdr(struct unrhdr *uh); 526 void clean_unrhdr(struct unrhdr *uh); 527 void clean_unrhdrl(struct unrhdr *uh); 528 int alloc_unr(struct unrhdr *uh); 529 int alloc_unr_specific(struct unrhdr *uh, u_int item); 530 int alloc_unrl(struct unrhdr *uh); 531 void free_unr(struct unrhdr *uh, u_int item); sys/_unrhdr.h\n// file: // sys/sys/_unrhdr.h  struct mtx; /* Header element for a unr number space. */ struct unrhdr { TAILQ_HEAD(unrhd,unr)\thead; u_int\tlow;\t/* Lowest item */ u_int\thigh;\t/* Highest item */ u_int\tbusy;\t/* Count of allocated items */ u_int\talloc;\t/* Count of memory allocations */ u_int\tfirst;\t/* items in allocated from start */ u_int\tlast;\t/* items free at end */ struct mtx\t*mtx; TAILQ_HEAD(unrfr,unr)\tppfree;\t/* Items to be freed after mtx lock dropped */ };  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-otype/user-obj/",
	"title": "User Object",
	"tags": [],
	"description": "",
	"content": " User space object manipulation is mainly implemented in lib/libcheri/libcheri_type.c.\nUser space type range Total user space type range is [0 , $2^{23}$ - 1 ], and kernel space is [$2^{23}$, $2^{24}$ -1 ].\nThe user space is further splited into two ranges:\n non-system type numbers: [1, $2^{22}$ - 1 ]; system type numbers: [$2^{22}$, $2^{23}$ - 1 ];\n// file: // lib/libcheri/libcheri_type.c  /* The number of bits in the type field of a capability. */ static const int libcheri_cap_type_bits = 24; /* The next non-system type number to allocate. */ static _Atomic(uint64_t) libcheri_type_next = 1; /* The maximum non-system type number to allocate (plus one). */ static const int libcheri_type_max = 1\u0026lt;\u0026lt;(libcheri_cap_type_bits-2); /* The next system type number to allocate. */ static _Atomic(uint64_t) libcheri_system_type_next = libcheri_type_max; /* The maximum system type number to allocate (plus one). */ static const int libcheri_system_type_max = 1\u0026lt;\u0026lt;(libcheri_cap_type_bits-1);  Type initialization and sealing root capability libcheri_sealing_root is the root sealing capability of the types provenance tree. Defined as:\n// file: // ./lib/libcheri/libcheri_type.c static void * __capability libcheri_sealing_root; In initialization step, libcheri_type_init(void), the root sealing capability is requested from the kernel, by calling sysarch(..).\nif (sysarch(CHERI_GET_SEALCAP, \u0026amp;libcheri_sealing_root) \u0026lt; 0) libcheri_sealing_root = NULL; assert((cheri_getperm(libcheri_sealing_root) \u0026amp; CHERI_PERM_SEAL) != 0); assert(cheri_getlen(libcheri_sealing_root) != 0); libcheri_type_init(void) is called during type allocation for the first time, more details in libcheri_alloc_type_capability(..).\nType allocation via libcheri Object type is allocated by libcheri_type_alloc(), a wrapper of libcheri_alloc_type_capability(), which will return a capability with a type.\nThe sealing capability is required. Here is libcheri_sealing_root.\n// file: // lib/libcheri/libcheri_type.c  /** * A simple type allocator. The `source` argument specifies the pointer value * that will be atomically incremented and whose current value should give the * integer representation of the type to allocate. The `max` argument * specifies value that the returned type must be less than. */ static inline void * __capability libcheri_alloc_type_capability(_Atomic(uint64_t) *source, uint64_t max) { void * __capability new_type_cap; uint64_t next; /* * We require that this counter be strictly monotonic, but we don\u0026#39;t * need to establish a happens-before relationship with any other * thread. */ next = atomic_fetch_add_explicit(source, 1, memory_order_relaxed); /* * If we\u0026#39;ve run out of types, return NULL so that we get an obvious * failure. */ if (next \u0026gt; max) { return (NULL); } /* * On first use, query the root object-type capability from the * kernel. */ if ((cheri_getperm(libcheri_sealing_root) \u0026amp; CHERI_PERM_SEAL) == 0) libcheri_type_init(); new_type_cap = cheri_maketype(libcheri_sealing_root, next); return (new_type_cap); } /* * A [very] simple CHERI type allocator. */ void * __capability libcheri_type_alloc(void) { return (libcheri_alloc_type_capability(\u0026amp;libcheri_type_next, libcheri_type_max)); }  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheriabi/llvm-builtins/",
	"title": "LLVM Builtins for CHERI",
	"tags": [],
	"description": "",
	"content": " A list of builtins // file: // sys/cheri/cheric.h  /* * Programmer-friendly macros for CHERI-aware C code -- requires use of * CHERI-aware Clang/LLVM, and full capability context switching. */ #define cheri_getlen(x) __builtin_cheri_length_get((x)) #define cheri_getbase(x) __builtin_cheri_base_get((x)) #define cheri_getoffset(x) __builtin_cheri_offset_get((x)) #define cheri_getaddress(x) __builtin_cheri_address_get((x)) #define cheri_getperm(x) __builtin_cheri_perms_get((x)) #define cheri_getsealed(x) __builtin_cheri_sealed_get((x)) #define cheri_gettag(x) __builtin_cheri_tag_get((x)) #define cheri_gettype(x) __builtin_cheri_type_get((x))  #define cheri_andperm(x, y) __builtin_cheri_perms_and((x), (y)) #define cheri_clearperm(x, y) __builtin_cheri_perms_and((x), ~(y)) #define cheri_cleartag(x) __builtin_cheri_tag_clear((x)) #define cheri_incoffset(x, y) __builtin_cheri_offset_increment((x), (y)) #define cheri_setoffset(x, y) __builtin_cheri_offset_set((x), (y)) #define cheri_setaddress(x, y) __builtin_cheri_address_set((x), (y))  #define cheri_seal(x, y) __builtin_cheri_seal((x), (y)) #define cheri_unseal(x, y) __builtin_cheri_unseal((x), (y))  #define cheri_getcause() __builtin_mips_cheri_get_cause() #define cheri_setcause(x) __builtin_mips_cheri_set_cause(x)  #define cheri_ccheckperm(c, p) __builtin_cheri_perms_check((c), (p)) #define cheri_cchecktype(c, t) __builtin_cheri_type_check((c), (t))  #define cheri_getdefault() __builtin_cheri_global_data_get() #define cheri_getidc() __builtin_mips_cheri_get_invoke_data_cap() #define cheri_getkr1c() __builtin_mips_cheri_get_kernel_cap1() #define cheri_getkr2c() __builtin_mips_cheri_get_kernel_cap2() #define cheri_getkcc() __builtin_mips_cheri_get_kernel_code_cap() #define cheri_getkdc() __builtin_mips_cheri_get_kernel_data_cap() #define cheri_getepcc() __builtin_mips_cheri_get_exception_program_counter_cap() #define cheri_getpcc() __builtin_cheri_program_counter_get() #define cheri_getstack() __builtin_cheri_stack_get()  #define cheri_local(c) cheri_andperm((c), ~CHERI_PERM_GLOBAL)  #define cheri_csetbounds(x, y) __builtin_cheri_bounds_set((x), (y)) #define cheri_csetboundsexact(x, y) __builtin_cheri_bounds_set_exact((x), (y)) /* XXXAR: shouldn\u0026#39;t this be the default and we add cheri_csetbounds_untyped? */ #define cheri_csetbounds_changetype(type, x, y) \\ (type)cheri_csetbounds((x), (y))) #define cheri_csetbounds_sametype(x, y) \\ ((__typeof__(x))cheri_csetbounds((x), (y)))  /* Create an untagged capability from an integer */ #define cheri_fromint(x) cheri_incoffset(NULL, x) Tracking __builtin_cheri_perms_and cheri_andperm // file: sys/cheri/cheric.h  #define\tcheri_andperm(x, y)\t__builtin_cheri_perms_and((x), (y)) __builtin_cheri_perms_and is compiler built in function to emit ??? instruction:\n// file: // clang/include/clang/Basic/Builtins.def  BUILTIN(__builtin_cheri_perms_and, \u0026#34;v*mvC*mz\u0026#34;, \u0026#34;nc\u0026#34;) LLM: What does this mean ??????????? // file: // clang/lib/CodeGen/CGBuiltin.cpp: L3624 in CodeGenFunction::EmitBuiltinExpr(..)  switch (BuiltinID){ ... case Builtin::BI__builtin_cheri_perms_and: return RValue::get(Builder.CreateCall( CGM.getIntrinsic(llvm::Intrinsic::cheri_cap_perms_and, SizeTy), {EmitScalarExpr(E-\u0026gt;getArg(0)), EmitScalarExpr(E-\u0026gt;getArg(1))})); ... } // file: // clang/lib/CodeGen/CGBuiltin.cpp:L12248 in *CodeGenFunction::EmitMIPSBuiltinExpr() switch (BuiltinID) { ... case Mips::BI__builtin_mips_cheri_and_cap_perms: return Builder.CreateCall( CGM.getIntrinsic(llvm::Intrinsic::cheri_cap_perms_and, SizeTy), {EmitScalarExpr(E-\u0026gt;getArg(0)), EmitScalarExpr(E-\u0026gt;getArg(1))}); ... }  Tracking intrinsic cheri_cap_perms_and cheri_cap_perms_and is an llvm intrinsic defined as:\n// file: // llvm/include/llvm/IR/IntrinsicsCHERICap.td def int_cheri_cap_perms_and : Intrinsic\u0026lt;[llvm_fatptr_ty], [llvm_fatptr_ty, llvm_anyint_ty], [IntrNoMem]\u0026gt;; // LLM: ????????????????// file: // llvm/lib/Target/Mips/CheriPureCapABI.cpp  // file: // llvm/lib/Target/Mips/MipsISelLowering.cpp: LowerCall()  if (ABI.IsCheriPureCap()) { if (FirstOffset != -1) { SDValue PtrOff = DAG.getPointerAdd(DL, StackPtr, FirstOffset); PtrOff = setBounds(DAG, PtrOff, LastOffset, /*CSetBoundsStatsLogged=*/true); PtrOff = DAG.getNode(ISD::INTRINSIC_WO_CHAIN, DL, CapType, DAG.getConstant(Intrinsic::cheri_cap_perms_and, DL, MVT::i64), PtrOff, DAG.getIntPtrConstant(0xFFD7, DL)); RegsToPass.push_back(std::make_pair(Mips::C13, PtrOff)); if (cheri::ShouldCollectCSetBoundsStats) { StringRef Name = \u0026#34;\u0026lt;unknown function\u0026gt;\u0026#34;; if (ES) { Name = ES-\u0026gt;getSymbol(); } else if (GlobalAddressSDNode *G = dyn_cast\u0026lt;GlobalAddressSDNode\u0026gt;(Callee)) { Name = G-\u0026gt;getGlobal()-\u0026gt;getName(); } cheri::CSetBoundsStats-\u0026gt;add( 1, LastOffset, \u0026#34;variadic call lowering\u0026#34;, cheri::SetBoundsPointerSource::Stack, StringRef(\u0026#34;setting varargs bounds for call to \u0026#34;) + Name, cheri::inferSourceLocation(DL.getDebugLoc(), DAG.getMachineFunction().getName())); } } else { // ...  } // ...  }   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/extending/intrinsics/",
	"title": "Intrinsics",
	"tags": [],
	"description": "",
	"content": "Reference: Extending LLVM: Adding instructions, intrinsics, types, etc.\n \u0026ldquo;Adding a new intrinsic function to LLVM is much easier than adding a new instruction. Almost all extensions to LLVM should start as an intrinsic function and then be turned into an instruction if warranted.\u0026rdquo;\n  llvm/docs/LangRef.html: Document the intrinsic. Decide whether it is code generator specific and what the restrictions are. Talk to other people about it so that you are sure it’s a good idea.\n llvm/include/llvm/IR/Intrinsics*.td: Add an entry for your intrinsic. Describe its memory access characteristics for optimization (this controls whether it will be DCE’d, CSE’d, etc). If any arguments need to be immediates, these must be indicated with the ImmArg property. Note that any intrinsic using one of the llvm_any*_ty types for an argument or return type will be deemed by tblgen as overloaded and the corresponding suffix will be required on the intrinsic’s name.\n llvm/lib/Analysis/ConstantFolding.cpp: If it is possible to constant fold your intrinsic, add support to it in the canConstantFoldCallTo and ConstantFoldCall functions.\n llvm/test/*: Add test cases for your test cases to the test suite\n lib/Target/*/*.td: Once the intrinsic has been added to the system, you must add code generator support for it. Generally you must do the following steps: Add support to the .td file for the target(s) of your choice in lib/Target/*/*.td. This is usually a matter of adding a pattern to the .td file that matches the intrinsic, though it may obviously require adding the instructions you want to generate as well. There are lots of examples in the PowerPC and X86 backend to follow.\n   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/llvm/",
	"title": "Learning LLVM",
	"tags": [],
	"description": "",
	"content": " Q \u0026amp; A  What is the LLVM address space?\n John: better name \u0026lsquo;namespace\u0026rsquo;: one namespace for memory load/store; another namespace for IO port load/store.  What is data layout string in LLVM?\n What kind of change we need to make to enable fat pointers for a legacy code?\n   Exceptions   References: reference More Landingpad References: LLVM Exception Handling A landing pad corresponds roughly to the code found in the catch portion of a try/catch sequence. When execution resumes at a landing pad, it receives an exception structure and a selector value corresponding to the type of exception thrown. The selector is then used to determine which catch should actually process the exception. More  Add New Pass to LLVM pipeline   References: Writing LLVM Pass in 2018 \u0026ndash; Part III Steps createXXXPass function initializeXXXPass function INITIALIZE_PASS_BEGIN/END/DEPENDENCY code. Put initializeXXXPass in the right place. update LinkAllPasses.h Put createXXXPass in the right place. More  Table Gen   References: TableGen Overview TableGen Programmer\u0026rsquo;s Reference TableGen Backend Developer\u0026rsquo;s Guide #### More  Debug Info  References: Source Level Debugging with LLVM Debugger Intrinsic Functions LLVM uses several intrinsic functions (name prefixed with \u0026ldquo;llvm.dbg\u0026rdquo;) to track source local variables through optimization and code generation. void @llvm.dbg.addr(metadata, metadata, metadata). Information about a local element (e.g., variable) first argument is metadata holding the address of the variable, typically a static alloca in the function entry block. Second argument is a local variable containing a description of the variable.\n Unique Naming Mechanisms in LLVM  References: llvm/include/llvm/IR/ValueSymbolTable.h ValueSymbolTable ValueSymbolTable: provides a symbol table of name/value pairs. It is essentially a std::map, but has a controlled interface provided by LLVM as well as ensuring uniqueness of names. classValueSymbolTable { ... private: ValueName *makeUniqueName(Value *V, SmallString\u0026lt;256\u0026gt; \u0026amp;UniqueName); /// This method adds the provided value \\p N to the symbol table. The Value /// must have a name which is used to place the value in the symbol table.\n LTO  Q\u0026amp;A How does the LTO help the optimizer to avoid relying on conservative escape analysis? References: LLVM Link Time Optimization A tight integration between the linker and LLVM optimizer. The linker treats LLVM bitcode files like native object files and allows mixing and matching among them. The linker use libLTO, a shared object, to handle LLVM bitcode files. The linker input allows the optmizer to avoid relying on conservative escape analysis.\n Extending  References: reference More Add a new SelectionDAG node References: Extending LLVM: Adding instructions, intrinsics, types, etc More Add a new Instruction to LLVM References: Extending LLVM: Adding instructions, intrinsics, types More Cheri CSetBounds Intrinsics References: Extending LLVM: Adding instructions, intrinsics, types Mips::CSetBounds new instruction support in LLVM IR intrinsics td file llvm/include/IR/IntrinsicsCHERICap.td def int_cheri_cap_bounds_set : Intrinsic\u0026lt;[llvm_fatptr_ty], [llvm_fatptr_ty, llvm_anyint_ty], [IntrNoMem, IntrWillReturn]\u0026gt;; def int_cheri_cap_bounds_set_exact : Intrinsic\u0026lt;[llvm_fatptr_ty], [llvm_fatptr_ty, llvm_anyint_ty], [IntrNoMem, IntrWillReturn]\u0026gt;; target td file llvm/lib/Target/Mips/MipsInstrCheri.\n Metadata  References: llvm/unittests/IR/MetadataTest.cpp  Tools  LLVM Command Guide An Example Using the LLVM Tool Chain clang hello.c -o hello clang -O3 -emit-llvm hello.c -c -o hello.bc clang -S -emit-llvm hello.c -o hello.ll lli hello.bc # invoke LLVM JIT llvm-dis \u0026lt; hello.bc | less # .bc to .ll llvm-as hello.ll -o hello.bc # .ll to bc llc hello.bc -o hello.s llc hello.ll -o hello.s llvm-lit: LLVM integrated tester. Regression Tests References: LLVM doc: Writing new regression tests Lit documentation More Cheri References: reference # llvm/utils/lit/lit/llvm/config.\n Asm  Q \u0026amp; A Can assembly language being compiled to LLVM IR so that it can be analysed? Yes, lots of tools can do this \u0026lsquo;lifting\u0026rsquo;. see assembly to llvm IR translators Assembly to LLVM IR llvm-mctoll remill libqemu llvm-qemu Mc Toll Reference 1 reference ↩ Remill Reference 1 To add new instructions to Remill: https://github.com/lifting-bits/remill/blob/master/docs/ADD_AN_INSTRUCTION.md SEM: semantic of an instruction. ISEL: An instruction \u0026lsquo;selection\u0026rsquo;.\n Proj  Reference 1 root dir Makefile Variables PROJECT_NAME LLVM_SRC_ROOT LLVM_OBJ_ROOT PROJ_SRC_ROOT PROJ_OBJ_ROOT PROJ_INSTALL_ROOT LEVEL include Makefile.config from $(LLVM_OBJ_ROOT) include Makefile.rules from $(LLVM_SRC_ROOT) two ways to set all these variables write your own Makefiles pre-made LLVM sample project Source Tree Layout lib/ include/ tools/ test/ Variables in subdir Makefile LEVEL DIRS PARALLEL_DIRS OPTIONAL_DIRS Variables for Building Libraries (lib/) LIBRARYNAME BUILD_ARCHIVE SHARED_LIBRARY Variables for Building Programs (tool/)\n Hacking  Reference 1 Types Reference 1 To Print type info: use dump() Type ↩ reference ↩  Attr  Q\u0026amp;A How to add new attributes and propagate it using LLVM? How about attributes in assembly language? LLVM References: How to use attributes Adding an annotation that gets to the backend How to add an attribute An attribute can be a single “enum” value (the enum being the [Attribute::AttrKind] enum), a string representing a target-dependent attribute, or an attribute-value pair. Some examples:\n Addrspace  Cite: relation between address spaces and physical memory locations On Wed, Mar 23, 2016 at 8:01 PM, David Chisnall via llvm-dev \u0026lt; llvm-dev at lists.llvm.org\u0026gt; wrote: On 23 Mar 2016, at 11:35, Mohammad Norouzi wrote: \u0026gt; \u0026gt; Thanks for the reply. \u0026gt; \u0026gt; On Wed, Mar 23, 2016 at 10:43 AM, James Molloy wrote: \u0026gt; Hi, \u0026gt; \u0026gt; Address spaces in LLVM are an abstract concept and LLVM attaches no internal meaning to address spaces, apart from: \u0026gt; \u0026gt; - Location 0 in address space 0 is \u0026lsquo;nullptr\u0026rsquo; and a pointer to this cannot be dereferenced in a well formed program.\n Instvisitor  Reference 1 Class InstVisitor: Base class for instruction visitors Instruction visitors are used when you want to perform different actions for different kinds of instructions without having to use lots of casts and a big switch statement (in your code, that is). To define your own visitor, inherit from this class, specifying your new type for the \u0026lsquo;SubClass\u0026rsquo; template parameter, and \u0026ldquo;override\u0026rdquo; visitXXX functions in your class. I say \u0026ldquo;override\u0026rdquo; because this class is defined in terms of statically resolved overloading, not virtual functions.\n LLVM IR   Q\u0026amp;A Reference 1 Example: class A { public: int f; } A* __capability a = new A; a-\u0026gt;f = 42;%call = tail call i8 addrspace(200)* @operator new(unsigned long)(i64 zeroext 4) %f = bitcast i8 addrspace(200)* %call to i32 addrspace(200)* store i32 42, i32 addrspace(200)* %f LLVM Language Reference Manual ↩  Data Layout  (From 1) layout specification: A module may specify a target specific data layout string that specifies how data is to be laid out in memory. The IR syntax for the data layout is simply: target datalayout = \u0026quot;layout specification\u0026quot; (From 2) The XXXTargetMachine constructor will specify a TargetDescription string that determines the data layout for the target machine, including characteristics such as pointer size, alignment, and endianness. For example, the constructor for SparcTargetMachine contains the following:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/linux/lubuntu/",
	"title": "Lubuntu",
	"tags": [],
	"description": "",
	"content": " Lubuntu Split window Lubuntu default shortcuts to split window horizontally to half, putting current window on left/right/top/bottom: Super + $\\leftarrow$; Super + $\\rightarrow$; Super + $\\uparrow$; Super + $\\downarrow$;\nTo change it manually by updating openbox configuration file ~/.config/openbox/lubuntu-rc.xml; see how.\nLubuntu natural scrolling synclient VertScrollDelta=-100 source\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/linux/",
	"title": "Linux",
	"tags": [],
	"description": "",
	"content": "Reference:\n Lubuntu   Lubuntu Split window Lubuntu default shortcuts to split window horizontally to half, putting current window on left/right/top/bottom: Super + $\\leftarrow$; Super + $\\rightarrow$; Super + $\\uparrow$; Super + $\\downarrow$; To change it manually by updating openbox configuration file ~/.config/openbox/lubuntu-rc.xml; see how. Lubuntu natural scrolling synclient VertScrollDelta=-100 source  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheriabi/tradeoff/",
	"title": "Tradeoff",
	"tags": [],
	"description": "",
	"content": "CheriABI1 \u0026ndash; Chapter 4.1 Implementation Tradeoffs\nChoices:\n Method of handling system call capability arguments; Kernel capability programming model (inline assembly, hybrid C, or pure-capability C); Making CheriABI the default ABI vs a compatibility ABI.  declaration annotation model: rejected. for compatibility.\nsystem-call stub/proxy model: rejected.\n Used in CHERI JNI. Can enforce capability restrictions only if the caller is inside a sandbox and unable to make system calls directly. Requires expensive copying semantics to prevent concurrency vulnerabilities[^2007watson].  verification based approach: rejected. Is where generated code checked the capabilities passed to system calls had appropriate bounds and permissions. Has serious drawbacks with advantages:\n time-of-check to time-of-use vulnerability. \u0026ldquo;less efforts to get basic pure-capability binaries up and running. Aided by the fact that FreeBSD generates many aspects of system-call tables using a script, so additional code generation could be slotted in with relative ease.\u0026rdquo;  Capability as first class citizen: Final choice, where \u0026ldquo;capabilities are carried down the call stack and are first class citizens in the kernel\u0026rdquo;. \u0026ldquo;In doing so, we converted the kernel to a hybrid program, eliminating the use of inline assembly macros in favor of annotated capabilities and compiler provided __builtin_* functions. However, hybrid kernel was fairly invasive.\n each system call need to be handled manually. all code that handles user pointers need to be modified to accept capabilities. code that handles objects containing capabilities needed to be modified to use annotated versions of the objects. To keep legacy binaries working, need to perform transformations to unify the type of storage used between legacy and CheriABI. In practice, this meant converting legacy virtual-address-based pointers into capabilities. Sentinels in place of pointers: SIG_DFL, SIG_IGN, or a signal handler function pointer __sighandler_t * ==\u0026gt; create any such sentinel cap with offset from NULL instead of from thread\u0026rsquo;s DDC.  [^2007watson] Exploiting concurrency vulnerabilities in system call wrappers. WOOT workshop, USENIX Security, 2007.\n2019.\n  CheriABI, UCAM-CL-TR-932. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/tools/rsync/",
	"title": "Rsync",
	"tags": [],
	"description": "",
	"content": " tar scp -r will follow symlinks; do not use.\ncompressed copy from server to local:\nssh user@192.168.xxx.xxx -p 22 \u0026#34;cd /home/smeller/ \u0026amp;\u0026amp; tar czf - Desktop\u0026#34; | tar xzf - compressed copy from local to server:\ntar cvjf - dir_a/ | ssh root@ip \u0026#34;(cd /dest/; tar xjf - )\u0026#34; rsync general: rsync source target\ncopy over ssh:\nall contents inside source folder copied to a target folder\nrsync -r -z -a -v -e \u0026#39;ssh -p2220\u0026#39; dir_a/ user@192.168.xxx.xxx:/dir_b/ ~= `cp -ar dir_a/* dir_b/\na folder copied as a subfolder in target folder\nrsync -r -z -a -v -e \u0026#39;ssh -p2220\u0026#39; dir_a user@192.168.xxx.xxx:/dir_b/ ~= cp -ar dir_a dir_b/dir_a\n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/tools/cscope/",
	"title": "Cscope/Vim",
	"tags": [],
	"description": "",
	"content": " Reference1:\nvim -t main\nCTRL-\\ s: all uses of the symbol pointed to by the current cursor;\nCTRL-t: jump back to the original location before search; unwind one at a time;\n:cscope find symbol foo, or :cs f s foo.\n s to find a C symbol; g to find global definition(s) of a symbol; c to find all calls to function; f to open th file name under cursor;  CTRL-spacebar s: split window into two horizontally, and put search result into the new window; CTRL-W w (or ctrl-W arraykey, ctrl-W h/j/k/l for left/up/down/right) to move between windows; CTRL-W c to close current window; CTRL-W o makes only the current windows open, close all others; CTRL-W s to split window into two horizontally, or CTRL-W v for vertical split; :spl[it] filename to open a file in a new window.\n:help cscope\nVim search: / or ?; n for next;\nJumps:\nCTRL-O: Move cursor positions back;\nCTRL-I: move cursor position forward;\n`.: jump to exact spot in last modification line;\n'.: jump to last modification line;\n[{: jump to the beginning of a C code block (while, switch, if, etc.); ]} to the end of block;\n[(: jump to the beginning of a parenthesis; ]) for the end of it;\n  Cscope vim tutorial ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/tools/",
	"title": "Tools",
	"tags": [],
	"description": "",
	"content": " Mscode  References: StackOverflow: Vertical rulers in Visual Studio Code \u0026#34;editor.rulers\u0026#34;: [80,120] \u0026#34;workbench.colorCustomizations\u0026#34;: { \u0026#34;editorRuler.foreground\u0026#34;: \u0026#34;#ff4081\u0026#34; }  Vim  References: How can I set up a ruler at a specific column? set colorcolumn=80  Make  Reference 1 %: one or more chars. used in matching patterns of targets, prerequests. $@: the target of the rule. $^: a list of the dependence files with their full paths. $\u0026lt;: the first dependence file. reference ↩  Gdb  CheatSheet Reference:  Rsync  tar scp -r will follow symlinks; do not use. compressed copy from server to local: ssh user@192.168.xxx.xxx -p 22 \u0026#34;cd /home/smeller/ \u0026amp;\u0026amp; tar czf - Desktop\u0026#34; | tar xzf - compressed copy from local to server: tar cvjf - dir_a/ | ssh root@ip \u0026#34;(cd /dest/; tar xjf - )\u0026#34; rsync general: rsync source target copy over ssh: all contents inside source folder copied to a target folder rsync -r -z -a -v -e \u0026#39;ssh -p2220\u0026#39; dir_a/ user@192.\n Cscope/Vim  Reference1: vim -t main CTRL-\\ s: all uses of the symbol pointed to by the current cursor; CTRL-t: jump back to the original location before search; unwind one at a time; :cscope find symbol foo, or :cs f s foo. s to find a C symbol; g to find global definition(s) of a symbol; c to find all calls to function; f to open th file name under cursor; CTRL-spacebar s: split window into two horizontally, and put search result into the new window; CTRL-W w (or ctrl-W arraykey, ctrl-W h/j/k/l for left/up/down/right) to move between windows; CTRL-W c to close current window; CTRL-W o makes only the current windows open, close all others; CTRL-W s to split window into two horizontally, or CTRL-W v for vertical split; :spl[it] filename to open a file in a new window.\n Git   Git submodule git submodule--helper list To change the url of a submodule # update the url in the .gitmodules file, then run git submodule sync --recursive Git rebase https://www.atlassian.com/git/tutorials/rewriting-history/git-rebase git rebase \u0026lt;base\u0026gt; git rebase --interactive \u0026lt;base\u0026gt; Change base from oldbase to newbase git rebase --onto \u0026lt;newbase\u0026gt; \u0026lt;oldbase\u0026gt; \u0026lt;featurebranch\u0026gt; More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/cpu_switch/",
	"title": "Cpu_switch",
	"tags": [],
	"description": "",
	"content": "Reference:\ncalled in sched_4bsd.c.\ndefined in sys/mips/mips/switch.S: (CheriBSD commit: 6bc17b8c7806fa912beef6efe69f71c599752f7e)\n/* * cpu_switch(struct thread *old, struct thread *new, struct mutex *mtx); *\ta0 - old *\ta1 - new *\ta2 - mtx * Find the highest priority process and resume it. */ NESTED(cpu_switch, CALLFRAME_SIZ, ra) mfc0\tt0, MIPS_COP_0_STATUS\t# t0 = saved status register nop nop and a3, t0, ~(MIPS_SR_INT_IE)\tmtc0\ta3, MIPS_COP_0_STATUS\t# Disable all interrupts ITLBNOPFIX beqz\ta0, mips_sw1 move\ta3, a0 PTR_L\ta0, TD_PCB(a0)\t# load PCB addr of curproc SAVE_U_PCB_CONTEXT(sp, PCB_REG_SP, a0)\t# save old sp PTR_SUBU\tsp, sp, CALLFRAME_SIZ REG_S\tra, CALLFRAME_RA(sp) .mask\t0x80000000, (CALLFRAME_RA - CALLFRAME_SIZ) SAVE_U_PCB_CONTEXT(s0, PCB_REG_S0, a0)\t# do a \u0026#39;savectx()\u0026#39; SAVE_U_PCB_CONTEXT(s1, PCB_REG_S1, a0) SAVE_U_PCB_CONTEXT(s2, PCB_REG_S2, a0) SAVE_U_PCB_CONTEXT(s3, PCB_REG_S3, a0) SAVE_U_PCB_CONTEXT(s4, PCB_REG_S4, a0) SAVE_U_PCB_CONTEXT(s5, PCB_REG_S5, a0) SAVE_U_PCB_CONTEXT(s6, PCB_REG_S6, a0) SAVE_U_PCB_CONTEXT(s7, PCB_REG_S7, a0) SAVE_U_PCB_CONTEXT(s8, PCB_REG_S8, a0) SAVE_U_PCB_CONTEXT(ra, PCB_REG_RA, a0)\t# save return address SAVE_U_PCB_CONTEXT(t0, PCB_REG_SR, a0)\t# save status register SAVE_U_PCB_CONTEXT(gp, PCB_REG_GP, a0) jal\tgetpc nop getpc: SAVE_U_PCB_CONTEXT(ra, PCB_REG_PC, a0)\t# save return address #ifdef CPU_CHERI SAVE_U_PCB_CHERIKFRAME(a0); #endif #ifdef CPU_CNMIPS lw\tt2, TD_MDFLAGS(a3)\t# get md_flags and\tt1, t2, MDTD_COP2USED beqz\tt1, cop2_untouched nop /* Clear cop2used flag */ and\tt2, t2, ~MDTD_COP2USED sw\tt2, TD_MDFLAGS(a3) and\tt2, t0, ~MIPS_SR_COP_2_BIT\t# clear COP_2 enable bit SAVE_U_PCB_CONTEXT(t2, PCB_REG_SR, a0)\t# save status register RESTORE_U_PCB_REG(t0, PS, a0)\t# get CPU status register and\tt2, t0, ~MIPS_SR_COP_2_BIT\t# clear COP_2 enable bit SAVE_U_PCB_REG(t2, PS, a0)\t# save stratus register /* preserve a0..a3 */ move\ts0, a0 move\ts1, a1 move\ts2, a2 move\ts3, a3 /* does kernel own COP2 context? */ lw\tt1, TD_COP2OWNER(a3)\t# get md_cop2owner beqz\tt1, userland_cop2\t# 0 - it\u0026#39;s userland context nop PTR_L\ta0, TD_COP2(a3) beqz\ta0, no_cop2_context nop j\tdo_cop2_save nop userland_cop2: PTR_L\ta0, TD_UCOP2(a3) beqz\ta0, no_cop2_context nop do_cop2_save: PTR_LA\tt9, octeon_cop2_save jalr\tt9 nop no_cop2_context: move\ta3, s3 move\ta2, s2 move\ta1, s1 move\ta0, s0 cop2_untouched: #endif PTR_S\ta2, TD_LOCK(a3)\t# Switchout td_lock  mips_sw1: #ifdef CPU_QEMU_MALTA /* * If per-thread tracing is disabled, skip this block and don\u0026#39;t muck * with emulator state. */ PTR_LA\tt2, _C_LABEL(qemu_trace_perthread)\t# Load address of var lw\tt2, 0(t2)\t# Load var value beqz\tt2, done_qemu_tracing\t# Skip if value is 0 nop /* * If per-thread tracing is enabled, update Qemu-internal state to * reflect the thread we are switching to. Don\u0026#39;t disable before * checking, so we can ensure that we get a full trace if both the * \u0026#39;old\u0026#39; and \u0026#39;new\u0026#39; threads have tracing enabled. */ lw\tt2, TD_MDFLAGS(a1)\t# Get new-\u0026gt;md_flags andi\tt2, t2, MDTD_QTRACE\t# Mask Qemu trace bit beqz\tt2, disable_qemu_tracing\t# Branch if not set nop enable_qemu_tracing: li\t$0, 0xbeef b\tdone_qemu_tracing nop disable_qemu_tracing: li\t$0, 0xdead done_qemu_tracing: #endif #if defined(SMP) \u0026amp;\u0026amp; defined(SCHED_ULE) PTR_LA\tt0, _C_LABEL(blocked_lock) blocked_loop: PTR_L\tt1, TD_LOCK(a1) beq\tt0, t1, blocked_loop nop #endif move\ts7, a1\t# Store newthread /* * Switch to new context. */ GET_CPU_PCPU(a3) PTR_S\ta1, PC_CURTHREAD(a3) PTR_L\ta2, TD_PCB(a1) PTR_S\ta2, PC_CURPCB(a3) PTR_L\tv0, TD_KSTACK(a1)\t# va of 1st half of kstack #if defined(__mips_n64) PTR_LI\ts0, MIPS_XKSEG_START #else PTR_LI\ts0, MIPS_KSEG2_START\t# If Uarea addr is below kseg2, #endif /* __mips_n64 */ bltu\tv0, s0, sw2\t# no need to insert in TLB. PTE_L\ta1, TD_UPTE + 0(s7)\t# a1 = u. pte #0 PTE_L\ta2, TD_UPTE + PTESIZE(s7)\t# a2 = u. pte #1 /* * Wiredown the USPACE of newproc in TLB entry#0. Check whether target * USPACE is already in another place of TLB before that, and if so * invalidate that TLB entry. * NOTE: This is hard coded to UPAGES == 2. * Also, there should be no TLB faults at this point. */ MTC0\tv0, MIPS_COP_0_TLB_HI\t# VPN = va HAZARD_DELAY tlbp\t# probe VPN HAZARD_DELAY mfc0\ts0, MIPS_COP_0_TLB_INDEX HAZARD_DELAY # MIPS_KSEG0_START + (2 * index * PAGE_SIZE) -\u0026gt; MIPS_COP_0_TLB_HI PTR_LI\tt1, MIPS_KSEG0_START\t# invalidate tlb entry #ifdef KSTACK_LARGE_PAGE bltz\ts0, inval_nxt1 #else bltz\ts0, entry0set #endif /* KSTACK_LARGE_PAGE */ nop sll\ts0, PAGE_SHIFT + 1 PTR_ADDU\tt1, s0 MTC0\tt1, MIPS_COP_0_TLB_HI PTE_MTC0\tzero, MIPS_COP_0_TLB_LO0 PTE_MTC0\tzero, MIPS_COP_0_TLB_LO1 MTC0\tzero, MIPS_COP_0_TLB_PG_MASK HAZARD_DELAY tlbwi HAZARD_DELAY #ifdef KSTACK_LARGE_PAGE /* * With a KSTACK_PAGE_SIZE of 16K and PAGE_SIZE of 4K it is possible that * a second TLB entry is currently mapping the kernel thread stack as a * regular 4K sized page(s). Check for this case and, if so, invalidate * that TLB entry as well. */ #if (PAGE_SIZE != 4096) \u0026amp;\u0026amp; (KSTACK_PAGE_SIZE != 16384) #error PAGE_SIZE is not 4K or KSTACK_PAGE_SIZE is not 16K. #endif inval_nxt1: move\tv1, v0 PTR_ADDU\tv1, PAGE_SIZE * 2 MTC0\tv1, MIPS_COP_0_TLB_HI\t# VPN = va HAZARD_DELAY tlbp\t# probe VPN HAZARD_DELAY mfc0\ts0, MIPS_COP_0_TLB_INDEX HAZARD_DELAY # MIPS_KSEG0_START + (2 * index * PAGE_SIZE) -\u0026gt; MIPS_COP_0_TLB_HI PTR_LI\tt1, MIPS_KSEG0_START\t# invalidate tlb entry bltz\ts0, entry0set nop sll\ts0, PAGE_SHIFT + 1 PTR_ADDU\tt1, s0 MTC0\tt1, MIPS_COP_0_TLB_HI PTE_MTC0\tzero, MIPS_COP_0_TLB_LO0 PTE_MTC0\tzero, MIPS_COP_0_TLB_LO1 MTC0\tzero, MIPS_COP_0_TLB_PG_MASK HAZARD_DELAY tlbwi HAZARD_DELAY #endif /* KSTACK_LARGE_PAGE */ entry0set: MTC0\tv0, MIPS_COP_0_TLB_HI\t# set VPN again HAZARD_DELAY /* SMP!! - Works only for unshared TLB case - i.e. no v-cpus */ mtc0\tzero, MIPS_COP_0_TLB_INDEX\t# TLB entry #0 HAZARD_DELAY PTE_MTC0\ta1, MIPS_COP_0_TLB_LO0\t# upte[0] HAZARD_DELAY PTE_MTC0\ta2, MIPS_COP_0_TLB_LO1\t# upte[1] HAZARD_DELAY #ifdef KSTACK_LARGE_PAGE li\tt1, KSTACK_TLBMASK_MASK MTC0\tt1, MIPS_COP_0_TLB_PG_MASK HAZARD_DELAY #else /* ! KSTACK_LARGE_PAGE */ MTC0\tzero, MIPS_COP_0_TLB_PG_MASK HAZARD_DELAY #endif /* ! KSTACK_LARGE_PAGE */ tlbwi\t# set TLB entry #0 HAZARD_DELAY #ifdef KSTACK_LARGE_PAGE MTC0\tzero, MIPS_COP_0_TLB_PG_MASK HAZARD_DELAY #endif /* KSTACK_LARGE_PAGE */ /* * Now running on new u struct. */ sw2: PTR_L\ts0, TD_PCB(s7) RESTORE_U_PCB_CONTEXT(sp, PCB_REG_SP, s0) PTR_LA\tt9, _C_LABEL(pmap_activate)\t# s7 = new proc pointer jalr\tt9\t# s7 = new proc pointer move\ta0, s7\t# BDSLOT /* * Restore registers and return. */ move\ta0, s0 move\ta1, s7 RESTORE_U_PCB_CONTEXT(gp, PCB_REG_GP, a0) RESTORE_U_PCB_CONTEXT(v0, PCB_REG_SR, a0)\t# restore kernel context RESTORE_U_PCB_CONTEXT(ra, PCB_REG_RA, a0) RESTORE_U_PCB_CONTEXT(s0, PCB_REG_S0, a0) RESTORE_U_PCB_CONTEXT(s1, PCB_REG_S1, a0) RESTORE_U_PCB_CONTEXT(s2, PCB_REG_S2, a0) RESTORE_U_PCB_CONTEXT(s3, PCB_REG_S3, a0) RESTORE_U_PCB_CONTEXT(s4, PCB_REG_S4, a0) RESTORE_U_PCB_CONTEXT(s5, PCB_REG_S5, a0) RESTORE_U_PCB_CONTEXT(s6, PCB_REG_S6, a0) RESTORE_U_PCB_CONTEXT(s7, PCB_REG_S7, a0) RESTORE_U_PCB_CONTEXT(s8, PCB_REG_S8, a0) #ifdef CPU_CHERI RESTORE_U_PCB_CHERIKFRAME(a0); #endif mfc0\tt0, MIPS_COP_0_STATUS and\tt0, t0, MIPS_SR_INT_MASK and\tv0, v0, ~MIPS_SR_INT_MASK or\tv0, v0, t0 mtc0\tv0, MIPS_COP_0_STATUS ITLBNOPFIX /* * Set the new thread\u0026#39;s TLS pointer. * * Note that this code is removed if the CPU doesn\u0026#39;t support ULRI by * remove_userlocal_code() in cpu.c. */ #ifdef CPU_CHERI # Get TLS address clc\t$c3, a1, TD_MDTLS($ddc) PTR_L\tt1, TD_MDTLS_TCB_OFFSET(a1)\t# Get TLS/TCB offset cincoffset $c3, $c3, t1 cwritehwr $c3, $chwr_userlocal cgetaddr v0, $c3 #else PTR_L\tt0, TD_MDTLS(a1)\t# Get TLS pointer PTR_L\tt1, TD_MDTLS_TCB_OFFSET(a1)\t# Get TLS/TCB offset PTR_ADDU v0, t0, t1 #endif MTC0\tv0, MIPS_COP_0_USERLOCAL, 2\t# write it to ULR for rdhwr j\tra nop END(cpu_switch)  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/sfi/armor/",
	"title": "ARMor: Fully Verified Software Fault Isolation",
	"tags": [],
	"description": "",
	"content": "Published at EMSOFT\u0026rsquo;11.\nReference:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/sfi/",
	"title": "Sfi",
	"tags": [],
	"description": "",
	"content": "Reference:\n ARMor: Fully Verified Software Fault Isolation  Published at EMSOFT\u0026rsquo;11. Reference:  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxsw/embed-usfi/",
	"title": "Usfi",
	"tags": [],
	"description": "",
	"content": "uSFI1.\n  Ultra-lightweight software fault isolation for iot-class devices. DATE, 2018. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/minion/",
	"title": "MINION: Securing Real-Time Microcontroller Systems through Customized Memory View Switching",
	"tags": [],
	"description": "",
	"content": "Reference:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/nesc/",
	"title": "NesC",
	"tags": [],
	"description": "",
	"content": "Reference:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/nescheck/",
	"title": "nesCheck",
	"tags": [],
	"description": "",
	"content": " nesCheck1.\n Statically find all provable memory bugs and report them as errors; Statically find all potentially unsafe memory accesses, determine and exclude those that will never result in a memory corruption in a conservative way; report the remaining vulnerabilities as warnings; Dynamically instrument all remaining vulnerable location with runtime checks, and catch all memory errors at runtime.  Related text with sil:\nSimilar to CCured, nesCheck leverages more extensive static analysis and tailored runtime checks for wireless sensor network system (TinyOS)\nStatic Analysis   nesCheck. AsiaCCS, 2017. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxsw/nacl/pnacl/",
	"title": "Portable NaCl",
	"tags": [],
	"description": "",
	"content": " Portable Native Client 1: control flow and memory integrity with average performance overhead of under 5% on ARM and 7% on x86-64.\nIntroduction About previous SFI on CISC Control+store SFI on x86-32, which we considered excessive, indicates about 25% overhead.\n \u0026ldquo;As we continued our exploration of ARM SFI and sought to understand ARM behavior relative to x86 behavior, we could not adequately explain the observed performance gap between ARM SFI at under 10% overhead with the overhead on x86-32 in terms of instruction set differences. With further study we understood that the prior implementations for x86-32 may have suffered from suboptimal instruction selection and overly pessimistic alignment.\u0026rdquo;\n ARM ISA and binary format On ARM, only 16-bit Thumb and 32-bit ARM instructions.\nARM binaries commonly include a number of read-only data embedded in the text segment. Such data in executable memory regions must be isolated to ensure it cannot be used to invoke system call instructions or other instructions incompatible with our sandboxing scheme.\nIndirect control flow and memory reference Indirect control flow and memory references must be constrained to within the untrusted memory region, achieved through sandboxing instructions.\nPage protection to replace segmentation (considered, but not used) Page-table protection would be used to prevent the untrusted code from manipulating trusted data; SFI is still required to enforce control flow instructions.\nHence, page protection only avoids data SFI; the control flow SFI persists.\nBut depends on OS-based protection mechanisom. This OS interaction is complicated y the requirement for multiple threads that transition independently between untrusted and trusted execution.\nHigh complexity and overhead, with small potential performance gain ==\u0026gt; Not suitable.\nArch Design  All use alignment masks on control flow target addresses;\n on ARM/x86-64, use high-order address bits to limit control flow targets to logical zero-based virtual address range;   Data mask\n No data mask on x86-32; use segmentation instead; ARM/x86-64: combining masking and guard pages to keep stores within the valid address range for untrusted data. Can read outside of sandbox. Explicit instruction data mask for ARM: Implicit in result width on x86-64:  Data type: ILP32\n Int, Long, Pointer are all 32 bit. same as x86-32, for portability between systems. can improve performance on x86-64 systems.  Instruction sequences\n Address space layout\n  Impl on ARM ARM designs:\n condition codes that can be used to predicate most instructions. ??? what is the predicate mean here?  ARM goals:\n No forbidden instructions in untrusted code; No store above 1GB in untrusted code; No jump above 1GB in untrusted code.  Extension to Wahbe et al. 2\n reserve no registers for holding sandboxed addresses; instead requiring they are computed and checked in a single instruction: ``; ensure integrity of multi-instruction sandboxing by ???, with adaption to further prevent execution of embeded data; ARM\u0026rsquo;s fully predicated instruction set to introduce an alternative data address sandboxing sequence: replace a data dependency with control dependency, preventing pipeline stalls and providing better overhead on multiple-issue and out-of-order microarchitectures. ??? why  Code layout: 16 bytes bundles/four instrs; All ARM instructions, no Thumb; data bundles starting with invalid offset to prevent execution as code.\nValidation:\n direct branch: confirms the target is a valid instruction (bundle start); indirect branch: forbide writing to r15, the PC; only allow explicit branch instruction, such as bx, r0 and their conditional equivalents; most significant 2 bits cleared; 4 least significant bits cleared;\nbic r0, r0, #0xc000,000f bx r0 /* # pop {pc} is replaced with */ pop {lr} bic lr, lr, 0xc000,000f bx lr  Note above code: data dependency between bx branch and masking instruction. This pattern(generating an address via the ALU and immediately jumping to it) is sufficiently common in ARM code that the modern ARM implementations[^3] can dispatch the sequence without stalling.\nData Stores: check within 1 GB.\ntst r0, #0xc0000000 streq r1, [r0, #12] ==\u0026gt; use tst rather than bic here avoids a data dependency between the guard instruction and the store, eliminating a two-cycle address-generation stall on Cortex-A8 that would otherwise triple the cost of the added instruction.\n(Again this is ARM\u0026rsquo;s fully predicated instruction set).\nGuard page: immediate displacement: $\\pm$ 4096 bytes (only base-plus-displacement addressing is allowed, forbide multiple registers), can be used to overflow/underflow 1GB by 4096 bytes; use guard page to trap such.\nStack SP: within 1 GB.\nLLVM 2.6 for ARM; faster than GCC.\nImpl on x86-64 x86-64 features:\n 8 new general purpose registers: r8 - r15.  Rules:\n 4 GB aligned region; flanked above/below by 10 x 4GB regions. ??? why 10?    Take aways   Adapting Software Fault Isolation to Contemporary CPU Architectures. USENIX SEC, 2010. ↩ Efficient software-based fault isolation. By R. Wahbe, S. Lucco, T.E. Anderson, and S.L. Graham. ACM SIGOPS Operating System Review. 1993. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/msinterview/",
	"title": "编程之美",
	"tags": [],
	"description": "",
	"content": "《编程之美》1\n一句话：关键不在于答案，而在于思考问题的方法。\n知己知彼：了解公司的文化、战略方向。\n笔试是基础，需要扎实的理解和考虑完备的解答。\n面试是探讨，需要缜密的代码和严密的分析赢得未来同事的尊重。思考问题的方法比最终的答案重要，面试者会更加在乎你解决问题的思考过程。\n通过自己实际的工作和产品来体现自己的水平。\n  《编程之美》，2008。 ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/tamper-resistance/",
	"title": "Tamper Resistant Software Design and Implementation: IVK",
	"tags": [],
	"description": "",
	"content": "Paper1: Make software immune to observation and modification.\nTamper-resistance using Integrity Verification Kernels:\n segments of code which are self-modifying, self-decrypting and installation unique. code segments communicates with other such code, creating an interlocking trust model.  Threats:\n breach communication access controls to attack the system;\n computer virus;\n attacker as insider: may modify at will.\n    Tamper Resistant Software Design and Implementation. 1999. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/detection/prima/",
	"title": "Prima",
	"tags": [],
	"description": "",
	"content": "PRIMA1: Info flow attestation.\n an extension to Linux IMA:\n measures the code (Linux IMA), and measures which information are present among processes.  attest Biba and Clark-Wilson2, CW-Lite3; CW-Lite attestation is proved.\n Implementation: on SELinux.\n  Info flow examples:\nBiba integrity requires that a process receive no input that is lower integrity than itself4.\nLOMAC(Low-Water Mark Integrity) requires that a process\u0026rsquo;s integrity be that of the lowest integrity input that it receives5.\nCW-Lite guarantee is same as Clark-Wilson: all flows from untrusted processes to high integrity ones must pass through a filtering/sanitizing procedure in the destination process.\nLinux IMA   PRIMA: Policy-Reduced Integrity Measurement Architecture. SACMAT, 2006. ↩ A comparison of commercial and military computer security policies. SP, 1987. ↩ Toward automated information flow integirty for security critical applications. NDSS. 2006. ↩ K. J. Biba. Integrity considerations for secure compter systems. MITRE MTR-3153. 1975. ↩ Lomac: Low water-mark integrity protection for cots environments. SP, Washington, DC, 2000. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/info-flow/",
	"title": "Info Flow Integrity",
	"tags": [],
	"description": "",
	"content": "Reference:\n 2009 Micro Cfo  Reference 1 Deferred exception Itanium: deferred exception tracking. can be used to support for information flow tracking. Deferred exception for speculatively executed instructions. An exception is deferred for later handling instead of being thrown out immediately. Each general purpose register is extended with an additional deferred exception token (NaT, Not a Thing) to keep track of exceptions. Token is propagated along with the executing instructions. Instruction to tnat check the existence of exceptions.\n Lattice   References: A Lattice Model of Secure Information Flow by Dorothy E. Denning, Purdue University. 1976. An information flow model FM is defined as below: To be secure, it requires: More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/detection/flicker/",
	"title": "Flicker",
	"tags": [],
	"description": "",
	"content": "Flicker1:\n 250 lines of code trusted; No trust on BIOS, OS, DMA devices. Trust processor (AMD/Intel) Fine-grained Attestation:\n e.g. A piece of server code handling the client password; no trust on all other softare stack from BIOS to OS. e.g. A Certificate Authority (CA) could sign certificates with its pricate key, even while keeping the key secret from a malicious BIOS/OS/DMA-enabled devices.  Use of Flicker can be attested.\n Executed code, its input and output, can be attested.\n  Processor Features:\n Late launch and attestation    Flicker: An execution Infrastructure for TCB minimization. EUROSYS, 2008. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/detection/verifyexe/",
	"title": "Verifiable Code Execution",
	"tags": [],
	"description": "",
	"content": "Pioneer1\nUntrusted computing platform can tamper with code execution in at least three ways:\n By modifying the code before invoking it; Executing alternate code; or modifying execution state such as memory or registers when the code is running.  Pioneer: challenge-response protocole between trusted \u0026amp; untrusted platform.\nAssuarance that:\n an arbitrary piece of code (the executable) on the untrusted platform is unmodified; the unmodified executable is invoked for execution on the untrusted platform; The exectable is executed untampered, despite the presence of malicious software on the untrusted platform.    Pioneer: Verifying Code Integrity and Enforcing Untampered Code Execution on Legacy Systems. SOSP, 2005. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/uxom/",
	"title": "uXOM",
	"tags": [],
	"description": "",
	"content": " $\\mu$XOM1: Efficient eXecute-Only Memory on ARM Cortex-M. USENIX Security, 2019.\nBackground Code injection attacks: W$\\oplus$X. Since virtually all processors today are equipped with at least five basic memory permissions: read-write-execute (RWX), read-write (RW), read-execute (RX), read-only (RO) and no-access (NA). W$\\oplus$X can be efficiently enforced in hardware for a memory region solely by disabling RWX.\nDisclosure attacks: attemps to read part of or possibly the entire code. Code often contains intellectual properties (IPs) including core algorithems and sensitive data like cryptographic keys. Can also be abused to launch code reuse attacks (CRAs).\nXOM: eXecute-Only-Memory.\n By main memory encryption 2. By hardware permission bits (execute-only) in Exoshim 3, Norax 4, and KHide 5, Readactor6. XOM permission bits are generally available on servers, desktops, smartphones, but not available on embedded devices. SFI-based XOM 7 kr^x 8: performs not optimally; can be circumvented (by privileged app).  Embeded devices: - Applications and kernels operates on same privilege level: - real-time constraints: mode switching is expensive 9\nCortex-M:\nIntersting Exceptions feature:\n an exception return occurs when a unique value of ESC_RETURN (e.g. 0xFFFF,FFF1) is loaded into the pc via memory load instructions, such as POP, LDM, LDR, or indirect branch instructions, such as BX.  Key Idea $\\mu$XOM converts all memory instructions into unprivileged ones and sets the code region as privileged. As a result, converted instructions cannot access code regions, thereby effectively enforcing the XO permission onto code regions.\nThreat model \u0026ldquo;The bare-metal software installed in the device is considered benign but internally holds software vulnerabilities, so that the attackers may exploit the vulnerabilities and ultimately have arbitrary memory read and write capability.\u0026rdquo;\n\u0026ldquo;We do not trust any software components, including the exception handlers.\u0026rdquo;\n\u0026ldquo;Event-driven nature of tiny embedded systems signifies that exception handlers can take a large portion of embedded software components10, so we cannot just assume the security of these handlers. Thus, we assume that attackers can trigger a vulnerability inside the exception handler and manipulate any data including the CPU context saved on exception entry.\u0026rdquo;\n==\u0026gt; untrusted exception handler: LLM: Then what to protect??? How to protect??? exception handler not the protected code contents???\nChallenges/Solutions C1: unconvertible memory instructions: Some memory instructions cannot be changed into uprivileged memory instructions.\n those access critical system resources, interrupt controller, timer, MPU, etc. load/store exclusive instructions do not have unprivileged conterparts.\n $\\mu$XOM: analyze the code to exclude them from instrumentation. Resulting in C3, C3, C4.\n  C2. Malicious indirect branches: unconverted instructions can be abused by jump to them. Can be used to 1) turn off the MPU; 2) reading code directly.\nC3. Malicious exception returns: Hardware based context save and restore for fast exception entry and return. Attackers can exploit a vulnerability while in exception handling mode to corrupt stack, such as return address.\n If attackers corrupt the return address and then trigger an exception return by assigning EXC_RETURN value to pc, they will be able to execute any instruction in the program including the unconverted load/stores.  C4. Malicious data manipulation: attacker can control all data. Call MPU function by passing crafted arguments.\nC5. Unintended instructions: alter control flow to execute unintended/unaligned/data-derived instructions in code region[^usfi]. immediate values in code; middle of 32-bit instructions.\nAddress C2, C3, C4: unconverted instructions in $\\mu$XOM are instrumented with verification routines:\n atomic verification: virtually enables memory instructions to be executed atomically with verification routine.  Address C5: replace danger sequence with secure equivalent. - e.g. LLM: ???\nKey Takeaways Atomic Verification Technique Inspired by Reference monitor: verify the memory access by the unconverted load/stores.\nTo be atomic:\n dedicated base register of every unconverted load/store; The dedicated register must be set to a target address of each unconverted load/store immediately before the associated verification routine; The dedicated register must hold a non-harmful address (i.e., not a code or the PPB address) when the atomic instruction sequence is not executed. Use sp as an alternative to \u0026ldquo;dedicated\u0026rdquo; register;  Disable interrupts before calling verification routine. Set sp as the target of unconverted load/store (such as PPB address), then call verification routine. When sp changes by a non-constant: insert sp check; When sp changes by a constant: (e.g. prolog/epilog), redzones: non-accessible regions around valid stack region (already on board); When sp changes in exception handler: check sp. If not, the attack would avoid all the checks for sp by triggering an interrupt right after they corrupt the sp.   Another way to be atomic (in Silhouette): CFI: cannot be jumped into the middle of a function; \u0026ndash;\u0026gt; but interrupts.returns has to be able to jump to, and can be abused.\nCRA defence as a use case Code disclosure in CRA:\n directly reading code; indirectly infer code layout by the value of code pointers.  Readactor11: a code diversification based CRA defence with resistance to code disclosure attacks. What Readactor do:\n places all code in XOM to prevent the direct disclosure replaces all code pointers with pointers to trampolines. Then code pointers containing the original code location are never stored in a register or memory ??? Then how to call it?  In uXOM:\n Every function call is replaced with a direct branch to the trampoline then a call to the original function in the trampoline. When original functino returns, another direct branch takes the control flow back to the original callsite. Every function pointer is replaced with a pointer to the corresponding functino trampoline. ==\u0026gt; ??? how about the function pointer in the trampoline then?  Evaluation LLVM compiler; Radare2 binary analysis framework12\n   Solution code size exe time energy     uXOM 15.7% 7.3% 7.5%   SFI-XOM 50.8% 22.7% 22.3%   uXOM-CRA 19.3% 8.6% 9.7%      $\\mu$XOM: Efficient eXecute-Only Memory on ARM Cortex-M. USENIX Security, 2019. ↩ David Lie, Chandramohan Thekkath, Mark Mitchell, Patrick Lincoln, Dan Boneh, John Mitchell, and Mark Horowitz. Architectural support for copy and tamper resistant software. ACM SIGPLAN Notices, 2000. ↩ Exoshim: Preventing memory disclosure using execute-only kernel code. Cyber Warfare and Security. 2016. ↩ Norax: Enabling execute-only memory for cots binaries on aarch64. SP, 2017. ↩ Preventing kernel code-reuse attacks through disclosure resistant code diversification. CNS, 2016. ↩ Readactor: Practical code randomization resilient to memory disclosure. SP, 2015. ↩ Leakage-resilient layout randomization for mobile devices. In NDSS, 2016. ↩ kr^x: Comprehensive kernel protection against just-in-time code reuse. CCS, 2017. ↩ Securing real-time microcontroller systems through customized memory view switching. In NDSS, 2018. ↩ Fie on firmware: Finding vulnerabilities in embedded systems using symbolic execution. USENIX Security. 2013. ↩ Readactor: Practical code randomization resilient to memory disclosure. SP, 2015. ↩ unix-like reverse engineering framework and commandline tools. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-process/2003pe/",
	"title": "Preventing Privilege Escalation",
	"tags": [],
	"description": "",
	"content": " 2003 USENIX Security1:\nPrivilege Escalation Services that require special privilege for their operation are critically sensitive. A programming error here may allow an adversary to obtain and abuse the special privilege.\nPrivilege Separation Privilege Seperation: a generic approach to limit the scope of programming bugs. The basic priciple of privilege separation is to reduce the amount of code that runs with special privilege without affecting or limiting the functionality of the service. This narrows the exposure to bugs in code that is executed with privileges.\nIdeally, the only consequence of an error in a privilege separated service is denial of service to the adversary itself.\nOpenSSH Reference:\n  Preventing Privilege Escalation. USENIX Security. 2003. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-backend/",
	"title": "Creating Backend for Cpu0",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to create a new section and store instruction and data\u0026rsquo;s metadata?\n like a new symbol table section?  how to implement a new calling convention?\n Intrinsics?  what is tablegen .td file? How it is used in LLVM infra?\n A domain specific language that describes functional modules and can be used to generate C++ code autotmatically. In LLVM, current usage of TableGen is to generate LLVM code generation code, and clang diagnostics and attributes;  Instrinsics; Calling conventions; Register set, instruction set;  More at TableGen  what is regression test and how does it work?\n Any code change will be tested against all existing (mostly unchanged) features of the system, to make sure new changes do not affect the existing features.   From writing an llvm backend:\n Important backend (parent) classes:  TargetMachine class (SparcTargetMachine.cpp); TableGen, RegisterInfo.td, TargetRegisterInfo class; TargetInstrFormats.td, TargetInstrInfo.td, TargetInstrInfo class; _XXX_ISelDAGToDAG.cpp, _XXX_ISelLowering.cpp (LLVM IR to native instructions) AsmPrinter class, TargetAsmInfo classs (LLVM IR to assembly strings) [optional] TargetSubtarget class (for -mcpu= and -mattr) [optional] TargetJITInfo class (for JIT support, emmitting binary code directly into memory).   Create Backend From Tutorial: Creating an LLVM Backend for the Cpu0 Architecture\nTo create a new backend:\nMachine ID and Relocations  in LLVM root dir:  machine ID \u0026amp; name. relocation records.   Root CMake # cmake/config-ix.cmake ... elseif (LLVM_NATIVE_ARCH MATCHES \u0026#34;mips\u0026#34;) set(LLVM_NATIVE_ARCH Mips)elseif (LLVM_NATIVE_ARCH MATCHES \u0026#34;cpu0\u0026#34;) set(LLVM_NATIVE_ARCH Cpu0)... # CMakeLists.txt set(LLVM_ALL_TARGETS ... Mips Cpu0 ... ) Target triple. // include/llvm/ADT/Triple.h  #undef mips  classTriple { public: enum ArchType { ... mips, // MIPS: mips, mipsallegrex, mipsr6  mipsel, // MIPSEL: mipsel, mipsallegrexe, mipsr6el  mips64, // MIPS64: mips64, mips64r6, mipsn32, mipsn32r6  mips64el, // MIPS64EL: mips64el, mips64r6el, mipsn32el, mipsn32r6el  cheri, // Capability Hardware Enhanced RISC Instructions  ... } enum SubArchType { ... MipsSubArch_r6, MipsSubArch_cheri64, MipsSubArch_cheri128, MipsSubArch_cheri256, ... } // lib/Support/Tripple.cpp  StringRef Triple::getArchTypeName(ArchType Kind) { switch (Kind) { case cheri: return \u0026#34;cheri\u0026#34;; case mips64: return \u0026#34;mips64\u0026#34;; case mips64el: return \u0026#34;mips64el\u0026#34;; case mips: return \u0026#34;mips\u0026#34;; case mipsel: return \u0026#34;mipsel\u0026#34;; } static Triple::ArchType parseArch(StringRef ArchName) { auto AT = StringSwitch\u0026lt;Triple::ArchType\u0026gt;(ArchName) .Cases(\u0026#34;mips64\u0026#34;, \u0026#34;mips64eb\u0026#34;, \u0026#34;mipsn32\u0026#34;, \u0026#34;mipsisa64r6\u0026#34;, \u0026#34;mips64r6\u0026#34;, \u0026#34;mipsn32r6\u0026#34;, Triple::mips64) .StartsWith(\u0026#34;mips64c\u0026#34;, Triple::mips64) // purecap/hybrid CHERI  .Case(\u0026#34;cheri\u0026#34;, Triple::cheri) // TODO: remove  ... .Default(Triple::UnknownArch); } StringRef Triple::getEnvironmentTypeName(EnvironmentType Kind) { switch (Kind) { case UnknownEnvironment: return \u0026#34;unknown\u0026#34;; case Android: return \u0026#34;android\u0026#34;; case CheriPurecap: return \u0026#34;purecap\u0026#34;; ... } static Triple::EnvironmentType parseEnvironment(StringRef EnvironmentName) { return StringSwitch\u0026lt;Triple::EnvironmentType\u0026gt;(EnvironmentName) .StartsWith(\u0026#34;cheripurecap\u0026#34;, Triple::CheriPurecap) .StartsWith(\u0026#34;purecap\u0026#34;, Triple::CheriPurecap) .StartsWith(\u0026#34;android\u0026#34;, Triple::Android) ... }  Relocation records basics of relocation records\n// include/llvm/Object/ELFObjectFile.h  template \u0026lt;classELFT\u0026gt; symbol_iterator ELFObjectFile\u0026lt;ELFT\u0026gt;::getRelocationSymbol(DataRefImpl Rel) const { } template \u0026lt;classELFT\u0026gt; uint64_t ELFObjectFile\u0026lt;ELFT\u0026gt;::getRelocationType(DataRefImpl Rel) const { } template \u0026lt;classELFT\u0026gt; StringRef ELFObjectFile\u0026lt;ELFT\u0026gt;::getFileFormatName() const { bool IsLittleEndian = ELFT::TargetEndianness == support::little; switch (EF.getHeader()-\u0026gt;e_ident[ELF::EI_CLASS]) { case ELF::ELFCLASS32: switch (EF.getHeader()-\u0026gt;e_machine) { case ELF::EM_386: return \u0026#34;ELF32-i386\u0026#34;; case ELF::EM_X86_64: return \u0026#34;ELF32-x86-64\u0026#34;; case ELF::EM_MIPS: return \u0026#34;ELF32-mips\u0026#34;; case ELF::EM_CPU0: // llvm-objdump -t -r  return \u0026#34;ELF32-cpu0\u0026#34;; ... } case ELF::ELFCLASS64: switch (EF.getHeader()-\u0026gt;e_machine) { case ELF::EM_386: return \u0026#34;ELF64-i386\u0026#34;; case ELF::EM_X86_64: return \u0026#34;ELF64-x86-64\u0026#34;; case ELF::EM_MIPS: return \u0026#34;ELF64-mips\u0026#34;; ... } } template \u0026lt;classELFT\u0026gt; Triple::ArchType ELFObjectFile\u0026lt;ELFT\u0026gt;::getArch() const { bool IsLittleEndian = ELFT::TargetEndianness == support::little; switch (EF.getHeader()-\u0026gt;e_machine) { case ELF::EM_X86_64: return Triple::x86_64; case ELF::EM_CHERI256: // CheriABI created with old compiler  if (EF.getHeader()-\u0026gt;e_ident[ELF::EI_CLASS] != ELF::ELFCLASS64) report_fatal_error(\u0026#34;Invalid ELFCLASS!\u0026#34;); if (IsLittleEndian) report_fatal_error(\u0026#34;CHERI must be big endian!\u0026#34;); return Triple::cheri; case ELF::EM_MIPS: switch (EF.getHeader()-\u0026gt;e_ident[ELF::EI_CLASS]) { case ELF::ELFCLASS32: return IsLittleEndian ? Triple::mipsel : Triple::mips; case ELF::ELFCLASS64: { unsigned Arch = EF.getHeader()-\u0026gt;e_flags \u0026amp; ELF::EF_MIPS_MACH; if (Arch == ELF::EF_MIPS_MACH_CHERI256 || Arch == ELF::EF_MIPS_MACH_CHERI128 || Arch == ELF::EF_MIPS_MACH_BERI) { if (IsLittleEndian) report_fatal_error(\u0026#34;BERI/CHERI must be big endian!\u0026#34;); return Triple::cheri; } return IsLittleEndian ? Triple::mips64el : Triple::mips64; } default: report_fatal_error(\u0026#34;Invalid ELFCLASS!\u0026#34;); } ... default: return Triple::UnknownArch; } } // include/llvm/BinaryFormat/ELF.h enum{ ... EM_MIPS = 8, // MIPS R3000  EM_RISCV = 243, // RISC-V  EM_CHERI256 = 0xC256, // 256-bit CHERI  ... } enum : unsinged { EF_MIPS_NOREORDER = 0x00000001, // Don\u0026#39;t reorder instructions  EF_MIPS_PIC = 0x00000002, // Position independent code  EF_MIPS_CPIC = 0x00000004, // Call object with Position independent code  EF_MIPS_ABI2 = 0x00000020, // File uses N32 ABI  ... // ABI flags  EF_MIPS_ABI_EABI32 = 0x00003000, // EABI in 32 bit mode.  EF_MIPS_ABI_EABI64 = 0x00004000, // EABI in 64 bit mode.  EF_MIPS_ABI_CHERIABI = 0x0000c000, // CHERIABI  EF_MIPS_ABI = 0x0000f000, // Mask for selecting EF_MIPS_ABI_ variant.  // MIPS machine variant  EF_MIPS_MACH_5500 = 0x00980000, // NEC VR5500  EF_MIPS_MACH_BERI = 0x00be0000, // BERI MIPS  EF_MIPS_MACH_CHERI128 = 0x00c10000, // CHERI 128-bit  EF_MIPS_MACH_CHERI256 = 0x00c20000, // CHERI 256-bit  EF_MIPS_MACH = 0x00ff0000, // EF_MIPS_MACH_xxx selection mask  ... } // ELF Relocation types for Mips enum { #include \u0026#34;ELFRelocs/Mips.def\u0026#34;};  Initial .td Files .td files may be used to describe\n a target\u0026rsquo;s register set, instruction set; scheduling information for instructions; calling conventions;  .td files will be translated into C++ source code (.inc) by tablegen.\nEvery backend has its own .td file to define target infromation.\nFor Mips:\n lib/Target/Mips/Mips.td lib/Target/Mips/MipsRegisterInfo.td lib/Target/Mips/MipsInstrInfo.td lib/Target/Mips/MipsInstrFormats.td lib/Target/Mips/MipsInstrCheri.td lib/Target/Mips/MipsInstrFormatsCheri.td\n// lib/Target/Mips/Mips.td def Cap64 : HwMode\u0026lt;\u0026#34;+cheri64,-cheri128,-cheri256\u0026#34;\u0026gt;; def Cap128 : HwMode\u0026lt;\u0026#34;+cheri128,-cheri64,-cheri256\u0026#34;\u0026gt;; def Cap256 : HwMode\u0026lt;\u0026#34;+cheri256,-cheri128,-cheri64\u0026#34;\u0026gt;; def FeatureMipsCheri : SubtargetFeature\u0026lt;\u0026#34;chericap\u0026#34;, \u0026#34;IsCheri\u0026#34;, \u0026#34;true\u0026#34;, \u0026#34;Supports the CHERI capability coprocessor\u0026#34;, [FeatureMipsBeri]\u0026gt;; def FeatureMipsCheri64 : SubtargetFeature\u0026lt;\u0026#34;cheri64\u0026#34;, \u0026#34;IsCheri64\u0026#34;, \u0026#34;true\u0026#34;, \u0026#34;Capabilities are 64 bits\u0026#34;, [FeatureMipsCheri]\u0026gt;; def FeatureMipsCheri128 : SubtargetFeature\u0026lt;\u0026#34;cheri128\u0026#34;, \u0026#34;IsCheri128\u0026#34;, \u0026#34;true\u0026#34;, \u0026#34;Capabilities are 128 bits\u0026#34;, [FeatureMipsCheri]\u0026gt;; def FeatureMipsCheri256 : SubtargetFeature\u0026lt;\u0026#34;cheri256\u0026#34;, \u0026#34;IsCheri256\u0026#34;, \u0026#34;true\u0026#34;, \u0026#34;Capabilities are 256 bits\u0026#34;, [FeatureMipsCheri]\u0026gt;; def FeatureCheriExactEquals : SubtargetFeature\u0026lt;\u0026#34;cheri-exact-equals\u0026#34;, \u0026#34;UseCheriExactEquals\u0026#34;, \u0026#34;true\u0026#34;, \u0026#34;CHERI capability comparison are exact (comparing all bits\u0026#34; \u0026#34; instead of just the address).\u0026#34;, [FeatureMipsCheri]\u0026gt;; class Proc\u0026lt;string Name, list\u0026lt;SubtargetFeature\u0026gt; Features\u0026gt; : ProcessorModel\u0026lt;Name, MipsGenericModel, Features\u0026gt;; def : Proc\u0026lt;\u0026#34;generic\u0026#34;, [FeatureMips32]\u0026gt;; def : ProcessorModel\u0026lt;\u0026#34;beri\u0026#34;, BeriModel, [FeatureMipsBeri]\u0026gt;; def : ProcessorModel\u0026lt;\u0026#34;cheri256\u0026#34;, BeriModel, [FeatureMipsCheri256, FeatureMipsCheri, FeatureMipsBeri]\u0026gt;; def : ProcessorModel\u0026lt;\u0026#34;cheri128\u0026#34;, BeriModel, [FeatureMipsCheri128, FeatureMipsCheri, FeatureMipsBeri]\u0026gt;; // MipsRegisterInfo.td // We have banks of 32 registers each. class MipsReg\u0026lt;bits\u0026lt;16\u0026gt; Enc, string n\u0026gt; : Register\u0026lt;n\u0026gt; { let HWEncoding = Enc; let Namespace = \u0026#34;Mips\u0026#34;; } ... // Mips Hardware Registers class HWR\u0026lt;bits\u0026lt;16\u0026gt; Enc, string n\u0026gt; : MipsReg\u0026lt;Enc, n\u0026gt;; // CHERI Hardware Registers class CheriHWR\u0026lt;bits\u0026lt;16\u0026gt; Enc, string n\u0026gt; : MipsReg\u0026lt;Enc, n\u0026gt;; // CHERI capability registers // Uncomment the subregs lines to pretend we are super-registers of the MIPS // integer registers. This is not true but could simulate a merged register file class CAP\u0026lt;bits\u0026lt;16\u0026gt; Enc, string n, list\u0026lt;Register\u0026gt; subregs = []\u0026gt; // : MipsRegWithSubRegs\u0026lt;Enc, n, subregs\u0026gt; { : MipsRegWithSubRegs\u0026lt;Enc, n, []\u0026gt; { // Pretend that we have sub-registers for the purpose of register allocation // let SubRegIndices = [sub_64]; let SubRegIndices = []; } // A capability register that \u0026#34;aliases\u0026#34; one of the MIPS registers // We use this to simulate a merged register file for the purpose of regalloc. // Note: This is a poor approximation, but if we mark the callee-saved registers // as aliased we should no longer get large performance wins over MIPS class AliasCAP\u0026lt;bits\u0026lt;16\u0026gt; Enc, string n, list\u0026lt;Register\u0026gt; aliases = []\u0026gt; : MipsRegWithSubRegs\u0026lt;Enc, n, []\u0026gt; { // Pretend that we have sub-registers for the purpose of register allocation // Unfortunately, this means that $s0 will also be saved if we write to $c18 // There must be an easier way to tell regalloc to avoid allocating one // let Aliases = aliases; } ... def CapRegType : ValueTypeByHwMode\u0026lt;[Cap64, Cap128, Cap256, DefaultMode], [iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR128]\u0026gt;; def CheriGPR : RegisterClass\u0026lt;\u0026#34;Mips\u0026#34;, [CapRegType], 256, (add C1, C2, C3, C4, C5, C6, C7, C8, C9, C10, C11, C12, C13, C14, C15, C16, C17, C18, C19, C20, C21, C22, C23, C24, C25, C26, C27, C28, C29, C30, C31)\u0026gt; { let RegInfos = RegInfoByHwMode\u0026lt;[Cap64, Cap128, Cap256, DefaultMode], [RegInfo\u0026lt;64,64,64\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;, RegInfo\u0026lt;256,256,256\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;]\u0026gt;; } def FakeCheriRegs : RegisterClass\u0026lt;\u0026#34;Mips\u0026#34;, [iFATPTR256], 256, (add DDC)\u0026gt;, Unallocatable; // Cap register class which includes both CNULL and DDC. This is not a // constraint used by any instructions, it is used as a common super-class. // This approach is copied from AArch64RegisterInfo.td def CheriRegsAll : RegisterClass\u0026lt;\u0026#34;Mips\u0026#34;, [CapRegType], 256, (add CheriGPR, CNULL, DDC)\u0026gt;, Unallocatable { let RegInfos = RegInfoByHwMode\u0026lt;[Cap64, Cap128, Cap256, DefaultMode], [RegInfo\u0026lt;64,64,64\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;, RegInfo\u0026lt;256,256,256\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;]\u0026gt;; } def CheriGPROrCNull : RegisterClass\u0026lt;\u0026#34;Mips\u0026#34;, [CapRegType], 256, (add CNULL, CheriGPR)\u0026gt;, Unallocatable { let RegInfos = RegInfoByHwMode\u0026lt;[Cap64, Cap128, Cap256, DefaultMode], [RegInfo\u0026lt;64,64,64\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;, RegInfo\u0026lt;256,256,256\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;]\u0026gt;; } def CheriGPROrDDC : RegisterClass\u0026lt;\u0026#34;Mips\u0026#34;, [CapRegType], 256, (add DDC, CheriGPR)\u0026gt;, Unallocatable { let RegInfos = RegInfoByHwMode\u0026lt;[Cap64, Cap128, Cap256, DefaultMode], [RegInfo\u0026lt;64,64,64\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;, RegInfo\u0026lt;256,256,256\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;]\u0026gt;; } def CheriHWRegs : RegisterClass\u0026lt;\u0026#34;Mips\u0026#34;, [CapRegType], 256, (sequence \u0026#34;CAPHWR%u\u0026#34;, 0, 31)\u0026gt;, Unallocatable { let RegInfos = RegInfoByHwMode\u0026lt;[Cap64, Cap128, Cap256, DefaultMode], [RegInfo\u0026lt;64,64,64\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;, RegInfo\u0026lt;256,256,256\u0026gt;, RegInfo\u0026lt;128,128,128\u0026gt;]\u0026gt;; } - lib/Target/Mips/MipsInstrFormats.td ... def CheriAsmOperand : MipsAsmRegOperand { let Name = \u0026#34;CheriAsmReg\u0026#34;; let PredicateMethod = \u0026#34;isCheriAsmReg\u0026#34;; let DiagnosticType = \u0026#34;CheriAsmReg\u0026#34;; } def CheriAsmOperand0IsDDC : MipsAsmRegOperand { let Name = \u0026#34;CheriAsmReg0IsDDC\u0026#34;; let PredicateMethod = \u0026#34;isCheriAsmReg0IsDDC\u0026#34;; let DiagnosticType = \u0026#34;CheriAsmReg0IsDDC\u0026#34;; } ... def CheriHWRegsAsmOperand : MipsAsmRegOperand { let Name = \u0026#34;CheriHWRegsAsmReg\u0026#34;; let PredicateMethod = \u0026#34;isCheriHWAsmReg\u0026#34;; } ... def CheriOpnd : RegisterOperand\u0026lt;CheriGPROrCNull\u0026gt; { let ParserMatchClass = CheriAsmOperand; let OperandNamespace = \u0026#34;Mips\u0026#34;; let OperandType = \u0026#34;OPERAND_CHERI_GPR_OR_NULL\u0026#34;; } def CheriOpnd0IsDDC : RegisterOperand\u0026lt;CheriGPROrDDC\u0026gt; { let ParserMatchClass = CheriAsmOperand0IsDDC; let OperandNamespace = \u0026#34;Mips\u0026#34;; let OperandType = \u0026#34;OPERAND_CHERI_GPR_OR_DDC\u0026#34;; } ... def CheriHWRegsOpnd : RegisterOperand\u0026lt;CheriHWRegs\u0026gt; { let ParserMatchClass = CheriHWRegsAsmOperand; }  .td files basics the class definition describes how data is laid out, and definitions act as the specific instance of the class.\ndef is used to create instance of class.\nlet to override the existed field from parent class;\ndeclare a new field for a class:  \ncmake changes for td in lib/Target/Mips/\n CMakeLists.txt:\n add .td file name; add tablegen command to generate .inc use add_public_tablegen_target(xxxCommonTableGen) to define xxxCommonTableGen using tablegen (see cmake/modules/TableGen.cmake)  LLVMBuild.txt\n subdirs, name, required libs, etc.   Register Target see here\nMIPS call MIPS stack frame\npass arguments in function call:\n pass in registers pass in stack\nint gI = 100; int sum_i(int x1, int x2, int x3, int x4, int x5, int x6) { int sum = gI + x1 + x2 + x3 + x4 + x5 + x6; return sum; } int main() { int a = sum_i(1, 2, 3, 4, 5, 6); return a; }# clang -target mips-unknown-linux-gnu -c ch9_1.cpp -emit-llvm -o ch9_1.bc # llc -march=mips -relocation-model=pic -filetype=asm ch9_1.bc -o ch9_1.mips.s # cat ch9_1.mips.s  .section .mdebug.abi32 .previous .file \u0026#34;ch9_1.bc\u0026#34; .text .globl _Z5sum_iiiiiii .align 2 .type _Z5sum_iiiiiii,@function .set nomips16 # @_Z5sum_iiiiiii .ent _Z5sum_iiiiiii _Z5sum_iiiiiii: .cfi_startproc .frame $sp,32,$ra .mask 0x00000000,0 .fmask 0x00000000,0 .set noreorder .set nomacro .set noat # BB#0: addiu $sp, $sp, -32 $tmp1: .cfi_def_cfa_offset 32 sw $4, 28($sp) sw $5, 24($sp) sw $t9, 20($sp) sw $7, 16($sp) lw $1, 48($sp) // load argument 5 sw $1, 12($sp) lw $1, 52($sp) // load argument 6 sw $1, 8($sp) lw $2, 24($sp) lw $3, 28($sp) addu $2, $3, $2 lw $3, 20($sp) addu $2, $2, $3 lw $3, 16($sp) addu $2, $2, $3 lw $3, 12($sp) addu $2, $2, $3 addu $2, $2, $1 sw $2, 4($sp) jr $ra addiu $sp, $sp, 32 .set at .set macro .set reorder .end _Z5sum_iiiiiii $tmp2: .size _Z5sum_iiiiiii, ($tmp2)-_Z5sum_iiiiiii .cfi_endproc .globl main .align 2 .type main,@function .set nomips16 # @main .ent main main: .cfi_startproc .frame $sp,40,$ra .mask 0x80000000,-4 .fmask 0x00000000,0 .set noreorder .set nomacro .set noat # BB#0: lui $2, %hi(_gp_disp) ori $2, $2, %lo(_gp_disp) addiu $sp, $sp, -40 $tmp5: .cfi_def_cfa_offset 40 sw $ra, 36($sp) # 4-byte Folded Spill $tmp6: .cfi_offset 31, -4 addu $gp, $2, $25 sw $zero, 32($sp) addiu $1, $zero, 6 sw $1, 20($sp) // Save argument 6 to 20($sp) addiu $1, $zero, 5 sw $1, 16($sp) // Save argument 5 to 16($sp) lw $25, %call16(_Z5sum_iiiiiii)($gp) addiu $4, $zero, 1 // Pass argument 1 to $4 (=$a0) addiu $5, $zero, 2 // Pass argument 2 to $5 (=$a1) addiu $t9, $zero, 3 jalr $25 addiu $7, $zero, 4 sw $2, 28($sp) lw $ra, 36($sp) # 4-byte Folded Reload jr $ra addiu $sp, $sp, 40 .set at .set macro .set reorder .end main $tmp7: .size main, ($tmp7)-main .cfi_endproc  argument passing mechanism implementation More documentation/tutorials:\n Writing an LLVM Backend The LLVM Target-Independent Code Generator   How Globals are written to the object files by Compilers?  Notes $gp value can be a fixed address (static or pic relocation with static link), the start of global address table. All global varaible names in C are statically linked 1 a dyn loaded address (pic relocation with dynamic link) Reference: Cpu0 \u0026ndash; Global Variables The global variable DAG translation is different from local variable ones. It creates IR DAG nodes at run time in backend C++ code according to llc -relocation-model option while the other DAG just do IR DAG to Machine DAG translation directly according to the input file of IR DAGs(except the Pseudo instruction REtLR used in Chapter 3_4).\n Obj Gen  Reference 1 llc -march=cpu0 llc -march=cpu0 -relocation-model=pic -filetype=obj ch4_1_match.bc -o ch4_1_match.cpu0.o LLVM Code: Cpu0InstPrinter.cpp MCTargetDesc/CMakeLists.txt MCTargetDesc/Cpu0AsmBackend.h MCTargetDesc/Cpu0AsmBackend.cpp MCTargetDesc/Cpu0BaseInfo.h MCTargetDesc/Cpu0ELFObjectWriter.cpp MCTargetDesc/Cpu0FixupKinds.h MCTargetDesc/Cpu0MCCodeEmitter.h MCTargetDesc/Cpu0MCCodeEmitter.cpp MCTargetDesc/Cpu0MCExpr.h MCTargetDesc/Cpu0MCExpr.cpp MCTargetDesc/Cpu0MCTargetDesc.h MCTargetDesc/Cpu0MCTargetDesc.cpp MCTargetDesc/Cpu0MCInstLower.h include/llvm/MC/MCRegisterInfo.h Cpu0RegisterInfo.td cmake_debug_build/lib/Target/Cpu0/Cpu0GenRegisterInfo.inc Cpu0InstrInfo.td src/lib/MC/MCELFStreamer.cpp Cpu0 \u0026ndash; Generating Object Files ↩  Regression  LLVM has its test cases (regression test) for each backend to verify the backend compiler without implementing any simulator or real hardware platform. regression test for arch in ./llvm/test/src/test/CodeGen/ To run: cheri# pwd /root/cheri/llvm-project/llvm/test/CodeGen/Mips/cheri cheri# /llvm-build-bin/llvm-lit cheri-sandbox-vaargs.ll llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/config.py:317: note: Running tests for CHERI_CAP_SIZE=16 llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/config.py:405: note: using clang: /root/sva/cheri/bsd112_sync_root/root/cheri/build/llvm-project-build/bin/clang llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/subst.py:127: note: Did not find llvm-exegesis in /root/sva/cheri/bsd112_sync_root/root/cheri/build/llvm-project-build/./bin llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/subst.py:127: note: Did not find llvm-mca in /root/sva/cheri/bsd112_sync_root/root/cheri/build/llvm-project-build/./bin llvm-lit: /root/cheri/llvm-project/llvm/utils/lit/lit/llvm/subst.py:127: note: Did not find llvm-rc in /root/sva/cheri/bsd112_sync_root/root/cheri/build/llvm-project-build/.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/go/setup/",
	"title": "Setup",
	"tags": [],
	"description": "",
	"content": " Environment Variables Reference:\nGOPATH: environment variable that specifies the location of your workspace. If no GOPATH is set, it is assumed to be $HOME/go on Unix systems and %USERPROFILE%\\go on Windows. more\nBinary Package Download\nGetting Started with Go\nBuild from Source Install Go from Source\nUninstalling Go  delete go directory. usually /usr/local/go under Unix or c:\\Go on Windows. remove Go bin directory from the $PATH environment variable. usually /etc/profile, or $HOME/.profile on Linux/FreeBSD; /etc/paths.d/go on MacOS; or Windows environment variable settings.   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/l4/",
	"title": "L4",
	"tags": [],
	"description": "",
	"content": "Reference:\n L4 wiki, L4 kernel projects;  seL4: from Data61\nOKL4: from Open Kernel Lab\nCoyotos: from John Hopkins,\nNova: from Dresden,\nL3:\n seL4  References: About seL4 seL4 Documentation Klein, Gerwin, Kevin Elphinstone, Gernot Heiser, June Andronick, David Cock, Philip Derrin, Dhammika Elkaduwe et al. \u0026ldquo;seL4: Formal verification of an OS kernel.\u0026rdquo; In Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles (SOSP), pp. 207-220. 2009. Murray, Toby, Daniel Matichuk, Matthew Brassil, Peter Gammie, Timothy Bourke, Sean Seefried, Corey Lewis, Xin Gao, and Gerwin Klein. \u0026ldquo;seL4: from general purpose to a proof of information flow enforcement.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/smart-sep/2019privana/",
	"title": "PrivAnalyzer: Measuring the Efficacy of Linux Privilege Use",
	"tags": [],
	"description": "",
	"content": "Reference: 2019 PrivAnalyzer1\n PrivAnalyzer: Measuring the Efficacy of Linux Privilege Use. DSN, 2019 ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/aop/",
	"title": "Aspect Oriented Programming",
	"tags": [],
	"description": "",
	"content": "Reference: what is aop\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/attack-sgx/2017-enclave/",
	"title": "Glamdring: Automatic Application Partitioning for Intel SGX",
	"tags": [],
	"description": "",
	"content": "Reference: Glamdring @ 2017ATC 1\n  Glamdring: Automatic Application Partitioning for Intel SGX. USENIX ATC, 2017. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/smart-sep/2007web/",
	"title": "Secure web applications via automatic partitioning",
	"tags": [],
	"description": "",
	"content": "Reference: Secure web @ 2007SOSP1.\n  Secure web applications via automatic partitioning. SOSP, 2007. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/smart-sep/2004privtrans/",
	"title": "Privtrans: Automatically Partitioning Programs for Privilege Separation",
	"tags": [],
	"description": "",
	"content": " References:\nPrivtrans @ 2004SP1;\nPrivilege separation in OpenSSH2;\nPartition a single program into two parts:\n a monitor, relegated all trust an privileges; a small TCB; a slave.  Q \u0026amp; A  What kind of static analysis techniques are used?\n LLM: user annotation for privileged variables and functions; then inter-procedural static analysis to propagate attributes; \u0026ldquo;meet-over-all-path\u0026rdquo; data-flow analysis to find proper place to insert calls to the monitor.  What kind of dynamic analysis techniques are used?\n LLM:  How to determine bounds of domain?\n How to define the interfaces between domains?\n  Solution:  Programmer annotations. Indicates privileged operations using attributes.\n privileged variables/functions.  Inter-procedural static analysis.\n Propagates attributes locate privileged functions and data  C-to-C translation. Partition the input source code into two programs: the monitor and the slave.\n Data flow techniques to find proper place to insert calls to the monitor. Static + Dynamic analysis to reduce the number of expensive calls made by the slave to the monitor. inserts dynamic checks: to reduce overhead by limiting the number of expensive calls from the slave to monitor ?.  Monitor-slave interface\n two processes, isolated by OS. commumicate via inter-process or inter-network sockets. A base RPC library is provided, as wrappers for common privileged calls  Allow finer-grained policies than access control.\n policies defined by programmer; policies implemented in and enforced by monitor.   User Annotations and Policies Annotations: Two C type qualifier3:\n \u0026ldquo;priv\u0026rdquo;: mark a) variable initialized from privileged resource, will be in the monitor; b) privileged functions, will be in the monitor. \u0026ldquo;unpriv\u0026rdquo;: only used when downgrading a privileged variable.  Policies: A monitor policy. Specifies what operations the slave can ask the monitor to perform.\n written in monitor as C code; enforced since all privileged operations go through the monitor. some can be automatically generated: CFG -\u0026gt; Finite State Machine (FSM) model of possible privileged calls; Pushdown Automata (PDA)  FSM call policy: - remove edges that do not lead to privileged call; got a a collapsed FSM, a directed graph of valid privileged call sequences; - FSM saved to file; read by monitor during initialization. - Requests from slave are checked against the FSM: a call is allowed only if there is an edge from the proceeding call to the current call in the FSM.\nPDA to limit FSM:\n limit the number of allowable call sequences.  PDA related work to limit the call sequences: MOPS 4, malicious call stream detection5, CIL6, Enforceable security policies7, 1999SP 8, and Automatic extraction of OO interfaces9.\n???Easier to write more precise policy than system-call interposition: \u0026ldquo;In system call interposition, a model is needed for both privileged and unprivileged system calls. The policy in system call interposition is usually more complex as the number of system call increases. Privilege separation limites the number of privileged operations to only the interface exported by the monitor, which may reduce the complexity of the resulting policy.\u0026rdquo; ???\nDowngrading data: allow privileged data to flow from the monitor to the slave.\nExample: reading a file contain public/private key pair; file is privileged, private key is privileged, but public key can flow out.\nPrivtrans Analysis \u0026amp; Transformation Overview:\nAttribute propagation\nCall to the monitor: The slave calls privwrap: the interface provided for slave to call the monitor; 1) marshaling the arguments; 2)sending arguments, along with a vector describing the run-time privileged status of each variable, to the monitor; 3) waiting for the monitor to respond; 4) demarshaling any results; 5) return proper results to the slave;\nExecution and return to monitor: The monitor calls privunwrap : 1) demarshals the arguments received; 2) checks the policy to see if the call is allowed; 3) looks up any privileged actuals in its state store; 4) performs the function; 5) if result are marked as privileged, hashes the results to its state store and set the return value of the function to be the hash index; 6) marshals the return values and sends them back to the slave.\nStarting the monitor: priv_init as the first instruction in main. It can optionally\n fork off the monitor process and drop the privileges of the slave; or it contacts an running monitor. ???\n the slave waits for notification from the monitor about successful initialization.\n  Locating privileged data -\u0026gt; Use CIL6 to read in and transform the source code.\n-\u0026gt; Use interprocedural static analysis to locate all potentially privileged call sites.\n A standard meet-over-all-paths data-flow analysis: the priv attribute is added to a variable if it can be assigned to by another privileged variable over any path in the program. Inter-procedural analysis by iteratively adding the privileged attribute across defined functions. ??? since we do not have the function body for procedures declared but not defined, we assume that the privileged attribute could be added to any pointer argument, i.e., a pointer value could be a return value. (??? is this talking about the compatibility with library functions?) ??? If an atrribute is missing, the slave will attempt a call without appropriate privileges, and the call will fail. (??? what if the attribute is not propagated to privileged function, and that function got called by slave directly?)\n After propagation of attributes, we got a set of calls that potentially should be executed by the monitor.\n  -\u0026gt; Rewrites a call to f that may be privileged to the wrapper function privwrap_f. Then privwrap_f use RPC to ask the monitor to execution the f.\n-\u0026gt; Insert run-time checks to limit the number of calls from the slave to the monitor.\n static analysis is conservative, any call site that may be privileged is considered privileged; combined with run-time information, the number of privileged calls could be reduced.  -\u0026gt; privilege polymorphic functions: can somewhere/sometime be privileged, and somewhere/sometime not privileged.\n  Privtrans: Automatically Partitioning Programs for Privilege Separation. SP, 2004. ↩ Preventing Privilege Escalation. SP, 2003. ↩ Rationale for International Standard \u0026ndash; Programming Languages \u0026ndash; C. American National Standard Institutue(ANSI), Oct 1999. ↩ MOPS: an infrastructure for examining security properties of software. CCS, 2002. ↩ Detecting manipulated remote call streams. SP, 2002. ↩ CIL: Intermediate language and tools for analysis and transformation of C programs. CCC, 2002. ↩ Fred Schneider. Enforceable security policies. Information and System Security, 2000. ↩ R. Sekar P Uppuluri. Synthesizing fast intrusion prevention/detection systems from high-level specifications. SP, 1999. ↩ John Whaley, Michael Martin, and Monica Lam. Automatic extraction of object-oriented component interfaces. In the Proceedings of the International Symposium on Software Testing and Analysis, 2002. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/runtimechecks/funcptrs/",
	"title": "Function Ptrs",
	"tags": [],
	"description": "",
	"content": " Reference: Enforcing Alias Analysis for Weakly Typed Languages, TR, 2005.\nRuntime Check on Function Pointers (From 2005 TR1) The call graph is simply checked explicity at each indirect call site ( some could be removed).\nCall graph is one of the input of SAFECode. The call graph is represented in the input type system by adding a function set attribute called $fs$ in Figure 2 to each function pointer type, making explicit the set of possible targets for that function pointer.\nThe function set attribute can be initialized using the $FSET$ definition. For example, the definition $FSET fs = func1, func2, func3;$ followed by a use $(int \\rightarrow int)*fs \\ \\ fptr;$ denotes a function pointer $fptr$ whose targets are the functions $func1, func2, func3$.\nOptimization Optimization by eliminate function pointer checks:\n Simple typing rules that can statically check the call graph contained in the pointer analysis in most cases;\n Add runtime checks where static checking is not possible;\n A more precise call graph by adding extra run-time checks only at call sites where more precision is required.\n  PAFSET attribute in addition to FSET attribute: - FSET: If two function pointers have the same FSET attribute, they potentially call the same set of functions. - PAFSET: To differentiate between the input call graph and the call graph given by the pointer analysis, use PAFSET to identify the function poiner from pointer analysis.\n Enforcing Alias Analysis for Weakly Typed Languages, TR, 2005. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/go/",
	"title": "Go",
	"tags": [],
	"description": "",
	"content": "Reference:\nConcurrency\n Setup  Environment Variables Reference: GOPATH: environment variable that specifies the location of your workspace. If no GOPATH is set, it is assumed to be $HOME/go on Unix systems and %USERPROFILE%\\go on Windows. more Binary Package Download Getting Started with Go Build from Source Install Go from Source Uninstalling Go delete go directory. usually /usr/local/go under Unix or c:\\Go on Windows. remove Go bin directory from the $PATH environment variable. usually /etc/profile, or $HOME/.\n Tour  A Tour of Go Types basic types: bool; // false is zero (initial) value for bool string; // \u0026ldquo;\u0026rdquo; (the empty string) is zero (initial) value for string int, int8, int16, int32, int64 uint, uint8, uint16, uint32, uint64, uintptr byte // alias for uint8 rune // alias for int32, Unicode point float32, float64 complex64, complex128 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/cmplx\u0026#34; ) var ( ToBe bool = false MaxInt uint64 = 1\u0026lt;\u0026lt;64 - 1 z complex128 = cmplx.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/rust/",
	"title": "Rust",
	"tags": [],
	"description": "",
	"content": "Reference:\n Oxide: The Essence of Rust  Reference 1 at its heart lies a novel approach to ownership that balances type system expressively with usability. Rust integrates decades of programming languages research into a production system. Oxide: The Essence of Rust. 2019. ↩  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/rust/",
	"title": "OS in Rust",
	"tags": [],
	"description": "",
	"content": "Reference: Writing an OS in Rust\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/2002controlc/",
	"title": "Control-C",
	"tags": [],
	"description": "",
	"content": " Control-C (in 2002 CASES1) , a subset of C, but with key restrictions designed to ensure that memory safety of code can be verified entirely by static checking, under certain system assumptions.\nRestrictions on C  T1. Requires strong typing of all functions, variables, assignments, and expressions, using the same types as in C.\n T2. Disallows casts to or from any pointer type. Casts between other types (e.g., intergers, floating point numbers, and characters) are allowed.\n T3. A union can only contain types that can be cast to each other; consequently a union cannot contain a pointer type.\n T4. No uses of uninitialized local pointer variables within a procedure. A pointer variable must be assigned a value before it is used or address is taken.\n  For example:\nint a, *p, **pp; pp = \u0026amp;p; print (**pp); p = \u0026amp;a;  p is uninitialized and cannot be assigned to pp. Dereferencing p via **pp is potentially unsafe and this violation would be difficult to detect.\nThe language therefore disallows taking the address of an uninitialized pointer.\n T5. If reserved address is used, then any individual data object should be no larger than the size of the reserved address range.\n Reserved address is leveraged to avoid null pointer checks at runtime (replaced with HW checks).  T6. Pointer arithmetic is disallowed.\n array traversals must be done using explicit array indexing in Control-C. string traversals must use strlen followed by explicit array index operations; A safe string library operations can also be provided.   Restrictions on Array Operations Limitation of symbolic integer analysis One of the fundamental limits in static program analysis lies in the analysis of contraints on symbolic integer expressions. For ensuring safety, the compiler must prove (symbolically) that the index expressions in an array reference lie within the corresponding array bounds on all possible execution path. For each index expression, this can be formulated as an integer contraint system with equalities, inequalities, and logical operators used to represent the computation and control-flow statements of the program.\n\u0026ldquo;Unfortunately, integer constrains with multiplication of symbolic variables is undecidable\u0026rdquo;.\nA broad, decidable class of symbolic integer constraints is Presburger arithmetic, which allows addition, subtraction, multiplication by constants, and the logical connectives $\\vee, \\wedge, \\neg, \\exists $ and $\\forall$. Omega library provides an efficient implementation that has been widely used for solving such integer programming problems in compiler research.\nExploiting static analysis based on Presburger arithmetic requires that our language only allows linear expressions with constant(known) coefficients for all computations that determine the set of values accessed by an array index expression.\nArray operation rules Definition of affine transformation: Let $F: R^n \\rightarrow R$, then a transformation, $F$, is said to be affine if $F(\\overrightarrow{\\rm p}) = C\\overrightarrow{\\rm p} + \\overrightarrow{\\rm q}$, where $C$ is any linear transformation, and $\\overrightarrow{\\rm q}$ contains only constants or known symbolic variables independent of $\\overrightarrow{\\rm p}$.\nIn the following, we assume affine transformations with known constant integer coefficients ($C$).\nArray operations in Control-C must obey the following rules. On all control flow paths,\n A1. The index expression used in an array access must evaluate to a value within the bounds of the array. A2. For all dynamically allocated arrays, the size of the array has to be a positive expression. A3. If an array, A, is accessed inside a loop, then:\n the bounds of the loop have to be provably affine transformations of the size of $A$ an outer loop index variables or vice versa;** ??? **the index expression in the array reference, has to be provably an affine transformation of the vector of loop index variables, or an affine transformation of the size of $A$; and if the index expression in the array reference depends on a symbolic variable $s$ which is independent of the loop index variable (i.e., appears in the constant term $\\overrightarrow{\\rm q}$ in the affine representation), then the memory locations accessed by that reference have to be provably independent of the value of $s$.  A4. If an array is accessed outside of a loop then\n the index expression of the array has to be provably an affine expression of the length of the array.   The compiler can statically check a program satisfies A1 only if the additional language rules A2 \u0026ndash; A4 are obeyed.\nExample:\n... /*** caller function ***/ if (( k \u0026gt; 0) \u0026amp;\u0026amp; (k \u0026lt; 5)) { B = (int *)RMalloc(k * 30); C = initialize(B, 20); } int * initialize(int *B, int n) { int *A,m; if (B[n] \u0026gt; 0) { A = (int *) RMalloc(5 * B[n] + 10); for (m=0; m \u0026lt; B[n]; ++m) A[m*4] = m ; return A; } else return null; } The code above is a valid Control-C because:\n $ n = 20$ can be proven to be an affine function of the size of $B$ (A4); $ m * 4 $ is clearly an affine function of $m$ (A3(2)); and the bounds of the loop ($0$ and $B[n]$) can be proven to be affine functions of the size of $A$ (A3(a)).  Once the above three conditions are satisfied, the compiler proves A1 for all array accesses.\nNote that for proving safety of $B[n]$, the compiler has to correctly include the constraint on $k$ ($ k \u0026lt; 5 $) and only then it can verify that $n(=20)$ is less than the size of $B$.\n Ensuring Code Safety Without Runtime Checks for Real-Time Control Systems. CASES, 2002. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/runtimechecks/arraychecks/",
	"title": "Arraychecks",
	"tags": [],
	"description": "",
	"content": " Reference1\nExtension to JK and JKRL.\nSummary of Jones-Kelly from 2006ICSE1: Jones-Kelly inserts the following checks (ignoring any later optimizaiton) on each arithmetic operation involving a pointer value:\n JK1. check the source pointer is not the invalid value (-2); JK2. find referent object for the source pointer value using the table; JK3. check that the result pointer value is within the bounds of this referent object plus the extra byte. If the result pointer exceeds the bounds, the result -2 is returned to mark the pointer value as valid. JK4. Finally, on any load or store, perform checks[JK1-JK3] but JK3 checks the source pointer itself.  Argument in ICSE 2006:\n if dereference -2 is not allowed by operating system, the JK4 check before loads/stores is strictly not necessary for bound checking; but useful for dangling pointers and cast errors. JK2 is most expensive. If JK2 did not found object, runtime check is skipped, and array bound violations may not be detected. One byte padded to allocated objects.  Not all object are padded during analysis: when inserting padding between two adjacent parameters could cause the memory layout of parameters to differ in check and unchecked code. Therefore: no pad to any function call if the call may invoke an unchecked function \u0026amp; no pad to formal parameters in any function that may be called from unchecked code. AND indirect calls must be treated conservatively.   Summary of Ruwase-Lam Extension To solve the illegal immediate problem that larger than 1 byte out of bounds, Ruwase and Lam extend the JK algorithm essentially by tracking the intended referent of pointers explicitly but only in the case where a pointer moves out of bounds of its intended referent.\n For every out-of-bounds pointer, an extra OOB object is allocated to hold some metadata for the pointer. The pointer itself is modified to point to the OOB object. The OOB contains actual pointer value, and the address of intended object (saved when the pointer first goes out of bounds).\n All OOB objects are stored in the hash table. The hash table is checked only before accessing the OOB object to ensure it is a valid OOB object address.\n All further arithmetic on the OOB pointer is performed on the value in the OOB object.\n If the pointer value comes back within bounds, the original pointer is restored to its current value and the OOB object is deallocated.\n  Argument in ICSE 2006:\n Extra overhead for out-of-bound pointers\n When object deallocated, having to scan OOB object hash table to deallocate any OOB objects that are corresponding to the freed object.\n  Key improvements to JKRL  Exploiting automatic pool allocation for much faster searches for referent objects;\n Instead of using one large splay tree for the entire program, we maintain one splay tree per pool; The lookup for each pointer access is much faster.  An extra level of indirection in the RL approach for OOB pointers that eliminates the need for run-time checks on most loads and stores.\n  Extension to Automatic Pool Allocation Handing non-heap data: original pool allocation only create pools for heap allocated data; Previous memory safety work assigns pool descriptors for all global and stack objects, but did not change how they are allocated.\n Pool allocation is extended to handle globals and stack data, also have partions for globals and stack, avoiding large splay trees. modified to create \u0026ldquo;dummy\u0026rdquo; pool descriptors for nodes that included only global or stack objects: A logical handle to a compiler-chosen subset of memory objects. automatically ensures the objects are created in the appropriate function. (e.g, in main if the node includes any globals). Record each object in the splay tree for the correpsonding pool.  in main for global objects in appropriate function for stack allocated variables (many local variables are promoted to registers and do not need to be stack-allocated or recorded).   OOB pointers Ruwas-Lam exetension to handle OOB pointers requires expensive checks on all loads/stores in the program (before the optimization via elimination of redundant checks).\nIn this work, don\u0026rsquo;t have to check all load/stores.\n A separate OOB hash-table per pool.\n Instead of returning the address of the OOB object and recording it in the out-of-bound pointer variable, we return an illegal (reserved) address. (trap upon access).\n A second hash table for each pool: mapping the returned value and the OOB object.\n When do pointer arithmetic on such OOB values, search for OOB object  On every pointer arithmetic $ p = q + c$:\n check whether $q$ is reserved address; if not reserved: do bound check; if out of bounds, create new OOB object, new reserved address, and their mappings in hash table, assign $p$ as reserved address; if reserved: get OOB; get original pointer value from OOB; do arithmetic; check new pointer value: if out of bounds, a new OOB; if in bounds, assign to $p$.   Weakness  (From 2006 ICSE, ch 3.2.1 ) For pointers with no known pool descriptors: no bounds check.  May not known either if the pointer q is derived from an integer-to-pointer cast or from unchecked code (e.g, as a result of a call the an external function). For int-to-ptr cast, which result in a U (Unknown) flag, the pointer may actually point to an object in some pool, but we don\u0026rsquo;t know which pool at compile time. We do not check pointer arithmetic on such pointers, which is weaker than Jones-Kelly as it allows bound violation goes undetected.    Backwards-Compatible Array Bounds Checking for C with Very Low Overhead, ICSE, 2006. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/hott/intro/",
	"title": "Intro",
	"tags": [],
	"description": "",
	"content": " Reference1\nType Theory Intro 1908 | Bertand Russel2. Invented.\n1933 | Alonzo Church3 [^chu40] [^chu41]. Rigorous formal system. Named $\\lambda$-calculus.\n1998 | Per Martin-Löf[^ML98]. a \u0026ldquo;predicative\u0026rdquo; modification of Church\u0026rsquo;s type system (dependent, constructive, intuitionistic). Named Martin-Löf type theory.\n[^ML98] Per Martin-Löf. An intuitionistic theory of types. In Giovanni Sambin and Jan M. Smith, edi- tors, Twenty-five years of constructive type theory (Venice, 1995), volume 36 of Oxford Logic Guides, pages 127–172. Oxford University Press, 1998.\nmatics, 30:222–262, 1908.\n34:839–864, 1933.\n[chu40]: Alonzo Church. A formulation of of the simple theory of types. Journal of Symbolic Logic, 5:56–68, 1940.\n[chu41]: Alonzo Church. The Calculi of Lambda Conversation. Princeton University Press, 1941.\n \u0026ldquo;Homotopy Type Theory: Univalent Foundations of Mathematics\u0026rdquo;. ↩ Bertand Russell. Mathematical logic based on the theory of types. American Journal of Mathe- ↩ Alonzo Church. A set of postulates for the foundation of logic 2. Annals of Mathematics, ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/hott/",
	"title": "Hott",
	"tags": [],
	"description": "",
	"content": "Reference1\n \u0026ldquo;Homotopy Type Theory: Univalent Foundations of Mathematics\u0026rdquo;. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/runtimecheck/jones-kelly/",
	"title": "Jones Kelly",
	"tags": [],
	"description": "",
	"content": " Reference1\nEarlier work:\nIn this work,\n pointer representations are not changed. A table of all known valid storage objects:\n mapping a pointer to an object descriptor; the descriptor contains the base, extent and additional information of the object.  All pointer arithmetic and pointer use are checked.\n arithmetic result must refer to the same object; every pointer-valued expression must derive its result from one original object. Incorrectly derived pointers are replaced with an illegal pointer value ((void *)-2).   Example: pointers to objects.\nPermitted operations for pointers above:\nObject/pinter tracking: track object when created/deleted:\n static: global variables, static variables in functions, and string constants: compiler/linker change. dynamic: malloc/free/mmap/sbrk: C library change. stack objects:\n Each object is padded by 1 byte. GCC alloca function. De-register: constructor/destructor mechanism. The following compilation happens:\nint sum (int n, int *a){ int i, s = 0; for (i = 0; i \u0026lt; n; ++i) s += a[i]; return s; }   Compiled to\nint sum (int n, int *a){ /* bounds push function enters a function context. A * matching call to bounds pop function will * delete parameters. */ __bounds_push_function (\u0026#34;sum\u0026#34;); __bounds_add_parameter_object (\u0026amp;n, sizeof (int), ...); __bounds_add_parameter_object (\u0026amp;a, sizeof (int*), ...); /* Extra scope created around the function. GCC will * call bounds pop function when leaving this * scope. */ { /* Declare stack objects, and use GCC\u0026#39;s destructor * mechanism to ensure __bounds_delete_stack_object is * called for each variable however we leave scope * (even if we leave with goto). */ int i; __bounds_add_stack_object (\u0026amp;i, sizeof (int), ...); int s = u; __bounds_add_stack_object (\u0026amp;s, sizeof (int), ...); for (i = 0; i \u0026lt; n; ++i) s += *(int*)__bounds_check_array_reference(a, i, sizeof (int), ...); __bounds_delete_stack_object(\u0026amp;s); __bounds_delete_stack_object(\u0026amp;i); } end; __bounds_pop_function(\u0026#34;sum\u0026#34;); /* Delete a, n. */ return s; } goto example. Figure 4: goto label1 creates b and goto label2 destroys b.\nCorner Cases:\n pointers passed from unchecked code to checked code:  If points to registered object: can be derived from another object (registered or unregisterd), cannot detect. If points to unregistered object: can detect and report, but allow such error.  pointers passed from checked code to unchecked code:  unchecked accesses can occur.   Splay trees to look up pointers:\n Binary tree where frequently used nodes migrate towards the top of the tree; on average, the look-up function was iterated 2.11 times per call on a typical large program. unrolled first two iterations of the loop to optimise these cases.  A Brief summary from ICSE 20062 Jones-Kelly inserts the following checks (ignoring any later optimizaiton) on each arithmetic operation involving a pointer value:\n JK1. check the source pointer is not the invalid value (-2); JK2. find referent object for the source pointer value using the table; JK3. check that the result pointer value is within the bounds of this referent object plus the extra byte. If the result pointer exceeds the bounds, the result -2 is returned to mark the pointer value as valid. JK4. Finally, on any load or store, perform checks[JK1-JK3] but JK3 checks the source pointer itself.   Backwards-compatible bounds checking for arrays and pointers in C programs, here. In Automated \u0026amp; Algorithmic Debugging, 1997. ↩ Backwards-Compatible Array Bounds Checking for C with Very Low Overhead, ICSE, 2006. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/runtimecheck/ruwas-lam/",
	"title": "Ruwas Lam",
	"tags": [],
	"description": "",
	"content": "Reference1\nA brief summary from ICSE 2006[^ICSE2006]:\nTo solve the illegal immediate problem that larger than 1 byte out of bounds, Ruwase and Lam extend the JK algorithm essentially by tracking the intended referent of pointers explicitly but only in the case where a pointer moves out of bounds of its intended referent.\n For every out-of-bounds pointer, an extra OOB object is allocated to hold some metadata for the pointer. The pointer itself is modified to point to the OOB object. The OOB contains actual pointer value, and the address of intended object (saved when the pointer first goes out of bounds).\n All OOB objects are stored in the hash table. The hash table is checked only before accessing the OOB object to ensure it is a valid OOB object address.\n All further arithmetic on the OOB pointer is performed on the value in the OOB object.\n If the pointer value comes back within bounds, the original pointer is restored to its current value and the OOB object is deallocated.\n   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/runtimecheck/",
	"title": "Runtime Bound Checking",
	"tags": [],
	"description": "",
	"content": " Reference1\nRuntime Bounds Checking Reference: Runtime Defenses agains Memory Corruption, or here\nThree kinds of solutions:\n Modified pointer representation.  Pointer keeps information about its referent object Incompatible with external code, libraries, etc.  Special table maps pointers to referent objects\n Check referent object on every dereference What if a pointer is modified by external code?  Keep track of address range of each object\n For every pointer arithmetic operation, check that the results points to the same referent object.   Examples:\n Jones-Kelly2: pad each object by 1 byte; maintain a runtime tree of allocated objects; replace all out-of-bound addresses with illegal value; backwards-compatible pointer representation.\n What if a pointer to an out-of-bounds address is used to compute an in-bounds address? ==\u0026gt; Result: False alarm. details  Ruwas-Lam3: catch out-of-bounds pointers at runtime.\n Requires instrumentation of malloc() and a special runtime environment. Out-of-bounds pointer pointer to a special OOB object: stores the original out-of-bounds value; stores a pointer to the original referent object. Pointer arithmetic on out-of-bounds pointers: details     Runtime Defenses agains Memory Corruption, here. ↩ Backwards-compatible bounds checking for arrays and pointers in C programs, here. In Automated \u0026amp; Algorithmic Debugging, 1997. ↩ A Practical Dynamic Buffer Overflow Detector, here. NDSS, 2004. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/basics/interprocedural/cfg/",
	"title": "Call Graphs",
	"tags": [],
	"description": "",
	"content": "Reference1\nIf the program includes the use of a procedure parameter or functin pointer, the target generally is not known until the program is run and, in fact, may vary from one invocation to another. Then, a call site can link to many or all procedures in the call graph.\nIndirect calls are the norm for object-oriented programming languages. When there is overriding of methods in subclasses, a use of method m may refer to any of a number of different methods, depending on the subclass of the receiver object to which it was applied. The use of such virtual method invocations means that we need to know the type of the receiver before we can determine which method is invoked.\n Compilers: Principles, Techniques, \u0026amp; Tools. 2nd ed, ch12.1.1. 2007. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/basics/interprocedural/",
	"title": "Interprocedural",
	"tags": [],
	"description": "",
	"content": " References:\n Ch12 of Dragon Book1. Static Program Analysis: Part 7 \u0026ndash; Interprocedural analysis  Intra-procedural Analysis Most compiler optimizations are performed on procedures one at a time. We refer to such analyses as intraprocedural. These analyses conservatively assume that procedures invoked may alter the state of all the variables visible to the procedures and that they may create all possible side effects, such as modifying any of the variables visible to the procedure or generating exceptions that cause the unwinding of the call stack.\nIntraprocedural analysis is thus relatively simple, albeit imprecise.\nSome optimizations do not need interprocedural analysis, while others may yield almost no useful information without it.\nInter-procedural Analysis An interprocedural analysis operates across an entire program, flowing information from the caller to its callees and vice versa.\ninline procedures: only applicable if we know the target of the procedure call; will increase code size exponentially.\nIf procedures are invoked indirectly through a pointer or via the method dispatch mechanism prevalent in object-oriented programming, analysis of the program\u0026rsquo;s pointers or references can in some cases determine the targets of the indirect invocations. If there is a unique target, inlining can be applied. Even if a unique target is determined for each procedure invocation, inlining must be applied judiciously. In general, it is not possible to inline recursive procedures directly, and even without recursion, inlining can expand the code size exponentially.\nWithout function pointers/indirect calls Reference:\n Static Program Analysis  The idea:\n Construct a CFG for each function Glue them together to reflect function calls and returns  Need to handle:\n Parameter passing Return values Values of local variables across calls (including recursive functions, so not enough to assume unique variable names)  Handling function pointers/indirect calls  Compilers: Principles, Techniques, \u0026amp; Tools, 2nd ed, 2007. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/dsa/passes/localdatastructures/",
	"title": "LocalDataStructures",
	"tags": [],
	"description": "",
	"content": "Computes the local data structure graphs for all of the functions in the program.\n Implemeted as a module pass; but should be a function pass.  Reference1\nClass definition in DataStructure.h:\n// // FIXME: This should be a Function pass that can be USED by a Pass, and would be automatically preserved. Until we can do that, this is a Pass. // classLocalDataStructures : public DataStructures { AddressTakenAnalysis* addrAnalysis; public: static char ID; LocalDataStructures() : DataStructures(ID, \u0026#34;local.\u0026#34;) {} ~LocalDataStructures() { releaseMemory(); } virtual bool runOnModule(Module \u0026amp;M); /// getAnalysisUsage - This obviously provides a data structure graph.  ///  virtual void getAnalysisUsage(AnalysisUsage \u0026amp;AU) const { AU.addRequired\u0026lt;AddressTakenAnalysis\u0026gt;(); AU.setPreservesAll(); } };  code ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/dsa/passes/datastructures/",
	"title": "DataStructures",
	"tags": [],
	"description": "",
	"content": "Reference1\nDefined in DataStructure.h:\nclassDataStructures : public ModulePass { typedef std::map\u0026lt;const Function*, DSGraph*\u0026gt; DSInfoTy; /// DataLayout, comes in handy  const DataLayout* TD; /// Pass to get Graphs from  DataStructures* GraphSource; /// Do we clone Graphs or steal them?  bool Clone; /// do we reset the aux list to the func list?  bool resetAuxCalls; /// Were are DSGraphs stolen by another pass?  bool DSGraphsStolen; void buildGlobalECs(svset\u0026lt;const GlobalValue*\u0026gt;\u0026amp; ECGlobals); void eliminateUsesOfECGlobals(DSGraph\u0026amp; G, const svset\u0026lt;const GlobalValue*\u0026gt; \u0026amp;ECGlobals); // DSInfo, one graph for each function  DSInfoTy DSInfo; // Name for printing  const char* printname; protected: /// The Globals Graph contains all information on the globals  DSGraph *GlobalsGraph; /// GlobalECs - The equivalence classes for each global value that is merged  /// with other global values in the DSGraphs.  EquivalenceClasses\u0026lt;const GlobalValue*\u0026gt; GlobalECs; SuperSet\u0026lt;Type*\u0026gt;* TypeSS; // Callgraph, as computed so far  DSCallGraph callgraph; // List of all address taken functions.  // This is used as target, of indirect calls for any indirect call site with // incomplete callee node.  std::vector\u0026lt;const Function*\u0026gt; GlobalFunctionList; void init(DataStructures* D, bool clone, bool useAuxCalls, bool copyGlobalAuxCalls, bool resetAux); void init(const DataLayout* T); void formGlobalECs(); void cloneIntoGlobals(DSGraph* G, unsigned cloneFlags); void cloneGlobalsInto(DSGraph* G, unsigned cloneFlags); void restoreCorrectCallGraph(); void formGlobalFunctionList(); DataStructures(char \u0026amp; id, const char* name) : ModulePass(id), TD(0), GraphSource(0), printname(name), GlobalsGraph(0) { // For now, the graphs are owned by this pass  DSGraphsStolen = false; } public: /// print - Print out the analysis results...  ///  void print(llvm::raw_ostream \u0026amp;O, const Module *M) const; void dumpCallGraph() const; /// handleTest - Handles various user-specified testing options.  /// Returns true iff the user specified for us to test something.  ///  bool handleTest(llvm::raw_ostream \u0026amp;O, const Module *M) const; virtual void releaseMemory(); virtual bool hasDSGraph(const Function \u0026amp;F) const { return DSInfo.find(\u0026amp;F) != DSInfo.end(); } /// getDSGraph - Return the data structure graph for the specified function.  ///  virtual DSGraph *getDSGraph(const Function \u0026amp;F) const { std::map\u0026lt;const Function*, DSGraph*\u0026gt;::const_iterator I = DSInfo.find(\u0026amp;F); assert(I != DSInfo.end() \u0026amp;\u0026amp; \u0026#34;Function not in module!\u0026#34;); return I-\u0026gt;second; } void setDSGraph(const Function\u0026amp; F, DSGraph* G) { DSInfo[\u0026amp;F] = G; } DSGraph* getOrCreateGraph(const Function* F); DSGraph* getGlobalsGraph() const { return GlobalsGraph; } EquivalenceClasses\u0026lt;const GlobalValue*\u0026gt; \u0026amp;getGlobalECs() { return GlobalECs; } const DataLayout\u0026amp; getDataLayout() const { return *TD; } const DSCallGraph\u0026amp; getCallGraph() const { return callgraph; } SuperSet\u0026lt;Type*\u0026gt;\u0026amp; getTypeSS() const { return *TypeSS; } /// deleteValue/copyValue - Interfaces to update the DSGraphs in the program.  /// These correspond to the interfaces defined in the AliasAnalysis class.  void deleteValue(Value *V); void copyValue(Value *From, Value *To); };  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/dsa/passes/tddatastructures/",
	"title": "TDDataStructures",
	"tags": [],
	"description": "",
	"content": "Reference1\nClass definition in DataStructure.h, drived from class DataStructures:\n// TDDataStructures // - Analysis that computes new data structure graphs for each function using the closed graphs for the callers computed by the bottom-up pass.  classTDDataStructures : public DataStructures { svset\u0026lt;const Function*\u0026gt; ExternallyCallable; /// CallerCallEdges - For a particular graph, we keep a list of these records  /// which indicates which graphs call this function and from where.  struct CallerCallEdge { DSGraph *CallerGraph; // The graph of the caller function.  const DSCallSite *CS; // The actual call site.  const Function *CalledFunction; // The actual function being called.  CallerCallEdge(DSGraph *G, const DSCallSite *cs, const Function *CF) : CallerGraph(G), CS(cs), CalledFunction(CF) {} bool operator\u0026lt;(const CallerCallEdge \u0026amp;RHS) const { return CallerGraph \u0026lt; RHS.CallerGraph || (CallerGraph == RHS.CallerGraph \u0026amp;\u0026amp; CS \u0026lt; RHS.CS); } }; std::map\u0026lt;DSGraph*, std::vector\u0026lt;CallerCallEdge\u0026gt; \u0026gt; CallerEdges; // IndCallMap - We memoize the results of indirect call inlining operations that have multiple targets here to avoid N*M inlining. The key to the map is a sorted set of callee functions, the value is the DSGraph that holds all of the caller graphs merged together, and the DSCallSite to merge with the arguments for each function.  std::map\u0026lt;std::vector\u0026lt;const Function*\u0026gt;, DSGraph*\u0026gt; IndCallMap; bool useEQBU; public: static char ID; TDDataStructures(char \u0026amp; CID = ID, const char* printname = \u0026#34;td.\u0026#34;, bool useEQ = false) : DataStructures(CID, printname), useEQBU(useEQ) {} ~TDDataStructures(); virtual bool runOnModule(Module \u0026amp;M); /// getAnalysisUsage - This obviously provides a data structure graph.  virtual void getAnalysisUsage(AnalysisUsage \u0026amp;AU) const { if (useEQBU) { AU.addRequired\u0026lt;EquivBUDataStructures\u0026gt;(); } else { AU.addRequired\u0026lt;BUDataStructures\u0026gt;(); AU.addPreserved\u0026lt;BUDataStructures\u0026gt;(); } AU.setPreservesAll(); } private: void markReachableFunctionsExternallyAccessible(DSNode *N, DenseSet\u0026lt;DSNode*\u0026gt; \u0026amp;Visited); void InlineCallersIntoGraph(DSGraph* G); void ComputePostOrder(const Function \u0026amp;F, DenseSet\u0026lt;DSGraph*\u0026gt; \u0026amp;Visited, std::vector\u0026lt;DSGraph*\u0026gt; \u0026amp;PostOrder); };  github code: DataStructure.h  ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/dsa/passes/eqtddatastructures/",
	"title": "EQTDDataStructures",
	"tags": [],
	"description": "",
	"content": "Reference1:\nEQTDDataStructures is the ``final\u0026rdquo; form of DSA and is probably the appropriate pass for most external clients to use. By including this pass, a client will get the results of the DSA analysis after all phases of DSA have been run. Merging has been performed for aliasing in both callers and callees, so fewer nodes will be incomplete than in bottom-up. Aliasing information will therefore be most precise.\nThe primary disadvantage of using EQTDDataStructures is the loss of precision caused by the additional merging of nodes relative to bottom-up. Depending on the needs of a client, therefore, EquivBuDataStructures may be more appropriate in specific cases.\nClass definition in DataStructure.h: derived from TDDataStructures\n/// EQTDDataStructures - Analysis that computes new data structure graphs /// for each function using the closed graphs for the callers computed /// by the EQ bottom-up pass. /// classEQTDDataStructures : public TDDataStructures { public: static char ID; EQTDDataStructures() :TDDataStructures(ID, \u0026#34;eqtd.\u0026#34;, true) {} ~EQTDDataStructures(); };  EQTDDataStructure doc in manual ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/dsa/passes/",
	"title": "Passes",
	"tags": [],
	"description": "",
	"content": " LocalDataStructures  Computes the local data structure graphs for all of the functions in the program. Implemeted as a module pass; but should be a function pass. Reference1 Class definition in DataStructure.h: // // FIXME: This should be a Function pass that can be USED by a Pass, and would be automatically preserved. Until we can do that, this is a Pass. // classLocalDataStructures : public DataStructures { AddressTakenAnalysis* addrAnalysis; public: static char ID; LocalDataStructures() : DataStructures(ID, \u0026#34;local.\n DataStructures  Reference1 Defined in DataStructure.h: classDataStructures : public ModulePass { typedef std::map\u0026lt;const Function*, DSGraph*\u0026gt; DSInfoTy; /// DataLayout, comes in handy const DataLayout* TD; /// Pass to get Graphs from DataStructures* GraphSource; /// Do we clone Graphs or steal them? bool Clone; /// do we reset the aux list to the func list? bool resetAuxCalls; /// Were are DSGraphs stolen by another pass? bool DSGraphsStolen; void buildGlobalECs(svset\u0026lt;const GlobalValue*\u0026gt;\u0026amp; ECGlobals); void eliminateUsesOfECGlobals(DSGraph\u0026amp; G, const svset\u0026lt;const GlobalValue*\u0026gt; \u0026amp;ECGlobals); // DSInfo, one graph for each function DSInfoTy DSInfo; // Name for printing const char* printname; protected: /// The Globals Graph contains all information on the globals DSGraph *GlobalsGraph; /// GlobalECs - The equivalence classes for each global value that is merged /// with other global values in the DSGraphs.\n TDDataStructures  Reference1 Class definition in DataStructure.h, drived from class DataStructures: // TDDataStructures // - Analysis that computes new data structure graphs for each function using the closed graphs for the callers computed by the bottom-up pass. classTDDataStructures : public DataStructures { svset\u0026lt;const Function*\u0026gt; ExternallyCallable; /// CallerCallEdges - For a particular graph, we keep a list of these records /// which indicates which graphs call this function and from where. struct CallerCallEdge { DSGraph *CallerGraph; // The graph of the caller function.\n EQTDDataStructures  Reference1: EQTDDataStructures is the ``final\u0026rdquo; form of DSA and is probably the appropriate pass for most external clients to use. By including this pass, a client will get the results of the DSA analysis after all phases of DSA have been run. Merging has been performed for aliasing in both callers and callees, so fewer nodes will be incomplete than in bottom-up. Aliasing information will therefore be most precise. The primary disadvantage of using EQTDDataStructures is the loss of precision caused by the additional merging of nodes relative to bottom-up.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/passes/stackcheck/",
	"title": "Stack Check",
	"tags": [],
	"description": "",
	"content": "Reference1\nsafecode/include/StackSafety.h:  This file defines checks for stack safety.\nstruct checkStackSafety : public ModulePass { public : ... virtual bool runOnModule(Module \u0026amp;M); virtual void getAnalysisUsage(AnalysisUsage \u0026amp;AU) const { AU.addRequired\u0026lt;DataLayout\u0026gt;(); AU.addRequired\u0026lt;EQTDDataStructures\u0026gt;(); AU.setPreservesAll(); } private : //  // Tracks the DSNodes that have already been analyzed by an invocation of  // markReachableAllocas().  //  std::set\u0026lt;DSNode *\u0026gt; reachableAllocaNodes; bool markReachableAllocas(DSNode *DSN, bool start=false); bool markReachableAllocasInt(DSNode *DSN, bool start=false); }; } }  safecode/lib/StackSafety/CheckStackPointer.cpp:  Implementation of StackSafety.h\n\u0026ldquo;FixMe: Can this pass get better results by using another DSA pass? It seems this pass may be too conservative by using the Top-Down DSA results.\u0026rdquo;\n runOnModule(): no changes.\n EQTDDataStructures: An DSA pass that \u0026ldquo;computes new data structure graphs for each function using the closed graphs for the callers computed by the EQ bottom-up pass.\u0026rdquo; more\nbool checkStackSafety::runOnModule(Module \u0026amp;M) { // TDDataStructures *TDDS; // TDDS = \u0026amp;getAnalysis\u0026lt;TDDataStructures\u0026gt;(); EQTDDataStructures *BUDS; BUDS = \u0026amp;getAnalysis\u0026lt;EQTDDataStructures\u0026gt;(); // // Get a pointer to the entry of the program. // Function *MainFunc = M.getFunction(\u0026#34;main\u0026#34;) ? M.getFunction(\u0026#34;main\u0026#34;) : M.getFunction (\u0026#34;MAIN__\u0026#34;); // // Scan each function and look for stack objects which can escape from the // function. // for (Module::iterator MI = M.begin(), ME = M.end(); MI != ME; ++MI) { Function \u0026amp;F = *MI; if (\u0026amp;F != MainFunc) { if (!F.isDeclaration()) { DSGraph * BUG = BUDS-\u0026gt;getDSGraph(F); // // If the function can return a pointer, see if a stack object can // escape via the return value. // if (isa\u0026lt;PointerType\u0026gt;(F.getReturnType())) { for (inst_iterator ii = inst_begin(F), ie = inst_end(\u0026amp;F); ii != ie; ++ii) { if (ReturnInst *RI = dyn_cast\u0026lt;ReturnInst\u0026gt;(\u0026amp;*ii)) { DSNode *DSN = BUG-\u0026gt;getNodeForValue(RI).getNode(); if (DSN) { markReachableAllocas(DSN); } } } } // // Conservatively assume that any stack object reachable from one of // the incoming arguments is a stack object that is placed there as an // \u0026#34;output\u0026#34; by this function (or one of its callees). // Function::arg_iterator AI = F.arg_begin(), AE = F.arg_end(); for (; AI != AE; ++AI) { if (isa\u0026lt;PointerType\u0026gt;(AI-\u0026gt;getType())) { DSNode *DSN = BUG-\u0026gt;getNodeForValue(AI).getNode(); markReachableAllocas(DSN, true); } } // // Any stack object that is reachable by a global may also escape the // function. Scan both for local variables that may alias with globals // as well as globals that are directly accessed by the function. // DSGraph::node_iterator DSNI = BUG-\u0026gt;node_begin(), DSNE = BUG-\u0026gt;node_end(); for (; DSNI != DSNE; ++DSNI) { if (DSNI-\u0026gt;isGlobalNode()) { markReachableAllocas(DSNI); } } DSGraph * GlobalGraph = BUG-\u0026gt;getGlobalsGraph(); DSNI = GlobalGraph-\u0026gt;node_begin(), DSNE = GlobalGraph-\u0026gt;node_end(); for (; DSNI != DSNE; ++DSNI) { if (DSNI-\u0026gt;isGlobalNode()) { markReachableAllocas(DSNI); } } } } } // // This pass never changes the module; always return false. // return false; }   markReachableAllocasInt(DSNode *DSN, bool start): Find all of the DSNodes that alias with stack objects and are reachable from the specified DSNode.\nbool checkStackSafety::markReachableAllocasInt(DSNode *DSN, bool start) { bool returnValue = false; reachableAllocaNodes.insert(DSN); // // If the initial node is an alloca node, then put it in the reachable set. // if (!start \u0026amp;\u0026amp; DSN-\u0026gt;isAllocaNode()) { returnValue = true; AllocaNodes.insert (DSN); } // // Look at the DSNodes reachable from this DSNode. If they alias with the // stack, put them in the reachable set. // DataLayout \u0026amp; TD = getAnalysis\u0026lt;DataLayout\u0026gt;(); for (unsigned i = 0, e = DSN-\u0026gt;getSize(); i \u0026lt; e; i += TD.getPointerSize()) if (DSNode *DSNchild = DSN-\u0026gt;getLink(i).getNode()) { if (reachableAllocaNodes.find(DSNchild) != reachableAllocaNodes.end()) { continue; } else if (markReachableAllocasInt(DSNchild)) { returnValue = returnValue || true; } } return returnValue; }    safecode/lib/StackSafety/ ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/passes/arraybnd/",
	"title": "Static Array Bound Checks",
	"tags": [],
	"description": "",
	"content": "lib/ArrayBoundChecks: This library contains serveral analysis passes for static array bounds checking1.\nsafecode/lib/ArrayBoundChecks/ArrayBoundCheckLocal.cpp: \n\u0026ldquo;ArrayBoundsCheckLocal - It tries to prove a GEP is safe only based on local information, that is, the size of global variables and the size of objects being allocated inside a function.\u0026rdquo;\nCode sinppets:\nEntry:\nbool ArrayBoundsCheckLocal::runOnFunction(Function \u0026amp; F) { //  // Get required analysis passes.  //  TD = \u0026amp;F.getParent()-\u0026gt;getDataLayout(); SE = \u0026amp;getAnalysis\u0026lt;ScalarEvolution\u0026gt;(); //  // Look for all GEPs in the function and try to prove that they\u0026#39;re safe.  //  visit (F); //  // We modify nothing; return false.  //  return false; } //  // If the offset is less than zero, then we know that we are indexing  // backwards from the beginning of the object. We know that this is illegal;  // declare it unsafe.  //  if ((SE-\u0026gt;getSMaxExpr(offset, zero) == zero) \u0026amp;\u0026amp; (offset != zero)) { ++unsafeGEPs; return; } //  // Otherwise, we are indexing zero or more bytes forward. Determine whether  // we will index past the end of the object.  //  if ((SE-\u0026gt;getSMaxExpr(diff, zero) == diff) \u0026amp;\u0026amp; (diff != zero)) { ++safeGEPs; SafeGEPs.insert (\u0026amp;GEP); return; } //  // We cannot statically prove that the GEP is safe.  //  return;  Array Bound Proof/Check\nsafecode/lib/ArrayBoundChecks/ArrayBoundCheckStruct.cpp: \n\u0026ldquo;This file implements the ArrayBoundsCheckStruct pass. This pass utilizes type-safety information from points-to analysis to prove whether GEPs2 are safe (they do not create a pointer outside of the memory object). It is primarily designed to alleviate run-time checks on GEPs used for structure indexing (hence the clever name).\u0026rdquo;\nsafecode/lib/ArrayBoundChecks/BottomUpCallGraph.cpp: \n\u0026ldquo;I believe this pass does two things:\u0026rdquo;\n\u0026rdquo; o) It attempts to improve upon the call graph calculated by DSA for those call sites in which a callee was not found.\u0026rdquo;\n\u0026rdquo; o) It finds functions that are part of Strongly Connected Components (SCCs) in the call graph and marks them being a part of an SCC.\u0026rdquo;\n\u0026rdquo; FIXME: I believe the fixup of the call graph is no longer necessary; DSA asserts if it can\u0026rsquo;t find a callee for a call instruction.\u0026rdquo;\nsafecode/lib/ArrayBoundChecks/BreakConstantGEPs.cpp: \n\u0026ldquo; This pass changes all GEP constant expressions into GEP instructions. This permits the rest of SAFECode to put run-time checks on them if necessary.\u0026rdquo;\nsafecode/lib/ArrayBoundChecks/ConstraintGeneration.cpp \u0026ldquo; Now we use the control dependence, post dominance frontier to generate constraints for ?\u0026rdquo;\n SAFECode Software Architecture Manual ↩ GEP: GetElementPtr instruction in LLVM. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/passes/ptrchecks/",
	"title": "Pass: Insert Pointer Checks",
	"tags": [],
	"description": "",
	"content": "Reference1\nC Zero Security Checks: \n\u0026ldquo;This transformation ensures that the code emitted (if there are no warnings) poses no security threat to the target system.\u0026rdquo;\nFree Removal Pass:\n\u0026ldquo;FIXME: This pass needs to be cleaned up and better understood. Some of the functionality seems to be addressed with poolcheckalign() in the Check Insertion pass; we should ensure that the functionality there is present in mainline and supercedes what is implemented here. Also, the checking of pool operations should be understood and updated/corrected if needed.\u0026rdquo;\n\u0026ldquo;This pass appears to do two things:\u0026rdquo;\n\u0026rdquo; o) It ensures that there are load/store checks on pointers that point to type-known data but are loaded from type-unknown partitions.\u0026rdquo;\n\u0026rdquo; o) It seems to perform some sort of sanity/correctness checking of pool creation/destruction.\u0026rdquo;\n\u0026ldquo;Original comment from initial implementation:\u0026rdquo; \u0026ldquo;Implementation of FreeRemoval.h : an EmbeC pass\u0026rdquo;\n\u0026ldquo;Some assumptions:\u0026rdquo;\n Correctness of pool allocation Destroys at end of functions.  \u0026ldquo;Pool pointer aliasing assumptions:\u0026rdquo;\n pool pointer copies via gep\u0026rsquo;s are removed no phinode takes two pool pointers because then they would be the same pool  \u0026ldquo;Result: If we look at pool pointer defs and look for their uses\u0026hellip; we check that their only uses are calls to pool_allocs, pool_frees and pool_destroys.\u0026rdquo;\n```\n src: safecode/lib/PointerChecks ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/passes/poolchecks/",
	"title": "Pass: Insert Pool Checks",
	"tags": [],
	"description": "",
	"content": "lib/InsertPoolChecks. This library contains\n the transform passes for inserting run-time checks and for inserting code to register memory objects within individual pools. the CompleteChecks pass which implements the Check Completion Phase.  Alignment Checks:\n\u0026ldquo; This pass instruments the code with alignment checks. This is required when load/store checks on type-safe memory objects are optimized away; pointers to type-safe memory objects that are loaded from type-unsafe memory objects may not point to a valid memory object or may not be alignment properly within a valid memory object.\u0026rdquo;\nCFI Checks:\n\u0026ldquo;This pass instruments indirect function calls to ensure that control-flow integrity is preserved at run-time.\u0026rdquo;\nClear Check Attributes: \n\u0026ldquo;This file implements a pass to remove special attributes from the run-time checking functions.\u0026rdquo;\nComplete Checks: \n\u0026ldquo;This pass instruments loads and stores with run-time checks to ensure memory safety.\u0026rdquo;\nGEP Checks:\n\u0026ldquo;This pass instruments GEPs1 with run-time checks to ensure safe array and structure indexing.\u0026rdquo;\nInvalid Free Checks: \n\u0026ldquo;This pass instruments calls to deallocators to ensure memory safety.\u0026rdquo;\nRegister Bounds Passes:\n\u0026ldquo;Various passes to register the bound information of variables into the pools\u0026rdquo;\nRegister Runtime Initializer:\n\u0026ldquo;Pass to register runtime initialization calls into user-space programs.\u0026rdquo;\nRegister Stack Object Pass:\n\u0026ldquo;This pass instruments code to register stack objects with the appropriate pool.\u0026rdquo;\nTerminiate Pass: \n\u0026ldquo;Pass to modify SAFECode\u0026rsquo;s initialization in the program to terminate on the first memory safety error.\u0026rdquo;\n GEP: GetElementPtr instruction. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/riscv/attacks/sp-analog/",
	"title": "A2: Analog Malicious Hardware",
	"tags": [],
	"description": "",
	"content": "Reference1\n\u0026ldquo;In the open spaces of an already placed and routed design, we contruct a circuit that use capacitors to siphon charge from nearby wires as they transition between digital values.\u0026rdquo;\n\u0026ldquo;When the capacitors fully charge, they deploy an attack that forces a victim flip-flop to a desired value, e.g the privileged bit for the processor.\u0026rdquo;\n\u0026ldquo;We replace the hundreds of gates required by conventional counter-based triggers implemented using digital logic with analog components \u0026ndash; a capacitor and a few transistors wrapped-up in a single gate.\u0026rdquo;\n A2: Analog Malicious Hardware, SP, 2016. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/riscv/attacks/",
	"title": "Attacks",
	"tags": [],
	"description": "",
	"content": "Reference1\n A2: Analog Malicious Hardware  Reference1 \u0026ldquo;In the open spaces of an already placed and routed design, we contruct a circuit that use capacitors to siphon charge from nearby wires as they transition between digital values.\u0026rdquo; \u0026ldquo;When the capacitors fully charge, they deploy an attack that forces a victim flip-flop to a desired value, e.g the privileged bit for the processor.\u0026rdquo; \u0026ldquo;We replace the hundreds of gates required by conventional counter-based triggers implemented using digital logic with analog components \u0026ndash; a capacitor and a few transistors wrapped-up in a single gate.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/cets/runtime/",
	"title": "Runtime Library of CETS",
	"tags": [],
	"description": "",
	"content": "file: safecode/runtime/SoftBoundRuntime/softboundcets.c and .h:\ntypedef struct { void* base; void* bound; size_t key; void* lock; } __softboundcets_trie_entry_t; A shadow stack:\n void __softboundcets_allocate_shadow_stack_space(int num_pointer_args) void* __softboundcets_load_base_shadow_stack(int arg_no) void* __softboundcets_load_bound_shadow_stack(int arg_no) key, lock\u0026hellip; store base/bound/key/lock __softboundcets_stack_memory_allocation(void** ptr_lock, size_t* ptr_key)   Bound check:\n void __softboundcets_spatial_call_dereference_check(void* base, void* bound, void* ptr) void __softboundcets_spatial_load_dereference_check(void *base, void *bound, void *ptr, size_t size_of_type) void __softboundcets_spatial_store_dereference_check(void *base, void *bound, void *ptr, size_t size_of_type) void __softboundcets_memcopy_check_i64(char* ptr, char* ptr_base, char* ptr_bound, size_t size) void __softboundcets_memcopy_check(char* dest, char* dest_base, char* dest_bound, char* src, char* src_base, char* src_bound, size_t size) void __softboundcets_temporal_load_dereference_check(void* pointer_lock, size_t key,void* base, void* bound) void __softboundcets_temporal_store_dereference_check(void* pointer_lock, size_t key,void* base, void* bound)   Metadata load/store:\n void __softboundcets_metadata_store(void* addr_of_ptr, void* base, void* bound, size_t key, void* lock) void __softboundcets_metadata_load(void* addr_of_ptr, void** base, void** bound, size_t* key, void** lock)  Memory alloca/dealloc:\n void __softboundcets_memory_deallocation(void* ptr_lock, size_t ptr_key)\n void* __softboundcets_allocate_lock_location()\n void __softboundcets_allocation_secondary_trie_allocate_range(void* initial_ptr, size_t size)\n void __softboundcets_allocation_secondary_trie_allocate(void* addr_of_ptr)\n void __softboundcets_memory_allocation(void* ptr, void** ptr_lock, size_t* ptr_key)\n void* __softboundcets_get_global_lock()\n void __softboundcets_add_to_free_map(size_t ptr_key, void* ptr)\n void __softboundcets_check_remove_from_free_map(size_t ptr_key, void* ptr)\nvoid * __softboundcets_safe_mmap(void* addr, size_t length, int prot, int flags, int fd, off_t offset){ return mmap(addr, length, prot, flags, fd, offset); } void* __softboundcets_safe_calloc(size_t nmemb, size_t size){ return calloc(nmemb, size); } void* __softboundcets_safe_malloc(size_t size){ return malloc(size); } void __softboundcets_safe_free(void* ptr){ free(ptr); }  file: safecode/runtime/SoftBoundRuntime/softboundcets-wrappers.c:\n__WEAK_INLINE void __softboundcets_read_shadow_stack_metadata_store(char** endptr, int arg_num)\n__WEAK_INLINE void __softboundcets_propagate_metadata_shadow_stack_from(int from_argnum, int to_argnum)\n__WEAK_INLINE void __softboundcets_store_null_return_metadata()\n__WEAK_INLINE void __softboundcets_store_return_metadata(void* base, void* bound, size_t key, void* lock\nsystem wrappers\nmain library wrappers\nmath library wrappers\nfile library wrappers\nunistd.h wrappers\nstring related wrappers\ntime related library wrappers\n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/hwsw/securehwsw/",
	"title": "Secure HW/SW Interface",
	"tags": [],
	"description": "",
	"content": " Motivation OS memory safety research Memory safety for OS code:\n OS designs based on safe languages; Compiler techniques such as SVA-M to enforce memory safety for commodity OSs in unsafe languages; Instrumentation techniques to isolate a kernel from extensions such as device drivers;  Singularity, SPIN, JX, JavaOS, SafeDrive, and SVA-M are examples of system that enforce a safe execution environment.\nCommon asumptions of OS memory safety research Unfortunately, all these memory safety techniques (except Verve, which has very limited I/O and no MMU support) make assumptions that are routinely violated by low-level initeractions between an OS kernel and hardware, even if implemented in safe programming language. Such assumptions include:\n A static, one-to-one mapping between virtual and physical memory; An idealized processor whose state is modified only via visible program instructions; I/O operations that cannot overwrite standard memory object except input I/O targets; A protected stack modifiable only via load/store operations to local variables.  Possible attacks A buggy kernel operation might overwrite program state while it is off-processor, and that state might later be swapped in between the definition and the use of the pointer value;\nA buggy MMU mapping might remap the underlying physical memory to a different virtual page holding data of a different type;\nA buggy I/O operation might bring corrupt pointer values into memory.\nReference 1\n Memory Safety for Low-Level Software/Hardware Interactions, Usenix Security, 2009. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/gnu-hurd/",
	"title": "Gnu Hurd",
	"tags": [],
	"description": "",
	"content": "GNU Hurd\nReference1\n reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/freebsd/",
	"title": "Freebsd",
	"tags": [],
	"description": "",
	"content": "Reference1\n reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/minix3/",
	"title": "Minix 3",
	"tags": [],
	"description": "",
	"content": "Minix\nMinix 3\nReference1\n reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/kernel-cap/",
	"title": "Kernel Cap",
	"tags": [],
	"description": "",
	"content": "2015 programmer\u0026rsquo;s guide:\n Kernel itself makes only minor use of capabilities; Kernel is not currently compiled with a capability-aware compiler; kernel threads do not have full capability-register-file state in their own PCBs.  EG: A hardcoded kernel capability1:\n/* * Definition for a highly privileged kernel capability able to name the * entire address space, and suitable to derive all other kernel-related * capabilities from, including sealing capabilities. */ #define\tCHERI_CAP_KERN_PERMS\t\\ (CHERI_PERMS_SWALL | CHERI_PERMS_HWALL) #define\tCHERI_CAP_KERN_BASE\t0x0 #define\tCHERI_CAP_KERN_LENGTH\t0xffffffffffffffff #define\tCHERI_CAP_KERN_OFFSET\t0x0  Grep Cap  Reference: 1 reference ↩   cherireg.h ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/intro/motivation/",
	"title": "Motivations",
	"tags": [],
	"description": "",
	"content": " Memory safety bugs 940, Rigorous, p4:\nMicrosoft estimates that 70% of the vulnerabilities they have patched between 2006 and 2018 are caused by memory safety issues[2].\nMITRE considers classic buffer overflows as the third most dangerous software error[3].\n [1] L. Szekeres, M. Payer, T. Wei, and D. Song, “Sok: Eternal war in memory,” in 2013 IEEE Symposium on Security and Privacy. IEEE, 2013, pp. 48–62. [2] M. Miller, “Trends, challenge, and shifts in software vulnerability mitigation,” https://github.com/Microsoft/MSRC-Security-Research/tree/master/presentations/2019_02_BlueHatIL, Februari 2019, microsoft Security Response Center. [3] B. Martin, M. Brown, A. Paller, D. Kirby, and S. Christey, “2011 CWE/SANS top 25 most dangerous software errors,” Common Weakness Enumeration, 2011.  Ubiquitous computing changes threat models ISA v5, p14:\n Dramatic changes in threat models, resulting from ubiquitous connectivity and pervasive uses of computer technology in many diverse and widely used applications such as wireless mobile devices, automobiles, and critical infrastructure.\n Endless \u0026ldquo;patch and pray\u0026rdquo; calls for architectural \u0026lsquo;immunity\u0026rsquo;  An extended \u0026ldquo;arm race\u0026rdquo; of inevitable vulnerabilities and novel new attack mechanisms has led to a cycle of \u0026ldquo;patch and pray\u0026rdquo;. \u0026hellip; a strong need for underlying architectures that offer stronger inherent immunity to attackers, minimize gained attack surfaces, and increase the work factor for attackers.\n Mature tool-chains bring new opportunities  New opportunities for research into (and possible revisions of) hardware-software interfaces, brought about by programmable hardware (especially FPGA soft cores) and complete open-source software stacks such as FreeBSD and LLVM.\n Similar hardware innovation already applied for performance/power purpose  An increasing trend towards exposing inherent hardware parallelism through virtual machines and explicit software multi-programming, and an increasing awareness of information flow for reasons of power and performance that may align well with the requirements of security. what is this mean, examples?\n PL advances brings new opportunity  Emerging advances in programming languages, such as the ability to map language structures into protection parameters to more easily express and implement various policies. what is this? examples?\n \u0026ndash;\u0026gt; Map language structures into protectin parameters?\nDiverse hardware architectures flourished  Reaching the tail end of a \u0026ldquo;compatibility at all costs\u0026rdquo; trend in CPU design, due to proximity to physical limits on clock rates and trends towards heterogeneous and distributed computing. While \u0026ldquo;Wintel\u0026rdquo; remains entrenched on the desktop, mobile systems \u0026ndash; such as phones and tablet PCs, as well as appliances and embedded devices \u0026ndash; are much more divers, running on a wide variety of instruction set architectures (especially ARM and MIPS).\n Various new OSes proved success of new security models  Likewise, new diversity in operating systems has arisen, in which commercial products such as Apple\u0026rsquo;s iOS and Google\u0026rsquo;s Android extend open-source systems such as FreeBSD, Mach, and Linux. These new platforms abandon many traditional constraints, requiring that rewritten applications conform to new security models, programming languages, hardware architectures, and user-input modalities.\n Capsicum is a success for hybrid capability system  Development of hybrid capability-system models, such as Capsicum, that integrate capability-system design tenets into current operating-system and language designs. With CHERI, we are transposing this design philosophy into the instruction-set architecture. Hybrid design is a key differentiator from prior capability-system processor designs that have typically required ground-up software-architecture redesign and reimplementation.\n Modern era allows deep hw/sw stack changes  Significant changes in the combination of hardware, software, and formal methods to enhance assurance now make possible the development of trustworthy system architectures that previously were simply too far ahead of their times.\n Client-server model evolved to similar complex client \u0026amp; server Client-server and cloud computing:\n even thin clients are not thin in most practical senses: as with client-server computer systems, they built from commodity operating system kernels, hundreds of user-space libraries, window servers, language runtime environments, and web browsers, which themselves include scripting language interpreters, virtual machines, and rendering engines.\nBoth server and embedded systems likewise depends on complex (and quite similar) software stacks. All require confluence of competing interests, representing multiple site, tasks, and end users in unified computing environments.\n Most software stacks have TCB in C  Whereas higher-layer applications are able to run on top of type-safe or constrained execution environments, such as JavaScript interpreters, lower layers of the system must provide the link to actual execution on hardware. As a result, almost all such systems are written in the C programming language; collectively, this Trusted Computing Base (TCB) consists of many tens of millions of lines of trusted (but not trustworthy) C and C++ code. Coarse hardware, OS, and language security models mean that much of this code is security sensitive: a single flaw, such as an errant NULL pointer dereference in the kernel, can expose all rights held by users of a system to an attacker or to malware.\n Inevitable software vulnerabilities calls for privilege separation  Even if low-level escalation techniques (such as arbitrary code injection and code reuse attacks) could be prevented, logical erros and supply-chain attacks will necessarily persist.\n.. compartmentalizing applications into components executed in isolated sandboxes can mitigate exploited vulnerabilities (sometimes referred to as privilege separation).\n Compartmentalization problem calls for hardware support Microkernel is abondened due to its limits applicability  Historically, compartmentalization of TCB components such as operating system kernels and central system services has caused significant difficulty for software developers \u0026ndash; which limits its applicability for large-scale, real-world applications, and leads to the abandonment of promissing research such as 1990s microkernel projects.\n OpenSSH, Chromium, Capsicum success but has coarse grain  A recent resurgence of compartmentalization, applied in userspace to applications such as OpenSSH and Chromium, and more recently in our own Capsicum project, has been motivated by a critical security need; however, it has seen success only at very coarse separation granularity due to the challenges involved.\n Performance is sacrificed Domain switching results in TLB overflowing, especially with large page table sizes.\n The TLB footprint of fine-grained, compartmentalized software increases with the product of in-flight security domains and objects due to TLB aliasing.\n Programmability is sacrificed Intra address space communication: pass a pointer; Inter address space communication:\n message passing, distributed programming model RPC systems, not suitable for TCB  Bittau, sthreads, an OS primitive that tightly couples UNIX processes via shared memory associated with data types \u0026ndash; a promising separation approach constrained by the realities of current CPU design.   Security is sacrificed, finally "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/linux/execve/",
	"title": "execve",
	"tags": [],
	"description": "",
	"content": " References:\n[1] How programs get run. LWN.net, 2015. [link1, link2]\nLoad ELF binary In fs/binfmt_elf.c: load_elf_binary(): examining ELF header.\nflush_old_exec(): clears up state in kernel that refers to the previous program.\nsetup_new_exec(): set up kernel\u0026rsquo;s internal state for the new program. flush_signal_handlers() sets up the signal handlers for the new program. do_close_on_exec() closes all of the old program\u0026rsquo;s file descriptors.\nSet up the virtual memory of the new program. The highest address for the stack is moved downward by a random offset. create_elf_tables()\n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/dsa/",
	"title": "Data Structure Analysis",
	"tags": [],
	"description": "",
	"content": " Q \u0026amp; A  How many incomplete nodes during evaluation?  Ans: Not much, but most program exists. Including the collapsed nodes, ranging from 1.2% ~ 88.5%. See evaluation: type inference result    Basics Flow sensitive1: takes into account the order of statements in a program.\nPath Sensitive: takes into account the branch conditions.\nContext Sensitive: names objects by entire acyclic call paths. A callee will return to its single call site instead of all possible call sites.\nDisjoint Data Structure Analysis A pointer analysis algorithm\n Identify disjoint instance of pointer-based data structure \u0026amp; their lifetimes. Identified by computing a point-to-graph: Data Structure Graph.  Data Structure Graph DS Graph is a field-sensitive representation of the point-to information. It is a directed multi-graph, where:\n one graph for each function. Except where all functions share a common graph.\n different nodes represent distinct memory objects.\n  One DS node = \u0026lt; $ \\tau $, F, M, A, G \u0026gt;:\n $ \\tau $: program defined type, or $\\perp$ for unknown type; F: an array of fields; M: memory class, $\\subseteq$ { Heap, Stack, Global, Unknown}; A: true if nodes includes an array; G: set of globals in the struct if G$\\in$ M.  One DS edge: \u0026lt; s, $f_s$, t, $f_t$ \u0026gt;:\n s, t: Two nodes; $f_s$, $f_t$: fields of s, t.  Full context sensitive It names heap objects by entire acyclic call paths (which we refer to as \u0026ldquo;full heap cloning\u0026rdquo;), which allows distinguishing heap object allocated/destroyed by common function calls (eg. lib functions).\nUnification-style analysis A pointer field at a node has only one outgoing DS edge, i.e. all targets of the pointer are merged into a single node.\nAnalysis is flow insensitive: does not take into account the order of statements.\nCollapsed Nodes Collapsed nodes are field-insensitive, represent objects that has incompatible types, tagged as \u0026ldquo;unknown type\u0026rdquo;.\n(2005LattnerPhD2) If operations using incompatible types are found, the type for the node is treated as unsized array of bytes (T(n)=void *), and the fields and edges of the node are \u0026ldquo;collapsed\u0026rdquo; into a single field with at most one outgoing edge. The node is marked as \u0026lsquo;O\u0026rsquo; meaning cOllapsed. If a node has been collapsed (i.e., O $\\in$ flags_(n)), it is always treated in this safe, but field-insensitive, manner.\nAvoid Exponential Behavior Full context-sensitive cloning is susceptible to exponential behavior in theory, however, the unification approach used effectively eliminates this in two ways:\n unifications inherently merges together most of the nodes created throught the cloning process. In case of analysis failure, when the analysis must assume that many nodes must all point to each other, unification based approcaches aggressively merge these nodes, shrinking the representation (e.g. 253.perlbmk, which is largely not type-safe).  Construction Algorithm DS graphs are created and refined in a three step process.\n First, construct a DS graph for each function in the program, using only intraprocedural information (a \u0026ldquo;local\u0026rdquo; graph); Second, a \u0026ldquo;Bottom-Up\u0026rdquo; analysis phase is used to eliminate incomplete information due to callees in a function, by incorporating information from callee graphs into the caller\u0026rsquo;s graph (creating a \u0026ldquo;BU\u0026rdquo; graph). Finally, a \u0026ldquo;Top-Down\u0026rdquo; phase eliminates incomplete information due to incoming arguments by merging caller graphs into callees (creating a \u0026ldquo;TD\u0026rdquo; graph).  The BU and TD phase operate on the \u0026ldquo;known\u0026rdquo; Strongly Connected Components (SCCs) in the call graph.\nA node must not be marked complete until it is known that all callers and callees potentially affecting that node have been incorporated into the graph.\nBottom up (From 2005Embed:) The \u0026ldquo;complete bottom-up\u0026rdquo; DS graph for a function incorporates the effects of all functions reachable from the current function (i.e., immediate callees and their callees and so on), including functions called via function pointers3.\nTop down (From 2005Embed:) A final, \u0026ldquo;top-down\u0026rdquo; DS graph of a function incorporates the effects of both the callers as well as the callees of a function, so that it captures the full set of memory objects and aliasing relationships from all possible call sites (as well as those due to side effects of callee functions).\nType inference No type inference (superseded by below): (From 2005LattnerPhD) DSA extracts LLVM types for a subset of memory objects in the program. It does this by using declared types in the LLVM code as speculative type information, and checks conservatively whether memory accesses to an object are consistent with those declared types, without having to perform type-inference.\nInference based on uses:\n(From 2005-TR-SAFECODE) DSA attempts to compute type information for every \u0026ldquo;points-to set\u0026rdquo; in the program by inferring the intended type based on the uses of pointers and not based on the type declarations or cast operations in the program. The \u0026ldquo;uses\u0026rdquo; include:\n indexing operations (\u0026amp;(x-\u0026gt;Fld) and \u0026amp;E[E]) loads stores indirect calls  By ignoring casts and considering only actual uses, DSA is able to infer heap objects allocated via the malloc operation in C, which is untyped: the (usual) cast of the returned pointer value is ignored, but any uses of the pointer are correctly considered.\nExperiments: DSA can infer type information for the targets of 70% of load/store operations in most C programs (on average), and over 90% in many programs.\nConsistent Type: If all pointers to a points-to set are used consitently as one type $\\tau *$ (or as the appropriate type for a field within $\\tau$), then DSA infers the type of all objects in that set to be $\\tau$.\nInconsistent Type: If type of pointers are not consistent in the points-to set, then DSA marks the type of the object to be \u0026ldquo;Unknown\u0026rdquo;.\nImplementation Complete DSA in LLVM, and analysis is performed entirely at link-time, using stubs for standard C library functions to reflect their behavior2.\nEvaluation Benchmark: SPEC CPU 95, SPEC CPU 2000, and unbundled programs (Povray 3.1, NAMD, boxed-sim and fpgrowth).\n How fast and how much resource required?\n How much type information is DSA able to infer?\n How precise is DSA for alias analysis?\n  Memory Instructions4 as a metric for benchmark size in addition to LoC.\nmax |SCC|: the size of the largest SCC in the call graph for the program.\nType inference result The following graph shows the type inference result:\nThe first two columns, Benchmark and Mem Instrs list the name and total number of memory instructions (including address arithmetic, calls, etc)\nSafe Access: the number of load/store instructions that target non-collapsed complete nodes.\nUnsafe Access: the number of load/store instructions which target either collapsed or incomplete nodes.\nApplication Automatic Pool Allocation Pointer Compression  Sensitivities of Data Flow Analysis, wiki. ↩ Macroscopic Data Structure Analysis and Optimization. Chris Lattner Ph.D. Thesis. 2005. ↩ Automatic pool allocation: Improving performance by controlling data structure layout in the heap. PLDI, 2005. ↩ Memory instructions are load, store, malloc, alloca, and getelementptr instructions. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/basics/complexity/halting/",
	"title": "Undecidability of Program Correctness",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/box-sgx/",
	"title": "Intel SGX",
	"tags": [],
	"description": "",
	"content": " Reference1 2\nInteractions Reference: Overview of Intel SGX, part2\nECALL: Enclave Call. Application invokes a pre-defined function inside the enclave.\n can pass input parameters and pointers to shared memory within the application.  OCALL: Outside Call. Enclave invokes a pre-defined function in the application.\n An OCALL cannot share enclave memory with the application; It must copy the parameters into the application memory before the OCALL;  AEX: Asynchronous Exit. Exit an enclave because of an interruption or an exception.\n Transfer control from the enclave to the application from arbitrary points inside the enclave.  Architectural Enclaves References: Communication between Architectural and Application Enclaves\nArchitectural Enclaves:\n Launch Enclave (LE)  Receives request from other enclaves wishing to launch on the platform; Examines requesting enclave\u0026rsquo;s signature and identity, to verify whether the requesting enclave is valid or not; Generates the EINITTOKEN from its private Launch Key; Assigns EINITTOKEN to the requesting enclaves;  Provisioning Enclave (PvE)  Retrieves the Attestation Key from Intel Provisioning Service; Has to use the certificate provided by Provisioning Certificate Enclave below;  Provisioning Certificate Enclave (PcE)  Is responsible for signing the processor certificate; Signs the certificate using its private Provisioning Key;  Quoting Enclave (QE)  Is responsible for providing trust in the enclave identity and its execution environment during remote attestation process; Uses the Attestation Key offered by Provisioning Enclave; Turns a REPORT (locally verifiable) into a QUOTE (remotely verifiable)  Platform Service Enclaves (PSE)  Are responsible for offering other enclaves various trusted services using Management Engine; Monotonic counters; Truste time;     Overview of Intel SGX, part1 ↩ Overview of Intel SGX, part2 ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/security-pol/",
	"title": "Security Policies",
	"tags": [],
	"description": "",
	"content": " PORTIA: Of a strange nature is the suit you follow;\nYet in such rule that the Venetian law\nCannot impugn you as you do proceed.\n[To Antonio.] You stand within his danger, do you not? \u0026ndash; The Merchant of Venice, IV, i, 177\u0026ndash;180\nBook: Computer Security, Art and Science, By Matt Bishop, 2nd edition.\n A security policy defines \u0026ldquo;secure\u0026rdquo; for a system or a set of systems.\nA security policy is a statement that partitions the states of the system into a set of authorized, or secure, states and a set of unauthorized, or nonsecure, states.\n Confidentiality Policies A confidentiality policy, also called an information flow policy, prevents unauthorized disclosure of information. Unauthorized alteration of information is secondary. For example, the navy must keep confidential the date on which a troop ship will sail. If the date is changed, the redundancy in the systems and paperwork should catch that change. But if the enemy knows the data of sailing, the ship could be sunk.\nBell-LaPadula Model\n Bell LaPadula  Reference: Computer Security, Art and Science/ By Matt Bishop, 2nd edition. The simplest type of confidentiality classification is a set of security clearance, or security classification arranged in a linear (total) ordering. For example, the set below is {TS, S, C, UC}: ------------------------------------- TOP SECRET (TS) Tamara, Thomas Personal Files SECRET (S) Sally, Samuel Electronic Mail Files CONFIDENTIAL (C) Claire, Clarence Activity Log Files UNCLASSIFIED (UC) Ulaley, Ursula Telephone List Files -------------------------------------- The goal of Bell-LaPadula model:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/2003nogc/",
	"title": "Memory Safety Without Runtime Checks or Garbage Collection",
	"tags": [],
	"description": "",
	"content": " Reference1\nChallenge: dangling pointers Proving statically that a general C program (for example) never dereferences a freed pointer (the \u0026ldquo;dangling pointer\u0026rdquo; problem) is undecidable.\nRegion-based memory management, however, has been used to guaranttee the safety of pointer-based accesses to region data without garbage collection, but with limitations: 1) manual effort to convert program to use regions; 2) many solutions disallow explicit deallocation.\nAutomatic regions inference algorithms have been developed to solve limitation completely or partially, such as in ML, or Cyclone. But these languages disallow explicit deallocation.\nIn this work, we use our fully automatic region inference algorithm called Automatic Pool Allocation that works for C with explict malloc and free. The transformation solves both the limitations above.\nUnfortunately, allowing individual object deallocation means that the transformation does not ensure memory safety.\nRestriction Rules for C  T1. Strong type: all variables, assignments and expressions (as in 2002); T2. Cast to a pointer from other types are disallowed; certaion pointer to pointer casts of two compatible targets are allowed (2002+);\n T3. Union can only contain types that can be cast to each other (as in 2002).\n  Rules for pointer safety:\n P1. Every local pointer variable must be initialized before being referenced (as in 2002); P2. Any individual type should be no larger than the size of the reserved address range (as in 2002); P3. The address of stack location cannot be stored in a heap-allocated object or a global variable, and cannot be returned from a function (new from 2002);  Heap safety by pool allocation  Memory Safety Without Runtime Checks or Garbage Collection. LCTES, 2003. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/poolalloc/",
	"title": "Automatic Pool Allocation",
	"tags": [],
	"description": "",
	"content": " Reading List:\n[1] Automatic pool allocation: Improving performance by controlling data structure layout in the heap. PLDI, 2005.\n[2] Linear Regions Are All You Need. European Symposium on Programming, 2006 paper\nRegion-based memory management Tofte-Talpin Data are allocated within lexically-scoped regions and all of the objects in a region are deallocated at the end of the region\u0026rsquo;s scope.\n restrictions on when data can be effectively reclaimed memory leaks  Cyclone\u0026rsquo;s dynamic regions and unique pointers Pool Allocation The idea of instrumentation How to determine a pool for which data structures Applicaions SAFECode Performance optimization "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/",
	"title": "CHERI",
	"tags": [],
	"description": "",
	"content": " Capability Hardware Enhanced RISC Instructions\nTop wonderings  Is ring-based privilege separation removable?\n SFI? How to remove compiler from trusted computing base?  Is the process model (with context switch consequence) a must for future applications, while the 64-bit address space is large enough to hold many applications?\n If we don\u0026rsquo;t have process model, all application sharing a single address space, how does the operating system do scheduling? How to run applications on multi-cores?\n Singularity, Midori, Verve  Achieve a sound and complete pointer analysis by constraining, and/or extending the Arch, PL, and OS designs? For the purpose of formal verification of the entire software stack.\n What CHERI cannot protect?\n most tasks in kernel\u0026rsquo;s control: memory management via page tables process create, capability initialization domain transition context switches  Given the theoretical secure isolation of sandboxes in CHERI, an interesting problem would be whether a cross-domain transition to/from trampoline sandbox is more efficient than the transition to/from kernel. And, how many sandboxes a single address space can have in scale. Or how to design sandbox interaction topology to avoid the bottleneck scenario in the traditional kernel/user architecture where a kernel is the bottleneck.\n a secure \u0026lsquo;trampoline\u0026rsquo; domain for domain transition. A sandbox that mimics the kernel to maintain a trusted stack that is not visible to all other domains outside.\n a \u0026lsquo;distributed\u0026rsquo; trampoline sandbox framework for domain transition? Each time a domain invokes another domain, a new \u0026lsquo;trampoline\u0026rsquo; domain is created dynamically with its own protected stack and ensures the return address will not be corrupted.\n  Can we do sound pointer analysis on C program using CHERI LLVM compiler?\n why pointer analysis is hard   ToDones  Cheri rigorous engineering\n Cheri Basics\n LLVM purecap hacking:\n the pointer discovery and manipulation pass: to enable purecap with base bound cover entire space; find the pointer size set pass; but not size reasoning path; to set base bounds for ones with annotations; find the annotation pass compile kernel with it  A toy example in kernel without libcheri, but mostly in assembly.\n  Cheri Usage:\n hybrid kernel implementation in CheriABI  where is the capabilities?   CheriBSD\n booting: pmap booting: how does the tagged memory got partitioned? system calls, context switch, thread create  CHERI itself:\n How does CHERI support multi-threading?  LLM: No support to multi-threading in Cheri\u0026rsquo;s sandboxing model, but can be added in the future. see comments in libcheri_ccall_trampoline.S.  What is the mechanism of capability revocation in CHERI? Or use-after-free, capability changes/updates to all pointers pointing to a single object, etc..  LLM: see their MICRO 2019 paper on temporal safety   Bluespec System Verilog source code:\n Where is the CP2 defined? See beri/cheri source code Where is the cload/cstore instruction being checked against the given capability? See beri/cheri source code How to change the semantics of cload/cstore? See beri/cheri source code  Sealing\n use libcheri to do encapsulation as in given examples; read libcheri implementation; A toy example in userspace using libcheri to encapsulate a portion of a data structure, with user-defined class types (as in system class types). (done)   Quotes  \u0026hellip; adoption of compartmentalization has been limited by a conflation of hardware primitives for virtual addressing and separation, leading to inherent performance and programmability problems when implementing fine-grained separationi.\nSpecifically, we seek to decouple the virtualization from separation to avoid scalability problems imposed by translation look-asside buffer (TLB)-based Memory Management Units (MMUs), which impose a very high performance penalty as the number of protectino domains increases, as well as complicating the writing of compartmentalized software.\nThe CHERI ISA provides a sound and formally based architectural foundation for the principled development of highly trustworthy systems.\n More  Planting your cheri tree advice\n What’s the smallest variety of CHERI?\n  Contents  Introduction  CHERI Background Material cite: CHERI Background @RISC-V SIG CHERI CHERI Talks/Videos Motivation for CHERI YouTube video (3-minutes) HotChips 2022 - Talk on Morello (CHERI on ARM): YouTube Slides CHERI Session at RISC-V Week in Paris Slides Industry Announcements about CHERI ARM Morello (CHERI on ARM) Web site Microsoft announce CHERI-RSIC-V embedded core Blog Microsoft security analysis of CHERI Report PDF on GitHub Background Research See the Cambridge CHERI project Web site An introduction to CHERI Report CHERI ISA reference Report More informative introductions:\n Cheri C Model  An implementation of C abstract machine that can run legacy C code with Strong memory protection guarantees.\n Cheri Temporal  More [2019 Micro] CHERIvoke: Characterising Pointer Revocation using CHERI Capabilities for Temporal Memory Safety. References: CHERIvoke: Characterising Pointer Revocation using CHERI Capabilities for Temporal Memory Safety. pdf. MICRO, 2019. Overview A new allocator with quanrantine buffer that stores \u0026ldquo;to-be-revoked\u0026rdquo; segments. Quanrantine Buffer (delayed sweeping): a list of object addresses that are freed but not safe to be reused yet. These addresses are kept in a cached list of addresses of freed object; addresses in this buffer cannot be reused (not really freed yet); only do sweep when the buffer is full; and address is available for reuse after sweep (here have the real free); sweep all memory that could contain references to the heap; invalidate any capability references that points to any region in the quanrantine buffer; sweep using a shadow map to store revocation metadata (1 bit for every 16-byte granule of the heap; 1\u0026frasl;128); Revocation Shadow Map: bit-map for quarantined objects (fast look-up): bit-mapped tags for all heap memory; 1-bit for 16 byte of heap; every allocation in quanrantine buffer is \u0026lsquo;painted\u0026rsquo; in this map, indicating a to-be-revoked region in the heap; To Sweep: scan all memory for references for each reference, perform a look-up at this map to determine whether to revoke the reference (capability/pointer); use the base of the reference to detect if it is pointing into a revoked object; new allocator dlmalloc_cherivoke to replace dlmalloc.\n Complete Spatial Safety for C and C\u0026#43;\u0026#43; using CHERI capabilities  References: Complete spatial safety for C and C++ using CHERI capabilities Evaluation 1 qsort() microbenchmark: The actual comparison of the integers is performed in a different DSO (Dynamic shared object). MiBench. ####　CHERISH Evaluation Cheri sub-object Hardening. MiBench Real issues found in CheriBSD. buffer overflows in jemalloc and libarchive out-of-bounds 2D array write in awk buffer overflow in cheritest layout incompatibility of _Unwind_Exception.\n Cheri Domain  Reference123. Questions Why do we need domain? Globals Across Domains Globals are accessible to all domains, no distinguish. This means if some data is passed from Domain A to Domain B, an unrelated domain, say Domain C, will also have a chance to know the data. Untagged Data Across Domains The untagged data in the argument list is not checked when do a CCall. Is it possible to leak information?\n CheriABI  Todos: what is the 1% of the C userspace not adapted to CHERI? Why? Lele: idiom violations/undefined behaviors; need manual change to be adapted. How to prevent confused-deputy attacks via the kernel? How cheri generate dynamically linked programs? What is ABI\u0026rsquo;s relation with Compilers, OS, and architectures? What is ABI? Motivation/Problems Problem of C C language is not safe. memory errors; injecting, manipulating, or abusing pointers in the run-time environment; explicit: declared data/code pointers; implicit: generated code to implement global variables (PIC, GOT, PLT) or return addresses; by the runtime to implement cross-library control flow.\n Cheri Concentrate  Reference: CHERI concentrate [ISAv9-draft, Chapter 3.5.4, CHERI Concentrate Compression]() Overview Cheri Concentrate(CC) is a compression scheme applied to CHERI. CC achieves the best published region encoding efficiency, solves important pipeline problems caused by a decompressed register file. Problem The object bounds and permission information encoded in capability pointers cause the largest overhead among all overheads. Thus need a new encoding scheme to reduce overhead, i.e a method for compression and decompression.\n CheriBSD  References: [1] CHERI ISA v5 (2016), v6(2017), v7 (2019). [2] CheriBSD, github, link. 2016 v5: Initial in-kernel privilege limitation 2017 v6: Mature kernel privilege limitation [3] CHERI programmer\u0026rsquo;s guide, UCAM-CL-TR-877, 2015. Questions/Proposals Kernel has no capability state during context switch: kernel state How does CheriBSD do memory partition for physical memory tags? In details Kernel Change List Kernel Capability\n Cheri FreeRTOS   Reference 1 2 Makefile change FreeRTOS/Demo/RISC-V_Galois_P1/Makefile Makefile fix for Clang/LLVM tools Initial Update Github: CHERI-FreeRTOS ↩ Using FreeRTOS on RISC-V Microcontrollers ↩  Cheri RTOS  CHERI-aware real-time operating system, CheriRTOS. Fine-grained memory protection Secure centralized heap management; Dynamic task loading; Low-latency and direct domain crossing; Distributed trusted stacks to protect return contexts; Secure peripherals. Current limitations MPU limitation MPU is a kernel space device, each register takes multiple cycles to configure; usually configured only globally at system start-up, which makes per-task memory access control difficult; user space cannot leverage it for intra-task protection; MPU entries are limited.\n Cheri Hypervisor  Reference 1 Google Hafnium. Project Oak reference ↩  Cheri Cloud  Reference 1 PCIe to SATA breakout board CHERI Cloud: Bluehive ↩  Cheri Formal  References: [1] CHERI ISA v5 (2016). Existing formal methodology applied to software security has significant problems with multi-address-space security models; formal approaches have relied on the usefullness of addresses(pointers) as unique names for objects. Whereas this weakness in formal methods is a significant problem for traditional CPU designs, which offser security primarily through rings and address-space translation, CHERI\u0026rsquo;s capability model is scoped within address spaces. This offers the possibility of applying existing software proof methodology in the context of hardware isolation (and other related properties) in a manner that was previously infeasible.\n Cheri Link    Cheri ISA Semantic  References: [1] ISA Semantics for ARMv8-A, RISC-V, and CHERI-MIPS. POPL, 2019 [2] CHERI ISA v8, 2020. Basics Architecture specifications define the fundamental interface between hardware and software: the envelope of allowd behaviour for processor implementations, and the basic assumtions for software development and verification. In practise, they are typically prose and pseudocode documents, not rigorous or executable artifacts, leaving software and verification on shaky ground. Sail: an ISA semantic language with dependent type system.\n Cheri Tagged Memory  Q \u0026amp; A How two layers tag cache work? How to update the nodes in the layers? How is the tag being set? all caps being originated from one cap: the cap covers entire address space. Each new pointer is created via explict capability. Local pointers Pointers to Global Pointers to Heap How can we propagate the tag? 2017 paper: Tags is cached with the memory they describe within the cache hierarchy.\n Cheri ELF  Reference 1 gABI Morello AArch64 ABI ELF for dynamic linking As in gABI(retrieve date 20221117) Note Section Type Name 0x0 [NT_CHERI_GLOBALS_ABI] 0x1 [NT_CHERI_TLS_ABI] 0x80000000 - 0xffffffff \u0026ndash; (Reserved for processor-specific use) NT_CHERI_GLOBALS_ABI, this note describes the ABI variant in use for accessing globals. Capabilities for globals can be obtained in the following different ways. 0x0: CHERI_GLOBALS_ABI_PCREL.\n Beri  Configure simulator ./memoryconfig (or $CHERI_MEMORY_CONFIG), describes how the hardware should be simulated. Individual simulated hardware periperals are built as shared libraries; The simulator will use dlopen() to load the libraries; Any module specific options are passed to the module at load-time. C-like syntax in the configuration file. module statement to load the simulated device module. device blocks to declare devices by declaring a class. class selects the simulated device type.\n Cheri X86  Capability Registers vs. Segments. x86 segments (CHERI ISA v7, Chapter 6) The x86 arch first added virtual memory support via relocatable and variable-sized segments. Each segment was assigned a mask of permissions. Memory references were resolved with respect to a specific segment including relocation to a base address, bounds checking, and access checks. Special segments types permitted transitions to and from different protection domains. Key differences with CHERI: x86 addresses are stored as a combination of an offset and a segment spanning two different registers.\n Cheri ARM -- Morello   References: reference More  CHERI RISC-V   References: reference More  CHERI MIPS   References: reference More  Cheri Qemu  References: [CHERI QEMU source code] QEMU Developer’s Guide Translate References: reference More CCall References: target/mips/translate.c // target/mips/translate.c mips_tr_translate_insn() --\u0026gt; gen_branch() // is_slot decode_opc() --\u0026gt; gen_compute_compact_branch() --\u0026gt; gen_branch() // bcond_compute == 0 --\u0026gt; gen_helper_copy_cap_btarget_to_pcc(cpu_env) // MIPS_HFLAG_BRCCALL/MIPS_HFLAG_BRC --\u0026gt; CHERI_HELPER_IMPL(copy_cap_btarget_to_pcc(CPUArchState *env)) More Syscall References: target/mips/translate.c mips_tr_translate_insn() --\u0026gt; decode_opc() // !(ctx-\u0026gt;hflags \u0026amp; MIPS_HFLAG_M16) --\u0026gt; decode_opc_special() --\u0026gt; generate_exception_end(ctx, EXCP_SYSCALL) generate_exception_end() -\u0026gt; generate_exception_err() // target/mips/translate.c // generate_exception_end(ctx, EXCP_SYSCALL) --\u0026gt; generate_exception_err(ctx, excp, 0) static inline void generate_exception_err(DisasContext *ctx, MipsExcp excp, int err) { TCGv_i32 texcp = tcg_const_i32(excp); TCGv_i32 terr = tcg_const_i32(err); save_cpu_state(ctx, 1); gen_helper_raise_exception_err(cpu_env, texcp, terr); tcg_temp_free_i32(terr); tcg_temp_free_i32(texcp); ctx-\u0026gt;base.\n Cheri LLVM  Reference1: Todones Passes to tracking data with attributes, such as privileged; Address space 200 data layout string (Programmer\u0026rsquo;s Guide, 2015) The data layout string is modified to define the address space for alloca instructions. It is assumed that, within a compilation unit, every alloca returns a pointer in the same address space. By default, this address space is 0, but when targeting the pure-capability ABI, it is set to 200.\n Hacking  Quick pinning CHERI source, good for both lib and kernel: __has_feature(capabilities), used in sys/, bin/, lib/, libexec/, contrib/, include/, stand/, and *.h, *.c; defined(__CHERI__), used in sys/, lib/, contrib/, and *.h, *.c, *.S; Cheri Simulation: Spike: https://github.com/CTSRD-CHERI/TestRIG Cross Reference 1 Cross-compiling for CheriBSD In order to cross-compile projects such as NGINX or PostgreSQL for CheriBSD you will first need a full SDK: cheribuild.py cheribsd-sdk. The you can then run cheribuild.\n Security Analysis of CHERI  References: Security Analysis of CHERI ISA, 2021. Windows 8 Heap Internals, BlackHat, USA, 2012. Software Defense: Mitigating Heap Corruption Vulnerabilities An Armful of CHERIs, Security Research \u0026amp; Defense, By Saar Amar, January 20, 2022 Type Confusion Attack Heap Attacks Software Defense: Mitigating Heap Corruption Vulnerabilities Metadata Corruption and Type Confusion Attack Assumption: the metadata is corrupted in some way.\n CFI with CHERI   References: Security Analysis of CHERI ISA CHERI ISA V5. From CHERI ISA V5: CHERI allows software privilege to be minimized at two levels of abstraction. architectural least privilege: memory capability. data pointers: against data-oriented vulnerabilities, such as buffer overflows. code pointers: support CFI by preventing corruption of code pointers/return addresses. application-level least privilege: software compartmentalization using object capabilities. More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/arm/",
	"title": "Arm",
	"tags": [],
	"description": "",
	"content": " ARM on Gem5 References:\n Extending gem5 for ARM\n Run FreeBSD on gem5 ARM\n  More  Trustzone  References: Intro to TrustZone Difference between SGX and TrustZone TrustZone Explained Dan Rosenberg, Reflections on Trusting TrustZone Normal world vs Secure World: Embeded OS vs Secure OS Context Switch normal world use SMC (secure monitor call) instruction to call secure world. ==\u0026gt; exception into the monitor mode (TrustZone kernel) Non-secure bit in Secure Configuration Register; Non-secure bit in the main memory;\n VMSA: Virtual Memory System Architecture   References: ARMv8-A Reference Manual A VMSA (in AArch64 state) provides a Memory Management Unit(MMU), that controls address translation, access permissions, and memory attribute determination and checking, for memory accesses made by the PE. More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/go/tour/",
	"title": "Tour",
	"tags": [],
	"description": "",
	"content": " A Tour of Go\nTypes basic types:\nbool; // false is zero (initial) value for bool\nstring; // \u0026ldquo;\u0026rdquo; (the empty string) is zero (initial) value for string\nint, int8, int16, int32, int64\nuint, uint8, uint16, uint32, uint64, uintptr\nbyte // alias for uint8\nrune // alias for int32, Unicode point\nfloat32, float64\ncomplex64, complex128\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/cmplx\u0026#34; ) var ( ToBe bool = false MaxInt uint64 = 1\u0026lt;\u0026lt;64 - 1 z complex128 = cmplx.Sqrt(-5 + 12i) ) Type conversion: explicit only; new_type(variable_name).\nType inference: by := or var\n when the right hand side of the declaration is typed, the new variable is of that the same type:\n{ var i int j := i // j is an int } when right hand side contains an untyped numeric constant, the new variable may be an int, float64, or complex128 depending on the precision of the constant.\npackage main import \u0026#34;fmt\u0026#34; func main() { v := 42 // int v2 := 42.01 // float64 v3 := 9.4 + 0.3i // complex128 \tfmt.Printf(\u0026#34;v is of type %T\\n\u0026#34;, v) fmt.Printf(\u0026#34;v2 is of type %T\\n\u0026#34;, v2) fmt.Printf(\u0026#34;v3 is of type %T\\n\u0026#34;, v3) }  Functions/Variables Functions/Variables: type comes after the variable name; omit redundant names; multiple returns; named return values;\nfunc add(x int, y int) int { return x + y } func swap(x, y int) (int, int) { //omit the type but the last, for consecutive shared type name. \treturn y, x // Go can return any number of result } Named return values:\nfunc split(sum int) (x, y int) { x = sum * 4 / 9 // named return values are treated variables defined at the top of a function \ty = sum - x return // a \u0026#39;naked\u0026#39; return returns named return values } func main() { fmt.Println(split(17)) // will print \u0026#39;7 10\u0026#39; }  Motivation: the confusing syntxt in C from Go\u0026rsquo;s delcaration Syntax:\n{ char *argv[]; // name in middle int (*fp) (int (*) (int, int), int); // function passed as parameter int (*(*fp)(int (*)(int, int), int))(int, int); // return a function } C\u0026rsquo;s syntax is read in Spiral: Clockwise/Spiral Rule.\n Go\u0026rsquo;s syntax, read from left to right:\n{ x int // x: int p *int // p: pointer to int a [3]int // a: array [3] of int  f func(func(int,int) int, int) int //function passed as a parameter f func(func(int,int) int, int) func(int,int) int //returns a function }  Variables: var and :=\nvar c, python bool var x, y int = 1, 2 // initialization var cxx, python3, java = true, false, \u0026#34;no!\u0026#34; // type can be omitted if initialization is present  func main() { var i int prolog, coq := true, \u0026#34;Yes!\u0026#34; // short variable declaration by \u0026#39;:=\u0026#39;, only used insie the function  fmt.Println(i, c, python) fmt.Println(x,y,cxx,python3,java) fmt.Println(prolog, coq) } Constants Like variables but with const and its expression for value, e.g. const Pi = 3.14\nconstant cannot use :=\nNumeric constants are high-precision values.\nPackages Packages: package main\nImports: import \u0026quot;fmt\u0026quot;\nExported names: begins with a capital letter;\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; ) import \u0026#34;math\u0026#34; func main(){ fmt.Println(\u0026#34;My favorite number is\u0026#34;, rand.Intn(1000)) fmt.Println(\u0026#34;PI:\u0026#34;, math.Pi) }  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/",
	"title": "FM",
	"tags": [],
	"description": "",
	"content": " Reference:\n An Overview of Formal Methods Tools and Techniques. Rigorous Software Development: An Introduction to Program Verification. 2011. Survey of Approches for Security Verification of Hardware/Software Systems. Onur Demir, Wenjie Xiong, Faisal Zaghloul, Jakub Szefer. 2016. pdf\n Wiki: Formal Verification\n Formal Methods\n 一文读懂基于SCADE模型的形式化方法\n  形式化方法是一种用把复杂系统描述为数学模型的方法。 通过把复杂的系统定义为逻辑严密的数学模型， 可以利用数学的方法验证系统的一些属性， 这类方法往往比基于经验的测试更全面彻底。\n虽然严密的数学方法能够有效的提高系统的可靠性，节省设计时间，增强可理解性，但学习或培训此类方法的周期比较长；而传统的工程教学并不会教授如何用形式化的数学方法描述一个计算系统。并且，各类形式化方法中的模型都会为了提高可证明性而增加各类限制规则。因此，在形式化方法的描述能力和严密程度上，必须做出取舍。\n形式化方法使用数学证明辅以系统测试，来保证被测试系统的行为准确性。随着系统变得越来越复杂，安全变得更为重要，形式化方法对系统设计提供了更高的安全保障。\n迪杰斯特拉（Dijkstra）等人已经展示过，通过测试的方法只能看出系统在什么样的情况下不会fail，但无法了解到对于测试用例之外的任何情况。相反的，如果一个数学定理被证明为正确，那么它将一直是正确的。\n有一点很重要，就是形式化验证并不能完全取代测试[Bowen95]。\n形式化方法的三个步骤：\n 形式化定义(formal specification)：在定义阶段，工程师使用一个模型语言(modeling languages)描述一个系统。这个过程类似于一个把word文档描述的问题转换为一个用数学代数语言描述的问题。 验证： 实现：一旦一个模型通过了定义和验证阶段，下一步就是把模型的定义转换成代码。  形式化方法的作用一直是广受怀疑的。自1960年代，形式化方法的研究便已经开始，但是工程师们接受这类方法的过程是相当缓慢的。这又多方面的原因，但是多数的原因是对形式化方法的错误应用。大多数的形式化系统的描述能力是相当强大的，多数建模语言在设计时都会把能够描述一切作为重要标准。\n工业应用  The growth in complexity of designs increases the importance of formal verification techniques in the hardware industry.[6][7] At present, formal verification is used by most or all leading hardware companies,[8] but its use in the software industry is still languishing.[citation needed] This could be attributed to the greater need in the hardware industry, where errors have greater commercial significance.[citation needed] Because of the potential subtle interactions between components, it is increasingly difficult to exercise a realistic set of possibilities by simulation. Important aspects of hardware design are amenable to automated proof methods, making formal verification easier to introduce and more productive.[9]\n  Basic Concepts  References: Terms Orderings Model Checking Temporal Logic https://plato.stanford.edu/entries/logic-temporal/ In order to ensure correct behavior of a reactive program, in which computations are non-terminating (e.g. an operating system), it is necessary to formally specify and verify the acceptable infinite executions of that program. In addition, to ensure correctness of a concurrent program, where two or more processors are working in parallel, it is necessary to formally specify and verify their interaction and synchronization.\n Constructive Logic  Reference 1 CMU Undergraduate Class ↩  Abstract Algebra   Reference 1 The Group Groups Reference 1 reference ↩ reference ↩  Galois  Reference 1 -- \u0026gt; Listen Galois pronunciation from 4:30 Galois Connection ↩  Abs Int  PPA version Reference 1 The theory of Abstract Interpretation is a general methodology for calculating analyses rather than just specifying them and then rely on a posteriori validation. Collecting Semantics records the set of traces $tr$ that can reach a given program point: $tr \\in Trace = (Var \\times Lab)^*$ e.g: $((x, ?), (y, ?), (z, ?), (y, 1), (z, 2), (z, 4), (y, 5), (z, 4), (y, 5), (y, 6))$\n Papers  Reference 1 CSpec Reference 1 201901 note. Verifying concurrent software using movers in CSPEC. OSDI, 2018. ↩ 2019 Arm Os Reference 1 Scalable Translation Validation of Unverified Legacy OS Code. FMCAD, 2019. ↩ Intscope Reference 1 Decompiler: Bestar, IDA Pro as front-end. translates x86 assembl into PANDA IR (freshly designed). Symbolic execution engine: leverage framework of GiNac[^c8]. Path Validator and Integer Overflow Checker: STP, a decision procedure for bit-vectors and arrays.\n Temporal Logic  Reference 1 CTL References: Lecture 7, Computation Tree Logics Path Quantifier $A$: for every path. $E$: there exists a path. Linear-time operators $\\boldsymbol{X}_p$: $p$ holds next time. $\\boldsymbol{F}_p$: $p$ holds sometime in the future. $\\boldsymbol{G}_p$: $p$ holds globally in the future. $p\\boldsymbol{U}q$: $p$ holds until $q$ holds. Path Formulas and State Formulas More reference ↩  Model Checking  References: Model Checking @CMU Model Checking Code @CMU Specification and Verification Center @CMU wiki: Model Checking, contains a list of model checking tools. Model Checking简述\n Hott  Reference1 \u0026ldquo;Homotopy Type Theory: Univalent Foundations of Mathematics\u0026rdquo;. ↩  Separation Logic  References: Separation Logic, Peter O\u0026rsquo;Hearn Separation logic, first developed by O\u0026rsquo;Hearn and Reynolds, is an extension of Hoare\u0026rsquo;s logic which addresses reasoning about program that access and mutate data structures. It includes a \u0026ldquo;frame rule\u0026rdquo; which enables more compact proofs and specs of imperative programs than before because of its support for local reasoning, where specification and proofs concentrate on the portion of memory used by a program component, and not the entire global state of the system.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/2005embed/",
	"title": "2005Embed",
	"tags": [],
	"description": "",
	"content": " Reference1:\nRestricted C + Compiler = Safe language benefits with no garbage collection, no runtime checks.\nSafe definition: define a software entity (module, thread, or a complete program) to be safe if:\n not out of bound: never reference a memory location outside the data area by or for the entity.\n no alien code execution: never executes instructions outside the code area created by the compiler and linker within that space.\n  Except dangling pointers, detect and prevent all other errors that could be prevented by a language with strong type safety.\nReplace null ptr runtime check with hardware address space protection.\nCompiler techniques 2 new + 2 previous\n automatic pool allocation: \u0026lsquo;safe dangling ptrs\u0026rsquo; interprocedural algorithem: propagating constraints on integer variables \u0026amp; prove the safety of affine array reference on integer variables.\n memory initialization using illegal address from hardware protection\n escape analysis: prevent dangling ptrs to stack objects.\n  Restrictions on C Complex/Unanalyzable array references are not allowed. (Or in future work, allowed with runtime checks added.)\n  Memory Safety Without Garbage Collection for Embedded Applications, ACM Transactions on Embedded Computing Systems, 2005. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/class-user/",
	"title": "Example: User Defined Object Capabilities",
	"tags": [],
	"description": "",
	"content": "  The object type in user space is splited into two ranges:\n non-system type numbers: [1, $2^{22}$ - 1 ]; system type numbers: [$2^{22}$, $2^{23}$ - 1 ];  while the object types in kernel space is [$2^{23}$, $2^{24}$ -1 ].\n Example 1: static sandboxes Code is derived from cheritest_ccall.c.\n(Note: This portion of testing code in CheriBSD is commented out in cheritest.c, which means no available by default. Original comments:\n Disable CCall/CReturn tests universally as nose doesn\u0026rsquo;t work with missing tests.\n The first example is a hand-crafted, minimalist sandbox that don\u0026rsquo;t even have stacks: no local data, just contain one instruction creturn. For stacks, see hello world example\nIn this example, five steps are presented to create and exectute a sanbox:\n First, an object type is allocated by libcheri_type_alloc(), which will return a capability with a type. Cheri Object Type\n Second, the code and data capability is created using codecap_create(), datacap_create();\n Third, the capability with a type is used as a sealing capability to seal the code and data capability, then we get a sealed code and a sealed data capability.\n Fourth, a CHERI object is created using the two seal capabilities as code and data.\n Fifth, the CHERI object is invoked via libcheri_invoke().\n  For code capability, need a function pointer as base, and another function pointer as the boundary enclosing the last instruction.\nIn this example, the sandbox contains a function named sandbox_creturn and ends on sandbox_creturn_end:\n/* file: bin/cheritest/cheritest_sandbox.S */ .text .type sandbox_creturn,@function .global sandbox_creturn .ent sandbox_creturn sandbox_creturn: creturn .end sandbox_creturn .global sandbox_creturn_end sandbox_creturn_end: .size sandbox_creturn, sandbox_creturn_end - sandbox_creturn .size sandbox_creturn_end, 0 For assembly basics.\nMain testing code to create/execute the above sandbox is defined as below. It will create a pair of sealed code and data capabilities; then define them as an cheri_object co;, finally invoke it via libcheri_invoke by using the cheri object co:\n// file: // bin/cheritest/cheritest_ccall.c  static void * __capability sandbox_creturn_sealcap; static void * __capability sandbox_creturn_codecap; static void * __capability sandbox_creturn_datacap; /* * One-type setup for ccall-related tests. */ void cheritest_ccall_setup(void) { /* * Create sealing, sealed code, and sealed data capabilities. */ sandbox_creturn_sealcap = libcheri_type_alloc(); sandbox_creturn_codecap = cheri_seal( codecap_create(\u0026amp;sandbox_creturn, \u0026amp;sandbox_creturn_end), sandbox_creturn_sealcap); sandbox_creturn_datacap = cheri_seal( datacap_create(\u0026amp;sandbox_creturn, \u0026amp;sandbox_creturn_end), sandbox_creturn_sealcap); } /* * CCall code that will immediately CReturn. */ void test_nofault_ccall_creturn(const struct cheri_test *ctp __unused) { struct cheri_object co; co.co_codecap = sandbox_creturn_codecap; co.co_datacap = sandbox_creturn_datacap; (void)libcheri_invoke(co, 0, 0, 0, 0, 0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL); cheritest_success(); } From codecap_create(\u0026amp;sandbox_creturn, \u0026amp;sandbox_creturn_end) and datacap_create(\u0026amp;sandbox_creturn, \u0026amp;sandbox_creturn_end), we can see that data capability is set to have the same range (base and bounds) as code capability. The different permission on the code and data capabilities would limit how they can be used.\nThe example above create code and data capability pair by codecap_create() and datacap_create(). Then use cheri_seal to seal the code and data capability with a type allocated from libcheri_type_alloc().\ncodecap_create() and datacap_create() There are two ABIs can be used to create data/code capability:\nIn pure-cap ABI, cheri_andperm is used to set permission bits for the already existing code or data capability (LLM: when the size of the code capability is determined ???? ).\nFor hybrid ABI, cheri_codeptrperm creates the code capability and cheri_ptrperm creates the data capability, from a pointer, where its size, and perms are given.\nHere is the definition of codecap_create():\nstatic void * __capability codecap_create(void (*sandbox_base)(void), void *sandbox_end) { void * __capability codecap; #ifdef __CHERI_PURE_CAPABILITY__ \t(void)sandbox_end; codecap = cheri_andperm(sandbox_base, CHERI_PERM_GLOBAL | CHERI_PERM_LOAD | CHERI_PERM_EXECUTE); #else \tcodecap = cheri_codeptrperm(sandbox_base, (size_t)sandbox_end - (size_t)sandbox_base, CHERI_PERM_GLOBAL | CHERI_PERM_LOAD | CHERI_PERM_EXECUTE); #endif \treturn (codecap); } Definition of datacap_create():\n//file: // ./bin/cheritest/cheritest_ccall.c  static void * __capability datacap_create(void *sandbox_base, void *sandbox_end) { void * __capability datacap; #ifdef __CHERI_PURE_CAPABILITY__ \t(void)sandbox_end; datacap = cheri_andperm(sandbox_base, CHERI_PERM_GLOBAL | CHERI_PERM_LOAD | CHERI_PERM_STORE | CHERI_PERM_LOAD_CAP | CHERI_PERM_STORE_CAP | CHERI_PERM_STORE_LOCAL_CAP); #else \tdatacap = cheri_ptrperm(sandbox_base, (size_t)sandbox_end - (size_t)sandbox_base, CHERI_PERM_GLOBAL | CHERI_PERM_LOAD | CHERI_PERM_STORE | CHERI_PERM_LOAD_CAP | CHERI_PERM_STORE_CAP | CHERI_PERM_STORE_LOCAL_CAP); #endif \treturn (datacap); } libcheri_invoke() libcheri_invoke: ccall wrappers\nCheri Perm definitions Cheri Permission Constants\nExample 2: hello world sandbox Overview Initialization of sandbox: sandbox mechanisms must be initialized before being used. This includes ???\u0026hellip;\nCreation\nOnce a user sandbox is created and need system service, the user sandbox need to call a method in the system sandbox. The path to system sandbox method:\nbin/cheri_helloworld/cheri_helloworld.c: main() -\u0026gt; lib/libhelloworld/compartment/helloworld.c: call_libcheri_system_helloworld() -\u0026gt; lib/libcheri/libcheri_system.h: libcheri_system_helloworld();\nmain func // file: // bin/cheri_helloworld/cheri_helloworld.c main(void) { struct sandbox_object *sbop; int ret; struct cheri_object stdout_fd; libcheri_init(); if (libcheri_fd_new(STDOUT_FILENO, \u0026amp;sbop) \u0026lt; 0) err(EX_OSFILE, \u0026#34;libcheri_fd_new: stdout\u0026#34;); ret = call_libcheri_system_helloworld(); assert(ret == 123456); ... } Initialization of libcheri libcheri_init() libcheri_init() is a centralised constructor for libcheri to ensure that initialisation happens in the desired order [vs. multiple constructors]. Users wish to create sandboxes should call this to make sure libcheri is property initialized.\n// file // lib/libcheri/libcheri_init.c  void libcheri_init(void) { if (libcheri_initialised) return; /* * Must initialise sealing capabilities before other aspects of * libcheri. */ libcheri_ccall_init(); libcheri_stack_init(); libcheri_enter_init(); sandbox_init(); libcheri_initialised = 1; } 4 pieces of initialization:\n The sealing capabilities used for invocation, rtld, and creturn are created; the sealed capabilities that are shared across many sandboxes are created; done in libcheri_ccall_init(), more; Ensure thread-local storage for the first thread\u0026rsquo;s trusted stack is suitably aligned. in libcheri_stack_init(); Allocate and initialize a stack for landing system class code libcheri_enter_init(); load sandbox setups from binary ELF file: required/provided methods from program binary code sandbox_init();  Call system sandbox methods in user sandbox // file: // bin/cheri_helloworld/cheri_helloworld.c  if (libcheri_fd_new(STDOUT_FILENO, \u0026amp;sbop) \u0026lt; 0) err(EX_OSFILE, \u0026#34;libcheri_fd_new: stdout\u0026#34;); ret = call_libcheri_system_helloworld(); assert(ret == 123456); ret = call_libcheri_system_puts(); assert(ret \u0026gt;= 0); stdout_fd = sandbox_object_getobject(sbop); ret = call_libcheri_fd_write_c(stdout_fd); assert(ret == 12); libcheri_fd_destroy(sbop); libcheri_fd_new/destroy libcheri_fd_new\n// file: // lib/libcheri/libcheri_fd.c  /* * XXXRW: libcheri system objects must have a corresponding sandbox_object to * use during domain transition. Define one here. */ /* * Allocate a new libcheri_fd object for an already-open file descriptor. * * XXXRW: What to return in the userspace CCall world order? The sandbox..? */ int libcheri_fd_new(int fd, struct sandbox_object **sbopp) { void * __capability invoke_pcc; struct libcheri_fd *lcfp; lcfp = calloc(1, sizeof(*lcfp)); if (lcfp == NULL) { errno = ENOMEM; return (-1); } lcfp-\u0026gt;lcf_fd = fd; /* * Construct a code capability for this class; for system classes, * this is just the ambient $pcc with the offset set to the entry * address. * * XXXRW: Possibly, we should just pass libcheri_fd to sandbox * creation rather than embedding this logic in each system class? */ invoke_pcc = cheri_setoffset(cheri_getpcc(), (register_t)LIBCHERI_CLASS_ENTRY(libcheri_fd)); /* * Set up system-object state for the sandbox. */ if (sandbox_object_new_system_object( (__cheri_tocap void * __capability)(void *)lcfp, invoke_pcc, libcheri_fd_vtable, \u0026amp;lcfp-\u0026gt;lcf_sbop) != 0) { free(lcfp); return (-1); } *sbopp = lcfp-\u0026gt;lcf_sbop; return (0); } libcheri_fd_destroy\n// file: // lib/libcheri/libcheri_fd.c  /* * Actually free a libcheri_fd. This can only be done if there are no * outstanding references in any sandboxes (etc). */ void libcheri_fd_destroy(struct sandbox_object *sbop) { struct libcheri_fd * __capability lcfp; lcfp = sandbox_object_getsandboxdata(sbop); sandbox_object_destroy(sbop); free((__cheri_fromcap struct libcheri_fd *)lcfp); } call_libcheri_system_helloworld/puts call_libcheri_system_helloworld\n// file // lib/libhelloworld/compartment/helloworld.c  int call_libcheri_system_helloworld(void) { return (libcheri_system_helloworld()); } call_libcheri_system_puts\n// file // lib/libhelloworld/compartment/helloworld.c  int call_libcheri_system_puts(void) { char * __capability hello_world_str_c; hello_world_str_c = cheri_ptrperm(\u0026amp;hello_world_str, sizeof(hello_world_str), CHERI_PERM_LOAD); /* Nul-terminated. */ return (libcheri_system_puts(hello_world_str_c)); } Those are \u0026lsquo;wrappers\u0026rsquo; of libcheri system methods. They call into system sandbox by calling libcheri_system_helloworld() and libcheri_system_puts(...), which is declared as LIBCHERI_SYSTEM_CALL attributes:\n// file: libcheri_system.c  /* * Methods themselves. */ LIBCHERI_SYSTEM_CCALL int libcheri_system_helloworld(void); LIBCHERI_SYSTEM_CCALL int libcheri_system_puts(const char * __capability str); // file: lib/libcheri/libcheri_system.h #ifdef LIBCHERI_SYSTEM_INTERNAL #define LIBCHERI_SYSTEM_CCALL \\ __attribute__((cheri_ccallee)) \\ __attribute__((cheri_method_class(_libcheri_system_object))) #else #define LIBCHERI_SYSTEM_CCALL \\ __attribute__((cheri_ccall)) \\ __attribute__((cheri_method_suffix(\u0026#34;_cap\u0026#34;))) \\ __attribute__((cheri_method_class(_libcheri_system_object))) #endif"
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/steensgaard/",
	"title": "Steensgaard",
	"tags": [],
	"description": "",
	"content": " Reference: B. Steensgaard. Points-to analysis in almost linear time. POPL, 1996.1\nType system   B. Steensgaard. Points-to analysis in almost linear time. POPL, 1996. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/",
	"title": "Fm in Arch",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How formal methods are used in the architectural design (IC/ASIC/FPGA)?  References:\n Part8: The 2018 Wilson Research Group Functional Verification Study  IC/ASIC adoption trends for formal property checking (e.g., model checking), as well as automatic formal applications:\n formal property checking:  Model checking;  automatic formal application tools:  SoC integration connectivity checking; deadlock detection; X semantic safety checks; coverage reachability analysis; many other properties that can be automatically extracted and then formally proven.   More  Sail Specification   UPEC  References: Processor Hardware Security Vulnerabilities and their Detection by Unique Program Execution Checking. By Mohammad Rahmani Fadiheh, et. al. 2018 arXiv, 2019 DATE UPEC: Unique Program Execution Checking. Orc Attack Leverage the RAW(Read after write) hazard: load latency is longer when RAW happens. Assumptions: (simplified for easy understanding) each cache line is selected based on lower 8 bits; a total of $2^8=256$ cache lines. Attack: guess a possible address #test_value; write a value at the #test_value load a secret to a register lw x4, 0(x1), where x1 is #protected_addr; ==\u0026gt; this will throw an exception, x4 will not have the secret value (not architectual visible).\n Kami   References: Kami: A Platform for High-Level Parametric Hardware Specification and Its Modular Verification, 2017, ICFP Wednesday @ 1130, 2016. Kami A Framework for RISC V HW Verification Murali Vijayaraghavan, MIT More  Spec HOL4 (x86-TSO...)  References: Relaxed-Memory Concurrency x86-TSO: A Rigorous and Usable Programmer’s Model for x86 Multiprocessors Relaxed-Memory Concurrency Multiprocessors are now pervasive and concurrent programming is becoming mainstream, but typical multiprocessors (x86, Sparc, Power, ARM, Itanium) and programming languages (C, C++, Java) do not provide the sequentially consistent shared memory that has been assumed by most work on semantics and verification. Instead, they have subtle relaxed (or weak) memory models, exposing behaviour that arises from hardware and compiler optimisations to the programmer.\n Spec PSL  References: reference EDA languages PSL: Property specification language (EDA standard) evovled from Sugar language; adopted as an IEEE standard (1850-2010); grafted onto both SystemVerilog and VHDL; act as an add-on to SystemVerilog/VHDL; Based on CTL/LTL; PSL is divided into four layers: Boolean layer (lowest layer), consists of instantaneous boolean expressions on signals in the design under test; The syntax of this layer follows that of the HDL to which PSL is being applied; Can be verilog, SystemVerilog, VHDL, or others; e.\n Formal methods in EDA  References: Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition. Chaper 15-20 More Logic Verification -- languages References: Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition. Chaper 15 Steps of IC design design in C/C++ model \u0026ndash;\u0026gt; simulators, func good design in RTL \u0026ndash;\u0026gt; simulating, and compare with the C/C++ reference model Synthesis: Translate RTL to gate-level netlist.\n Spec Sail  References: RISCV Sail on Github Using Sail Specifications in Isabelle/HOL, August 29, 2018. pdf Sail Goals: engineer-friendly, vendor-pseudocode-like language for describing instruction semantics. Sail: a first-order imperative language, but with lightweight dependent typing for numeric types and bitvector lengths. Side-effects: Sail use its effect system to determine whether a function has side-effects and needs to be monadic. Monadic function: All about monads: Monads is a way to structure computations in terms of values and sequences of computations using typed values.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/x86/",
	"title": "X86",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-sys/",
	"title": "Example: System class object capabiilties",
	"tags": [],
	"description": "",
	"content": "  The object type in user space is splited into two ranges:\n non-system type numbers: [1, $2^{22}$ - 1 ]; system type numbers: [$2^{22}$, $2^{23}$ - 1 ];  while the object types in kernel space is [$2^{23}$, $2^{24}$ -1 ].\n Cheri System class is the CHERI system type of the system library.\n Object type: libcheri_system_type  Overview  IN file: lib/libcheri/libcheri_system.h:\nThe header defines the interface for the libcheri system class. Currently, it is a bit catch-all, and provides a few key service that make it easy to implement (and debug) sandboxed code. In the future, we anticipate the system class being an entry point to a number of other classes \u0026ndash; e.g., providing an open() method that returns file-descriptor objects. We are definitely not yet at that point.\n System sandbox type // file // lib/libcheri/libcheri_system.h  /* * XXXRW: Probably should be library-private: the CHERI type of the system * library. */ extern void * __capability\tlibcheri_system_type; // ??? but where it is assigned to a value? Type allocation Never called in current CHERIBSD source code\n// file // lib/libcheri/libcheri_type.c  void * __capability libcheri_system_type_alloc(void) { return (libcheri_alloc_type_capability(\u0026amp;libcheri_system_type_next, libcheri_system_type_max)); } System sandbox creation/initialization libcheri_system_new(...) creates a new CHERI system object for use with a specific sandbox object.\nThis is called during sandbox loading process.\nint libcheri_system_new(struct sandbox_object *sbop, struct sandbox_object **sbopp) { void * __capability invoke_pcc; /* * Construct an object capability for the system-class instance that * will be passed into the sandbox. * * The private data pointer is to the sandbox object that this system * object serves. * * The code capability will simply be our $pcc. * * XXXRW: For now, we will populate $c0 with $pcc on invocation, so we * need to leave a full set of permissions on it. Eventually, we * would prefer to limit this to LOAD and EXECUTE. * * XXXRW: We should do this once per class .. or even just once * globally, rather than on every object creation. * * XXXRW: Use cheri_codeptr() here in the future? * * XXXRW: Is this up-to-date? * * Set up vector pointer, remove sealing, point at tranpoline? */ invoke_pcc = cheri_getpcc(); invoke_pcc = cheri_setaddress( invoke_pcc, (register_t)LIBCHERI_CLASS_ENTRY(libcheri_system)); return (sandbox_object_new_system_object( (__cheri_tocap void * __capability)(void *)sbop, invoke_pcc, libcheri_system_vtable, sbopp)); } System sandbox inner Methods // file // lib/libcheri/libcheri_system.h/c  /* * Just a test function. */ int libcheri_system_helloworld(void); /* * Implementation of puts(), but with a capability argument. No persistent * state, so no recovery required if an exception is thrown due to a bad * capability being passed in. */ int libcheri_system_puts(const char * __capability str); int libcheri_system_putchar(int c); int libcheri_system_clock_gettime(clockid_t clock_id, struct timespec * __capability tp); int libcheri_system_calloc(size_t number, size_t size, void * __capability * __capability ptrp); int libcheri_system_free(void * __capability ptr); /* * Call a legacy user function. */ int libcheri_system_user_call_fn(register_t methodnum, register_t a0, register_t a1, register_t a2, register_t a3, register_t a4, register_t a5, register_t a6, void * __capability c3, void * __capability c4, void * __capability c5, void * __capability c6, void * __capability c7); /* * Allow the application to register its own methods. */ void libcheri_system_user_register_fn(libcheri_system_user_fn_t fn_ptr);  Global Data:  System sandbox vtable  LLM: ??? it looks like every sandbox will have this libcheri_system_vtable re-initialized upon sandbox initialization in sandbox_program_init(); However, if this vtable is a global variable and shared as the same for all sandboxes, will this be a conflict between all the sandboxes that are using this vtable?\n Declare as extern in libcheri_system.h\n// file: // lib/libcheri/libcheri_system.h  /* * Vtable for cheri_system methods. */ extern vm_offset_t * __capability\tlibcheri_system_vtable; Defined and used in libcheri_sandbox.c:\n// file: // lib/libcheri/libcheri_sandbox.c  /* * libcheri_system_vtable is defined here and not in libcheri_system.h to avoid * running into https://github.com/CTSRD-CHERI/cheribsd/issues/180 */ vm_offset_t * __capability libcheri_system_vtable; ... int sandbox_program_init(void) { ... /* XXXBD: cheri_system needs to do this. */ libcheri_system_vtable = sandbox_make_vtable(NULL, \u0026#34;_libcheri_system_object\u0026#34;, main_provided_classes); ... } sandbox_make_vtable will take the main_provided_classes parsed from the sandbox binary and create it\nExampl(e: execute hello world sandbox as a system class method Invoke the sandbox inner methods First path test_sandbox_cs_helloworld() -\u0026gt; invoke_cheri_system_helloworld() -\u0026gt; libcheri_system_helloworld();\n// The `invoke_cheri_system_helloworld()` will invoke hello world in a sandbox:  // file: bin/cheritest/cheritest_libcheri.c void test_sandbox_cs_helloworld(const struct cheri_test *ctp __unused) { register_t v; v = invoke_cheri_system_helloworld(); if (v \u0026lt; 0) cheritest_failure_errx(\u0026#34;Sandbox returned %jd\u0026#34;, (intmax_t)v); else cheritest_success(); } The following is the declaration of the call gate of invoke_cheri_system_helloworld()\n// file: libexec/cheritest-helper/cheritest-helper.h struct cheri_object; BEGIN_CAPABILITIES //... CHERITEST_CCALL int\tinvoke_cheri_system_helloworld(void); //... END_CAPABILITIES // file: libexec/cheritest-helper/cheritest-helper.c extern struct cheri_object cheritest; #ifdef CHERITEST_INTERNAL #define\tCHERITEST_CCALL\t\\ __attribute__((cheri_ccallee))\t\\ __attribute__((cheri_method_class(cheritest))) #else #define\tCHERITEST_CCALL\t\\ __attribute__((cheri_ccall))\t\\ __attribute__((cheri_method_suffix(\u0026#34;_cap\u0026#34;)))\t\\ __attribute__((cheri_method_class(cheritest))) #endif  int invoke_cheri_system_helloworld(void) { return (libcheri_system_helloworld()); } The assembly code for test_sandbox_cs_helloworld():\n/* file: cheritest.s , commit: def7a422bf */ 000000000003c8a8 test_sandbox_cs_helloworld: 3c8a8: 67 bd ff e0 daddiu $sp, $sp, -32 3c8ac: ff bf 00 18 sd $ra, 24($sp) 3c8b0: ff be 00 10 sd $fp, 16($sp) 3c8b4: ff bc 00 08 sd $gp, 8($sp) 3c8b8: 03 a0 f0 25 move $fp, $sp 3c8bc: 3c 01 00 11 lui $1, 17 3c8c0: 00 39 08 2d daddu $1, $1, $25 3c8c4: 64 3c f7 58 daddiu $gp, $1, -2216 3c8c8: df 81 89 20 ld $1, -30432($gp) 3c8cc: df 83 87 80 ld $3, -30848($gp) 3c8d0: dc 22 00 00 ld $2, 0($1) 3c8d4: d8 20 18 00 clc $c1, $3, 0($ddc) 3c8d8: 64 61 00 20 daddiu $1, $3, 32 3c8dc: d8 40 08 00 clc $c2, $1, 0($ddc) 3c8e0: df 99 87 88 ld $25, -30840($gp) 3c8e4: 48 03 02 bf cgetnull $c3 3c8e8: 48 04 02 bf cgetnull $c4 3c8ec: 48 05 02 bf cgetnull $c5 3c8f0: 48 06 02 bf cgetnull $c6 3c8f4: 48 07 02 bf cgetnull $c7 3c8f8: 48 08 02 bf cgetnull $c8 3c8fc: 48 09 02 bf cgetnull $c9 3c900: 48 0a 02 bf cgetnull $c10 3c904: 64 04 00 00 daddiu $4, $zero, 0 3c908: 64 05 00 00 daddiu $5, $zero, 0 3c90c: 64 06 00 00 daddiu $6, $zero, 0 3c910: 64 07 00 00 daddiu $7, $zero, 0 3c914: 64 08 00 00 daddiu $8, $zero, 0 3c918: 64 09 00 00 daddiu $9, $zero, 0 3c91c: 64 0a 00 00 daddiu $10, $zero, 0 3c920: 03 20 f8 09 jalr $25 3c924: 64 0b 00 00 daddiu $11, $zero, 0 3c928: 04 41 00 06 bgez $2, 28 \u0026lt;test_sandbox_cs_helloworld+0x9c\u0026gt; 3c92c: 00 00 00 00 nop 3c930: df 81 80 c8 ld $1, -32568($gp) 3c934: 00 02 28 00 sll $5, $2, 0 3c938: df 99 84 90 ld $25, -31600($gp) 3c93c: 03 20 f8 09 jalr $25 3c940: 64 24 3b ce daddiu $4, $1, 15310 3c944: df 99 84 88 ld $25, -31608($gp) 3c948: 03 20 f8 09 jalr $25 3c94c: 00 00 00 00 nop Another disassembly from cheriabitest:\n/* file: cheriabitest.s, commit: def7a422bf*/ 0000000120087310 test_sandbox_cs_helloworld: 120087310: 4a 6b 5f 80 cincoffset $c11, $c11, -128 120087314: fb 0b 00 06 csc $c24, $zero, 96($c11) 120087318: fa 4b 00 04 csc $c18, $zero, 64($c11) 12008731c: fa 2b 00 02 csc $c17, $zero, 32($c11) 120087320: 48 18 58 11 cincoffset $c24, $c11, $zero 120087324: 3c 01 00 14 lui $1, 20 120087328: 64 21 e1 30 daddiu $1, $1, -7888 12008732c: 48 12 60 51 cincoffset $c18, $c12, $1 120087330: 74 32 08 60 clcbi $c1, 34304($c18) 120087334: 74 52 03 5a clcbi $c2, 13728($c18) 120087338: c8 41 00 03 cld $2, $zero, 0($c1) 12008733c: d8 22 00 00 clc $c1, $zero, 0($c2) 120087340: d8 42 00 02 clc $c2, $zero, 32($c2) 120087344: 75 92 03 5c clcbi $c12, 13760($c18) 120087348: 48 03 02 bf cgetnull $c3 12008734c: 48 04 02 bf cgetnull $c4 120087350: 48 05 02 bf cgetnull $c5 120087354: 48 06 02 bf cgetnull $c6 120087358: 48 07 02 bf cgetnull $c7 12008735c: 48 08 02 bf cgetnull $c8 120087360: 48 09 02 bf cgetnull $c9 120087364: 48 0a 02 bf cgetnull $c10 120087368: 64 04 00 00 daddiu $4, $zero, 0 12008736c: 64 05 00 00 daddiu $5, $zero, 0 120087370: 64 06 00 00 daddiu $6, $zero, 0 120087374: 64 07 00 00 daddiu $7, $zero, 0 120087378: 64 08 00 00 daddiu $8, $zero, 0 12008737c: 64 09 00 00 daddiu $9, $zero, 0 120087380: 64 0a 00 00 daddiu $10, $zero, 0 120087384: 48 11 63 3f cjalr $c12, $c17 120087388: 64 0b 00 00 daddiu $11, $zero, 0 12008738c: 04 41 00 09 bgez $2, 40 \u0026lt;test_sandbox_cs_helloworld+0xa4\u0026gt; 120087390: 00 00 00 00 nop 120087394: 00 02 08 00 sll $1, $2, 0 120087398: e8 2b 00 03 csd $1, $zero, 0($c11) 12008739c: 4a 81 58 08 csetbounds $c1, $c11, 8 1200873a0: 34 01 ff d7 ori $1, $zero, 65495 1200873a4: 74 72 08 54 clcbi $c3, 34112($c18) 1200873a8: 75 92 01 92 clcbi $c12, 6432($c18) 1200873ac: 48 11 63 3f cjalr $c12, $c17 1200873b0: 48 0d 08 4d candperm $c13, $c1, $1 1200873b4: 75 92 01 8e clcbi $c12, 6368($c18) 1200873b8: 48 11 63 3f cjalr $c12, $c17 1200873bc: 00 00 00 00 nop  Example 3: libcheri sandboxes  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/stores/ccall-tests/",
	"title": "CCall Examples",
	"tags": [],
	"description": "",
	"content": " References:\n[1]\nStack Underflow //file: ./bin/cheritest/cheritest_libcheri_trustedstack.c /* * Perform a return without a corresponding invocation, to underflow the * trusted stack. */ void test_sandbox_trustedstack_underflow(const struct cheri_test *ctp __unused) { struct cheri_object returncap; void * __capability codecap /* currently ignored: asm (\u0026#34;$c1\u0026#34;) */; void * __capability datacap /* currently ignored: asm (\u0026#34;$c2\u0026#34;) */; returncap = libcheri_make_sealed_return_object(); codecap = returncap.co_codecap; datacap = returncap.co_datacap; /* * TODO: the branch delay slot has been removed. We can remove the nop * once we no longer expect to run on older bitfiles */ __asm__ __volatile__ (\u0026#34;ccall %0, %1, 1\\n\\tnop\u0026#34; : : \u0026#34;C\u0026#34;(codecap), \u0026#34;C\u0026#34;(datacap)); cheritest_failure_errx(\u0026#34;continued after attempted CReturn\u0026#34;); }"
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/eda-fm/languages/",
	"title": "Logic Verification -- languages",
	"tags": [],
	"description": "",
	"content": " References:\n Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition.  Chaper 15   Steps of IC design  design in C/C++ model \u0026ndash;\u0026gt; simulators, func good design in RTL \u0026ndash;\u0026gt; simulating, and compare with the C/C++ reference model Synthesis: Translate RTL to gate-level netlist. Place and Route: netlist as input, generates polygons that will become wires and transistors on the chip.  Verification: making sure that C and RTL models are functionally correct.\nThis is the most serious, time-consuming challenge in digital hardware design.\nThe so-called formal verification techniques, which amount to efficient exhaustive simulation, have been gaining ground, but suffer from capacity problems.\nTesting:\n provides no guarantees of completeness, meaning bugs may go unnoticed. Good assertions in hardware systems (which often check a temporal property, such as \u0026ldquo;acknowledge arrives within three cycles of every request\u0026rdquo;) are much more difficult to write than those for software (which most often check data structure consistency). There is no way to know when enough assertions have been added; It is possible that the assertions themselves have flaws (e.g., they let bugs by) Finally, test cases that achieve 100% coverage can also let bugs by because the criterion for coverage is necessarily weak.  Coverage typically checks what states particular variables have been in, but it cannot consider all combination because their number grows exponentially quickly with design size. As a result, certain important combination may not be checked even though coverage checks report \u0026ldquo;complete coverage\u0026rdquo;.   Pure formal techniques  consider all the possible behaviors by definition; do not require explicit test cases (implicitly, they consider all possible test cases); do not need to consider coverage; But knowing what behavior is unwanted is crucial for formal techniques, whose purpose is to either expose unwanted behavior or formally prove it cannot occur.  History: CTL/LTL based languages  1970s[20], Pnueli suggested the use of temporal logic; early 1980s, research on automatic verification\n linear temporal logic computational tree logic CCS, dynamic logic, temporal logic of actions(TLA)  In early 2000s, a sort of renaissance occurred in verification languages.\n Temporal logics, specifically linear temporal logic (LTL), and computation tree logic (CTL): form the mathematical basis for most assertion checking.  CTL: specify both liveness properties and safety properties;\n Liveness property: \u0026ldquo;this good thing will eventually happen\u0026rdquo; Safety properties: \u0026ldquo;this bad thing will never happen\u0026rdquo;  LTL: a subset of CTL, expresses only safety properties\n can be turned into checking automata meant to be run in concert with a simulation to look for unwanted behavior.  but their traditional mathematical syntax is awkward for hardware designers.\n Instead, a number of more traditional computer languages, which combine a more human-readable syntax for the bare logic with a lot of \u0026ldquo;syntactic sugar\u0026rdquo; for more naturally expressing common properties, were proposed for expressing properties in these logics.\n Two industrial efforts from Intel (ForSpec) and IBM (Sugar) emerged as the most complete;\n They were later adopted in part by SystemVerilog and VHDL.  CBV from Motorola\n Some EDA companies were producing languages designed for writing test benches and checking simulation coverage.\n Vera and e are two most commercially successful; Vera: originally designed by System Science and since acquired by Synopsys; e: designed and sold by Cadence (formerly Verisity)   ==\u0026gt; These industrial languages were donated to the Accellera standards body and have been the basis for defining a new IEEE standard called PSL.\nPSL: Property specification language (EDA standard)  evovled from Sugar language; adopted as an IEEE standard (1850-2010); grafted onto both SystemVerilog and VHDL;  act as an add-on to SystemVerilog/VHDL;  Based on CTL/LTL; PSL is divided into four layers:  Boolean layer (lowest layer), consists of instantaneous boolean expressions on signals in the design under test; The syntax of this layer follows that of the HDL to which PSL is being applied;  Can be verilog, SystemVerilog, VHDL, or others; e.g. a[0:3] \u0026amp; b[0:3] and a(0 to 3) and b(0 to 3) represent the bitwise and of the four most significant bits of vectors a and b in the Verilog and VHDL flavors, respectively.  Temporal layer (second layer), allows a designer to state properties that hold across multiple clock cycles. e.g. always !(ena \u0026amp; enb) states that the signals ena and enb will never be true simultaneously in any clock cycle.  The always operator, which states that a Boolean expression holds in every clock cycle, is one of the most basic.  e.g. always(req -\u0026gt; next ack) states that in every cycle that the req signal is true, the ack signal is true in the next cycle.  The next operator, one of the operators that specify delays.  e.g. req -\u0026gt; next[2] ack means that ack must be true two cycles after each cycle in which req is true.  The -\u0026gt; symbol denotes implication, that is, if the expression to the left is true, that on the right must also be true.  e.g. always {req; ack; !cancel} is a syntactic sugar for always (req -\u0026gt; next (ack -\u0026gt; next !cancel)), means that ack must be true after any cycle in which req is true, and cancel must be false in the cycle after that. weak and strong property:  weak property can be checked in simulation; i.e., for safety properties; strong property: can only be checked formally; express liveness properties; strong property is marked with a trailing exclamation point !. some operators come in both strong and weak varieties. e.g. always (req -\u0026gt; eventually! ack) states that after req is asserted, ack will always be asserted eventually. eventually! operator illustrates the meaning of strong operators. This is not something that can be checked in simulation: if a particular simulation saw req but did not see ack, it would be incorrect to report that this property failed because running that particular simulation longer might have produced ack. This is the fundamental differences between safety and liveness properties: safety states something bad never happens; liveness states something good eventually happens;  Specify a property in which times moves backward.  always ((a \u0026amp;\u0026amp; next[3] (b)) -\u0026gt; c), states that when a is true and b is true three clock cycles later, c is true in the first cycle when a is true.  Verification layer (third layer), instructs a verification tool what tests to perform on a particular design; It amounts to a binding between properties defined with expressions from the Boolean and temporal layer, and modules in the design under test. The following example declares a \u0026ldquo;verification unit\u0026rdquo; called ex1a, binds it to the instance named top_block_i1_i2 in the design under test, and declares (the assertion named A1) that the signals ena and enb in that instance are never true simultaneously.\nvunit ex1a(top_block.i1.i2){ A1: assert never (ena \u0026amp;\u0026amp; enb); } use directives\n assert, assume, assume a given property; assume_guarantee, both assumes and tests a particular property; restrict, constraints the tool to only consider inputs that have a given property; cover, asks the tool to check whether a certain property was ever observed; fairness, which instructs the tool to only consider paths in which the given property occurs infinitely often, for example, only when the system does not wait indefinitely.  Modeling layer (fourth layer): allows Verilog, SystemVerilog, VHDL, or other code to be included inline in a PSL specification.\n The intention here is to allow addition details about the system under test to be included in the PSL source file.\n   The \u0026ldquo;e\u0026rdquo; language  developed by Verisity as part of its Specman product as a tool for efficiently writing test benches. an imperative object-oriented language, with following features:  concurrency, the ability to generate constrained random values, mechanisms for checking functional (variable value) coverage, a way to check temporal properties (assertions).  Syntax of \u0026ldquo;e\u0026rdquo;:  all code must be enclosed in \u0026lt;' and '\u0026gt; symbols; otherwise it will be comments; declarations are written in \u0026ldquo;name: type.\u0026rdquo; fields in compound types (e.g., structs) includes particles such as % and !. % indicate when a field is to be driven on the device under test; ! indicates when a field is not randomly computed.    SystemVerilog  1983-1984, Verilog HDL; buoyed largely by the speed of its \u0026ldquo;XL\u0026rdquo; gate-level simulation algorithm;  1995, IEEE standard; 1999, Superlog, a Verilog dialect, extended with software-like constructs; adopted in Verilog standardization body in 2002; 1995, Vera language, for describing Verilog test benches; 1998 bought by Synopsys; 2001 OpenVera by Synopsys; 2005, Verilog, Superlog, OpenVera were merged to produce the SystemVerilog standard;  One of the SystemVerilog\u0026rsquo;s strengths remains its ability to represent test benches along with the model being tested；\n The following example: a test bench for a simple multiplexier mux. It applies a sequence of inputs over time and prints a report of the observed behavior.\nmodule testbench; logic a, b, sel, f; mux dut(f, a, b, sel); initial begin $display(“a,b,sel -\u0026gt; f”); $monitor($time,, “%b%b%b -\u0026gt; ”, a, b, sel, f); a = 0; b = 0; sel = 0; #10 a = 1; #10 sel = 1; #10 b = 1; #10 a = 0; #10 sel = 0; #10 b = 0; end endmodule  the output of the example:\na,b,sel -\u0026gt; f 0 000 -\u0026gt; 0 10 100 -\u0026gt; 1 20 101 -\u0026gt; 0 30 111 -\u0026gt; 1 40 011 -\u0026gt; 1 50 010 -\u0026gt; 0 60 000 -\u0026gt; 0   Random test generation taken from Vera language;\n Coverage constructs;\n Temporal assertions; allow a test engineer to specify both desirable and undesirable properties that take place over one, two, or more clock cycles;\n originally from the formal verification community; but only for a system when is being subjected to random test vectors;  Verilog Shortcommings:\n Compared to VHDL: SystemVerilog does a poor job at protecting users from themselves. Verilog\u0026rsquo;s variables are shared variables and the language permits all the standard pitfalls associated with them;  such as races and nondeterministic behavior; SystemVerilog allows more dangerous usage;    The implementation in Figure 15.12a appears to be correct, but in fact may not behave as expected because the language says the simulator is free to execute the three always blocks in any order when they are triggered. If the processes execute top to bottom, the module becomes a one-stage shift register, but if they execute bottom to top, the behavior is as intended. The real danger here is that the simulation might work as desired but the synthesized circuit may behave differently, defeating the value of the simulation.\nFigure 15.12b shows a correct implementation of the shift register that uses nonblocking assignments to avoid this problem. The semantics of these assignments are such that the value on the right-hand side of the assignment is captured when the statement runs, but the the actual assignment of values is only done at the \u0026ldquo;end\u0026rdquo; of each instant in time, that is, after all three blocks have finished executing. As a result, the order in which the three assignments are executed does not matter, and therefore the code always behaves like a three-stage shift register.\nNon-blocking assignments. ???\nVHDL  Created in 1983 and 1984, essentially concurrently with Verilog;  IEEE standard 1076 in 1987, revised in 1993,2002, 2008; The orignal objectives of the VHDL language were to provide a means of documenting hardware (i.e., as an alternative to imprecise English descriptions) and verifying it through simulation. As such, a VHDL simulator was developed along with the language. A verbose syntax derived from Ada;  Like SystemVerilog, VHDL describes designs as a collection of hierarchical modules; Unlike SystemVerilog, VHDL splits modules into syntactically into two parts:  interfaces: called entities, and their implementations, called architectures;  Case Insensitive;  Bit and BIT are equivalent;   Verification in VHDL  Assertions;\n can be used to check temporal properties;\nprocess begin wait until clk\u0026#39;event and clk = \u0026#39;1\u0026#39; and request = \u0026#39;1\u0026#39;; wait until clk\u0026#39;event and clk = \u0026#39;1\u0026#39;; assert acknowledge = \u0026#39;1\u0026#39;; end process; support PSL constructs: assert always (request -\u0026gt; next acknowledge);\n   SystemC  \u0026ldquo;The few commercial products that have provided hardware synthesis from SystemC have met with little commercial success\u0026rdquo;.\n Much faster for higher-level models than Verilog/HDL;\n On detailed models, the simulation speed of a good compiled-code Verilog or VHDL simulator may be better;\n the contex-switching cost in SystemC is higher than that of a good Verilog/VHDL simulator when running a more detailed model; a system with many small processes would not simulate as quickly;   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/eda-fm/digital-sim/",
	"title": "Logic Verification -- Digital Simulation",
	"tags": [],
	"description": "",
	"content": " References:\n Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition.  Chapter 16   Simulation: when the program (or model) runs correctly, then one can be reasonably assured that the logic of the design is correct, for the cases that have been tested in the simulation.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/mips/",
	"title": "Mips",
	"tags": [],
	"description": "",
	"content": " Reference: MIPS directives.\nDirectives .set pop/push The directives .set push and .set pop may be used to save and restore the current settings for all the options which are controlled by .set. The .set push directive saves the current settings on a stack. The .set pop directive pops the stack and restores the settings.\nThese directives can be useful inside an macro which must change an option such as the ISA level or instruction reordering but does not want to change the state of the code which invoked the macro.\nTraditional MIPS assemblers do not support these directives.\n.set mipsn  CP0  Reference 1 Regs Reference 1 EntryLo0: low half of TLB entry for even virtual address (VPN) EntryLo1: low half of TLB entry for odd virtual address (VPN) R4000 book. ↩ reference ↩  Instructions  Reference: https://github.com/MIPT-ILab/mipt-mips/wiki/MIPS-Instruction-Set  Regs  Source: https://github.com/MIPT-ILab/mipt-mips/wiki/MIPS-registers http://www.cs.uwm.edu/classes/cs315/Bacon/Lecture/HTML/ch05s03.html Number Name Use Preserved across function calls? 0 $zero constant 0 — 1 $at assembler temporary no 2, 3 $v0, $v1 function return values no 4 - 7 $a0 - $a3 function arguments no 8 - 15 $t0 - $t7 temporaries no 16 - 23 $s0 - $s7 temporaries yes 24, 25 $t8, $t9 temporaries no 26, 27 $k0, $k1 reserved for OS kernel — 28 $gp global pointer — 29 $sp stack pointer — 30 $s8 temporaries yes 31 $ra return address —  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxsw/",
	"title": "Software Mechanisms",
	"tags": [],
	"description": "",
	"content": "Put malicious part (or security part) into a box, using pure software. Example:\n Process-based, or thread-based Isolation SFI and its variants   Lang Sep  References: reference More Fidelius Charm: Isolating Unsafe Rust Code Reference 1 Rust: memory safety is lost when any unsafe blocks are used. Fedelius Charm(FC): limiting access to the program\u0026rsquo;s memory while executing unsafe libraries: move sensitive program data to protected pages before entering unsafe code; call userspace lib e.g. fc_immutable in which call system call mprotect to change page permission bits and switch to isolated mode; allow unsafe code to run normally without modifications; restore visibility of the protected state when unsafe code completes; call userspace lib e.\n Byte Sfi  Reference: Fast Byte-Granularity Software Fault Isolation. SOSP, 2009. Byte Granularity Isolation (BGI) is implemented as a compiler plug-in that genrates instrumented code for kernel extenstions, and an interposition library that mediates communication between the extensions and the kernel. BGI runs extensions in separate protection domains that share the same address space. It associates an access control list (ACL) with each byte of virtual memory that lists the domains that can access the byte and how they can access it.\n Usfi  uSFI1. Ultra-lightweight software fault isolation for iot-class devices. DATE, 2018. ↩  Google Native Client Sandboxing  Reference: NaCl1, PNaCl2 Original NaCl Inner sandbox, the NaCl module: code section is read-only and statically linked; code section is conceptually divided into fixed sized bundles of 32 bytes. All valid instructions are reachable by a dissassembly starting at a bundle beginning. All indirect control flow instructions are replaced by a multiple-instruction sequence (pseudo-instruction) that ensures target address alignment to a bundle boundary. No instructions or pseudo-instrucitons in the binary crosses a bundle boundary.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxhw/",
	"title": "Hardware Mechanisms",
	"tags": [],
	"description": "",
	"content": " Intel SGX Hardware Capabilities   Rings  Reference 1 Lord X86 Reference 1 Lord of the x86 Rings: A Portable User Mode Privilege Separation Architecture on x86. CCS, 2018. ↩ reference ↩  SSM  Reference1 reference ↩  Trustzone  See Architecture - ARM - TrustZone\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/riscv/",
	"title": "RISC-V",
	"tags": [],
	"description": "",
	"content": " References:\n[1] TIMBER-V: Tag-Isolated Memory Bringing Fine-grained Enclaves to RISC-V. NDSS, 201902. paper\n[2] XuanTie 910, Pingtouge (Honey Badger), 20190725.\nRISCV Terms  Hart: Hardware thread. Spec 20191213, Page 2.  More  Attacks  Reference1 A2: Analog Malicious Hardware Reference1 \u0026ldquo;In the open spaces of an already placed and routed design, we contruct a circuit that use capacitors to siphon charge from nearby wires as they transition between digital values.\u0026rdquo; \u0026ldquo;When the capacitors fully charge, they deploy an attack that forces a victim flip-flop to a desired value, e.g the privileged bit for the processor.\u0026rdquo; \u0026ldquo;We replace the hundreds of gates required by conventional counter-based triggers implemented using digital logic with analog components \u0026ndash; a capacitor and a few transistors wrapped-up in a single gate.\n Ibex  References: ibex docs ibex rtl on github RTL Coding ibex core integration Main module is ibex_top, defined in ibex_top.sv Core logic is split-out from the register file and RAMs under ibex_top. This is to facilitate a dual-core lockstep implementation. Register File RegFile defined in rtl/ibex_pkg.sv Three register file implementations, depending on different target technologies: ibex_pkg::RegFileFF: flip-flop-based, default; ibex_pkg::RegFileLatch: latch-based; ibex_pkg::RegFileFPGA: for FPGA target; Identification CSRs Read-only CSRs, defined in rtl/ibex_pkg.\n Sonic Boom  Instruction Fetch References: Docs » Instruction Fetch The Front-end fetches instructions and makes predictions throughout the Fetch stage to redirect the instruction stream in multiple fetch cycles (F0, F1\u0026hellip;) Misprediction: Detected in BOOM\u0026rsquo;s Back-end(execution pipeline); A request is sent to the Front-end; ICache: Virtually indexed, physically tagged set-associative cache; To save power, the i-cache is only fired up again once the fetch register has been exhausted (or a branch prediction directs the PC elsewhere).\n J Extension  References: Pointer Masking Proposal, 2022-10 Pointer Masking Feature of RISC-V: when enabled, the MMU will ignore the top N bits of the effective address. Then the application can use these top N bits in their own ways. Most commonly, those bits are used to store various type of tags, which can be leveraged by a number of hardware/software features, including sandboxing mechanisms and dynamic safety checkers such as HWASAN.\n IOPMP  References: Syntacore IOPMP proposal. v.20210124, mailto:stanislav.zhelnio@syntacore.com Proposal Overview \u0026ldquo;The block is designed to filter requests to memory and peripherals\u0026rdquo; \u0026ldquo;Requests are checked on the basis of request address (and size) and the request source ID (SID)\u0026rdquo; Possible usage scenarios: filtering the CPU requests when the CPU PMP managed by OS or hypervisor is not trusted; filtering the DMA requests when the IOMMU settings managed by hypervisor are not trusted; filtering all the requests to memory or peripheral device.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/book-soft/v2-plf/",
	"title": "V2 Programming Language Foundations",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/smart-sep/",
	"title": "&#39;Smart&#39; Privilege Separation",
	"tags": [],
	"description": "",
	"content": " Collection of works about\n compiler or formal methods assisted privilege separation. large scale analysis tools for privileges.  More  2019 CCS: Program-mandering: Quantitative Privilege Separation  References: Liu, Shen, Dongrui Zeng, Yongzhe Huang, Frank Capobianco, Stephen McCamant, Trent Jaeger, and Gang Tan. \u0026ldquo;Program-mandering: Quantitative privilege separation.\u0026rdquo; In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pp. 1023-1040. 2019. Input: a) source code + user annoations on sensitive functions/globals; b) metircs budgets and the optimization goal. Output: A set of functions and globals that should be included in the sensitive domain.\n 2015 SOAAP  Security-Oriented Analysis of Application Programs (SOAAP)[^c1]. LLVM-based tool; uses source code annotations for compartmentalization hypotheses. Able to help with: creating new compartmentalizations for complex applications; discover design faults in existing compartmentalized applications. Challenges Reasoning about the compartmentalization tradeoffs is difficult: Information about past vulnerabilities is not easily accessible; Call graphs of compartmentalized applications are extremely complex; Simple control-flow analysis cannot follow manually encoded cross-domain actions \u0026ndash; such as those via IPC; reasoning about information flow; failures caused by compartmentalization are hard to debug and testing; performance impacts are difficult to predict and control.\n PrivAnalyzer: Measuring the Efficacy of Linux Privilege Use  Reference: 2019 PrivAnalyzer1 PrivAnalyzer: Measuring the Efficacy of Linux Privilege Use. DSN, 2019 ↩  Secure web applications via automatic partitioning  Reference: Secure web @ 2007SOSP1. Secure web applications via automatic partitioning. SOSP, 2007. ↩  Privtrans: Automatically Partitioning Programs for Privilege Separation  References: Privtrans @ 2004SP1; Privilege separation in OpenSSH2; Partition a single program into two parts: a monitor, relegated all trust an privileges; a small TCB; a slave. Q \u0026amp; A What kind of static analysis techniques are used? LLM: user annotation for privileged variables and functions; then inter-procedural static analysis to propagate attributes; \u0026ldquo;meet-over-all-path\u0026rdquo; data-flow analysis to find proper place to insert calls to the monitor.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/reading/",
	"title": "Reading",
	"tags": [],
	"description": "",
	"content": " How to read papers:\n Summarizing 12 months of reading papers. By Alastair Reid, Google.  ~100 papers per year.   Conference paper collections:\n ACM OpenTOC  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-temporal/2019-micro-cherivoke/",
	"title": "[2019 Micro] CHERIvoke: Characterising Pointer Revocation using CHERI Capabilities for Temporal Memory Safety.",
	"tags": [],
	"description": "",
	"content": " References:\n CHERIvoke: Characterising Pointer Revocation using CHERI Capabilities for Temporal Memory Safety. pdf. MICRO, 2019.  Overview A new allocator with quanrantine buffer that stores \u0026ldquo;to-be-revoked\u0026rdquo; segments.\n Quanrantine Buffer (delayed sweeping): a list of object addresses that are freed but not safe to be reused yet.  These addresses are kept in a cached list of addresses of freed object; addresses in this buffer cannot be reused (not really freed yet); only do sweep when the buffer is full; and address is available for reuse after sweep (here have the real free); sweep all memory that could contain references to the heap; invalidate any capability references that points to any region in the quanrantine buffer; sweep using a shadow map to store revocation metadata (1 bit for every 16-byte granule of the heap; 1\u0026frasl;128);  Revocation Shadow Map: bit-map for quarantined objects (fast look-up):  bit-mapped tags for all heap memory; 1-bit for 16 byte of heap; every allocation in quanrantine buffer is \u0026lsquo;painted\u0026rsquo; in this map, indicating a to-be-revoked region in the heap;  To Sweep:  scan all memory for references for each reference, perform a look-up at this map to determine whether to revoke the reference (capability/pointer); use the base of the reference to detect if it is pointing into a revoked object;   new allocator dlmalloc_cherivoke to replace dlmalloc.\n(- set the bounds of its returns to match the requested allocation.)\nQuanrantine buffer:\n maintains a quarantine buffer proportional to heap size; free() insert allocations to a quanrantine buffer; when certain limit reaches, dlmalloc_cherivoke logs a simulated sweep event and returns all chunks in the quarantine buffer to the internal free list.  Shadow map:\n each mmap() call is accompanied by a smaller mapping at a fixed transform/shifting from the original allocation. when a region is unmapped, its corresponding shadow map is also unmapped. delays shadow-space operation until a simulated sweep is triggered.  before the sweep event, we traverse the quanrantined chunks in the buffer and set shadow-map bits for each. after a sweep event, these bits are cleared.  shadow-map painting precedure optimized: large and ligned contiguous regions use byte, half-word, word, and double-word store instructions when possible, rather than setting individual bits.  Sweep Optimization:\n Sweep locations: anywhere that can contain references to the heap.\n heap, stack, register files, global segments(.data, .bss)  Goal: a highly optimized inner loop.\n Optimization:\n should fully utilize the DRAM bandwidth of the system; can extends direct memory access (DMA) engines or digital signal processors (DSPs) in the system to perform this loop at bus speed and without CPU involvement.   simulation for x86-64 (Chapter 5.3 Sweeping Cost):\n dump the core image periodically when the quarantine buffer is full; preprocess the image to identify all virtual addresses that lie within regions of the core dump; zero all non-pointer words. This way, a test against zero will simulate the ability to test the capability tag. core dump also preserves the revocation shadow map, which is used during the sweep.  Evaluation CHERI FPGA platform (derived from 1). 64-bit MIPS IV ISA. MIPS R4000. BERI in Bluespec SystemVerilog[^2014-isca-c4]. Altera Stratix IV FPGA. 100MHz, single core, 256KiB LLC, 6-stage in-order scalar pipeline, 1GiB DDR2, with Branch predictor. FreeBSD 10.\nCHERIvoke on a modern x86-64 machine. Intel Core i7-7820HK CPU, 2.9GHz, 4 cores 8 threads, 8MiB LLC, 14-18 stage out-of-order superscalar pipeline, AVX2 support, 16GiB DDR4 2400, FreeBSD 12.0.\n\u0026ldquo;To measure their impact on performance, we have desigend experiments to evaluate CHERIvoke revocation on a modern x86-64 machine to establish performance expectations for a wide deployment of mature CHERI implementations.\u0026rdquo;\n\u0026ldquo;Perform revocation sweeps on the CHERI FPGA implementation over application dumps taken from our x86 system, allowing us to measure data elimination for applications that are not yet able to execute natively on the CHERI-MIPS architecture. \u0026ldquo;\nReference 2\n[^2014-isca-c4] Bluespec SystemVerilog Version 3.8 Reference Guide, Bluespec, Inc., Waltham, MA, November 2004.\n  https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/201406-isca2014-cheri.pdf ↩ CHERIvoke: Characterising Pointer Revocation using CHERI Capabilities for Temporal Memory Safety. pdf. MICRO, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-ccall/",
	"title": "Libcheri CCall and Trampolines",
	"tags": [],
	"description": "",
	"content": " libcheri_ccall.c\nThis file provides the C implementation of the userspace CCall trampoline for libcheri. Three object types are used: CCall path into rtld initialization, invocation, and CReturn.\nFor CCall data capabilities, we use the sandbox object pointer, where we can find any data required to perform the domain transition, including a suitable capability for use with TLS.\nCurrently, this means deriving these sealed data capabilities from DDC. (LLM: ??? where to derive in the future)\nFor CReturn data capabilities, we use a pointer to a global data structure that contains a suitable capability for use with TLS \u0026ndash; as with above, we currently derive this capability from DDC.\n XXXRW: Will we also want to do something to provide per-thread execution stacks to handle failures in CCall and CReturn.\nXXXRW: How to handle signal delivery during CCall and CReturn?\n init, ccall, and creturn vectors External assembly trampolines for Initialization, CCall/invocation and CReturn. Ideally the rtld and general invocation vectors might be shared, but userspace CCall cannot currently reliable access the operand object type (see comments in trampoline source code: L129.)\n// file // lib/libcheri/libcheri_ccall.c extern void\tlibcheri_ccall_rtld_vector; extern void\tlibcheri_ccall_invoke_vector; extern void\tlibcheri_creturn_vector; They are trampolines defined in lib/libcheri/mips/libcheri_ccall_trampoline.S. More details here.\nSealing capabilities Sealing capabilities used to seal invocation, rtld, and creturn capabilities.\n// file // lib/libcheri/libcheri_ccall.c static void * __capability libcheri_ccall_invoke_type; static void * __capability libcheri_ccall_rtld_type; static void * __capability libcheri_creturn_type; Three sealed capabilities The following sealed capabilities are shared across all sandbox objects: code for invocation and rtld; code and data for creturn:\n// file // lib/libcheri/libcheri_ccall.c static void * __capability\tlibcheri_ccall_invoke_sealed_code; static void * __capability\tlibcheri_ccall_rtld_sealed_code; static struct cheri_object\tlibcheri_creturn_object; CCall init libcheri_ccall_init(void), defined in file lib/libcheri/libcheri_ccall.c\nThis is a one-time initialisation of libcheri on startup:\n (1) Initialise sealing capabilities for invocation, rtld, and creturn; and (2) Initialise sealed capabilities where the values will be shared across many sandboxes.  Initialize the sealing cap:\n// file // lib/libcheri/libcheri_ccall.c: libcheri_ccall_init(void)  /* * Initialise sealing capabilities for invocation, rtld, and creturn, * */ libcheri_ccall_invoke_type = libcheri_type_alloc(); libcheri_ccall_rtld_type = libcheri_type_alloc(); libcheri_creturn_type = libcheri_type_alloc(); /* * Pointer to the invocation vector. */ cap = cheri_getpcc(); cap = cheri_setaddress(cap, (vaddr_t)\u0026amp;libcheri_ccall_invoke_vector); libcheri_ccall_invoke_sealed_code = cheri_seal(cap, libcheri_ccall_invoke_type); /* * Pointer to the rtld vector. */ cap = cheri_getpcc(); cap = cheri_setaddress(cap, (vaddr_t)\u0026amp;libcheri_ccall_rtld_vector); libcheri_ccall_rtld_sealed_code = cheri_seal(cap, libcheri_ccall_rtld_type); /* * Pointer to the creturn vector, with global bounds in order to * provide access to the trusted stack (etc). There is no * call-specific data, so use dummy data. * * XXXRW: Global bounds only for code, not data..? */ cap = cheri_getpcc(); cap = cheri_setaddress(cap, (vaddr_t)\u0026amp;libcheri_creturn_vector); libcheri_creturn_object.co_codecap = cheri_seal(cap, libcheri_creturn_type); #ifdef __CHERI_CAPABILITY_TLS__ \tcap = \u0026amp;libcheri_creturn_data; #else \t/* * Needed without bounds so it covers TLS. */ cap = cheri_getdefault(); cap = cheri_setaddress(cap, (vaddr_t)\u0026amp;libcheri_creturn_data); #endif \tlibcheri_creturn_object.co_datacap = cheri_seal(cap, libcheri_creturn_type);  Trampolines  file: lib/libcheri/mips/libcheri_ccall_trampoline.S This file contains \u0026ldquo;userspace implementation of libcheri invocation and return semantics\u0026rdquo;. \u0026ldquo;These vectors are intended to run on the inside of sealed call and return code capabilities, perform any necessary checks, transform the capability register file, and then jump into the target domain. Outline of trampolines Three types of objects and with corresponding three kinds of CCalls: for rtld init: libcheri_ccall_rtld_vector: is used for rtld initialization and destruction.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/attacks/conpe/",
	"title": "Container Privilege Escalation",
	"tags": [],
	"description": "",
	"content": "Reference:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/attacks/",
	"title": "Attacks",
	"tags": [],
	"description": "",
	"content": "Reference:\n Sgx  Reference 1 2010-03-10 unfixable flaw reference ↩  Rop  Reference 1 Return Oriented Programming Attacks reference ↩  Container Privilege Escalation  Reference:  DOP  Data Oriented Programming Attacks  Side Channel   References: reference More Spectre Attacks References: Survey of Transient Execution Atacks. Wenjie Xiong, Jakub Szefer. Arxiv, 2020. More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/",
	"title": "Privilege Separation",
	"tags": [],
	"description": "",
	"content": " Todos  Privtrans 3.2.2 and forward. 20190802  Top wonderings  How to automatically achieve privilege separation, or program partition, for as many partions as we need, and every partition has its least privilege?\n A maximum numbers of partitions possible to do automatically (minimum = no partition)?  How to find the number of partitions we actually need?\n How to determine the bounds of each partition, and the least privilege of a partition?\n How to define and restrict the communications between partitions?\n Just as DSA using pointer analysis to automatically find the disjoint memory objects, and using the result to partition the memory into pools, could we also leverage pointer analysis to find some disjoint program modules with its own code and data, and use the result to automatically partition a program?\n  Example Evaluations For Privilege Separation  Kernel Drivers, see:\n 2009 SOSP, BGI 2015 ASPLOS, Nested Kernel 2019 arxiV, Neverland  OpenSSL, see:\n 2019 Usenix Security, ERIM, Intel MPX 2008 NSDI, Wedge 2016 OSDI, lwC 2018, Unsafe Rust 2015 CCS, SOAAP, has code.  wget, see:\n 2013 SP, Capsicum Automatic Instrumentation, Harris 2019 CCS, PM  fetch, see:\n 2015 CCS, SOAAP, has code.  OpenSSH, see:\n 2003 USENIX Security, Preventing Privilege Escalation 2004 SP, Privtrans 2008 NSDI, Wedge 2014 ASPLOS, SVA 2015 CCS, SOAAP, has code.    Process or thread-like solutions for Privilege Separation  Many used in automatic separtion More 2009 Eurosys: Isolating Web Programs in Modern Browser Architectures References: Reis, Charles, and Steven D. Gribble. \u0026ldquo;Isolating web programs in modern browser architectures.\u0026rdquo; In Proceedings of the 4th ACM European conference on Computer systems, pp. 219-232. 2009. More Preventing Privilege Escalation 2003 USENIX Security1: Privilege Escalation Services that require special privilege for their operation are critically sensitive.\n Capability based privilege separation   More Capsicum CHERI Compartmentalization  Isolation at instruction level  Reference [^1] Userspace store/load on ARM. Arm Inst Iso Reference 1 Instruction-Level Data Isolation for the Kernel on ARM. DAC\u0026rsquo;17. ↩  Intel SGX  Reference1 2 Interactions Reference: Overview of Intel SGX, part2 ECALL: Enclave Call. Application invokes a pre-defined function inside the enclave. can pass input parameters and pointers to shared memory within the application. OCALL: Outside Call. Enclave invokes a pre-defined function in the application. An OCALL cannot share enclave memory with the application; It must copy the parameters into the application memory before the OCALL; AEX: Asynchronous Exit.\n Software Mechanisms  Put malicious part (or security part) into a box, using pure software. Example: Process-based, or thread-based Isolation SFI and its variants Lang Sep References: reference More Fidelius Charm: Isolating Unsafe Rust Code Reference 1 Rust: memory safety is lost when any unsafe blocks are used. Fedelius Charm(FC): limiting access to the program\u0026rsquo;s memory while executing unsafe libraries: move sensitive program data to protected pages before entering unsafe code; call userspace lib e.\n Hardware Mechanisms   Intel SGX Hardware Capabilities Rings Reference 1 Lord X86 Reference 1 Lord of the x86 Rings: A Portable User Mode Privilege Separation Architecture on x86. CCS, 2018. ↩ reference ↩ SSM Reference1 reference ↩ Trustzone See Architecture - ARM - TrustZone  \u0026#39;Smart\u0026#39; Privilege Separation  Collection of works about compiler or formal methods assisted privilege separation. large scale analysis tools for privileges. More 2019 CCS: Program-mandering: Quantitative Privilege Separation References: Liu, Shen, Dongrui Zeng, Yongzhe Huang, Frank Capobianco, Stephen McCamant, Trent Jaeger, and Gang Tan. \u0026ldquo;Program-mandering: Quantitative privilege separation.\u0026rdquo; In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pp. 1023-1040. 2019. Input: a) source code + user annoations on sensitive functions/globals; b) metircs budgets and the optimization goal.\n Fine-grained privilege separation   References: reference More 2020 Sec Firefox Reference 1 Shravan Narayan, Craig Disselkoen, Tal Garfinkel, Nathan Froyd, Eric Rahm, Sorin Lerner, Hovav Shacham, and Deian Stefan.RLBox: Retrofitting Fine Grain Isolation in the Firefox Renderer. In Proceedings of USENIX Security Symposium. August, 2020 ↩  Formalization for Privilege Separation   References: reference More Reasoning About a Machine with Local Capabilities: Provably Safe Stack and Return Pointer Management Formalizing the Security Guarantees of Compartmentalizing Compilation  2015 Nested Kernel   References: Dautenhahn, Nathan, Theodoros Kasampalis, Will Dietz, John Criswell, and Vikram Adve. \u0026ldquo;Nested kernel: An operating system architecture for intra-kernel privilege separation.\u0026rdquo; In Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 191-206. 2015. More  Enclave-Aware Compartmentalization and Secure Sharing with Sirius   References: Tarkhani, Zahra, and Anil Madhavapeddy. \u0026ldquo;Sirius: Enabling System-Wide Isolation for Trusted Execution Environments.\u0026rdquo; arXiv preprint arXiv:2009.01869 (2020). More  μTiles: Efficient Intra-Process Privilege Enforcement of Memory Regions   References: Tarkhani, Zahra, and Anil Madhavapeddy. \u0026ldquo;$\\mu $ Tiles: Efficient Intra-Process Privilege Enforcement of Memory Regions.\u0026rdquo; arXiv preprint arXiv:2004.04846 (2020). More  2020 Isca Nested Sgx   References: Park, Joongun, Naegyeong Kang, Taehoon Kim, Youngjin Kwon, and Jaehyuk Huh. \u0026ldquo;Nested enclave: supporting fine-grained hierarchical isolation with SGX.\u0026rdquo; In 2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA), pp. 776-789. IEEE, 2020. More  Civet: An Efficient Java Partitioning Framework for Hardware Enclaves   References: Tsai, Chia-Che, Jeongseok Son, Bhushan Jain, John McAvey, Raluca Ada Popa, and Donald E. Porter. \u0026ldquo;Civet: An Efficient Java Partitioning Framework for Hardware Enclaves.\u0026rdquo; In 29th {USENIX} Security Symposium ({USENIX} Security 20). 2020. More  Donky: Domain Keys – Efficient In-Process Isolationfor RISC-V and x86  References: Schrammel, David, Samuel Weiser, Stefan Steinegger, Martin Schwarzl, Michael Schwarz, Stefan Mangard, and Daniel Gruss. \u0026ldquo;Donky: Domain Keys–Efficient In-Process Isolation for RISC-V and x86.\u0026rdquo; In 29th {USENIX} Security Symposium ({USENIX} Security 20), pp. 1677-1694. 2020. Evaluation Three realistic use cases: Secure V8 Sandboxing; Software Vaults; Untrusted Third-party libraries; Two Implementations: RISC-V Ariane CPU, Synthesized on FPGA Intel-MPK-based emulation for X86 Cross-domain switches are 16-116x faster than regular process context switches.\n 1989 SP: A Secure Identity-Based Capability System   References: Gong, Li. \u0026ldquo;A Secure Identity-Based Capability System.\u0026rdquo; In IEEE symposium on security and privacy, pp. 56-63. 1989. ICAP: An Identity-based CAPability protection system. More  2012\u0026#39;SEC AdSplit: Separating smartphone advertising from applications   References: Shekhar, Shashi, Michael Dietz, and Dan S. Wallach. \u0026ldquo;Adsplit: Separating smartphone advertising from applications.\u0026rdquo; In Presented as part of the 21st {USENIX} Security Symposium ({USENIX} Security 12), pp. 553-567. 2012. More  2008 Osdi Loki  Reference 1 Hardware enforcement of application security policies using tagged memory. 2008, OSDI. ↩  Xoar: Breaking up is hard to do: security and functionality in a commodity hypervisor  Reference 1 Xoar: a modified version of Xen. Breaks the control VM into multiple single-purpose components called service VMs. Colp, Patrick, Mihir Nanavati, Jun Zhu, William Aiello, George Coker, Tim Deegan, Peter Loscocco, and Andrew Warfield. \u0026ldquo;Breaking up is hard to do: security and functionality in a commodity hypervisor.\u0026rdquo; In Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles, pp. 189-202. 2011. ↩  2016 Sp Shreds  Reference 1 reference ↩  2016 OSDI Light-weight Contexts: An OS Abstraction for Safety and Performance  light-weight Context (lwC) A first-class OS abstraction that extends the POSIX API, and present common coding patterns demonstrating its different uses. A process may contain multiple lwCs, each with their own virtual memory mappings, file descriptor bindings, and credentials, and those can also be selectively shared. lwCs are not schedulable entities: they are completely orthogonal to threads that may execute within a process. A thread may start in lwC a, then invoke a system call to switch to lwC b.\n 2015 Atc Arbiter  Reference 1 J. Wang, X. Xiong, and P. Liu. Between Mutual Trust and Mutual Distrust: Practical Fine-grained Privilege Separation in Multithreaded Applications. In 2015 USENIX Annual Technical Conference (USENIX ATC 15), pages 361–373, Santa Clara, CA, July 2015. USENIX Association. ↩  2015 Salus  Reference 1 R. Strackx, P. Agten, N. Avonds, and F. Piessens. Salus: Kernel Support for Secure Process Compartments. EAI Endorsed Transactions on Security and Safety, 15(3), 1 2015. ↩  2008 Nsdi Wedge  Reference: A. Bittau, P. Marchenko, M. Handley, and B. Karp. Wedge: Splitting Applications into Reduced-privilege Compartments. In Proceedings of the 5th USENIX Symposium on Networked Systems Design and Implementation, NSDI’08, pages 309–322, Berkeley, CA, USA, 2008. USENIX Association. Evaluation Apache/OpenSSL Introducing compartments to preserve the confidentiality and integrity of SSL connnections. protect the server\u0026rsquo;s RSA private key prevent one user from obtaining the cleartext sent over another user\u0026rsquo;s SSL connection or prevent one user from injecting content to another user\u0026rsquo;s SSL connection.\n 2016 CCS SMV  Questions How to determine and represent boundaries? Which level of the page is tagged? Virtual or Physical? ANS: virtual page is tagged with permissions. Memory protection domain is defined as a countigous range of virtual memory. How to design a secure call gate to cross boundaries? How many compartments in the benchmarks? Reference 1 3 generations of privilege separation 1st gen: split a process into different single-process compartments.\n 2019 Pyronia  Reference 1 IoT devices are mostly single-purpose running a dedicated, single application. As a result, vulnerabilities in third party libraries within a process pose a much bigger threat than on traditional platforms. Pyronia: protects against untrusted third-party code with unmodified source code. Goals: control how an application may obtain data from files/devices; control how in-memory data is propagated within an application, specifically between lib and app; control to which remote network destinations an application may export data Design:\n AsiaCCS\u0026#39;12 AdDroid: Privilege Separation for Applications and Advertisers in Android  References: AdDroid: Privilege Separation for Applications and Advertisers in Android. By Paul Pearce, Adrienne Porter Felt, Gabriel Nunez, and David Wagner. AsiaCCS, 2012. Overview: Problem from Study: Overprivileging of ads: 49% of android apps contain at least one ad library; these libraries overprivilege 46% of ad-supported apps; 56% of apps with ads that request location (34% of all apps) only because of ads; Solution: a new ad framework, AdDroid, to apply privilege separation to advertising libraries:\n Hardscope  Reference 1 Non-control data attacks: DOP. Lexical scope for every variable in C/C++: Statically checked at compile time but can be violated at runtime, leveraged by DOP. Solution: Run-time Scope Enforcement (RSE): fine-grained compartmentalization of data memory within programs. hardware assisted RSE scheme: a set of six new instructions; compiler instrumentation; creating runtime rules defining which code blocks can access which pieces of memory. rules as a stack; check on every load/store; check simultaneously with ?\n 2018 Micro Stache  Reference 1 MicroStache: A lightweight Execution Context for In-Process Safe Region Isolation. ↩  BreakApp: Automated, Flexible Application Compartmentalization   Vasilakis, Nikos, Ben Karel, Nick Roessler, Nathan Dautenhahn, André DeHon, and Jonathan M. Smith. \u0026ldquo;BreakApp: Automated, Flexible Application Compartmentalization.\u0026rdquo; In NDSS. 2018.  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/typesys/",
	"title": "Type System in SAFECode",
	"tags": [],
	"description": "",
	"content": " Q \u0026amp; A  How to do encoding? What kind of information has been encoded? How does the type checking work on those encodings? What kinds of safety property can be checked?  Program Presentation SAFECode support full C, but here a subset of C is used the simplify the presentation:\nFigure 2006DinakarPhD1, same as in 2005SAFECodeTR2: This language includes most sources of potential memory errors in the weakly typed C language, including:\n P1. dangling pointers to freed heap memory; P2. array bound violation; P3. access via uninitialized pointers, and P4. arbitrary cast from an int type to another pointer type and subsequent use.  Same as in C: int, char, cast, malloc, free;\nNew from SAFECode: alloca and galloc : alloca to allocate memory on stack; galloc to allocate/initilize global variables. These two features make it unnecessary to apply the \u0026amp; operator to get the address of a stack variable or global object; \u0026amp; is only used for indexing into structures, arrays and for function pointers. $\\rightarrow$ Lele: why is this important?\nPointer Analysis From 2006DinakarPhD1/2005SAFECodeTR2:\nIntuitively, the pointer analysis representation can be thought of as a storage-shape graph, also referred to as a points-to graph. Pointers pointing to two different nodes in the graph are not aliased.\n Each node represents a set of memory objects created by the program Two distinct nodes represent disjoint sets of memory objects.  We assume there is one points-to graph per function, since this allows either context-sensitive or insensitive analyses.\nWe use a type system to encode the results of points-to analysis (i.e., the storage shape graph) as type attributes within the program, using a type system analogous to Steensgaard\u0026rsquo;s3.\n each points-to graph node is encoded as a distinct type, as $\\rho$ defined by association $(\\rho, \\tau)$ below; each pointer in this type system has a node attribute, $\\rho$, describing the node it points to.  For example, in Figure 3 below:\nThe type of y is int*r2, denoting that it points to objects of node (or type) r2 in the points-to graph. Since a pointer can point into objects at an offset, we use $\\tau * (p, n)$ to denote the type of a pointer pointing to offset n (where n is a compile type constant), within a struct of type $\\tau$ at node $\\rho$.\nThe statement associate($\\rho,\\tau$) associates node $\\rho$ of the graph with type $\\tau$, denoting that the node $\\rho$ contains objects of type $\\tau$. These objects may be pointers, such as associate(r1, $\\tau'$ * r2): this encodes a \u0026lsquo;points-to\u0026rsquo; edge from node r1 to node r2. associate (r1, r2) also encode the edge between r1, r2. Redundant cases like this is kept to take pointer analysis results directly from Steensgaard\u0026rsquo;s like type system3.\nAs a unification-based analysis, there can be only one target node for each variable or field of pointer type.\nMemory that is used in a type inconsistent manner, e.g., via unions or casts in C, is assigned type Unknown, which is intepreted as an array of chars.\n SAFECode: A Platform for Developing Reliable Software in Unsafe Languages, Ph.D. Thesis, 2006. ↩ Enforcing Alias Analysis for Weakly Typed Languages, TR, 2005. ↩ B. Steensgaard. Points-to analysis in almost linear time. POPL, 1996. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/cets/",
	"title": "CETS: Compiler Enforced Temporal Safety for C",
	"tags": [],
	"description": "",
	"content": " Reference:\n CETS paper  Temporal errors include:\n dangling pointer dereferences (referencing an object that has been deallocated), double frees (calling free() on the same object multiple times), invalid frees (calling free() with a non-heap address or pointer to the middle of a heap-allocated region).  CETS: Compiler Enforced Temporal Safety.\nMovivation Temporal errors are challenging. Prior proposals suffer from one or more of the following deficiencies:\n high runtime overheads, high memory overheads, failure to detect all temporal errors (for example, to the stack, to reallocated heap locations, or in the face of arbitrary casts) requiring annotations inserted by the programmer, or altering memory layout (which breaks compatibility with existing C code).  Example: Widely used Valgrind Memcheck tool1:\n Fail to detect dangling pointers to reallocated data locations; Exhibits runtime overheads in excess of 10x.  Overview CETS: Compiler Enforced Temporal Safety.\nCombination of two existing techniques:\n An identifier-based scheme, which assigns a unique key for each allocation region to identify dangling pointers 2 3 4. This per-pointer metadata is tracked using a disjoint shadowspace, yielding high compatibility because memory layout is unchanged.  Optimization in prototype implementation:\n temporal-check elimination optimizations (analogous to, but different from, bounds-check elimination optimizations 5 6 7) reduces the number of checks by 70% on average.  Design and Implementation  CETS\u0026rsquo;s temporal safety properties can be guaranteed only if spatial safety is enforced too (otherwise metadata corruption could occure).\n CETS lock and key implementation CETS avoids the compatibility problems of fat pointers by borrowing the shadowspace mechanisms commonly used in location-based approaches to support per-pointer metadata without changing memory layout. See Figure 2 below:\nEach pointer with two additional word-sized fields:\n (1) a unique allocation key (2) a lock address that points to a lock location, which is queried on temporal checks 3 4.  Each allocated memory object is associated with a unique key.\nUsage of lock and key:\n Whenever memory region is allocated:  1. a unique key is associated with the region of the allocated memory; 2. a lock location is allocated; 3. the lock value is initialized to the key value. Invariant Property: the pointer is not a dangling pointer if and only if the pointer\u0026rsquo;s key and the value of the lock match.  When a memory region is deallocated:  1. the lock location associated with the memory region is set to INVALID_KEY. The lock location can be reused but only as another lock value, and never for some other purpose. 2. the memory region is marked for possible reuse. Invariant Property: Dangling pointers holding the old key will never be used for a successful dereference since the lock is either invalid or has a different lock value.  A mapping from keys to freeable pointers  defenses to temporal errors:  1. free on pointers that are not returned by malloc(). 2. call free twice:  There is at most one freeable pointer associated with that key (i.e., the one originally returned by malloc()). (LLM: only one in all cases??? how about pointer assigned to another one, or passed to another function then freed there???).   Metadata operations\n Initialization. Heap allocation. Pointer metadata propagation. Dangling pointer check. Heap deallocation. Allocation/deallocation of lock addresses. Call stack allocations and deallocations.  A key and corresponding lock address is associated with each stack frame. This key and lock pair is given to any pointer derived from the stack pointer (and thus points to an object on the stack).  Metadata propagation with function calls.  When pointers are passed as arguments or returned from functions, the key and lock address must also travel with them. Uses procedure cloning to transform every function declaration and function call site to include additional arguments for key and lock address. (LLM: backward compatibility is sacrificed.)   Formal Model of Memory Safety todo\nEvaluation Overhead 8:\n48% for temporal check;\n116% for both spatial and temporal check.\n N. Nethercote and J. Seward. Valgrind: A Framework for Heavy-weight Dynamic Binary Instrumentation. In Proceedings of the SIGPLAN 2007 Conference on Programming Language Design and Implementation, June 2007. ↩ T. M. Austin, S. E. Breach, and G. S. Sohi. Efficient Detection of All Pointer and Array Access Errors. In Proceedings of the SIGPLAN 1994 Conference on Programming Language Design and Implementation, June 1994. ↩ H. Patil and C. N. Fischer. Low-Cost, Concurrent Checking of Pointer and Array Accesses in C Programs. Software — Practice \u0026amp; Experience, 27(1):87–110, 1997. ↩ W. Xu, D. C. DuVarney, and R. Sekar. An Efficient and Backwards-Compatible Transformation to Ensure Memory Safety of C Programs. In Proceedings of the 12th ACM SIGSOFT International Symposium on Foundations of Software Engineering (FSE), 2004. ↩ R. Bodı́k, R. Gupta, and V. Sarkar.ABCD: Eliminating Array Bounds Checks on Demand. In Proceedings of the SIGPLAN 2000 Conference on Programming Language Design and Implementation, June 2000. ↩ R. Gupta. A Fresh Look at Optimizing Array Bound Checking. In Proceedings of the SIGPLAN 1990 Conference on Programming Language Design and Implementation, June 1990. ↩ T. Würthinger, C. Wimmer, and H. Mössenböck. Array Bounds Check Elimination for the Java HotSpot Client Compiler. In Proceedings of the 5th International Symposium on Principles and Practice of Programming in Java, 2007. ↩ CETS: Compiler-Enforced Temporal Safety for C, ISMM, 2010. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/context-switch/",
	"title": "CheriBSD Context Switch",
	"tags": [],
	"description": "",
	"content": " References:\n[1] CHERI programmer\u0026rsquo;s guide, chapter 8.2, UCAM-CL-TR-877, 2015.\nCapability state save/restore for each thread and domain inside.\n CheriBSD extends the kernel\u0026rsquo;s support for context management and switching to provide each user thread with its own capability-register file. This allows each thread to have its own complete capability state, compatible with the idea that capabilities are compiler-managed.\n Context switching to kernel in 3 ways:\n an initial saving of the userspace $PCC and C0 performed by the hardware and low-level exception handling code; a more complete capability register context save and restore when transitioning from a low-level exception handler to kernel C code; finally, saving and restoring of a capability-register-file subset during voluntary kernel context switches.  PCB struct extended with CHERI state Extends thread control block, pcb, with four new fields:\n pcb_cheriframe: userspace CHERI registers; pcb_cheristack: the CHERI trusted stack; pcb_cheri_signal: signal handling context to install when a signal is delivered within a sandbox; pcb_cherik_frame: caller-save registers across a kernel voluntary context switch.  Kernel state \u0026ndash; no capability 2015 programmer\u0026rsquo;s guide:\n Kernel itself makes only minor use of capabilities; Kernel is not currently compiled with a capability-aware compiler; kernel threads do not have full capability-register-file state in their own PCBs.   Currently, CheriBSD maintains a \u0026lsquo;full\u0026rsquo; CHERI capability-register context only for userspace, not the kernel, as the kernel is compiled by a CHERI-unaware compiler. Instead, the kernel uses fixed global values for C0 and PCC, and its context switches maintain two capability registers for use in setting up userspace state, performing capability-aware memory copies, etc: C11 and C12.\n Context-switching philosophy Fast-exception handlers for exception delivery -\u0026gt; full userspace context saving for a full C function execution.\nMIPS: use (K0, K1) as reserved exception handling registers;\nCHERI: saves the userspace C0 in KR2C; then installs the kernel\u0026rsquo;s own C0.\nLazy context-switching of capability-coprocessor is not currently implemented, requiring a full save and restore of the capability register file when entering kernel C code.\nPCB setup and state changes PCB CHERI state initialization: execve -\u0026gt; exec_setregs -\u0026gt;\n cheri_exec_setregs: sets up the first thread\u0026rsquo;s live and signal-handling C0, C11 (stack), IDC, and PCC registers for ambient authority; cheri_stack_init: initialize an empty trusted stack.  MIPS machine dependent state for a new thread: cpu_set_upcall -\u0026gt;\n cheri_context_copy: register context; literal cheri_signal_copy: signal delivery context; cheri_stack_copy: copy the current trusted stack the the new thread. Desiable or should get a fresh new trusted stack?  fork system call, implemented in MIPS machine depedent cpu_fork-\u0026gt; cheri_context_copy; cheri_signal_copy; cheri_stack_copy.\n4 types of context switches  Low-level exception enter/return. CHERI_EXCEPTION_ETNER, CHERI_EXCEPTION_RETURN;\n User-to-kernel switch: SAVE_U_PCB_CHERIFRAME, RESTORE_U_PCB_CHERIFRAME. This occurs if an excecption deliverd to user code cannot be satisfied without entering C code \u0026ndash; e.g. to process a full VM fault rather than just a TLB miss that a low-level assembly handler can resolve.\n Kernel involuntary switch: an exception preempts the kernel istelf (e.g. a kernel TLB miss or interrupt), the full MIPS general-purpose state will be saved by MipsKernGenException, but only C11 and C12 will be preserved, as the kernel currently use only these capability registers. In the future, this code will need to preserve a full kernel CHERI frame.\n Kernel voluntary switch: If a kernel thread sleeps (perhaps due to blocking on a mutex or waiting on I/O), then a voluntary context switch via cpu_switch, which in turn will call SAVE_U_PCB_CHERIKFRAME and RESTORE_U_PCB_CHERIKFRAME to save and restore callersave registers in the PCB.\n  Questions/Proposals compiler-manged capabilities: for compiler to be able to manage capabilities, each thread must have its own complete capability state. Extending this idea, if compiler could manage all the context switching states of a thread, we don\u0026rsquo;t need an operating system anymore, yes? So if entire system, all applications, resides in the same address space, then, we can get ride of operating system to do context switching and all work will be done by compilers, automatically. Reasonable?\nkernel code compilation: To use capability inside kernel, we must use capability-aware compiler to compile kernel code. However, currently not done yet (2015, programmer\u0026rsquo;s guide). What is the main challenge here?\n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/",
	"title": "SAFECode",
	"tags": [],
	"description": "",
	"content": " Questions/Todos  Runtime check of SAFECode.\n LLM: Runtime checks in SAFECode  Function Pointers in SAFECode?\n LLM: Function pointers are checked against a static CFG at runtime (some could be checked at compile time).  Where does the pool meta-data stored and used?\n Can we also store meta-data for all pointers in type-unknown regions?\n What is affine transformations? used in Control-C\n  Overview Memory safety in C language.\nInput:\n a program written in C; The result of a flow-insensitive, field-sensitive, unification-based pointer analysis on that program.  Includes both points-to information and type information for some subset of memory objects. The analysis may use various forms of context-sensitivity.  A call graph computed for the program.  Type inference in DSA: (2005TR1:) DSA attemps to compute type information for every \u0026ldquo;points-to set\u0026rdquo; in the program by inferring the intended type based on the uses of pointers to a points-to set object, and not based on the type declarations or cast operations in the program.\nInsights (From 2006DinakarPhD) Automatic pool allocation partitions the heap into regions based on a points-to graph. This leads us to the following new insight that is the key to the SAFECode work:\n Insight1: pool based check instead of acrossing all memory range2:\n Precondition (guarantteed by DSA): unaliasable memory objects are not allocated within the same region.\n poolcheck($ph$, A, $o$): verifies that address, A, is contained within the set of memory ranges assigned to pool, $ph$, and has the correct alignment for the pool\u0026rsquo;s data type (or for the field at offset $o$ if $o\\neq0$)\n  Insight2: No run-time check needed on initialized pointers in TK; Runtime check needed for arithmetic derived pointers and TU pointers3.\n An initialized pointer obtained from a TK region will always be valid4; It cannot have been corrupted in an unpredictable way, e.g., via arbitrary casts and subsequent stores (it would then be in a TU region).  Insight3: Reused TK region will not violate type safety5.\n Insight4: Release is safe only when no pointers into that regions6.\n  Official Document  SAFECode Software Architecture Manual Installation User Guide  Published Papers:\nControl-C in 2002CASES 7, 2003 LCTES 8, 2005Embed 9, 2005SAFECodeTR 1, 2005PLDIPool10,\n2006ICSE 11, 2006PLDI 12, 2006DinakarPhD 13, 2011Formal 14.\nImplementation The SAFECode analysis and transformation sources are organized as follows (from manual 15):\n lib/ArrayBoundChecks: This library contains several analysis passes for static array bounds checking. lib/InsertPoolChecks: This library contains the transform passes for inserting run-time checks and for inserting code to register memory objects within individual pools. It also contains the CompleteChecks pass which implements the Check Completion Phase. lib/OptimizeChecks: This library contains several passes for optimizing run-time checks. lib/RewriteOOB: This library contains passes for implementing Ruwase/Lam pointer rewriting. This code allows SAFECode to tolerate out-of-bounds pointers that are never dereferenced. lib/DebugInstrumentation: This library implements code that modifies run-time checks to contain additional debug information (if such debug information is present in the program). It is used in SAFECode’s debug tool mode. lib/DanglingPointers: This library contains a pass that modifies a pro- gram to perform dangling pointer detection.  \nIn details  Control-C  Control-C (in 2002 CASES1) , a subset of C, but with key restrictions designed to ensure that memory safety of code can be verified entirely by static checking, under certain system assumptions. Restrictions on C T1. Requires strong typing of all functions, variables, assignments, and expressions, using the same types as in C. T2. Disallows casts to or from any pointer type. Casts between other types (e.g., intergers, floating point numbers, and characters) are allowed.\n Memory Safety Without Runtime Checks or Garbage Collection  Reference1 Challenge: dangling pointers Proving statically that a general C program (for example) never dereferences a freed pointer (the \u0026ldquo;dangling pointer\u0026rdquo; problem) is undecidable. Region-based memory management, however, has been used to guaranttee the safety of pointer-based accesses to region data without garbage collection, but with limitations: 1) manual effort to convert program to use regions; 2) many solutions disallow explicit deallocation. Automatic regions inference algorithms have been developed to solve limitation completely or partially, such as in ML, or Cyclone.\n 2005Embed  Reference1: Restricted C + Compiler = Safe language benefits with no garbage collection, no runtime checks. Safe definition: define a software entity (module, thread, or a complete program) to be safe if: not out of bound: never reference a memory location outside the data area by or for the entity. no alien code execution: never executes instructions outside the code area created by the compiler and linker within that space.\n Steensgaard   Reference: B. Steensgaard. Points-to analysis in almost linear time. POPL, 1996.1 Type system B. Steensgaard. Points-to analysis in almost linear time. POPL, 1996. ↩  Type System in SAFECode  Q \u0026amp; A How to do encoding? What kind of information has been encoded? How does the type checking work on those encodings? What kinds of safety property can be checked? Program Presentation SAFECode support full C, but here a subset of C is used the simplify the presentation: Figure 2006DinakarPhD1, same as in 2005SAFECodeTR2: This language includes most sources of potential memory errors in the weakly typed C language, including:\n Runtime Checks  Runtime Check in SAFECode All pointers in Type-Unknown pools are checked. All casts from int to pointer are runtime checked to ensure in the right pool. Pointers in TU are all loaded as int1 All pointers derived from array indexing operations need run-time check (2006 PLDI1), regardless of TK or TU. More about array bound checking. All function pointers need runtime check before being used. (2005-SAFECode-TR: function pointer)\n Passes  Stack Check Reference1 safecode/include/StackSafety.h: This file defines checks for stack safety. struct checkStackSafety : public ModulePass { public : ... virtual bool runOnModule(Module \u0026amp;M); virtual void getAnalysisUsage(AnalysisUsage \u0026amp;AU) const { AU.addRequired\u0026lt;DataLayout\u0026gt;(); AU.addRequired\u0026lt;EQTDDataStructures\u0026gt;(); AU.setPreservesAll(); } private : // // Tracks the DSNodes that have already been analyzed by an invocation of // markReachableAllocas(). // std::set\u0026lt;DSNode *\u0026gt; reachableAllocaNodes; bool markReachableAllocas(DSNode *DSN, bool start=false); bool markReachableAllocasInt(DSNode *DSN, bool start=false); }; } } safecode/lib/StackSafety/CheckStackPointer.\n \n Enforcing Alias Analysis for Weakly Typed Languages, TR, 2005. ↩ Original text from 2006DinakarPhD: if memory objects corresponding to each node are located in a region of the heap, we would check efficiently at run-time that a pointer is a valid member of the compile-time points-to set for that pointer, i.e., that alias analysis is not invalidated. ↩ Original text from 2006DinakarPhD: Any initialized pointer read from an object in a TK region or from an allocation site, will hold a valid address for its target region; All other pointers, i.e., pointers derived from indexing operations, and pointers from TU regions (including function pointers), need run-time checks before being used. ↩ Precondition: In the absence of dangling pointer errors and array indexing errors ↩ From 2006 DinakarPhD: In a TK (type-homogeneous) region, if a memory block holding one or more objects were freed and then reallocated to another request in the same region with the same alignment, then dereferencing dangling pointers to the previous freed object cannot cause either a type violation or an aliasing violation. ↩ From 2006 DinakarPhD: \u0026ldquo;We can safely release the memory of a region when there are no reachable pointers into that region. This gives us a way to release memory to the system. Since Automatic Pool Allocation already binds the life times of regions (using escape analysis), we can arrange for memory to be released at the end of a region’s life time.\u0026rdquo; ↩ Ensuring Code Safety Without Runtime Checks for Real-Time Control Systems. CASES, 2002. ↩ Memory Safety Without Runtime Checks or Garbage Collection. LCTES, 2003. ↩ Memory Safety Without Garbage Collection for Embedded Applications, ACM Transactions on Embedded Computing Systems, 2005. ↩ Automatic pool allocation: Improving performance by controlling data structure layout in the heap. PLDI, 2005. ↩ Backwards-Compatible Array Bounds Checking for C with Very Low Overhead, ICSE, 2006. ↩ SAFECode: Enforcing Alias Analysis for Weakly Typed Languages, PLDI, 2006. ↩ SAFECode: A Platform for Developing Reliable Software in Unsafe Languages, Ph.D. Thesis, 2006. ↩ Formalizing the SAFECode Type System, 2011. ↩ SAFECode Software Architecture Manual ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/",
	"title": "Secure Virtual Architecture",
	"tags": [],
	"description": "",
	"content": " Todos  Where is the pool metadata created/used in SAFECode passes? Where is the runtime check instrumentation in SAFECode passes?  Learn the code from SVA on FreeBSD and propose a solution for the policy to be ported/re-implemented on CheriBSD:\n sosp 2007\n booting signal handler dispatch code I/O instructions. kernel allocators. for analysis(ch6.3): int to pointer casts, stack usage, sys_iotctl, initial task structure, stack pointer to structure.   sec 2009\n memory mapped I/O MMU configuration context switching, thread creation  sp 2014, KCoFI\n label based protection for programmed indirect jumps; a thin run-time layer protects key OS data structures like thread stacks and monitors all low-level state manipulations performed by the OS.  asplos 2014, Virtual Ghost\n compiler instrumentation run-time checks   Top Wonderings  How can SAFECode be used to enforce compartmentalization in a single address space? How does the compartmentalization look like?\n LLM: Like automatic memory partition using pointer analysis as in DSA, can we do automatic program partition using some similar static analysis techniques?  A two-compartment address space: How can we use SAFECode to eliminate the need of transition between user/kernel mode?\n LLVA-OS: Kernel operations as language semantics instead of a lib or handwritten assembled OS?\n abstracting kernel features as special imperative operations with kernel semantics compilers taking control the entire kernel code just as how it is controling an application. But this application(the kernel) is written with a new language with kernel semantics. Instead of restrict C language, how can we extend it to support OS operations as the language\u0026rsquo;s \u0026lsquo;native\u0026rsquo; mechanisms, just as go in Golang for multi-threading?   Compared to CCured with SAFECode?\n CCured (From 2014-ISCA-CHERI1): elides bounds checks where it can statically prove them unnecessary. Not thread-safe due to non-atomic pointer access (as noted in its documentation).    Contents  Automatic Pool Allocation   Reading List: [1] Automatic pool allocation: Improving performance by controlling data structure layout in the heap. PLDI, 2005. [2] Linear Regions Are All You Need. European Symposium on Programming, 2006 paper Region-based memory management Tofte-Talpin Data are allocated within lexically-scoped regions and all of the objects in a region are deallocated at the end of the region\u0026rsquo;s scope. restrictions on when data can be effectively reclaimed memory leaks Cyclone\u0026rsquo;s dynamic regions and unique pointers Pool Allocation The idea of instrumentation How to determine a pool for which data structures Applicaions SAFECode Performance optimization  SAFECode  Questions/Todos Runtime check of SAFECode. LLM: Runtime checks in SAFECode Function Pointers in SAFECode? LLM: Function pointers are checked against a static CFG at runtime (some could be checked at compile time). Where does the pool meta-data stored and used? Can we also store meta-data for all pointers in type-unknown regions? What is affine transformations? used in Control-C Overview Memory safety in C language.\n LLVA OS  References: 2006-LLVA-OS 1 2003-LLVA 2 Idea of LLVA and LLVA-OS LLVA (Low Level Virtual Architecture) supports arbitrary languages including C, and enables sophisticated analyses and optimizations. It provides computational, memory access, and control flow operations. However, LLVA \u0026ldquo;lacks operations a kernel needs to configure hardware behavior and manipulate program state\u0026rdquo;. Thus comes LLVA-OS. LLVA-OS is a set of extensions to LLVA that provides an interface between the OS kernel and a general purpose processor architecture.\n SVA-OS  References: 2007-SOSP-SVA 1 2009-SEC-SVA 2 Questions/Proposals Compiler assisted program partition to achieve the SVA effect? Memory Safety by kernel C language memory safety in kernel\u0026rsquo;s code base Memory safety related functionality of the kernel process states in trap/exceptions, including context switching. virtual/physical page mappings I/O memory, DMA memory Idea of SVA-OS LLVA-OS is an interface prvoides \u0026ldquo;richer OS-information for hardware, greater flexibility in evolving hardware, and sophisticated analysis and optimization capabilities for kernel code\u0026rdquo;.\n Memory Safety in Hardware and Software Interactions  Secure HW/SW Interface Motivation OS memory safety research Memory safety for OS code: OS designs based on safe languages; Compiler techniques such as SVA-M to enforce memory safety for commodity OSs in unsafe languages; Instrumentation techniques to isolate a kernel from extensions such as device drivers; Singularity, SPIN, JX, JavaOS, SafeDrive, and SVA-M are examples of system that enforce a safe execution environment. Common asumptions of OS memory safety research Unfortunately, all these memory safety techniques (except Verve, which has very limited I/O and no MMU support) make assumptions that are routinely violated by low-level initeractions between an OS kernel and hardware, even if implemented in safe programming language.\n Virtual Ghost  Virtual Ghost1: Compiler instrumentation of operating system code: creating ghost memory, which kernel cannot access; A thin hardware abstraction layer (SVA-based): kernel must use to be restricted; user application use them to protect themselves via ghost memory management, encryption, signing, and key management; Compiler Instrumentation ghost memory protection. LLVM bitcode translation and validation. CFI on kernel code: ensures the compiler instrumentation is not bypassed. Evaluation Implimentation:\n Intrinsics  Reference:  Intrumentation  Reference:   2014-ISCA-CHERI, p9. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/pointer-ana/",
	"title": "Pointer Analysis",
	"tags": [],
	"description": "",
	"content": "References:\n Pointer Analysis: Haven\u0026rsquo;t we solved this problem yet? By Micheal Hind, IBM. PASTE, 2001.\n Wiki: Program Analysis: https://en.wikipedia.org/wiki/Program_analysis\n   Undecidability   References: Pointer Analysis The undecidability of aliasing More  Multi-layer Type Analysis  Reference 1 C++ and Casting Pointer to virtual function tables is frequently cast to general types such as char*, rendering the type match ineffective. MLTA: a mechanism to precisely connect VTables to the corresponding classes and to keep track of class casting. Similar work 2 3: a virtual function call can only invoke the virtual functions implemented in the current class or its derived class, but not others. Use an expanded single-layer type for finding targets.\n Andersen  Reference 1 reference ↩  Steensgaard  Reference 1 reference ↩  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-c-model/",
	"title": "Cheri C Model",
	"tags": [],
	"description": "An implementation of C abstract machine that can run legacy C code with Strong memory protection guarantees.",
	"content": " An implementation of C abstract machine that can run legacy C code with Strong memory protection guarantees.\nReferences:\n Beyond the PDP-11: Architectural support for a memory-safe C abstract machine. 2015, ASPLOS. paper, slides\n ISO/IEC 9899:2011 Information technology \u0026ndash; Programming languages \u0026ndash; C. link\n Is address space 1 reserved? LLVMdev, 2015. link\n CheriABI: Enforcing Valide Pointer Provenance and Minimizinig Pointer Privilege in the POSIX C Run-time Environment, ASPLOS, 2019.\n Into the depths of C: elaborating the de facto standards. ACM SIGPLAN Notices, 51(6), pp.1-15. 2016. pdf\n Exploring C Semantics and Pointer Provenance, POPL, 2019.\n  Question/Proposals the #pragma Pure-capability enabled for zlib, but still need the pragma changes to keep compatable with MIPS ABI.\n What does the pragma do? What will happen if we enable pure-capability for the kernel? will we also need a pragma, or we will eliminate all the pragma?  Refine Compilers instead of CHERI ISA  Instead of refine CHERI ISA to support the idioms, is it possible to change the Compiler to converting those unsafe idioms into a safe one in the older CHERI ISA?  Refine C abstract machine  How could we extend C abstract machine to include more memory safety related semantics, such as malloc, kernel\u0026rsquo;s context switching, signal handler dispatching, I/O memory, MMU, etc. Can SVA be viewed as an extended C abstract machine? But implements all extensions as a library rather than C language semantics?  Compiler assisted Temporal Safty in CHERI?  Tracking all the pointer-\u0026gt;integer-\u0026gt;pointer flows. Make the collector accurate first. Then find a way to optimize it.\n might track the integer with one more bit, indicating whether it is converted from pointers or not. allow pointer to integer, but once casted to/from a pointer, the integer automatically becomes a capability and will never be casted back again (in architecture\u0026rsquo;s view, not in user\u0026rsquo;s view).  Use SAFECode Strategy for a quoted safe.\n  Common Pointer Idioms  Around 2M lines of C code surveyed Thousands of instances found Breaking them is not acceptable  CHERI := Fat Pointers ++ Original Fat Pointers:\n Describe a pointer Add metadata   Capabilities:\n Unforgeable Monotonic length and permissions Grant rights  Original C Abstract Machine malloc() is outside of the abstract machine.  Integer arithmetic and then cast to pointers, mostly in malloc(). The C specification indicates that each block of memory returned by malloc() is an object. And it is undefined behavior to use it after calling free(). The memory that has not been returned by malloc() is not yet part of the C abstract machine. The compiler makes sufficient allowances to permit these functions to be implemented in C atop some more primitive functionality, mmap() or brk(), which deals with pages of memory.  Address translation (MMUs) is outside of the C abstract machine  memory in CHERI terminology always mean virtual memory.  Unions to subvert the type system  If the member used to read the contents of a union object is not the same as the member last used to store a value in the object, the appropriate part of the object representation of the value is reinterpreted as an object representation in the new type\u0026hellip; This might be a trap representation.\n This requirement is useful for low-level contexts: it is possbile to subvert the type system and interpret memory as differnet formats.\nCode pointers as data  C is intended to be usable on microcontrollers with separate address spaces for code and data. POSIX breaks this separation by introducing void *dlsym(...) function, used to look up a symbol in a shared library. Notion of shared libraries is beyond the scope of the C language specification. Unfortunately, looking up function pointers is a common use for dlsym, and is not defined behaviour in C.  Const in C type system is not strict  memchr in C specification, takes a const-qualified pointer as the first argument, and returns a non-const pointer derived from it.  Provenance of pointers in C is broken  pointer -\u0026gt; integer -\u0026gt; pointer. e.g. xor linked list: each node has a pointer that is the address of the previous node xor\u0026rsquo;d with the address of the next node, allowing traversal in both directions.\n unused bits in a pointer used to store information.\n  Temporal safety in C is difficult  Casting integer to pointer makes accurate garbage collection impossible. Because any integer value may potentially be combined with others to form a valid address. It is not possible to implement a copying or relocating garbage collector if it is possible for object addresses to escape from the collector.\n Efficient implementation of full temporal safety will have unexpected behavior for much existing code.\n  CHERI Refined Refine CHERI to meet C Abstract model.\nExamples:\n v1 -\u0026gt; v2 : prevent integer loaded into capability registers -\u0026gt; allow propagation of tags.\n memcpy() does not need to aware the existence of pointers in the copied data. unions too.  v2 -\u0026gt; v3: add \u0026lsquo;fat pointers\u0026rsquo; style, an offset.\n supporting arbitrary pointer arithmetic and comparison: CPrtCmp\n allow more permission fields\n additional hw checks, such as GC, info-flow tracking, integrity in concurrency, etc.\n const by removing the store permission. __input and __output to discard permissions.\n   CToPtr and CFromPtr\n will lose bound in traditional pointers. must be used carefully only in hybrid environment  __capability qualifier for hybrid compilation mode.\n v3 supports storing data in unused bit of a pointer (must in bound)\n  More refinement ongoing:  Function Pointers as Capability\n v3 can support (but not yet) using a code capability for every function: CJALR(capability jump and link register), such that when a function is executing, it is impossible to jump out of it without an explicit call. legacy compilers and linkers place constants close to the functions and depend on the program counter address to locate globals. Thus use function pointers as capabilities would break these applications.  A relocating generational garbage collector.\n use tagged memory to distinguish capbilities and other data. already implemented, but need to determine how much software will be broken on it.   Evaluation Idioms Support Summary of idioms supported by different interpretations of C abstract machine   x86/PDP-11/MIPS baselines, HardBound, Intel MPX, CHERIv2: no offset, a pointer addition decreases the range. CHERIv3: with offset, etc. a translator from C code into a simple abstract machine interpreter, to quickly modify the abstract machine and run the test cases extracted from the idioms to see which fail.  relaxed: integer can be modified but still points to valid object strict: integer not allowd to be modified.   Benchmarking 100MHz Stratix IV FPGA. DDR DRAM is faster then CPU, so cache misses are less costly.\n Olden. pointer intensive. Dhrystone. Less pointer intensive. tcpdump zlib  Code Changes\nLines of code changed to port from MIPS to CHERIv2 and CHERIv3   Annotation are manually added to understand their placement. But compiler can represent pointers using capalibities internally, avoiding the need for manual annotations.\n Semantic Changes:\n tcpdump on cheriv2: 1.6K lines to avoid pointer subtraction. tcpdump on cheriv3: 2 lines to mark readonly access to the packet being parsed rather then the whole packet buffer.  Compiler support:\n a new ABI in which all pointers are implemented as capabilities; references to on-stack objects are derived from a stack capability. zlib version 1: header annotation for compatability with MIPS ABI. A single pragma at the start and end of the library header. zlib version 2: copying structures when they are passed across the library boundary.   Overhead of CHERI-zlib normalized against zlib compiled for a conventional MIPS ISA  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/lowfat/",
	"title": "Low Fat Pointers",
	"tags": [],
	"description": "",
	"content": "References:\n[1] Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-based Security. [paper]\nLow-fat Capability Format  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/attacks/data-op/",
	"title": "DOP",
	"tags": [],
	"description": "",
	"content": "Data Oriented Programming Attacks\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/tools/",
	"title": "Tools/Methods",
	"tags": [],
	"description": "",
	"content": " References:\n More  More  Kami  References Kami: A Platform for High-Level Parametric Hardware Specification and Its Modular Verification Kami: A Framework for (RISC-V)HW Verification  Coq  Reference: The Coq Proof Assistant Isabelle advantages over Coq: From Benjamin Pierce notion of equality is extensional; it eliminates a lot of low-level tedium in proofs of involves equality. a much better story about variable binding; formalizing sth that involves binding variables. nominal data type package. Coq = Gallina + Tactics Gallina Core of the Coq: Gallina, a functional programming language; Heart of Gallina: typed lambda calculus.\n Isabelle  References: Higher order logic (HOL) Isar - Intelligible semi-automated reasoning. Concrete Semantics Video: Haskell for imperative programmers Video: Math 220, Pepperdine.edu Structured Proof Language. Arithmetic Expressions: Concrete Abstract 5 N 5 (constants) x V \u0026ldquo;x\u0026rdquo; (variables) x + y Plus (V \u0026ldquo;x\u0026rdquo;) (V \u0026ldquo;y\u0026rdquo;) 2 + (z + 3) Plus (N 2) (Plus (V \u0026ldquo;z\u0026rdquo;) (N 3))  SCADE  References: 一文读懂基于SCADE模型的形式化方法 More\n Z3   References: jfmc\u0026rsquo;s Z3 Playground Z3 wiki Z3 is a state-of-the-art theorem prover from Microsoft Research. It can be used to check the satisfiability of logical formulas over one or more theories. More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-temporal/",
	"title": "Cheri Temporal",
	"tags": [],
	"description": "",
	"content": " More  [2019 Micro] CHERIvoke: Characterising Pointer Revocation using CHERI Capabilities for Temporal Memory Safety.  References: CHERIvoke: Characterising Pointer Revocation using CHERI Capabilities for Temporal Memory Safety. pdf. MICRO, 2019. Overview A new allocator with quanrantine buffer that stores \u0026ldquo;to-be-revoked\u0026rdquo; segments. Quanrantine Buffer (delayed sweeping): a list of object addresses that are freed but not safe to be reused yet. These addresses are kept in a cached list of addresses of freed object; addresses in this buffer cannot be reused (not really freed yet); only do sweep when the buffer is full; and address is available for reuse after sweep (here have the real free); sweep all memory that could contain references to the heap; invalidate any capability references that points to any region in the quanrantine buffer; sweep using a shadow map to store revocation metadata (1 bit for every 16-byte granule of the heap; 1\u0026frasl;128); Revocation Shadow Map: bit-map for quarantined objects (fast look-up): bit-mapped tags for all heap memory; 1-bit for 16 byte of heap; every allocation in quanrantine buffer is \u0026lsquo;painted\u0026rsquo; in this map, indicating a to-be-revoked region in the heap; To Sweep: scan all memory for references for each reference, perform a look-up at this map to determine whether to revoke the reference (capability/pointer); use the base of the reference to detect if it is pointing into a revoked object; new allocator dlmalloc_cherivoke to replace dlmalloc.\n [2020 Oakland] Cornucopia: Temporal Safety for CHERI heaps  References: N. Wesley Filardo et al., \u0026ldquo;Cornucopia: Temporal Safety for CHERI Heaps\u0026rdquo; 2020 IEEE Symposium on Security and Privacy (SP), 2020. Motivation Language-level temporal safety. With CHERI, the temporal safety can be achieved via one of the two ways: Table lookups. This is avoided for performance in the CHERI design. Identifying capabilities in memory to revoke them. This is similar to a garbage-collector sweep. CHERIvoke: a prior feasibility study on latter, key aspects modeled on x86 machines.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-stack/",
	"title": "libcheri Stack",
	"tags": [],
	"description": "",
	"content": " file: libcheri_stack.c\nThis file implements the \u0026ldquo;trusted stacks for the libcheri compartmentalization model\u0026rdquo;. \u0026ldquo;Each pthread has its own trusted stack that tracks calls between libcheri objects; frames contain the information required to recover control safely to the caller context (in another protection domain) both in the event of a CRetrun from the callee, and in the event of a trusted-stack unwind due to an exception termination execution in a object permaturely.\u0026rdquo;\nImplement Stack as TLS: This implementation uses linker/compiler-provided thread-local storage for the stack, to avoid the need for explicit pthreads-based initialization and management that would otherwise need to incur inline in libcheri_invoke(). Although we might want to change this functional simplification for performance reasons in the future.\nTODO: Reentrancy and signal: XXX: Today we access this field lock-free, since it won\u0026rsquo;t be accessed by other threads (at least currently). However, there is a question about reentrancy and signal handers, where some more care may be required, as signal handlers may wish to rewrite the trusted stack \u0026ndash; and must be carefull in the event that the signal is delivered while the trusted stack is already being used/manipulated. One example would be if a domain transition or other manipulation is taking place when a timer interrupt fires. This suggests the notion of a critical section protecting the trusted stack, but we\u0026rsquo;d like to avoid the need for this in invocation path as our goal is to avoid system calls there. Some more thinking is required here \u0026ndash; e.g., do we want to do a soft-interrupt-style thing along the lines if interrupts taken during spl()s in the kernel, with the singal handler \u0026lsquo;scheduling\u0026rsquo; the change to take place once the preemted code returns..?\nStack Struct \u0026amp; init /* * Currently, we have a maximum invocation depth that is low, and encoded in * the ABI. We might want to revisit these choices to hide any limit from the * library consumer, to raise it, and perhaps to allow flexible per-thread * limits. A lot will depend on eventual common usage patterns. */ #define\tLIBCHERI_STACK_DEPTH\t8\t/* XXXRW: 8 is a nice round number. */struct libcheri_stack { register_t\tlcs_tsp;\t/* Byte offset into lcs_frames, * not frame index. */ register_t\tlcs_tsize;\t/* Stack size, in bytes. */ register_t\t_lcs_pad0; register_t\t_lcs_pad1; struct libcheri_stack_frame\tlcs_frames[LIBCHERI_STACK_DEPTH]; } __aligned(CHERICAP_SIZE); Questions TLS model XXXAR: we use local-exec tls model here to ensure that we can load the values without using the captable.\n__thread struct libcheri_stack __libcheri_stack_tls_storage __attribute__((__aligned__(32), tls_model(\u0026#34;local-exec\u0026#34;))) = { .lcs_tsize = LIBCHERI_STACK_SIZE, .lcs_tsp = LIBCHERI_STACK_SIZE, }; Stack init \u0026ndash; align check // file: // lib/libcheri/libcheri_stack.c  void libcheri_stack_init(void) { /* * Ensure thread-local storage for the first thread\u0026#39;s trusted stack is * suitably aligned. */ assert(((vaddr_t)\u0026amp;__libcheri_stack_tls_storage % CHERICAP_SIZE) == 0); } stack get/set/unwind APIs to get and set the trusted stack, which currently encode the internal stack structure, and assume a fixed-size trusted stack.\nint libcheri_stack_get(struct libcheri_stack *lcsp): Return success/failure on \u0026ldquo;get to allow for the possibility that trusted stacks might be allocated on-demand in the future, and hence might not be present if libcheri hasn\u0026rsquo;t been used from a thread previously.\n// file: // lib/libcheri/libcheri_stack.c: libcheri_stack_get(struct libcheri_stack *lcsp):  memcpy(lcsp, \u0026amp;__libcheri_stack_tls_storage, sizeof(*lcsp)); int libcheri_stack_numframes(int *numframesp): Return the number of frames on the trusted stack; similarly, retain a return value in case in the future we need to make this conditional on a trusted stack being allocated.\nint libcheri_stack_set(struct libcheri_stack *lcsp): Allow the trusted stack to be set, subject to various safety constraints.\n// file: // lib/libcheri/libcheri_stack.c  int libcheri_stack_set(struct libcheri_stack *lcsp) { if (lcsp-\u0026gt;lcs_tsize != __libcheri_stack_tls_storage.lcs_tsize) { errno = EINVAL; return (-1); } if (lcsp-\u0026gt;lcs_tsp \u0026lt; 0 || lcsp-\u0026gt;lcs_tsp \u0026gt; LIBCHERI_STACK_SIZE || (lcsp-\u0026gt;lcs_tsp % LIBCHERI_STACKFRAME_SIZE) != 0) { errno = EINVAL; return (-1); } memcpy(\u0026amp;__libcheri_stack_tls_storage, lcsp, sizeof(__libcheri_stack_tls_storage)); return (0); } int libcheri_stack_unwind(ucontext_t *uap, register_t ret, u_int op, u_int num_frames): Unwind the trust stack the specified number of frames (or all) \u0026ndash; machine-independent portion.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-spatial/",
	"title": "Complete Spatial Safety for C and C++ using CHERI capabilities",
	"tags": [],
	"description": "",
	"content": " References:\n Complete spatial safety for C and C++ using CHERI capabilities  Evaluation 1  qsort() microbenchmark: The actual comparison of the integers is performed in a different DSO (Dynamic shared object).\n MiBench.\n  ####　CHERISH Evaluation Cheri sub-object Hardening.\n MiBench\n Real issues found in CheriBSD.\n buffer overflows in jemalloc and libarchive out-of-bounds 2D array write in awk buffer overflow in cheritest layout incompatibility of _Unwind_Exception. Incompatibility between two declarations of struct _Unwind_Exception, used for thread unwinding and C++ exceptions.  Memory protection benefit evaluation\n BOdiagsuite suite of 291 programs by Kratkiewicz 1. Used by Hardbound2 and CheriABI. Juliet CWE test suite 3, no sub-object overflows. Compare against ASan Stack canaries _FORTIFY_SOURCE Valgrind EffectiveSan SoftBound-CETS CheriABI   PostgreSQL, WebKit.\nMore   BOdiagsuite. ↩ Hardbound. ↩ Juliet CWE. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-enter/",
	"title": "libcheri Enter",
	"tags": [],
	"description": "",
	"content": " libcheri_enter_init() initializes the landing-pad environment for system-object invocation.\nIt implements a stack landing pad for system classes provided by libcheri. The single stack is statically allocated \u0026ndash; meaning no concurrent invocation from sandboxes in multiple threads (or reentrantly). Currently, that is ensured by virtue of applications not themselves invoking sandboxes concurrently.\n// file: // lib/libcheri/libcheri_enter.c  void libcheri_enter_init(void) { /* XXX: Should be MAP_STACK, but that is broken. */ __libcheri_enter_stack = mmap(NULL, LIBCHERI_ENTER_STACK_SIZE, PROT_READ | PROT_WRITE, MAP_ANON, -1, 0); assert(__libcheri_enter_stack != MAP_FAILED); /* * In CheriABI, we use the capability returned by mmap(2), which $sp * will be relative to, and implement solely $csp. Otherwise, assume * a global $sp and use $c0. */ #ifdef __CHERI_PURE_CAPABILITY__  __libcheri_enter_stack_csp = (caddr_t)__libcheri_enter_stack + LIBCHERI_ENTER_STACK_SIZE; #else  __libcheri_enter_stack_cap = cheri_getdefault(); __libcheri_enter_stack_sp = (register_t)((char *)__libcheri_enter_stack + LIBCHERI_ENTER_STACK_SIZE); #endif  __libcheri_object_creturn = libcheri_make_sealed_return_object(); } CCall landing pad code For a sandbox to call system class services, the Cheri System class CCall landing pad code is designed for a user sandbox to trigger the CCall.\n CHERI system class CCall landing pad code: catches CCalls inbound from sandboxes seeking system services, and bootstraps C code. A number of differences from sandboxed code, including how $c0 is handled, and not setting up the C heap.\n Macro LIBCHERI_CLASS_ASM(class) is defined in lib/libcheri/mips/libcheri_system_md.h, which includes the definition of global entry point for all sandboxes: __libcheri_## class ## _entry.\nGeneral what it do includes:\n load sandbox object\u0026rsquo;s DDC via IDC. Then install global invocation stack __libcheri_enter_stack_***; set up global pointer _gp; try to get method vtable and call methods;\n If found valid vatable, load method with proper offset, and use cjalr into the proper methods; If vtable not valid, ??? Crash here?  define return code:\n load __libcheri_object_creturn capability; load two parameters from __libcheri_object_creturn into c1, c2; CCALL($c1, $c2); //??? why this is a ccall not jalr? Differences between CCALL and cjalr are ??   For pure capability with captable:\n global invocation stack is __libcheri_enter_stack_csp, which is derived from pcc, captab_rel, and __libcheri_enter_stack_csp; return capability, __libcheri_object_creturn, is derived from pcc and captab_rel;  For pure capability without captable:\n global invocation stack is directly the __libcheri_enter_stack_csp; return capability __libcheri_object_creturn is derived directly;  For hybrid mode:\n global invocation stack is loaded directly from __libcheri_enter_stack_cap, and __libcheri_enter_stack_sp; set up global pointer _gp; return capability __libcheri_object_creturn is derived directly;\n// file: // lib/libcheri/mips/libcheri_system_md.h  #define\tLIBCHERI_CLASS_ASM(class)  Tracking LIBCHERI_CLASS_ASM Callers:\n LIBCHERI_CLASS_ASM(libcheri_system): LIBCHERI_CLASS_ASM(libcheri_fd):  Both are defined in [lib/libcheri/mips/libcheri_classes_cabi.S]() for CheriABI and [lib/libcheri/mips/libcheri_classes_hybrid.S]() for hybrid ABI;\nMethod numbers for sandbox runtime itself Method numbers:\n// file: // /* * Method numbers used by the sandbox runtime itself. * * WARNING: These values must match those currently hard coded in the sandbox * C runtime (lib/csu/libcheri/crt_invoke.S and crt_rtld.S). * * NB: In the future, these should be via a reserved entry point rather than * the primary object-capability \u0026#39;invoke\u0026#39; entry point, so that they can be * called only by the runtime. */ #define\tSANDBOX_RUNTIME_CONSTRUCTORS\t(-1) #define\tSANDBOX_RUNTIME_DESTROCTORS\t(-2)  #define\tCHERI_SYSTEM_USER_BASE\t1000 #define\tCHERI_SYSTEM_USER_CEILING\t2000  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-sandbox/",
	"title": "libcheri Sandbox",
	"tags": [],
	"description": "",
	"content": " Initialization of system-class sandbox see libcheri system sandbox\nInitialization of user defined sandbox sandbox_init() in libcheri_sandbox.c;\nJobs include:\n get current process text file and open it; sandbox_parse_ccall_methods: parse elf binary file (CHERI_CALLEE, and CHERI_CALLER sections) get a list of sandbox_provided_classes (class, methods, offset), and its required methods (name, class, offset). sandbox_update_main_required_method_variables, use the returned required method list from last step, updating the data structure in the sandbox (initialize the vtable offset); create libcheri_system_vtable, libcheri_fd_vtable\n// file: // lib/libcheri/libcheri_sandbox.c  sandbox_init(void) -\u0026gt; sandbox_program_init(void)// file: // lib/libcheri/libcheri_sandbox.c  /* XXXBD: should be done in sandbox_init(), but need access to argv[0]. */ int sandbox_program_init(void) { ... /* XXXBD: do this with RTLD or hypothentical getexecfd(). */ // Lele: kern.proc.pathname.(-1): current processes text file if ((sysctl(mib, 4, buf, \u0026amp;cb, NULL, 0) != -1) \u0026amp;\u0026amp; cb \u0026gt; 0) { if ((fd = open(buf, O_RDONLY)) == -1) warn(\u0026#34;%s: open %s (from kern.proc.pathname.(-1))\u0026#34;, ... if (sandbox_parse_ccall_methods(fd, \u0026amp;main_provided_classes, \u0026amp;main_required_methods) == -1) { ... return (-1); } if (sandbox_update_main_required_method_variables() == -1) { ... return (-1); } /* XXXBD: cheri_system needs to do this. */ libcheri_system_vtable = sandbox_make_vtable(NULL, \u0026#34;_libcheri_system_object\u0026#34;, main_provided_classes); libcheri_fd_vtable = sandbox_make_vtable(NULL, \u0026#34;libcheri_fd\u0026#34;, main_provided_classes); close(fd); return (0); }  create new instance of a class/object In lib/libcheri/libcheri_sandbox.c:\nsandbox_class_new(...), loading a sandbox binary from a given file. Resolve the methods.\nsandbox_object_new(struct sandbox_class *sbcp, size_t heaplen, struct sandbox_object **sbopp),\nsandbox_object_new_system_object(void * __capability private_data, void * __capability invoke_pcc, vm_offset_t * __capability vtable, struct sandbox_object **sbopp),\nExample 1: cheritest-helper File: bin/cheritest/cheritest_libcheri.c\n// file // bin/cheritest/cheritest_libcheri.c  int cheritest_libcheri_setup(void) { /* * Prepare CHERI objects representing stdin, stdout, and /dev/zero. */ if (libcheri_fd_new(STDIN_FILENO, \u0026amp;sbop_stdin) \u0026lt; 0) err(EX_OSFILE, \u0026#34;libcheri_fd_new: stdin\u0026#34;); if (libcheri_fd_new(STDOUT_FILENO, \u0026amp;sbop_stdout) \u0026lt; 0) err(EX_OSFILE, \u0026#34;clibheri_fd_new: stdout\u0026#34;); zero_fd = open(\u0026#34;/dev/zero\u0026#34;, O_RDWR); if (zero_fd \u0026lt; 0) err(EX_OSFILE, \u0026#34;open: /dev/zero\u0026#34;); if (libcheri_fd_new(zero_fd, \u0026amp;sbop_zero) \u0026lt; 0) err(EX_OSFILE, \u0026#34;libcheri_fd_new: /dev/zero\u0026#34;); if (sandbox_class_new(\u0026#34;/usr/libexec/cheritest-helper\u0026#34;, 4*1024*1024, \u0026amp;cheritest_classp) \u0026lt; 0) err(EX_OSERR, \u0026#34;sandbox_class_new: cheritest-helper\u0026#34;); if (sandbox_object_new(cheritest_classp, 2*1024*1024, \u0026amp;cheritest_objectp) \u0026lt; 0) err(EX_OSERR, \u0026#34;sandbox_object_new: cheritest-helper\u0026#34;); cheritest = sandbox_object_getobject(cheritest_objectp); cheritest2 = sandbox_object_getobject(cheritest_objectp); libcheri_system_user_register_fn(\u0026amp;cheritest_libcheri_userfn_handler); return (0); }  Class Object  Sandbox Class vs Object Class: \u0026lsquo;sandbox class\u0026rsquo; is an instance of code that may be sandboxed and invoked, along with statistics/monitoring information, etc. (see lib/libcheri/libcheri_sandbox_internal.h) Object: \u0026lsquo;sandbox object\u0026rsquo;, or sandbox instance, is an in-flight combination of code and data. Currently, due the compiler limitations, we must conflate the \u0026lsquo;code\u0026rsquo;, \u0026lsquo;heap\u0026rsquo;, and \u0026lsquo;stack\u0026rsquo;, but eventually would like to allow one VM mapping of code to serve many object instances. This would also ease supporting multithreaded objects.\n Sandbox Methods  sandbox_provided_classes No two binaries can provide the same class as vtable offsets would be inconsistant. /* * List of classes provided by a sandbox binary. Each binary can * support one or more classes. No two binaries can provide the same * class as vtable offsets would be inconsistant. */ struct sandbox_provided_classes { struct sandbox_provided_methods\t**spcs_classes;\t/* Class pointers */ size_t\tspcs_nclasses; /* Number of methods */ size_t\tspcs_maxclasses; /* Array size */ size_t\tspcs_nmethods; /* Total methods */ vm_offset_t\tspcs_base;\t/* Base of vtable */ }; sandbox_required_method\n Sandbox Loader  // file: lib/libcheri/libcheri_sandbox_loader.c sandbox class load int sandbox_class_load(struct sandbox_class *sbcp) This will set up the code capability for a new sandbox class; (CHERI todo) set up the code and data capabilities differently. Steps includes: parse the provided classes, required methods from the ELF binary. set bounds and mask permissions on code capabilities. set offset of rtld, invoke vectors. sandbox object load int sandbox_object_load(struct sandbox_class *sbcp, struct sandbox_object *sbop)\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/softbound/",
	"title": "SoftBound: Highly Compatible and Complete Spatial Memory Safety for C",
	"tags": [],
	"description": "",
	"content": " Reference:\n SoftBound: Highly Compatible and Complete Spatial Memory Safety for C. PLDI, 2009.  Background spatial violation detection and prevention.\nObject-Based Approaches.\nPointer-Based Approaches.\nComparison of Various Approaches.\nDesign Associates base and bound metadata with every pointer.\nDisjoint metadata representation avoids memory layout changes and arbitrary casts.\nMetadata Propagation with Function Calls.\n When pointers are passed as arguments or returned from functions, their base and bound metadata must also travel with them. If all pointer arguments were passed and returned on the stack (i.e., via memory and not registers), the above table-lookup approach for handling in-memory metadata would suffice. However, when passed via registers:  use procedure cloning [^c12] to transform every function declaration and function call site to include additional arguments for base and bound. the function name is appended with a SoftBound-specific unique identifier, specifying this function has been transformed by SoftBound.  For variable argument functions:  extended with two more parameters: the number of parameters passed (in bytes) the number of pointers passed (and thus the number of extra base/bound arguments passed to the function)   Implementation Instrumentaton The SoftBound pass inserts code to:1\n Create a base and bound value for each pointer non-memory value in the program; perform base/bound metadata manipulation prior to every memory operation that reads or writes a pointer; perform a bound check before memory operation; rewrite all function calls to pass the base and bounds.  Global Variables Memcpy() Function pointers Creating pointers from integers Arbitrary Casts and unions Redundant elimination To eliminate some obviously redundant checks of the same pointer, our prototype performs a simple intra-procedural dominator-based redundant check elimination. These transformations are all strictly local (intra-procedural) transformations, without any whole program type inference or alias analysis.\nCalls to external functions (i.e. any library function that has not been SoftBound transformed) are mapped to wrapper functions.\nSoftBound uses standard C functions to implement the code to access the base/bound metadata and to perform the bounds checks. The SoftBound pass invokes these routines by inserting appropriate function calls that are later forcibly inlined by subsequent LLVM passes.\nMetadata Implementation Two implementations: a hash table and a tag-less shadow space.\nHash Table:\n Each entry: a three tuple: (tag, base, bound)\n 64-bit pointers, each entry is 24 bytes.  Hash function: the double-word address modulo the number of entries in the table.\n simple shift-and-mask operation. (with num of entries in the table is power of 2.)  9 x86 instructions for the lookup.\n  Shadow Space:\n a large enough table in the virtual address space. 5 x86 instructions for the lookup.  Evaluation Overhead:\n67% full checking;\n22% store-only checking.\nCompiler: LLVM 2.4\nBenchmark:\n a testbed for buffer overflow attacks RIPE; real programs with spatial errors: go, compress, gzip, polymorph. SPECint, SPECfp, Olden.  Comparison:\n Valgrind/memcheck, Valgrind/ptrcheck; GCC Mudflap; Jones and Kelly version of GCC; CCured MSCC  In general, better than MSCC, worse than CCured.\nNot Complete for pointer protection:  memcpy(): infer whether the memory has pointers by looking at the type being copied at the call site \u0026ndash; not foolproof;\n functin pointers: base=bound=pointer, zero-sized object. can prevent data pointer to function pointer casting; but cannot prevent func to func casting;\n no temporal.\n   SoftBound: Highly Compatible and Complete Spatial Memory Safety for C. PLDI, 2009. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/book-soft/v3-vfa/",
	"title": "Volume 3 Verified Functional Algorithms",
	"tags": [],
	"description": "",
	"content": " References:\n Software Foundations Volume 3, Verified Functional Algorithms, by Andrew W. Appel, with contributions from Andrew Tolmach and Micheal Clarkson.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/finegrain/",
	"title": "Fine-grained privilege separation",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  2020 Sec Firefox  Reference 1 Shravan Narayan, Craig Disselkoen, Tal Garfinkel, Nathan Froyd, Eric Rahm, Sorin Lerner, Hovav Shacham, and Deian Stefan.RLBox: Retrofitting Fine Grain Isolation in the Firefox Renderer. In Proceedings of USENIX Security Symposium. August, 2020 ↩  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/seminars/",
	"title": "Seminars",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Oakland 2020  Reference 1 Videos: https://www.youtube.com/channel/UC6pXMS7qre9GZW7A7FVM90Q/videos Opening Missing Doug Tygar, from UC berkeley. Awards. 104 out of 8xx. ~12% Mem Safety xMP Data oriented programming xen altp2m ptr -\u0026gt; hash -\u0026gt; key Buddy allocator context switch read-only permissions from outside of xMP domain. Talk with P. seL4: no trust on hardware; verified safe. PSOS: layer ontop of layer; verify one layer ontop of a verified layer. CHERI: security in market in 3~4 years.\n 2020 Asplos  Reference 1 Most influential: Africa(Kenya) zebra tracking; peer-to-peer epidemic propagation; energy saving. Betteryless in IoT: Intermittent Timekeeping in Intermittent Computing RC circuits: capacitor discharged time. This work: a sequential discharged chain of RC circuits instead of one. TotalRecall Avoid all NVM-writes by taking checkpoints that reside entirely in SRAM. SRAM volatility: ~5 minutes (20 C) Long time off times: predictable; irrelavant; TICS: Batteryless on legacy software Time annotated C source.\n Ur  Seminars/Lectures December 02 Nathan Beckmann From CMU. Pushing the limits of online and offline caching. Marry thery and practice computing tight bounds on OPT even when is NP-hard. E.G. Mysql, cache can be 100x faster. Caches: Think smarter, not larger: a better cache policy. LRU, ++. Caching: theory questions; practical questions; online \u0026amp; offline policies. ==\u0026gt; an intersection of these. Beckmann, NSDI\u0026rsquo;18. LHD, AdaptSize, Hyperbolic, GDSF, LRU. Figure.\n 2022 Arm Tech Symposia  References: Live link CEO, Rene Haas. Mohamed Awad. \u0026ldquo;the future is built on arm\u0026rdquo; World\u0026rsquo;s global infrastructure. ARM Neoverse: E/N/Y-series. E: Efficient throughput N: Scale Out Performance V: Arm AMBA CHI (Chai) CMN: Core Mesh Network. Cloud, development for free: alibaba, aws, google 5G Solutions Lab. Software defined vehicle on arm. 100M lines of code on a vehicle. engine, \u0026hellip;., adas corte x-a52 IoT: Fighting Fragmentation: Matter protocols, for Smarthome\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/pagebits/",
	"title": "Secure by Permission bits on Page Table",
	"tags": [],
	"description": "",
	"content": "Example:\n MMU and its variants MPK on Intel MPU on ARM Supervisor Mode Access Prevention. On CR4/x86  Reference 1\n Dang  Q\u0026amp;A How to detect there is still reference pointing to a pool? What if there is a buffer overflow to the freed variable on the same page? Reference 1 Problem: Allocate only one object per physical page would be quickly exhaust physical memory. Changing the allocation in this way would potentially lead to poor cache performance in physically indexed cache. Overview: Use a new virtual page for each allocation of the program but map it to the same physical page as the original allocator.\n HyperSafe: A Lightweight Approach to Provide Lifetime Hypervisor Control-Flow Integrity  Reference 1 reference ↩  Intel MPK  References: [1] ERIM: Secure, Efficient In-process Isolation with Memory Protection Keys (MPK), SEC, 201908. paper\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/pump/",
	"title": "Pump",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  How to init tags?\n LLM: developer writes rules in a special language; software handler computes the rule and generates mappings of tags (as policy) 2018sp-stack: Compiler + adding instructions into programs. 2018sp-stack: Lazy tagging (first write) + Lazy clearing (on all write, check only on read)  How to propagate tags?\n LLM: mapping of tags (policy rules) will be used to propagagte tags during execution of PUMP.  Is there any new instruction added to the ISA spec?\n Is there any new instructions added to the binary?\n How to add object type to it as in CHERI Domain?\n  Reference 1\nRISC processor (Alpha): in-order implementation with a 5-stage pipeline suitable for energy-conscious applications. gem5, generate instruction traces; PUMP simulator, instr. traces; Address-trace simulator, addr. traces;\nEvery word in a PUMP system is associated with a pointer-sized tag. memory, caches, registers including PC.\n simple metatdata can store directly in the tag; complex (unbounded) metadata can use tag as address of metadata in memory;  PUMP rules (2014 HASP) The core architectural feature proposed is the PUMP \u0026ndash; an architectural mechanism designed to enforce runtime policies.\n The PUMP should operate in parallel with the normal ALU computation to avoid slowing down the computation. PUMP Cache: To the hardware, the metadata tags are uninterpreted. Accordingly, the hardware does not compute rules. Instead, rules are cached in the hardware: the mapping between the inputs and outputs of rules. Software interpretation: when a rule is not found in the cache, it traps to a software handler that can resolve the rule and insert it into the hardware cache.  Policy as mapping of tags PUMP allows a programmer or system designer to create policies. A policy is defined as a functional mapping of a set of tags to another set of tags resulting in a collection of rules that implement some desired tracking and enforcement mechanism and also manipulate the tags.\nRules come in two forms: software \u0026ndash; symbolic rules; and hardware \u0026ndash; concrete rules.\nSymbolic rules opcode: (PC, CI, OP1, OP2, MR) --\u0026gt; (PC_new, R, allow?)  SAYS:\n rule matches on the given opcode + metadatas on PC, current instruction(CI), two operands (OP1, OP2), and if any, on memory read value (MR) on a match, right hand side determine wether instruction is allowd and how metadata should be updated on PC, and Result.  Concrete rules A rule representation for efficient hardware implementation of symbolic rules.\nRule checking  Instruction is issued; PUMP check if there is a rule that validates the current instruction:  match against all rules; if match found, the cache returns the new tag of the PC and if needed, a tag for the instructions result; if no match, faults to PUMP miss handler:  consults the symbolic rules via software handler; if allowed, new concrete rule will be inserted; if not allowed, security fault handler;    RISC-V Impl Drapper, Dover, CoreGuard\nPatents US10261794B2\n  Architectural Support for Software-Defined Metadata Processing. ASPLOS, 2015. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-otype/kern-obj/",
	"title": "Kernel Object",
	"tags": [],
	"description": "",
	"content": " Kernel object manipulation is mainly defined in sys/cheri/cheri_otype.c.\nKernel Sealing capability A global sealing capability kernel_sealcap is used throughout the kernel; it is initiliazed in _start().\nkernel_sealcap is initialized to have PCC with offset CHERI_SEALCAP_KERNEL_BASE, bounds CHERI_SEALCAP_KERNEL_LENGTH, perms CHERI_SEALCAP_KERNEL_PERMS.\nSee more on Cheri kernel booting\nstructs for objects management A struct unrhdr *cheri_otypes is used to maintain a unit number space for type value allocations.\nThe unit number space is created as a set of all possible type values for allocation. The unit number space is named cheri_otypes, which is defined as:\nstatic struct unrhdr *cheri_otypes; unit number space: It is a number space described by the unit number space header as below:\n// file: // sys/sys/_unrhdr.h  /* Header element for a unr number space. */ struct unrhdr { TAILQ_HEAD(unrhd,unr)\thead; u_int\tlow;\t/* Lowest item */ u_int\thigh;\t/* Highest item */ u_int\tbusy;\t/* Count of allocated items */ u_int\talloc;\t/* Count of memory allocations */ u_int\tfirst;\t/* items in allocated from start */ u_int\tlast;\t/* items free at end */ struct mtx\t*mtx; TAILQ_HEAD(unrfr,unr)\tppfree;\t/* Items to be freed after mtx lock dropped */ }; Basically, it maintains a set of unit numbers from low to high, while keeping track of the number of allocated items, the items allocated, etc.\ncheri_otype_init(void * dummy __unused) The unit numeber space is initialized by creating a struct unrhdr which represents a set of numbers in [CHERI_OTYPE_KERN_MIN, CHERI_OTYPE_KERN_MAX], with a lock cheri_otype_lock, which is used to lock the set internally evey time the unit number is allocated/freed from the set.\n// file: // sys/cheri/cheri_otype.c static void cheri_otype_init(void *dummy __unused) { mtx_init(\u0026amp;cheri_otype_lock, \u0026#34;CHERI object type lock\u0026#34;, NULL, MTX_DEF); cheri_otypes = new_unrhdr(CHERI_OTYPE_KERN_MIN, CHERI_OTYPE_KERN_MAX, \u0026amp;cheri_otype_lock); } SYSINIT(cheri_otype_init, SI_SUB_LOCK, SI_ORDER_FIRST, cheri_otype_init, NULL); This function is called during system startup via registeration of SYSINT macro above.\ncheri_otype_alloc(void) A type is allocated via cheri_otype_alloc(). It returns an otype_t, which is defined as a capability type:\n// file // sys/sys/types.h  typedef\tvoid * __capability\totype_t; cheri_otype_alloc use a global sealing capability, kernel_sealcap, to create a capability with a new type. Type value is generated by alloc_unr() which allocates a unit number from unit number space cheri_otype.\nkenrel_sealcap is initialized during boot.\n// file: // sys/cheri/cheri_otype.c otype_t cheri_otype_alloc(void) { u_int type; type = alloc_unr(cheri_otypes); if (type == -1) return (NULL); return (cheri_maketype(kernel_sealcap, type - CHERI_SEALCAP_KERNEL_BASE)); } cheri_otype_free(otype_t cap) cheri_otype_free is used to return a type to the pool. Ideally we would ensure that no capablities of this type remain in memory, but that would be VERY expensive.\nIn practice, most consumers will never free a type.\n// file: // sys/cheri/cheri_otype.c void cheri_otype_free(otype_t cap) { u_int type; type = cheri_getbase(cap); free_unr(cheri_otypes, type); } Until CheriBSD commit (e430b100ab1e8408ec92655ad26786bb5ec23ef1) on Aug 29, there is no call to \u0026lsquo;cheri_otype_free()\u0026rsquo; from any place in the entire cheribsd source code (master branch).\nExamples Until CheriBSD commit (e430b100ab1e8408ec92655ad26786bb5ec23ef1) on Aug 29, there is no call to \u0026lsquo;cheri_otype_alloc()\u0026rsquo; from any place in the entire cheribsd source code (master branch).\nHowever, cheri_otype_init is called during system boot.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/",
	"title": "Defences",
	"tags": [],
	"description": "",
	"content": "Reference:\n Control Flow  References: reference More uCFI References: Enforcing Unique Code Target Property for Control-Flow Integrity, CCS\u0026rsquo;18 UCT: Unique Code Target ICT: Indirect Control-flow Transfer Key: collecting the necessary runtime information and using it to augment the points-to analysis on control data. Contraining data: the data helps to determine the target of indirect calls. How to identify the constraining data? How to collect this data efficiently? How to perform the points-to analysis efficiently and accurately?\n Capability  Reference 1 Capability Reference 1 ACL vs Capability Access control list: attributes on objects, stating which subjects has which permissions; e.g. file permission attribute bits on Linux. Capability: attributes on subjects, stating the subject has what permissions over certain objects; format, each capability has form of ; a subject can have a list of capabilities. reference ↩ Confused Deputy References: N. Hardy, “The confused deputy (or why capabilities might have been invented),” ACM SIGOPS Operating Systems Review, vol.\n Silhouette  Reference 1 Cves Reference 1 Two CVEs on FreeRTOS: reference ↩ reference ↩  Sfi  Reference: ARMor: Fully Verified Software Fault Isolation Published at EMSOFT\u0026rsquo;11. Reference:  Tamper Resistant Software Design and Implementation: IVK  Paper1: Make software immune to observation and modification. Tamper-resistance using Integrity Verification Kernels: segments of code which are self-modifying, self-decrypting and installation unique. code segments communicates with other such code, creating an interlocking trust model. Threats: breach communication access controls to attack the system; computer virus; attacker as insider: may modify at will. Tamper Resistant Software Design and Implementation. 1999. ↩  Info Flow Integrity  Reference: 2009 Micro Cfo Reference 1 Deferred exception Itanium: deferred exception tracking. can be used to support for information flow tracking. Deferred exception for speculatively executed instructions. An exception is deferred for later handling instead of being thrown out immediately. Each general purpose register is extended with an additional deferred exception token (NaT, Not a Thing) to keep track of exceptions. Token is propagated along with the executing instructions.\n Side Channel   References: reference More sel4: time protection 2020 Carrv Wistoff: Prevention of microarchitectural covert channels on an open-source 64-bit risc-v core References: Wistoff, Nils, Moritz Schneider, Frank K. Gürkaynak, Luca Benini, and Gernot Heiser. \u0026ldquo;Prevention of microarchitectural covert channels on an open-source 64-bit risc-v core.\u0026rdquo; arXiv preprint arXiv:2005.02193 (2020). fence.t Temporal Fence Instruction fence.t More  Verified  References: PSOS CompCert seL4 CertiKOS More PSOS The Provably Secure Operating System (PSOS) project began in 1973 and continued until 1983. The 1980 PSOS final report includes the system architecture and many of the basic hardware and operating system layers, plus some illustrative applications (all formal specified in the SPECIAL language of HDM, the Hierarchical Development Methodology). The Feiertag/Neumann paper summarizing the architecture as of 1979 is available in a retyped, more or less correct, hand-edited pdf form.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/runtimechecks/",
	"title": "Runtime Checks",
	"tags": [],
	"description": "",
	"content": " Runtime Check in SAFECode  All pointers in Type-Unknown pools are checked.\n All casts from int to pointer are runtime checked to ensure in the right pool. Pointers in TU are all loaded as int1  All pointers derived from array indexing operations need run-time check (2006 PLDI1), regardless of TK or TU. More about array bound checking.\n All function pointers need runtime check before being used. (2005-SAFECode-TR: function pointer)\n  Runtime check methods:\n poolcheck(ph, A, o): verifies that the address, A, is contained within the set of memory ranges assigned to pool, ph, and has the correct alignment for the pool\u0026rsquo;s data type (or for the field at offset o, if o $\\neq$ 0).  SAFECode summary in SVA SOSP 20072:\n Prevents uninitialized reference: data flow analysis for local variables \u0026amp; initilize allocated memory to illegal address for all other pointer variables.\n Prevents array bound violations: extension of the Jones-Kelly approach for detecting array bounds violations. Uses a separate run-time search tree (a splay tree) in each pool to record all array objects at run-time, and looks up pointer values in this table to check for bounds violations.\n Ensures type-safety in TK pools.\n Ensures CFI by generating native code itself \u0026amp; preventing write to code pages \u0026amp; using runtime checks to ensure that indirect function calls match the CFG at compile time.\n Guaranttee the soundness of the operational semantics, given the correctness of analysis information (i.e., the call graph, point-to graph, and type information for TH partitions)\n   Function Ptrs  Reference: Enforcing Alias Analysis for Weakly Typed Languages, TR, 2005. Runtime Check on Function Pointers (From 2005 TR1) The call graph is simply checked explicity at each indirect call site ( some could be removed). Call graph is one of the input of SAFECode. The call graph is represented in the input type system by adding a function set attribute called $fs$ in Figure 2 to each function pointer type, making explicit the set of possible targets for that function pointer.\n Arraychecks  Reference1 Extension to JK and JKRL. Summary of Jones-Kelly from 2006ICSE1: Jones-Kelly inserts the following checks (ignoring any later optimizaiton) on each arithmetic operation involving a pointer value: JK1. check the source pointer is not the invalid value (-2); JK2. find referent object for the source pointer value using the table; JK3. check that the result pointer value is within the bounds of this referent object plus the extra byte.\n  SAFECode: Enforcing Alias Analysis for Weakly Typed Languages, PLDI, 2006. ↩ SVA. SOSP 2007. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/trusted-stack/",
	"title": "Trusted Stack",
	"tags": [],
	"description": "",
	"content": " References:\n[1] CHERI programmer\u0026rsquo;s guide, UCAM-CL-TR-877 Chapter 8.4, 2015.\nOne trusted stack for each thread: pcb_cheristack.\nInitialized to empty when first thread in a process is created.\nStack updates/inspections in the following situations:\n CCall exception CReturn exception CHERI_GET_STACK via sysarch system call CHERI_SET_STACK via sysarch system call cheri_stack_unwind: if a signal is delivered to a thread that is executing sandboxed code, and suitable signal-handling configuration has not been set up to safely receive the delivered signal, then for certian signals the kernel will automatically unwind the stack back to the caller of the sandbox. show cheristack command in DDB.  TLS and stack The TLS stores the trusted stack pointer. see trampolines of libcheri\nTLS pointer is derived from the stack pointer $29 when __CHERI_CAPABILITY_TLS__ is disabled.\nWhen __CHERI_CAPABILITY_TLS__ is enabled, the TLS pointer is derived from $chwr_userlocal instead of $29;\n// file // lib/libc/mips/static_tls.h  static __inline uintptr_t _libc_get_static_tls_base(size_t offset) { #ifndef __CHERI_CAPABILITY_TLS__  vaddr_t tlsbase; #else  uintptr_t tlsbase; #endif  #if defined(__mips_n64) #ifndef __CHERI_CAPABILITY_TLS__  __asm__ __volatile__ ( \u0026#34;.set\\tpush\\n\\t\u0026#34; \u0026#34;.set\\tmips64r2\\n\\t\u0026#34; \u0026#34;rdhwr\\t%0, $29\\n\\t\u0026#34; \u0026#34;.set\\tpop\u0026#34; : \u0026#34;=r\u0026#34; (tlsbase)); #else  __asm__ __volatile__ ( \u0026#34;creadhwr\\t%0, $chwr_userlocal\u0026#34; : \u0026#34;=C\u0026#34; (tlsbase)); #endif  tlsbase -= TLS_TP_OFFSET + TLS_TCB_SIZE; #else /* mips 32 */ __asm__ __volatile__ ( \u0026#34;.set\\tpush\\n\\t\u0026#34; \u0026#34;.set\\tmips32r2\\n\\t\u0026#34; \u0026#34;rdhwr\\t%0, $29\\n\\t\u0026#34; \u0026#34;.set\\tpop\u0026#34; : \u0026#34;=r\u0026#34; (tlsbase)); tlsbase -= TLS_TP_OFFSET + TLS_TCB_SIZE; #endif /* ! __mips_n64 */ tlsbase += offset; return (tlsbase); }"
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/hardbound/",
	"title": "HardBound",
	"tags": [],
	"description": "",
	"content": " References:\n[1] HardBound: Architectural Support for Spatial Safety of the C Programming Language. [paper]\n The C programming language is at least as well known for its absence of spatial memory safety guarantees (i.e., lack of bounds checking) as it is for its high performance. C\u0026rsquo;s unchecked pointer arithmetic and array indexing allow simple programming mistakes to lead to erroneous executions, silent data corruption, and security vulnerabilities.\nMany prior proposals have tackled enforcing spatial safety in C programs by checking pointer and array accesses. However, existing software-only proposals have significant drawbacks that may prevent wide adoption, including: unacceptably high runtime overheads, lack of completeness, incompatible pointer representations, or need for non-trivial changes to existing C source code and compiler infrastructure.\n Overview Hardbound: A hardware bounded pointer architectural primitive that supports cooperative hardware/software enforcement of spatial memory safety for C programs.\nA new hardware primitive datatype for pointers that leaves the standard C pointer representation intact, but augments it with bounds information maintained separately and invisibly by the hardware.\n The bounds are initialized by the software and they are then propagated and enforced transparently by the hardware, The hardware automatically checks a pointer\u0026rsquo;s bounds before it is dereferenced.  One mode of use requires instrumenting only malloc, which enables enforcement of per-allocation spatial safety for heap-allocated objects for existing binaries.\nWhen combined with simple intra-procedural compiler instrumentation, hardware bounded pointers enable a low-overhead approach for enforcing complete spatial memory safety in unmodified C programs.\nDesign  extends every register and word of memory in the virtual address space with a \u0026ldquo;sidecar\u0026rdquo; shadow base and bound.\n \u0026lt;value, base, bound\u0026gt; Non-pointers: base/bound are zeroes. Pointers: base/bound checked upon every load and store instructions.  setbound instruction:\n readbound instruction:\n readbase instruction:\n  Bound set and propagation Bound set and propagation in registers:\n A failed check will raise processor exception; runtime handles expection:  by terminating the process, or invoking some other language-specific exception.    Pointer arithmetic and other pointer manipulations are common in C programs. To free the compiler from the burden of explicitly maintaining and propagating bounds information (and eliminate the associated run-time overhead), the hardware automatically propagates the bounds information when a register containing a pointer is manipulated.\n Bound propagation to/from Memory:\nEvery value in memory also conceptually has a base and bound word associated with it (Mem[add].value, Mem[addr].base, Mem[add].bound).\n Metadata placed in virtual memory space, paralleling the normal data space, but offset b a constant amount.\n base(addr) = SHADOW_SPACE_BASE + (addr * 2) bound(addr) = SHADOW_SPACE_BASE + (addr *2) + 1  Pointer and Non-pointer encoding\n tag metadata space. 1-bit per word to indicate whether the word is a pointer or not. If pointer, load base/bound. If not a pointer, no need to load base/bound. tag metadata cache. In parallel with L1 cache.   Compressing Bounded Pointers  Many pointers in C programs point to structs or small arrays. CCured\u0026rsquo;s success in inferring SAFE pointers indicates that often the value and base component of a pointer are identical. Furthermore, most C structs are small so the differences between the pointer base and bound is also small. These observations suggest a simple mechanism for compressing the metadata: use just a few bits to encode the common case of pointers to small objects, but retain the full base/bound encoding option as a backup.\n todo.\nEvaluation Binary Compatitbility: Yes.\nSource code changes: Almost no, except malloc.\nHardbound:\n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/llvaos/",
	"title": "LLVA OS",
	"tags": [],
	"description": "",
	"content": " References:\n2006-LLVA-OS 1\n2003-LLVA 2\nIdea of LLVA and LLVA-OS LLVA (Low Level Virtual Architecture) supports arbitrary languages including C, and enables sophisticated analyses and optimizations. It provides computational, memory access, and control flow operations.\nHowever, LLVA \u0026ldquo;lacks operations a kernel needs to configure hardware behavior and manipulate program state\u0026rdquo;. Thus comes LLVA-OS.\nLLVA-OS is a set of extensions to LLVA that provides an interface between the OS kernel and a general purpose processor architecture.\nTwo similar set of abstraction layers:\n Application -\u0026gt; libc -\u0026gt; operating system/hardware\n OS Kernel -\u0026gt; LLVA-OS -\u0026gt; hardware\n  OS-hardware Interfaces  Two types:\n access specialized and privileged hardware components.\n registering interrupt handlers; configuring the MMU; performing I/O.  manipulate the state of itself and other programs.\n context switching; signal delivery; process createion.    Program states virtual states  Virtual state is the system state as seen by external software, including the OS. The virtual state of an LLVA program includes:\n The set of all virtual registers for all currently active function activations (?). The implicit program counter indicating which virtual instruction to execute next. The contents of memory used by the current program. The current stack pointer indicating the bottom of the currently active stack. The current privilege mode of the processor (either privileged or unprivileged). A set of MMU control registers. A local interrupt enable/disable flag.   native states  Native state is the state of the underlying physical processor and includes any processor state used by a translated program, such as\n general purpose, floating point, and control flow registers. coprocessors, such as MMUs, FPUs.   Overhead caused by the abstraction  Our evaluation revealed where our design choices added virtualization overhead to the Linux kernel: context switching, data copies between user and kernel memory, read page faults, and signal handler dispatch.\n Applications of LLVA-OS Memory safety for kernel SVA-OS.\nKernel portability improvement If LLVA-OS is able to support a large amount of architectures. Then the same kernel code would be able to run all the architectures without any modification.\nJust like an unmodified java application runs on JVM on any architecture that could run JVM, an unmodified operating system will run on LLVA-OS on any architecture that are supported by LLVA-OS.\n? Any related work. No. Here we see that advancement gap between application research and os research.\nOS compatability of LLVA-OS Different kernels would be able to be supported by the LLVA-OS interfaces.\nJust like C, Java, and Rust can all be compiled to LLVM IR, and do optimization or security analysis in LLVM IR level, different OS kernels should also be able to be \u0026lsquo;compiled\u0026rsquo; to the LLVA with LLVA-OS, enabling \u0026lsquo;IR level\u0026rsquo; compiler analysis.\n? Any related work. No. What is the core challenge here?\nA compiler with full kernel knowledge, just like considering a kernel as a new language but contains the special instructions buried anywhere in any forms. How to compile this much messed language?\n A virtual instruction set interface for operating system kernels, WIOSCA, 2006. ↩ LLVA: A Low-level Virtual Instruction Set Architecture. MICRO, 2003. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/",
	"title": "Program Analysis",
	"tags": [],
	"description": "",
	"content": " Top Wonderings  How to create a restricted language that allows sound and complete point-to analysis?\n Allow/Forbide dynamic allocation? How to handle recursive data structures?  If we can revise the foundamental elements of a system, so that we can use a totally different memory model in the architecture, languages, and OS, can we make pointer-to analysis a decidable and polynomial problem?\n Is it possible to always statically know the size of any memory object? Can we remove the malloc-like mechanisms from the memory model while keeping the memory being dynamically available for program to use? Can we revise the malloc-like mechanisms so that every pointer\u0026rsquo;s property can be statically checked before execution? Rust style: pointer\u0026rsquo;s ownership. Statically or dynamically checked? CHERI style: needs runtime information and check at runtime. Others?    2019CCS Multi-Layer Type Analysis  Reference 1 GeorgiaTech SS Lab: https://gts3.org/pages/projects.html System software commonly uses indirect calls to realize dynamic program behaviors. However, indirect-calls also bring challenges to constructing a precise control-flow graph that is a standard prerequisite for many static program-analysis and system-hardening techniques. Unfortunately, indentifying indirect-call targets is a hard problem. In particular, modern compilers do not identify indirect-call targets by default. Existing approaches identify indirect-call targets based on type analysis that matches the type of function pointers and the ones of address-taken functions.\n Basics  Reference 1 Escape Capture References: Escape Analysis \u0026amp; Capture Tracking in LLVM Pointer Capture: A pointer value is captured if the function makes a copy of any part of the pointer that outlives the call. Pinter Escape: A pointer value escapes if it is accessible from outside the current function or thread. The latter case is sometimes considered separate and called thread-escape. Capture and Escape are not opposites: Informally, escaping is concerned with the contents of the pointer, while capturing is concerned with the pointer itself 1.\n Diff Good Bad  Reference 1 AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context. ICSE. 2015. ↩  Data Structure Analysis  Q \u0026amp; A How many incomplete nodes during evaluation? Ans: Not much, but most program exists. Including the collapsed nodes, ranging from 1.2% ~ 88.5%. See evaluation: type inference result Basics Flow sensitive1: takes into account the order of statements in a program. Path Sensitive: takes into account the branch conditions. Context Sensitive: names objects by entire acyclic call paths. A callee will return to its single call site instead of all possible call sites.\n Pointer Analysis  References: Pointer Analysis: Haven\u0026rsquo;t we solved this problem yet? By Micheal Hind, IBM. PASTE, 2001. Wiki: Program Analysis: https://en.wikipedia.org/wiki/Program_analysis Undecidability References: Pointer Analysis The undecidability of aliasing More Multi-layer Type Analysis Reference 1 C++ and Casting Pointer to virtual function tables is frequently cast to general types such as char*, rendering the type match ineffective. MLTA: a mechanism to precisely connect VTables to the corresponding classes and to keep track of class casting.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/",
	"title": "Cheri Domain",
	"tags": [],
	"description": "",
	"content": " Reference123.\nQuestions  Why do we need domain?\n Globals Across Domains\n Globals are accessible to all domains, no distinguish. This means if some data is passed from Domain A to Domain B, an unrelated domain, say Domain C, will also have a chance to know the data.  Untagged Data Across Domains\n The untagged data in the argument list is not checked when do a CCall. Is it possible to leak information?  Performance Problem\n Memory footprints caused by larger size of pointers in pointer intensive applications: 46% on average for Olden microbenchmark.  How to selectively use capabilities and traditional pointers?  CCall/CReturn overhead.  Pure-hardware solution, but still with flexibility for OS settings? Like MMU as hardware acceleration for page tables?    Motivation (from 2 and 1) Compared with exploit mitigation, which targets attack-vector characteristics, compartmentalization:\n limits privileges and further attack surfaces available to attackers; mitigate a broader class of attack; does not depend on knowledge of specific attack vectors, and is resistant to an arms race as attack and defense co-evolve;  Challenges:\n complexity, programmability, scalability.  Overview Security models A variety of object-capability semantics have been proposed, and we would like to be able to explore many of them on a single platform. For example, prior work has seen disagreement on synchronicity for object-capability invocation: asynchronous primitives allow callers to avoid placing trust in callee termination, but current software designs incorporate strong assumptions of synchronicity 4.\nUser-level C-language TCBs\nA userspace address-space executive, with code spanning libc libcheri, is responsible for security-critical TCB functions such as memory management and class loading.\nThe executive configures memory protection to implement isolation, safely allocates (and reallocates; e.g. via garbage collection) memory and objects, loads class code and passes initial capabilities for both memory and communications into new objects.\nUseful comparison can be made between the address-space executive and both microkernels and language security-model runtimes (e.g. Java). Unlike a microkernel, the executive resides within a UNIX process; like Java support for native code, the executive is responsible for coordinating communication between compartments and general OS services. Unlike the Java security model, code injection attacks are part of the threat model, and containment is maintained even if unexpected unexpected instructions enter execution.\nSealing Capabilities are sealed using CSeal instruction, which accepts two capability-register operands:\n the code or data memory capability to be sealed, and a second capability with the Permit_Seal permission set.  The virtual address of a capability with Permit_Seal set is treated as a type. Object types prevent instance data from being used with the wrong class.\nImplementation Object-capability invocation  CCall/CReturn rely on software exception handlers to partially implement both instructions. CCall performs  Hardware checks, sealing, suitable permissions, matching types select exception vector according to results  CReturn  Trigger a software exception without checks May be eschewed if CCall is used as an asynchronous message-send primitive.  Exception handers:  flush sensitive registers before transition CHERICCallVector -\u0026gt; CHERICCall || CHERICReturn   Compiler Changes (2015 SP): the compiler generates codes that captures object bounds, pointer-integrity properties, and control flow. A new domain-crossing calling convention.\nModified 8KLoC in 2MLoC of total LLVM/Clang code, including LLVM C front end, MIPS backend, and target-independent optimizers.\n Capabilities are used wherever possible to limit accidental buffer overruns, protect pointers (including those used in control flow.) A new calling convention, CHERI_CCall, for functions that can be invoked across domains.  with knowledge of the function type, only the compiler is aware of which argument and return-value registers are used. Compiler clears unused argument registers in the caller context, and unusded return registers in the callee context. CCall and CReturn are responsible for clearing other registers.   Annotations \u0026amp; Compiler  cheri_ccall: compiler will replace calls to it with specially crafted calls to cheriinvoke, with method number (identified by a global variable that is initialised by the sandbox loader) in correct register. This annotation provides two declarations of the function:\n cheri_method_suffix: specifies a suffix that takes an explicit CHERI class argument. cheri_method_class: specifies a global variable that automatically sets the class (code and data capability) argument.  cheri_ccallee: will use the ccall calling convention. The compile will zero any return registers. Allow functions to be declared that are usable both inside and between compartments.\n Functions with ccall calling convention have two extra capability argument registers, $c1 and $c2, which contains the code and data capabilities, an extra integer argument register, $v0, which contains the method number. These are not exposed to functions marked as using the ccallee calling convention, which accept the normal calling convention\u0026rsquo;s argument registers.   OS changes Added 4KLoC in 13MLoC kernel code. More details: kernel changes\n Per-thread trusted stack that links a chain of disjoint, pre-compartment stacks used by each object executing in the thread. Each invoation, CCall saves a code and data capability that CReturn will use to resume. The caller is responsible for setting the invoked data capability ($idc) to a memory region (typically on the caller\u0026rsquo;s stack) that contains everything needed to restore state.  (2015, programmer\u0026rsquo;s guide:) Kernel implements CCall and CReturn via a combined exception handler: CHERICCallVector -\u0026gt; CHERICCall or CHERICReturn. The handlers performs tests and following ABI specifications. (from ABI: invoked code capability is in C1, data cap in C2).\nCCall will push IDC, PCC, and PC+4; CReturn pops them. PC will be in PCC in the future (2015, programmer\u0026rsquo;s guide).\nISA CCall  Checks the provided sealed code ($scc) and data (`$sdc) capabilities are valide and properly sealed, and have matching types and suitable permissions; Checks that argument capabilities are either untagged or have the Global permission. (Untagged data and globals are not protected across domains. Then, how to constrain a Global to only accessible by limited number of domains? domains ontop of domains? layers?).  ISA CReturn  Validating that any returned capability is global or NULL; Clearning non-return registers; Poping and restoring $pcc and $idc.  Microarchitecture Changes  minor additions to implement compartmentalization-focused ISA extension, sealing mechanism, and capability flow control. CClearRegs: modification to register forwarding logic. zero mask on register file: a single bit for each register indicates whether a read should return zero.  Capability Flow Control Addressing the temporal issues when memory is passed between protection domains.\nCHERI has a mechanism to allow some capabilities to be shared but not others. (UCAM-CL-TR-940)\n 2-bit capability: Global vs Local cap;\n Global may be stored via any writable capability;\n Local may be stored only via capabilities that themselves have the Permit_Store_Local permission set.\n CHERIBSD: heap references as global; stack references as local. Sharing of stack data between protection domains is prevented.\n If compartments are setting up with just the authority to read capabilities and to store global capabilities to a shared region, they cannot exchange their local capabilities.(UCAM-CL-TR-940)\nPerformance  Memory Footprints  A worst-case analysis for linked-list and tree traversal operation. Olden microbenchmark suite. Use Capabilities for all pointers. 46% overhead on average in Olden microbenchmark suite.  Domain Crossing Overhead Total cycle count, spanning userspace and kernel, for a zero-byte memcpy in a sandbox   A best-case invoke and return analysis: CCalling a zero-byte memcpy. With hardware argument validation, i.e., object type checking in CCall: -44 cycles(5.5%). With CClearRegs instruction: -172 cycles(21%).  zlib Compartmentalization Compression time for gzip with library compartmentalization   Comparison: CHERI + Process-based Compartmentatlization (Capsicum) + unmodified version. CHERI: a small, near constant, overhead.\n domain switch once. shares memory using capabilities.   Capsicum: linear overhead.\n Must transfer data using IPC.   Scalable Software Compartmentalization, Oakland, 2015.\nMore details  Cheri Compartmentalization Papers  References: reference More 2016 Thesis: Hardware support for compartmentalisation References: Norton, Robert M. Hardware support for compartmentalisation. No. UCAM-CL-TR-887. University of Cambridge, Computer Laboratory, 2016. More 2017 Asplos: CHERI JNI: Sinking the Java security model into the C References: Chisnall, David, Brooks Davis, Khilan Gudka, David Brazdil, Alexandre Joannou, Jonathan Woodruff, A. Theodore Markettos et al. \u0026ldquo;CHERI JNI: Sinking the Java security model into the C.\n Cheri Object Types  Questions from ISAv7 ch3.3.3: The capability is unsealed ( has otype of $2^64 -1$ ). What the $2^64 -1$ comming from? don\u0026rsquo;t we only have 23 bits for object type? ans01: in version 7 of ISA, sealed/unsealed capabilities are no longer distinguished by flag s. Unsealed capabilities were redefined as having otype of $2^64 -1$ and this bit was reclaimed as reserved. User/Kernel Split \u0026ldquo;The CHERI object-type space is split between userspace and kernel, permitting kernel object references to be delegated to userspace (if desired).\n Cheri Permission Constants  CHERI ISA defined permissions 11 permission bits are hardware defined in CHERI ISA. //file: // ./sys/mips/include/cherireg.h /* * CHERI ISA-defined constants for capabilities -- suitable for inclusion from * assembly source code. * * XXXRW: CHERI_UNSEALED is not currently considered part of the perms word, * but perhaps it should be. */ #define\tCHERI_PERM_GLOBAL\t(1 \u0026lt;\u0026lt; 0)\t/* 0x00000001 */#define\tCHERI_PERM_EXECUTE\t(1 \u0026lt;\u0026lt; 1)\t/* 0x00000002 */#define\tCHERI_PERM_LOAD\t(1 \u0026lt;\u0026lt; 2)\t/* 0x00000004 */#define\tCHERI_PERM_STORE\t(1 \u0026lt;\u0026lt; 3)\t/* 0x00000008 */#define\tCHERI_PERM_LOAD_CAP\t(1 \u0026lt;\u0026lt; 4)\t/* 0x00000010 */#define\tCHERI_PERM_STORE_CAP\t(1 \u0026lt;\u0026lt; 5)\t/* 0x00000020 */#define\tCHERI_PERM_STORE_LOCAL_CAP\t(1 \u0026lt;\u0026lt; 6)\t/* 0x00000040 */#define\tCHERI_PERM_SEAL\t(1 \u0026lt;\u0026lt; 7)\t/* 0x00000080 */#define\tCHERI_PERM_CCALL\t(1 \u0026lt;\u0026lt; 8)\t/* 0x00000100 */#define\tCHERI_PERM_UNSEAL\t(1 \u0026lt;\u0026lt; 9)\t/* 0x00000200 */#define\tCHERI_PERM_SYSTEM_REGS\t(1 \u0026lt;\u0026lt; 10)\t/* 0x00000400 */ .\n Rings  Reference 1 (From v7 2.3.14) Use of privileged features within privileged rings, depends on the program-counter capability having a suitable hardware permission set, rather than the traditional permissions in virtual memory as the supervisor. This feature allows code within kernels, microkernels, and hypervisors to be compartmentalized, preventing bypass of the capability model within the kernel virtual address space through control of virtual memory features. The feature also allows vulnerability mitigation by allowing only explicit use of privileged features: kernel code can be compiled and linked so that most code executes with a program-counter capability that does not authorize use of privilege, and only by jumping to selected program-counter capabilities can that privilege be exercised, preventing accidental use.\n Cheri Seal  Questions How can Java/C++ benefit from CHERI\u0026rsquo;s sealed caps? Can Rust ownership benefit from CHERI\u0026rsquo;s sealed caps? Why explicit unseal/ccall (ISAv71 Ch 8.18): Unseal is an explicit operation. In CHERI, it requires explicit operation to convert an undereferenceable object into a pointer. CUnseal or CCall. An alternative architecture would have been one with implicit* unsealing, where a sealed capability could be dereferenced without explicitly unsealing it first, provided that the subsystem attempting the dereference had some kind of ambient authority that permitted it to dereference sealed capabilities of that type.\n Example: User Defined Object Capabilities  The object type in user space is splited into two ranges: non-system type numbers: [1, $2^{22}$ - 1 ]; system type numbers: [$2^{22}$, $2^{23}$ - 1 ]; while the object types in kernel space is [$2^{23}$, $2^{24}$ -1 ]. Example 1: static sandboxes Code is derived from cheritest_ccall.c. (Note: This portion of testing code in CheriBSD is commented out in cheritest.c, which means no available by default.\n Example: System class object capabiilties  The object type in user space is splited into two ranges: non-system type numbers: [1, $2^{22}$ - 1 ]; system type numbers: [$2^{22}$, $2^{23}$ - 1 ]; while the object types in kernel space is [$2^{23}$, $2^{24}$ -1 ]. Cheri System class is the CHERI system type of the system library. Object type: libcheri_system_type Overview IN file: lib/libcheri/libcheri_system.h: The header defines the interface for the libcheri system class.\n Libcheri CCall and Trampolines  libcheri_ccall.c This file provides the C implementation of the userspace CCall trampoline for libcheri. Three object types are used: CCall path into rtld initialization, invocation, and CReturn. For CCall data capabilities, we use the sandbox object pointer, where we can find any data required to perform the domain transition, including a suitable capability for use with TLS. Currently, this means deriving these sealed data capabilities from DDC. (LLM: ??? where to derive in the future)\n libcheri Stack  file: libcheri_stack.c This file implements the \u0026ldquo;trusted stacks for the libcheri compartmentalization model\u0026rdquo;. \u0026ldquo;Each pthread has its own trusted stack that tracks calls between libcheri objects; frames contain the information required to recover control safely to the caller context (in another protection domain) both in the event of a CRetrun from the callee, and in the event of a trusted-stack unwind due to an exception termination execution in a object permaturely.\n libcheri Enter  libcheri_enter_init() initializes the landing-pad environment for system-object invocation. It implements a stack landing pad for system classes provided by libcheri. The single stack is statically allocated \u0026ndash; meaning no concurrent invocation from sandboxes in multiple threads (or reentrantly). Currently, that is ensured by virtue of applications not themselves invoking sandboxes concurrently. // file: // lib/libcheri/libcheri_enter.c void libcheri_enter_init(void) { /* XXX: Should be MAP_STACK, but that is broken. */ __libcheri_enter_stack = mmap(NULL, LIBCHERI_ENTER_STACK_SIZE, PROT_READ | PROT_WRITE, MAP_ANON, -1, 0); assert(__libcheri_enter_stack !\n libcheri Sandbox  Initialization of system-class sandbox see libcheri system sandbox Initialization of user defined sandbox sandbox_init() in libcheri_sandbox.c; Jobs include: get current process text file and open it; sandbox_parse_ccall_methods: parse elf binary file (CHERI_CALLEE, and CHERI_CALLER sections) get a list of sandbox_provided_classes (class, methods, offset), and its required methods (name, class, offset). sandbox_update_main_required_method_variables, use the returned required method list from last step, updating the data structure in the sandbox (initialize the vtable offset); create libcheri_system_vtable, libcheri_fd_vtable\n libcheri_invoke: CCall Implementation in CheriBSD  libcheri_invoke is defined in assembly code; two versions for different ABIs respectively. Hybrid libcheri_invoke The Hybrid MIPS ABI (github): # file: lib/libcheri/mips/libcheri_invoke_hybrid.S # # Assembly wrapper for CCall on an object-capability. Its function is to save # and restore any general-purpose and capability registers needed on either # side of CCall, but not handled by the compiler. This is done by creating an # on-stack frame which will be pointed to by $idc before CCall, and then # unwrapping it again.\n Stores  Reference: CCall Examples References: [1] Stack Underflow //file: ./bin/cheritest/cheritest_libcheri_trustedstack.c /* * Perform a return without a corresponding invocation, to underflow the * trusted stack. */ void test_sandbox_trustedstack_underflow(const struct cheri_test *ctp __unused) { struct cheri_object returncap; void * __capability codecap /* currently ignored: asm (\u0026#34;$c1\u0026#34;) */; void * __capability datacap /* currently ignored: asm (\u0026#34;$c2\u0026#34;) */; returncap = libcheri_make_sealed_return_object(); codecap = returncap.co_codecap; datacap = returncap.co_datacap; /* * TODO: the branch delay slot has been removed.\n  Fast Protection-Domain Crossing in the CHERI Capability-System Architecture, MICRO, 2016. ↩ CHERI: A Hybrid Capability-System Architecture for ↩ CHERI Programmer\u0026rsquo;s Guide, UCAM-CL-TR-877, 2015. ↩ EROS: a fast capability system. by Shapriro, J., Smith, J., and Farber, D. SOSP, 1999. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/mmachine/",
	"title": "M-Mmachine",
	"tags": [],
	"description": "",
	"content": "References:\n[1] Hardware support for fast capability based addressing. SIGPLAN, 1994.\n[2] CHERI Concentrate: Practical Compressed Capabilities, IEEE Transactions on Computers, 2019.\nM-Machine Capability Format  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/mpx/",
	"title": "Intel MPX",
	"tags": [],
	"description": "",
	"content": " Reference1\nArch support Instructions:\n BNDMK: saving bound pair for bounds register\n BNDCL: checking lower bound with bounds register value and operands\n BNDCU, BNDCN: checking upper bound with bounds register upper value and operands.\n BNDMOV: accessing bound register.\n BNDLDX: loading bounds reigister from memory.\n BNDSTX: saving bounds register to memory.\n  Registers:\n BND0-3 Bound registers. BNDCFGU. configuration register for bound paging in ring 3. BNDCFGS. configuration register for bound paging in ring 0/1/2. BNDSTATUS.  OS support Bound paging: Bound Directory \u0026mdash;\u0026ndash;\u0026gt; Bound Table \u0026mdash;\u0026mdash;\u0026gt; Bound Table Entry\n Bound Table max size is 2GB (64-bit mode). kernel allocates bounds table dynamically; add VM_MPX flag to VM page attributes.  Latest Researches  LLVM MPX (BOGO)  Q\u0026amp;A How to determine the size of object? How to store the bound info in MPX? How to do bound checking? How to choose the instrumentation point? A Map from instruction to the pointer it want to access? Reference 1 Overview A module pass: class llmpx: public ModulePass runOnModule(Module \u0026amp;) Methods: mpxPass(Module \u0026amp;) harden_cfi(Module \u0026amp;) create_global_constants(Module \u0026amp;) collect_safe_access(Module \u0026amp;) transform_functions(Module \u0026amp;) transform_global(Module \u0026amp;)\n BOGO: Buy Spatial Memory Safety, Get Temporal Memory Safety (Almost) Free  Reference 1 LLVM MPX (BOGO) Q\u0026amp;A How to determine the size of object? How to store the bound info in MPX? How to do bound checking? How to choose the instrumentation point? A Map from instruction to the pointer it want to access? Reference 1 Overview A module pass: class llmpx: public ModulePass runOnModule(Module \u0026amp;) Methods: mpxPass(Module \u0026amp;) harden_cfi(Module \u0026amp;) create_global_constants(Module \u0026amp;) collect_safe_access(Module \u0026amp;) transform_functions(Module \u0026amp;) transform_global(Module \u0026amp;)\n USENIX Security\u0026#39;19 ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK)  References: Vahldiek-Oberwagner, Anjo, Eslam Elnikety, Nuno O. Duarte, Michael Sammler, Peter Druschel, and Deepak Garg. \u0026ldquo;ERIM: Secure, efficient in-process isolation with protection keys (MPK).\u0026rdquo; In 28th USENIX Security Symposium (USENIX Security 19), pp. 1221-1238. 2019. Background Intel MPK: 4-bits permission bits in page table entry; 16 disjoint domains. PKRU: 32-bit registers; 2-bits perms for each region. 11-260 cycles to update PKRU. 0.07 to 1.0% overhead per 100,000 switches/s on a 2.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/pagebits/mpk/",
	"title": "Intel MPK",
	"tags": [],
	"description": "",
	"content": "References:\n[1] ERIM: Secure, Efficient In-process Isolation with Memory Protection Keys (MPK), SEC, 201908. paper\n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxhw/ssm/",
	"title": "SSM",
	"tags": [],
	"description": "",
	"content": "Reference1\n reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/book-soft/v4-qc/",
	"title": "V4 Quick Chick: Property-Based Testing in Coq",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/neverland/",
	"title": "Neverland",
	"tags": [],
	"description": "",
	"content": " Reference 1 Neverland: Lightweight Hardware Extensions for Enforcing Operating System Integrity.\nMontivations Current solutions has draw backs:\n Secure Boot, driver signing  Secure Boot is not enough to protect kernel from being tempered: attackers could exploit software vulnerabilities to perform malicious actions such as overwriting kernel memory, executing malware in kernel-mode, or disabling driver integrity checks (example attacks can be seen in [^c64] [^c8] [^c16] [^c41] [^c62] [^c54] [^c48] [^c44]).\n Supervisor Mode Access/Execution prevention.\n In kernel integrity monitor.\n  Continuous Integrity Monitor can be subverted if run at the same privilege level: a kernel bug has previously been exploited to bypass Microsoft\u0026rsquo;s Kernel Patch Protection (KPP) feature[^c1].\n virtualization based kernel protection.  Protection mechanisms via virtualization support [^c17] [^c22] [^c33] [^c60] [^c55] [^c50] [^c12]: either in a hypervisor or in another separate virtualized operating system. E.G: Microsoft Windows 10 has adopted this approach to protect its driver and kernel integrity enforcement mechanisms[^c66].\nTrusted execution environment. TrustZone, SGX. EG. Android devices commonly take advantage of TrustZone to isolate the kernel integrity mechanisms from the main kernel [^c5] [^c7].\nHowever,\n Vulnerabilities inside protection mechanisms remain exploitable. Attacks on TrustZone [^c42] [^c7]. Virtualization based security relies on hypervisors, which themselves has large attack surface and serious vulnerabilities have been found [^c43] [^c45] [^c46] [^c47]. And overhead is high [^63] [^26].  Neverland hardware based protection, zero runtime performance overhead.\nDuring boot, neverland takes away the ability of OS to overwrite certain configuration registers and portions of the physical address space.\n lock the kernel\u0026rsquo;s code and read-only sections; security critical configurations(driver signing configuration tables, system call table); CPU configuration registers that store kernel entry points.\n prevents the CPU from fetching kernel-mode code from any memory region lying outside the physical address assigned to the OS kernel and drivers, regardless of virtual page permissions.\n hardware permission table to mark physical address space as read-only, executable, privileged, and locked. (Similar to ARM MPU, RISC-V PMP)\n locked CPU configuration registers, to prevent system call/interrupt hijacking.\n  Prevented attacks Kernel mode rootkits:\n Malicious Drivers Privilege Escalation attacks Code patching System call and interrupt table hooking Hooking code pointers Direct kernel object manipulation (DKOM)  Implementation   Neverland: Lightweight Hardware Extensions for Enforcing Operating System Integrity. by Salessawi Ferede Yitbarek, Todd Austin. arXiv, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxhw/trustzone/",
	"title": "Trustzone",
	"tags": [],
	"description": "",
	"content": "See Architecture - ARM - TrustZone\n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/paperwriting/",
	"title": "Paper Writing",
	"tags": [],
	"description": "",
	"content": " UChicago: The Craft of Writing Effectively    Valuable to the audience\n Valueable is determined by people people in and out over time, knowledge in and out over time. knowledge will be \u0026lsquo;abondoned\u0026rsquo; after it is done. What make it be important? Words: neitherless, however, although, inconsistent, reported, \u0026hellip; Words creating value to the readers.  Words signaling community: widely, reported, \u0026hellip; Words for flow/transition: and, but, however, Words for Instability (tension/contradiction): anomaly, inconsistent, but, however,  The code shared in the community to create values.  Polite way.  Ph.D. 4-5 years: learning more things + learning to know your readers. Identify the readers and give what they want.  Professional writing is not conveying your ideas to your readers, but changing their ideas.\n \u0026ldquo;Why do you think that?\u0026rdquo; is a bad question to an expert. Teachers ask this because they want to know what the students think.  If reader does not understand, do not explain. Why shouldn\u0026rsquo;t you explain?\n Explain is to revealing the world the inside of your head. But no one cares about the inside of your head (unless teachers are paid to care about your ideas).  Why teachers read student\u0026rsquo;s text?\n Paid to care about the students.  Why collegues (journals, conference) reading your writing?\n Valuable \u0026gt;\u0026gt;\u0026gt; Persuasive, Organized, Clear Value is not determined at your Word, but at the Readers. Different people (community/conference/journal) has different \u0026lsquo;value\u0026rsquo; judgement.   Think \u0026mdash; Words, for experts.\n Think about word in difficult ways. Writing pattern: (Horizontal) Write words to help yourself think. Challenge problems. Reader pattern: (Vertical) Slow down, re-reading; misunderstand; agervated.  Rules of writing: good for \u0026ldquo;low value\u0026rdquo; writing.\n short memo every day. think about rules, about readers.   UChicago: More faculty than freshmen.\nTutorial from Derek Dreyer How to write a paper and give talks that people follow\n   Flow from sentence to sentence: old to new things.\n Point sentence of a paragraph.\n Structure:\n Top-Down: explain multi times, each time deeper with different abstractions. For complex ideas. E.G: abstract -\u0026gt; Intro -\u0026gt; Key ideas -\u0026gt; Tech meat -\u0026gt; related work.   Name your baby. Consistent between collaborators.\nJust in time for technical information, not before.\nCGI model Context, Gap , Innovation.\nmotivation, problem/existing, new stuff.\nUnderstanding how readers processing information. References:\n element of style: \u0026ldquo;Be clear\u0026rdquo;, but how? Style: Toward clarity and grace. 1990. Jseph M. Williams. How to write a great research paper. Simon  Excellent Samples:\nPortable Native Client @ USENIX Security 20101\nStyles:\nVirtual Ghost 2: introduction = comparison to related + design + implementation + evaluation. No challenges explicitly explained, no contributions explictly listed as bullets.\n Limitations  Limitation Every work has limitations. Some inherits from the design; Some exist because they are just obvious but complex to implement. Reviewers might be interested in this to see how you understand the solution by yourself. Some reviewers will reject you if they pointed out some limitations that you haven\u0026rsquo;t discussed in the paper. However, if you can discuss the limitation of your work thoroughly, this will show the depth of your understanding in the field and will get your work be understood better.\n  Adapting Software Fault Isolation to Contemporary CPU Architectures. USENIX SEC, 2010. ↩ Virtual Ghost: Protecting Applications from Hostile Operating Systems. ASPLOS, 2014. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/",
	"title": "System Security",
	"tags": [],
	"description": "",
	"content": "Reference:\n Security Policies  PORTIA: Of a strange nature is the suit you follow; Yet in such rule that the Venetian law Cannot impugn you as you do proceed. [To Antonio.] You stand within his danger, do you not? \u0026ndash; The Merchant of Venice, IV, i, 177\u0026ndash;180 Book: Computer Security, Art and Science, By Matt Bishop, 2nd edition. A security policy defines \u0026ldquo;secure\u0026rdquo; for a system or a set of systems. A security policy is a statement that partitions the states of the system into a set of authorized, or secure, states and a set of unauthorized, or nonsecure, states.\n Attacks  Reference: Sgx Reference 1 2010-03-10 unfixable flaw reference ↩ Rop Reference 1 Return Oriented Programming Attacks reference ↩ Container Privilege Escalation Reference: DOP Data Oriented Programming Attacks Side Channel References: reference More Spectre Attacks References: Survey of Transient Execution Atacks. Wenjie Xiong, Jakub Szefer. Arxiv, 2020. More  Defences  Reference: Control Flow References: reference More uCFI References: Enforcing Unique Code Target Property for Control-Flow Integrity, CCS\u0026rsquo;18 UCT: Unique Code Target ICT: Indirect Control-flow Transfer Key: collecting the necessary runtime information and using it to augment the points-to analysis on control data. Contraining data: the data helps to determine the target of indirect calls. How to identify the constraining data? How to collect this data efficiently? How to perform the points-to analysis efficiently and accurately?\n Detection  Reference: Hw Monitor Reference 1 Hardware-based monitoring technique that can detect if the system calls of sophisticated embedded operating systems (e.g. Linux) deviate from the originally programmed behavior due to an attack. By Verifying operation at the level of an individual processor instruction, we can detect any deviation almost instantaneously. By limiting the monitoring to a fraction of the operating system code (i.e. system calls) and not the entire code base, we can achieve low overhead compared to other hardware monitoring approaches.\n VMI  Reference 1 Hwvmi Reference 1 Introspection in hardware. To match network connections to the application-layer while being isolated and undetected from the operating system or the hypervisor. Motivation Firewalls: external firewall: external device only connected to network cannot see the content of the target computer\u0026rsquo;s physical memory, thus cannot make decision based on what code is accessing the traffic; software-based firewall: installed on a target computer. can be the target of attacks themselves.\n Surveys   References: reference More On the State of Internet of Things Security: Vulnerabilities,Attacks, and Recent Countermeasures References: SISODIA, DEVKISHEN. \u0026ldquo;On the State of Internet of Things Security: Vulnerabilities, Attacks, and Recent Countermeasures.\u0026rdquo; University of Oregon, Tech. Rep (2020). More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/detection/",
	"title": "Detection",
	"tags": [],
	"description": "",
	"content": "Reference:\n Hw Monitor  Reference 1 Hardware-based monitoring technique that can detect if the system calls of sophisticated embedded operating systems (e.g. Linux) deviate from the originally programmed behavior due to an attack. By Verifying operation at the level of an individual processor instruction, we can detect any deviation almost instantaneously. By limiting the monitoring to a fraction of the operating system code (i.e. system calls) and not the entire code base, we can achieve low overhead compared to other hardware monitoring approaches.\n Prima  PRIMA1: Info flow attestation. an extension to Linux IMA: measures the code (Linux IMA), and measures which information are present among processes. attest Biba and Clark-Wilson2, CW-Lite3; CW-Lite attestation is proved. Implementation: on SELinux. Info flow examples: Biba integrity requires that a process receive no input that is lower integrity than itself4. LOMAC(Low-Water Mark Integrity) requires that a process\u0026rsquo;s integrity be that of the lowest integrity input that it receives5.\n Flicker  Flicker1: 250 lines of code trusted; No trust on BIOS, OS, DMA devices. Trust processor (AMD/Intel) Fine-grained Attestation: e.g. A piece of server code handling the client password; no trust on all other softare stack from BIOS to OS. e.g. A Certificate Authority (CA) could sign certificates with its pricate key, even while keeping the key secret from a malicious BIOS/OS/DMA-enabled devices. Use of Flicker can be attested.\n Verifiable Code Execution  Pioneer1 Untrusted computing platform can tamper with code execution in at least three ways: By modifying the code before invoking it; Executing alternate code; or modifying execution state such as memory or registers when the code is running. Pioneer: challenge-response protocole between trusted \u0026amp; untrusted platform. Assuarance that: an arbitrary piece of code (the executable) on the untrusted platform is unmodified; the unmodified executable is invoked for execution on the untrusted platform; The exectable is executed untampered, despite the presence of malicious software on the untrusted platform.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/signal/",
	"title": "Signals in Sandboxed Code",
	"tags": [],
	"description": "",
	"content": " Questions/Proposals  Can a signal handler in userspace overwrite the trusted stack?  Umodified signal handling:\n a regular MIPS process CHERI-aware process that does not make use of sandboxing (protection domains).  Signal in a sandbox When a signal must be delivered to the target thread and the code is executing in a sandbox of that thread. Then sandbox code\u0026rsquo;s stack cannot be used for signal handling. Kernel will have different operations in the following situations 1:\nSandboxed code, trap signal arises, no registered signal handler \u0026ndash; unwind Automatic trusted-stack unwinding using cheri_stack_unwind, returning control to the caller. Assumptions:\n a thread triggers a trap signal due to an exception, and the signal is uncaught, and signal is tagged as SIGPROP_SBUNWIND  In this case, \u0026lsquo;sandboxed code\u0026rsquo; means that one or more frames are present on the trusted stack, rather than that the current execution context lacks privilege.\nSandboxed code, registered signal handler, no alternative signal stack \u0026ndash; terminate If handler registered, then we must install a suitable signal-handling context (typically, ambient authority).\nHowever, we cannot trust the stack in the sandbox context, thus we will instead use the UNIX alternative signal stack.\nIf one is not defined for the thread, the process will be terminated as there is no safe way to handle the signal.\nIn this case and the following case, \u0026lsquo;sandboxed code\u0026rsquo; means that the current executing context does not have ambient authority \u0026ndash; i.e., that it cannot invoke system calls.\nSandboxed code, registered signal handler, alternative signal stack \u0026ndash; deliver If an alternative signal stack is configured, then ambient authority will be temporarily restored and signal delivery will take place no the alternative stack.\nCurrently, the kernel installs ambient-authority capabilities in PCC, C0, C11 (stack capability), and IDC prior to executing the signal handler.\nWhen signal handler returns, the kernel will restore capability-register state saved on the stack. This will release ambient authority if the saved (and possibly rewritten) register does not hold it.\nConfiguring an alternative signal stack requires that a signal stack be allocated and registered with signalstack and the signal handler be registered to use it with the SA_ONSTACK flag in sigaction1.\nImmature ABI Up to 2015, programmer\u0026rsquo;s guide:\nUser code can access the saved capability-coprocessor register values, including the capability-cause register (cf_capcause), via a struct cheriframe pointed to by the uc_mcontext.mc_cp2state pointer in the context_t argument to the signal handler.\nThe signal handler should check that the mc_cp2state pointer is non-NULL, and the correponding uc_mcontext.mc_cp2state_len field is equal to sizeof(struct cheriframe), before proceeding.\nThis ABI is currently immature, as the same daa structure is used both for kernel\u0026rsquo;s internal representation of the capability and its on-stack representation; this will change in the future version of CheriBSD.\nTrusted stack writable for signal handlers As ambient authority is installed, signal handlers are also able to rewrite the trusted stack1. This allows more mature handling of exceptions within sandboxes or other invoked contexts \u0026ndash; for example, unwinding of the trusted stack, garbage collection activitites, etc. In CheriBSD\u0026rsquo;s cheritest tool, this is used to handle timeouts trigged by SIGALRM, terminating sandboxed if they overrun their execution-time limit, for example.\nA key design choice is that signal handlers are not invoked by a CCall-like mechanism. This is done for several reasons, not least that we wish to be able to handle trusted-stack overflow in userspace via a signal handler. Great care must be exercised in writing signal handlers that execute with ambient authority in order to not leak privileges to a non-ambient context2.\n CHERI programmer\u0026rsquo;s guide, TR-877, 2015. ↩ Who can write signal handlers? ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/svaos/",
	"title": "SVA-OS",
	"tags": [],
	"description": "",
	"content": " References:\n2007-SOSP-SVA 1\n2009-SEC-SVA 2\nQuestions/Proposals  Compiler assisted program partition to achieve the SVA effect?  Memory Safety by kernel  C language memory safety in kernel\u0026rsquo;s code base Memory safety related functionality of the kernel  process states in trap/exceptions, including context switching. virtual/physical page mappings I/O memory, DMA memory   Idea of SVA-OS LLVA-OS is an interface prvoides \u0026ldquo;richer OS-information for hardware, greater flexibility in evolving hardware, and sophisticated analysis and optimization capabilities for kernel code\u0026rdquo;.\nRemoving compiler from TCB SVA type system:\nEncoding security policies as type systems within the typed bytecode language in SVA.\n derived from SAFECode, enhanced with metapool.\n allows to check that complex pointer analysis is correct.\n a soundness gurantee on the principles used in this work. (LLM: which principles?)\n  Typing rules in the type system check that the annotated types are never violated.\nType checker implements the typing rules to check the encoded proof is correct.\nMore typing: information flow[^35], security automata[^48]\n Secure Virtual Architecture: A Safe Execution Environment for Commodity Operating Systems, SOSP, 2007. ↩ Memory Safety for Low-Level Software/Hardware Interactions, Usenix Security, 2009. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheriabi/",
	"title": "CheriABI",
	"tags": [],
	"description": "",
	"content": " Todos:\n what is the 1% of the C userspace not adapted to CHERI? Why?\n Lele: idiom violations/undefined behaviors; need manual change to be adapted.  How to prevent confused-deputy attacks via the kernel?\n How cheri generate dynamically linked programs?\n What is ABI\u0026rsquo;s relation with Compilers, OS, and architectures? What is ABI?\n  Motivation/Problems Problem of C C language is not safe.\n memory errors; injecting, manipulating, or abusing pointers in the run-time environment; explicit: declared data/code pointers; implicit: generated code to implement global variables (PIC, GOT, PLT) or return addresses; by the runtime to implement cross-library control flow.  How to protect C programs.\nProblem of MMU based protections  MMU:  process-granularity fault isolation. OS correct mappings. page granularity protection. No scale for fine-grain protection. e.g. for language-defined objects. often much smaller than a page or not sized in whole pages. No distinguish of virtual addr from arbitrary integers.   MMU\u0026rsquo;s granularity and address validation\nProblem of lastest research works C-language memory safety research:\nSoftware and hardware based mitigation techniques\n protect the integrity of pointers constrain control flow protect the code and data referenced by pointers  Examples:\n MPX\n Hardbound/SoftBound/FatPointers\n SAFECode/CETS\n  Cons:\ndisruptive:\n requiring large changes to existing codebases; using a unique OS or library infrastructure in stead of a full POSIX environment; being limited to statically linked code; lacking coverage in run-time libraries or kernels; incurring high performance costs.  Proposing:\n abstract capability: describes the accesses that should be allowed at a given point in the execution, whether in the kernel or userspace.\n a large-scale C-language software stack with strong pointer-based protection, with only modest changes to existing C codebases, and with reasonable performance cost.\n a complete C, C++, assembly-language software stack, including the open source FreeBSD OS, and PostgreSQL database, to employ ubiquitous capability-based pointer and virtual-address protection.\n  Two Key Challenges  capabilities are in terms of virtual addresses:\n with virtual-physical mapping, each capability allows direct access to a specific subset of physical memory; Mapping change overtime: when OS creates a new user process, maps additional memory, alters the backing of a mapping, or context switches to other address spaces.  diversity of pointers: created in a wide variety of ways; some of which require special intervention to preserve the provenance chain of abstract capabilities: paged out pointers; pointers in debugging mode.\n  Overview Two priciples1:\n Principle of least privilege. Principle of intentional use. An invoked privilege should be selected explicitly rather than implicitly.  The new CheriABI introduces a new process execution environment in which pure-capability CHERI code can be executed2.\nThe kernel expects all pointers passed via the system-call interface, and also other interfaces such as command-line arguments and environmental variable, ELF auxiliary arguments, signal handling, and so on, will also be via capabilities rather than MIPS pointers.\nThis feature can be enabled by compiling options COMPAT_CHERIABI into the kernel, but is currently considered experimental (2015 programmer\u0026rsquo;s guide2).\nMinimal privilege Memory accesses are not merely via arbitrary integers (checked against only the process address space), but also require an abstract capability, conferring an appropriate set of memory access permissions;\nProvenance Provenance in this paper is a series of correct operations like those we describe in 2019-POPL3, not to the attribution of errors as in Bond4.\nAbstract capabilities are constructed only by legitimate provenance chains of operations, successively reducing permissions from initial maximally permissive capabilities provided at machine reset; and code is not given access to excessive capabilities.\nWhole-system execution environment  Importantly, we aim to provides this across whole-system executions, not just within the C-language portion of user processes.\n Where pointers are constructed and manipulated:\n process creation; virtual memory including swapping; system calls; dynamic linking; context switching; signal delivery; debugging; a host of C-language operations.  Key Challenge: confused-deputy attacks via the kernel Virtual to physical mapping  Virtual to physical mapping: Each process get a principle ID\n prevent illegal access from another process.  Physical memory managed: a never-before-used addresses for allocation.\n prevent two different virtual address mapped to same physical address.   Swapping  maintain a swapping metadata that resides in memory and not swapped.  recording tags for each 256-bit memory that was swapped out. storing reconstructing the capability tags when swapped in.    \u0026ndash;\u0026gt; Kernel must have the full capability to reconstruct any capability during swapping in.\nThen how to constraint this part of kernel to have least privilege?\nDetailed ABIs Register usage    Register Compiler Usage     $v0 contains the method number for cross-domain calls.   $c0 Used implicitly for all non-capability memory accesses.   $c1 - $c16 Used for arguments in the \u0026ldquo;fast\u0026rdquo; calling convention.   $c1 - $c2 Code and data capability arguments with the ccall calling convention.   $c3 Capability return value.   $c3 - $c10 Capability arguments (caller-save).   $c11 Sack capability (pure-capability ABI).   $c12 Used with cjalr as the destination register (pure-capability ABI).   $c13 Capability to on-stack arguments (variadic functions only).   $c11 - $c15 Temporary (caller-save) registers.   $c17 Capability link register used with cjalr (pure-capability ABI).   $c16 - $c24 Saved (callee-save) registers.   $c25 - $c31 Not used by the compiler.    Two ABIs Cheri compiler supports two ABIs, an extended version of the MIPS n64 ABI and the pure-capability ABI where each pointer is a capability.\nMIPS ABI  use jalr $t9, $ra for function call.\n calling convention: add support of capability arguments\n $c3 - $c10 are passed as capability arguments, with $c3 also used for capability return values.  variadic calls does not support capability arguments.\n  Pure-capability ABI  use $c11 as stack capability. use cjalr $c12, $c17 for function call. use cjr $c17 for return. variadic calls: all arguments are passed on stack.  $c13 register holds a capability to the on-stack arguments. va_start function copies the value that was stored in $c13 on entry to the function. va_list is a capability to the (on-stack) variadic arguments and va_arg calls ensure correct alignment, load from the capability, and increment its offset past the value. The alignment requirements can result in large gaps in the variadic argument list if integer and capability arguments are inverleaved. extending use of $c13 for general range of on-stack arguments.   Cross-domain calls: ccall chericcallcc calling convention2: - use $c1 and $c2 for the first two capability arguments and $v0 for the method number. - frontend will lower structs to a sequence of scalars, which is generated from a two-capability struct.\n backend will track argument registers and return registers, zero unused ones.\n compiler generates two special sections, which libcheri runtime will leverage to match the cross domain calls.\n __cheri_sandbox_required_methods: metadata about methods that are required by the binary. __cheri_sandbox_provided_methods: metadata about methods that are provided by the binary.   The metadata struct for a method in __cheri_sandbox_provided_methods:\n// file: lib/libcheri/libcheri_sandbox_methods.c  /* * Description of a method provided by a sandbox to be called via ccall. * This data is used to create the \u0026#39;sandbox class\u0026#39; vtable, resolve symbols * to fill in caller .CHERI_CALLER variables, and store the corresponding * method numbers in the .CHERI_CALLEE variables of each \u0026#39;sandbox object\u0026#39;. */ struct sandbox_provided_method { char\t*spm_method;\t/* Method name */ vm_offset_t\tspm_index_offset;\t/* Offset of callee variable */ }; /* * List of methods provided by a sandbox. Sandbox method numbers (and * by extension vtable indexs) are defined by method position in the * spms_methods array. * * XXX: rename to sandbox_provided_class */ struct sandbox_provided_methods { char\t*spms_class;\t/* Class name */ size_t\tspms_nmethods;\t/* Number of methods */ size_t\tspms_maxmethods; /* Array size */ struct sandbox_provided_method\t*spms_methods;\t/* Array of methods */ }; /* * List of classes provided by a sandbox binary. Each binary can * support one or more classes. No two binaries can provide the same * class as vtable offsets would be inconsistant. */ struct sandbox_provided_classes { struct sandbox_provided_methods\t**spcs_classes;\t/* Class pointers */ size_t\tspcs_nclasses; /* Number of methods */ size_t\tspcs_maxclasses; /* Array size */ size_t\tspcs_nmethods; /* Total methods */ vm_offset_t\tspcs_base;\t/* Base of vtable */ }; The metadata struct for a method in __cheri_sandbox_required_methods:\n// file: lib/libcheri/libcheri_sandbox_methods.c  /* * Description of a method required by a sandbox to be called by ccall. */ struct sandbox_required_method { char\t*srm_class;\t/* Class name */ char\t*srm_method;\t/* Method name */ vm_offset_t\tsrm_index_offset;\t/* Offset of caller variable */ vm_offset_t\tsrm_vtable_offset;\t/* Method number */ bool\tsrm_resolved;\t/* Resolved? */ }; /* * List of methods required by a sandbox (or program). Sandbox objects * must not be created until all symbols are resolved. */ struct sandbox_required_methods { size_t\tsrms_nmethods;\t/* Number of methods */ size_t\tsrms_unresolved_methods; /* Number */ struct sandbox_required_method\t*srms_methods;\t/* Array of methods */ }; Example header dumped from cheri_tcpdump:\nAssumptions:\n os/lib assumption: they will zero/preserve all non-argument registers across security domain transitions. float assumption: always used and not cleared; need revisiting.  see cheri domain for more details about ccall.\nGlobal initialization  \u0026ldquo;Capabilities cannot be statically defined in the binary as other data, because doing so will not set the tag.\u0026rdquo;\n What if we have tags in the binary file, i.e. on the disk storage?   A new section in ELF binary: __cap_relocs, which contains instances of the capreloc structure, one for each capability.\nstruct capreloc { void *__capability capability_location; void *object; uint64_t offset; uint64_t size; uint64_t permissions; };  capability_location: relative address of the capability that must be initialized at run time; object: address of the object that the capability refers to. offset: offset within this object. size: size of underlying object.  For example, the code\nextern int a[5]; int *b[] = {\u0026amp;a[2], \u0026amp;a[1], a}; will be compiled to the following three structures in the ELF:\n{ \u0026amp;b[0], \u0026amp;a, 8, 0, 0}, { \u0026amp;b[1], \u0026amp;a, 4, 0, 0}, { \u0026amp;b[2], \u0026amp;a, 0, 0, 0} The size is 0 and will be reset after linking.\n Limitations (in 2015, programmer\u0026rsquo;s guide):\n should have a flag to indicate code or data capability. have no way of enforcing permissions. dynamically linked binaries will need a run-time linker to provide symbol sizes.   Return address protection In the pure-capability ABI, return address is a $pcc-relative capability.\n If overwritten with non-capability, will trigger tag violation. If overwritten by a non-executable capability, will trigger a permission violation.  A success attack, will have to\n find an executable capability trick the program into writing over the return address  In the MIPS ABI, return sequence is modified:\n non-leaf functions, when spill return address, also spill a return capability: $pcc with its offset to the return address. use cjr to return. still spill the return address for compatability (some tools rely on the position of the return address on the stack).   RISC architectures typically provide a jump instruction that puts the return address in another register (e.g. jalr on MIPS, bl[x] on ARM). If the called function calls another function, it must spill return address to the stack, where it can be reloaded later.\n  CheriABI: Enforcing Valide Pointer Provenance and Minimizinig Pointer Privilege in the POSIX C Run-time Environment, ASPLOS, 2019. ↩ CHERI Programmer\u0026rsquo;s Guide, 2015. ↩ Exploring C Semnatics and Pointer Provenance. POPL 2019. ↩ Tracking Bad Apples. OOPSLA, 2007. It tracks the origin using metadata stores the origin infomation and reports the origin of null and undefined value errors. It shows how to record where these values come into existence, correctly propagate them, and report them if the cause an error. The key idea is value piggybacking: when the original program stores an unusable value, value piggybacking instead stores origin information in the spare bits of the unusable value. Modest compiler support alters the program to propagate these modified values through operations such as assignments and comparisons. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/",
	"title": "Memory Safety",
	"tags": [],
	"description": "",
	"content": " Top Wonderings  Until now, how many ways do we have to resolve memory safety issues?  Tackling layers in the system, one or two but not all layers: New language. Cyclone, CCured, Java, Rust, \u0026hellip; Compiler analysis/instrumentation. SoftBound, Hardware extension. NX bit, page/region permission, Intel MPX, Enclaves, HardBound, \u0026hellip; Operating system. ASLR, \u0026hellip; A new ecosystem (with revision to all layers) CHERI. Technique side: Static property checking  Some static types for memory safety. Examples ???  Dynamic property checking  Some dynamic types for memory safety. Examples ???    Quotes:\n Intel Memory Protection Extensions(MPX) and Software Guard Extensions (SGX), as well as Oracle Silicon Secured Memory (SSM), signal an unprecedented industrial willingness to implement hardware mechanisms for memory safety and security.\n Capability Pointers vs. address-space separation\n Capability pointers are stronger than fault detection schemes such as MPX and SSM, and are able to achieve provable containment at the granularity of program-defined objects that is as strong as address-space separation.\n Surveys  SoK: Eternal War in Memory. SP. 2013.\n \u0026ldquo;70% of all security issues addressed in Microsoft products are caused by violations of memory safety\u0026rdquo;\n Matt Miller. Trends, challenges, and strategic shifts in the software vulnerability mitigation landscape. BlueHat, 2019. slides   Contents  Temporal  References: [1] CETS: Compiler-Enforced Temporal Safety for C, ISMM, 2010. [paper] Basics Temporal safety Temporal safety erros include: dangling pointer dereferences (referencing an object that has been deallocated); dangling pointer to stack; dangling pointer to reallocated heap objects; double free\u0026rsquo;s (calling free() on the same object multiple times); invalid frees (calling free() with a non-heap address or pointer to the middle of a heap-allocated region). Location-based temporal checking Use location (or address) to determine whether it is allocated or not.\n Mem Tag  Q \u0026amp; A Is it possible to automatically set/check tags without changing ISA interface? Taint tracking tags? References: Efficient Tagged Memory, ICCD, 2017. CheriABI UCAM-CL-TR-932, 2019. Secure program execution via dynamic information flow tracking. 2004, ASPLOS. A small cache of large ranges: Hardware methods for efficiently searching, storing, and updating big dataflow tags. 2008. MICRO. Hardware enforcement of application security policies using tagged memory. 2008, OSDI. E.\n Secure by Permission bits on Page Table  Example: MMU and its variants MPK on Intel MPU on ARM Supervisor Mode Access Prevention. On CR4/x86 Reference 1 Dang Q\u0026amp;A How to detect there is still reference pointing to a pool? What if there is a buffer overflow to the freed variable on the same page? Reference 1 Problem: Allocate only one object per physical page would be quickly exhaust physical memory. Changing the allocation in this way would potentially lead to poor cache performance in physically indexed cache.\n Secure Memory by Compiling  A special case of building isolated software boxes. With Static \u0026amp; Dynamic analysis and/or Compiler Instrumentations. Examples: Shadow Stacks SafeCode nesCheck Reference 1 201904 Secswift Reference 1 A compiler approach to cyber-security ↩ Sok: Shining Light on Shadow Stacks Reference 1 SoK: Shining Light on Shadow Stacks. arXiv, 2019. ↩ Defending Embedded Systems Against Control Flow Attacks A hardware controlled stack split: one for data, one for return; Reference 1 Defending Embedded Systems Against Control Flow Attacks.\n Secure Memory by using Metadata for Pointers  Bookkeeping the metadat for pointers, such as base,bounds,ownerships,lock/keys, etc., to secure the system. Examples: fat pointers and its variants. Reference 1 Code Pointer Integrity References: Code Pointer Integrity Motivation CFI 1 2 3 4 5 is shown to be ineffective 6 7 8. Transactions on Information Forensics and Security, 6(4):1404–1417, Dec. 2011. More Code-Pointer Integrity References: Code-Pointer Integrity Goal Guarantees the integrity of all code pointers in a program, e.\n Secure Memory by Language  Design or leverage language features to secure a system. Example: Cyclone CCured nesC CheckedC Reference 1 CCured Reference 1 CCured: Type-Safe Retrofitting of Legacy Software. ACM Transactions on PL and Systems. 2005. ↩ nesC Reference 1 reference ↩ reference ↩  Attacks  Reference 1 Overflow Reference 1 Heart Bleed CVE-2014-0160 OpenSSL 1.0.1f, Fixed in 1.0.1g tlsl_process_heartbeat() in t1_lib.c // 2553 int tls1_process_heartbeat(SSL *s){ unsigned char *p = \u0026amp;s-\u0026gt;s3-\u0026gt;rrec.data[0], *pl; unsigned short hbtype; unsigned int payload; unsigned int padding = 16; /* Use minimum padding */ /* Read type and payload length first */ hbtype = *p++; n2s(p, payload); pl = p; if (s-\u0026gt;msg_callback) s-\u0026gt;msg_callback(0, s-\u0026gt;version, TLS1_RT_HEARTBEAT, \u0026amp;s-\u0026gt;s3-\u0026gt;rrec.data[0], s-\u0026gt;s3-\u0026gt;rrec.length, s, s-\u0026gt;msg_callback_arg); if (hbtype == TLS1_HB_REQUEST) { unsigned char *buffer, *bp; int r; /* Allocate memory for the response, size is 1 bytes * message type, plus 2 bytes payload length, plus * payload, plus padding */ buffer = OPENSSL_malloc(1 + 2 + payload + padding); bp = buffer; /* Enter response type, length and copy payload */ *bp++ = TLS1_HB_RESPONSE; s2n(payload, bp); memcpy(bp, pl, payload); bp += payload; /* Random padding */ RAND_pseudo_bytes(bp, padding); r = ssl3_write_bytes(s, TLS1_RT_HEARTBEAT, buffer, 3 + payload + padding); .\n RIPE: Runtime Intrusion Prevention Evaluator  850 buffer overflow attack forms. RIPE 1 extends 2003 NDSS 2 paper from 20 attack forms to 850 attack forms. Dimensions Location of the buffer in memory, target code pointer, overflow technique, D1: Location Stack Heap BSS segment Data segment D2: Target Code Pointer Return address Old base pointer: The previous contents of the EBP register, which is used to reference functin arguments and local variables Functino pointers: Generic function pointers allowing programmers to dymanically call different functions from the same code Longjmp buffers: Setjmp/longjmp is a technique which allows programmers to easily jump back to a predefined point in their code.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/book-soft/v5-vc/",
	"title": "V5 Verifiable C",
	"tags": [],
	"description": "",
	"content": " References:\n Verifiable C, version 2.11, 2022-08-19  Overview Verifiable C is a a language. The language is a subset of CompCert C light; it is a dialect of C in which side-effects and loads have been factored out of expressions.\nVerifiable C is a program logic. The program logic is a higher-order separation logic, a kind of Hoare logic with better support for reasoning about pointer data structures, function pointers, and data abstraction.\nVerifiable C is for reasoning about functional correctness of C programs.\nVerifiable C is foundationally sound. That is, it is proved that, \u0026ldquo;Whatever observable property about a C program you prove using the Verifiable C program logic, that property will acutually hold on the assembly-language program that comes out of the C compiler\u0026rdquo;.\n The program logic is proved sound with respect to the semantics of CompCert C, by a team of researchers primarily at Princeton University; The C compiler is proved correct with respect to those same semantics, by a team of researchers primarily at INRIA. This chain of proofs from top to bottom, connected in Coq at specification interfaces, is part of the Verified Software Toolchain.  Workflow  Write a C program, say F.c Run clightgen -normalize F.c to translate it into a Coq file F.v Write a verification of F.v in a file such as verif_F.v. That latter file must import both F.v and the VST Floyd program verification system, VST.floyd.proofauto.  clignten tool: from CompCert, translates C into CompCert Clight language.\nLoad Paths. CoqIDE or Proof General will need their load paths properly initialized. Running make in vst creates a file _CoqProject file with the right load paths for proof development of the VST itself (or of its progs/examples).\ncoqide progs/verif_reverse.v \u0026amp;  In normal use(not using the examples in VST/progs/), your own files (F.c, F.v, verif_F.v) will not be inside the VST directory. You will need to use _CoqProject-export file to tell Coq to access the VST components:\ncd my-own-directory cp my/path/to/VST/_CoqProject-export _CoqProject coqide myfile.v \u0026amp;  Restrictions to C  No casting between integers and pointers. No goto statements. No bitfields in structs. No struct-copying assignments, struct parameters, or struct returns. Only structured switch statements (No Duff\u0026rsquo;s device). No varargs functions, except limited undocumented support for calling printf and fprintf.  CompCert Clight language (and clightgen tool) does support some of the above language features (such as goto, bitfields, struct-copying), but programs with those features cannot be proved in Verifiable C.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/bluespec/",
	"title": "Bluespec",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Packages  Reference 1 Connectable The Connectable type class defines the module mkConnection, which is used to connect a pair of related types. typeclass Connectable#(type a, type b); module mkConnection#(a x1, b x2)(Empty); endtypeclass Instances of typeclass to be connectable Get and Put instance Connectable#(Get#(a), Put#(a)); One put and another will get the element. Tuples instance Connectable#(Tuple2#(a, c), Tuple2#(b, d)) provisos (Connectable#(a, b), Connectable#(c, d)); This is used by ClientServer to connect the Get of Client to the Put of the Server and visa-versa.\n Types  Reference 1 Strong, static type-checking. Every variable and every expression in BSV has a type. Convention: first char uppercase. (except for int and bit for backward compatibility with Verilog) Type expression Type expression/paramterized types: X#(t1,\u0026hellip;,tn). X is the type constructor and x1,\u0026hellip;,xn are parameters of X. // Type Expression Examples Tuple2#(int, Bool) // pair of items, an int and a Bool Tuple3#(int, Bool, String) List#(Bool) List#(List#(Bool)) RegFile#(Integer, String) //paraeter can be natural numbers (numeric types) Bit#(16) // 16-bit wide bit-vector (16 is a numeric type) bit[15:0] // synonym for Bit#(16) Vector#(16, Int#(29)) // Vector of size 16, containing Int#(29)\u0026#39;s bit[m:n] \u0026ndash;\u0026gt; n must be 0.\n Type Classes   Reference 1 Type classes (overloading groups) and provisos predefined type classes: Bits, Eq. reference ↩  Modules  Reference 1 Overview Modules and interfaces form the heart of BSV. Modules and interfaces turn into actual hardware. An interface for a module m mediates between m and other, external modules that use the facilities of m, i.e. clients of m. Module definition vs instantiation A single module definition of a FIFO, and multiple instantiations of this FIFOs in a design. Pure hierarchy. In a module definition, mkM, one can specify instantiations of other modules.\n TLM  The TLM library package allows users to create bus-based protocol-independent designs. This package is provided as part of the Bluespec Foundation library, and is available to all users 1. FoundationIP Lib ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/conf/",
	"title": "Conferences",
	"tags": [],
	"description": "",
	"content": " Security and System Conferences\nTraditions Deadlines: conferences +/- 1 month\nJanuary: SP, ATC, CCS,\nFeburary: UsenixSec-4, SP, CCS\nMarch: SP,\nApril: SOSP, SP, SecDev\nMay: UsenixSec-1, OSDI, SP, CCS,\nJune: NDSS,\nJuly: POPL,\nAugust: UsenixSec-2, CCS, ASPLOS, Asia CCS\nSeptember: NDSS,\nOctober: EuroSP,\nNovember: UsenixSec-3, VEE, DAC, PLDI, PLDI, EuroSys,\nDecember: AsiaCCS, DSN, SP,\nUpcoming    Conference Paper/notifcn Poster Date \u0026amp; Location     SP\u0026rsquo;21 Dec 3 / Feb 19  May 23-27, 2021 San Francisco, CA   SP\u0026rsquo;21 Sep 3 / Nov 20  May 23-27, 2021 San Francisco, CA   SP\u0026rsquo;21 Jun 13, 1st / Feb 1st  May 23-27, 2021 San Francisco, CA   ACSAC\u0026rsquo;20 Jun 12, 2020  December 7-11, 2020, Austin, Texas    Passed Dues    Conference Paper/notifcn Poster Date \u0026amp; Location     SecDev\u0026rsquo;20 May 25, 2020  Sep 28-30, 2020. Georgia Tech Conference Center, Atlanta, GA   OSDI\u0026rsquo;20 May 20, 20 abs  Nov 4-6, 2020, Alberta, Canada   CCS\u0026rsquo;20 May 4, 2020  Nov 9-13, 2020, Orlando, USA   OOPSLA\u0026rsquo;20 Apr 15 2020  Nov 20, 2020, Chicago, Illinois, USA   SP\u0026rsquo;21 Mar 5 / May 22, 2020  May 23-27, 2021 San Francisco, CA   SOUPS2020 UsenixSec\u0026rsquo;20 Feb 20, 2020  Aug 12-14, 2020 Boston, USA   UsenixSec\u0026rsquo;20 Feb 15, 2020 Jul 7, 2020 Aug 12-14, 2020 Boston, USA   CCS\u0026rsquo;20 Jan 20, 2020  Nov 9-13, 2020, Orlando, USA   ATC\u0026rsquo;20 Jan 15 / Apr 03  Jul 15-17, 2020 Boston, MA   VEE\u0026rsquo;20 Nov 30, abs      Dec 6, ppr     AsiaCCS\u0026rsquo;20 Dec 10 / Feb 15  June 1-5, 2020 Taipei, Taiwan   DSN\u0026rsquo;20 Dec 3, abs  Jun 29 - Jul 2, Spain    Dec 13 / Mar 4     SP\u0026rsquo;20/LangSec - Jan 15 / Feb 15, 2020 May 21, 2020 San Francisco, CA   SP\u0026rsquo;20/SafeThings - Jan 25 / Feb 25, 2020 May 21, 2020 San Francisco, CA   SP\u0026rsquo;20 Dec 1st / Feb 1st  May 18-20, 2020 San Francisco, CA   DAC\u0026rsquo;20 Nov 21, 2019  July 19-23, 2020 San Francisco, CA   PLDI\u0026rsquo;20 Nov 22 / Feb 3  Jun 15-20, 2020 London, UK   EuroSP\u0026rsquo;20 Oct 22, 2019 abs      Nov 20, 2019/ Jan 6  Jun 16-18, 2020 Genova, Italy   UsenixSec\u0026rsquo;20 Nov 15, 2019 Jul 7, 2020 Aug 12-14, 2020 Boston, USA   EuroSys\u0026rsquo;20 Nov 04, 2019/ Feb 15, 2020 Mar 1, 2020 Apr 27-30, 2020 Heraklion, Greece   NDSS\u0026rsquo;20 Sep 13 / Oct 31  Feb 23-26, 2020 San Diego, CA   AsiaCCS\u0026rsquo;20 Aug 20 / Oct 25  June 1-5, 2020 Taipei, Taiwan   ASPLOS\u0026rsquo;20 Aug 9, abs  Mar 16-20, 2020 Lausanne, Swizerland    Aug 16, ppr     HPCA\u0026rsquo;20 Jul 30  Feb 22-26, 2020 San Diego, CA   POPL\u0026rsquo;20 Jul 10 / Sep 16  Jan 19-25, 2020 Louisiana, US   NDSS\u0026rsquo;20 Jun 14 / Jul 15  Feb 23-26, 2020 San Diego, CA   CCS\u0026rsquo;19 May 15, 2019 Aug 26, 2019 Nov 11-15, 2019. London, UK   SOSP\u0026rsquo;19 Apr 17, 19, abs      Apr 24 / Jul 8  October 27-30, 2019. Huntsville, Ontario, Canada   SecDev\u0026rsquo;19 Apr 15, 2019, abs      Apr 22, 2019  September 25-27, 2019. McLean, Virginia, USA   NSDI\u0026rsquo;20 March 12, 2019  Feb 25-27, 2020. Santa Clara, CA, USA.   CCS\u0026rsquo;19 Feb 05, 2019 Aug 26, 2019 Nov 11-15, 2019. London, UK     EdgeIoT  Internet of Things, Edge Computing, Cloud Computing Conferences. Traditions Deadlines: conferences +/- 1 month January- March: April-June: July-September: October-December: Upcoming | Conference | Paper/notifcn | Date \u0026amp; Location | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; |\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | SEC\u0026rsquo;20 | May 29, 2020 | November 12-14, 2020 San Jose CA, USA | Ubicomp\u0026rsquo;21 | May 15, 2020\u0026frasl;8 weeks| | MobiCom\u0026rsquo;20 | Mar 07, 2020/ May 19, 2020| | Ubicomp\u0026rsquo;21 | Feb 15, 2020\u0026frasl;8 weeks| | ACMsocc\u0026rsquo;19 | Jun 03, 2019 | Nov 20-23, 2019.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/secure-tlb/",
	"title": "Secure TLBs",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Secure TLBs. ISCA, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/hwsw/",
	"title": "Memory Safety in Hardware and Software Interactions",
	"tags": [],
	"description": "",
	"content": " Secure HW/SW Interface  Motivation OS memory safety research Memory safety for OS code: OS designs based on safe languages; Compiler techniques such as SVA-M to enforce memory safety for commodity OSs in unsafe languages; Instrumentation techniques to isolate a kernel from extensions such as device drivers; Singularity, SPIN, JX, JavaOS, SafeDrive, and SVA-M are examples of system that enforce a safe execution environment. Common asumptions of OS memory safety research Unfortunately, all these memory safety techniques (except Verve, which has very limited I/O and no MMU support) make assumptions that are routinely violated by low-level initeractions between an OS kernel and hardware, even if implemented in safe programming language.\n KCoFI  Reference1 reference ↩  Reference1\n reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/memcopy/",
	"title": "Copying Memory",
	"tags": [],
	"description": "",
	"content": "The kernel\u0026rsquo;s bcopy, memcpy, copyin, and copyout routines are capability-unaware and will not preserve tag bits.\nNew cheri_bcopy, cheri_memcpy, copyincap, and copyoutcap are used in situations where preserving tags is desirable \u0026ndash; such as copying in or out of CHERI trusted stacks.\nClearing tag bits across conventional IPC, system call arguments, and so on is important in preventing the accidental leaking of rights between address space where only data copies are intended.\n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/",
	"title": "OS",
	"tags": [],
	"description": "",
	"content": "  Basics  Reference 1 Memory Management Reference 1 Layout of FreeBSD process in memory and on disk: ![figure-3-3. Layout of FreeBSD process in memory and on disk] To begin execution of a binary file, kernel: Text portion of the binary is mapped into the low part of the process\u0026rsquo;s address space. (The first page of the address space is marked as invalid, so that attempts to read or write through a null pointer will fault) Initilized data portion of the file is mapped into the address space following the text.\n Unikernels  Reference 1 Demikernel Reference 1 The Demikernel is a library operating system architecture designed for use with kernel-bypass I/O devices. The Demikernel architecture offers a uniform system call API across kernel-bypass technologies (e.g., RDMA, DPDK) and OS functionality (e.g., a user-level networking stack for DPDK). Demikernel: kernel-bypass IO abstraction for data centers. Github: Demikernel ↩ reference ↩  Freertos   References: FreeRTOS Implementation FreeRTOS Implementation Building Blocks Detailed Example More  L4  Reference: L4 wiki, L4 kernel projects; seL4: from Data61 OKL4: from Open Kernel Lab Coyotos: from John Hopkins, Nova: from Dresden, L3: seL4 References: About seL4 seL4 Documentation Klein, Gerwin, Kevin Elphinstone, Gernot Heiser, June Andronick, David Cock, Philip Derrin, Dhammika Elkaduwe et al. \u0026ldquo;seL4: Formal verification of an OS kernel.\u0026rdquo; In Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles (SOSP), pp. 207-220. 2009.\n OS in Rust  Reference: Writing an OS in Rust  Gnu Hurd  GNU Hurd Reference1 reference ↩  Freebsd  Reference1 reference ↩  Minix 3  Minix Minix 3 Reference1 reference ↩  Linux  Reference1 reference ↩  Windows  References: reference More Heap Protection References: Windows 8 Heap Internals, BlackHat, USA, 2012. Software Defense: Mitigating Heap Corruption Vulnerabilities Heap for Windows Vista/Server2008/Windows7 The following features are enabled by default: Randomized heap base address The base address of a heap region is randomized as part of ASLR; 5 bits of entropy; Function pointer encoding Function pointers in heap data structures are encoded with a random value; This will prevent them from being replaced with an untrusted value; Algorithm variation\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/systemv/",
	"title": "System Verilog",
	"tags": [],
	"description": "",
	"content": " Reference 1\nHDL Languages Hardware description languages. Three elements seldom present in a PL:\n Concurrency. Representation of time. Representation of structure. Gate and hardware structure persist and have a state even if they are doing nothing.  Verilog (1980s) -\u0026gt; Verilog 1.0 (1995) -\u0026gt; Verilog 2.0 (2001) -\u0026gt; Verilog 3.1a (System Verilog, 2005)\nExtended Verilog to system-level modeling.\nVHDL (Very High Speed Integrated Circuit)\nSystem C\nUsage:\n OVM, VMM, UVM  System Verilog Object Oriented Programming\nStatic vs. Automatic\n static: default. not destroyed after simulation function. automatic: destroyed after function.   Verilog  Reference 1 Port vs Parameters Port: arguments/interfaces to other modules, contains input/output. Parameter: constants. Typically used to specify the width of variables and time delays; has default value; can be overwritten during module instantiation. Verilog Functions https://www.chipverify.com/verilog/verilog-functions For certain pieces of code to be repetitive and called multiple times within the RTL. function [automatic] [return_type] name ([port_list]); [statements] endfunction Starts with function, ends with endfunction. Should have at least one input.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/job-choices/",
	"title": "Job Choices",
	"tags": [],
	"description": "",
	"content": " References:\n Job and Career Advice   A connection on LinkedIn asked me for help deciding between job offers. I can\u0026rsquo;t provide personalize advice, but here are my thoughts in general.\n 在LinkedIn上有朋友私信让我帮他在几个工作offer之间做出选择。虽然我不能针对特定个人的情况做出具体的建议，但是我可以从宏观的视角，大概的谈谈我自己对找工作的想法。\n You must accept personal ownership for choosing what you want to do with at least the next few years of your life. Nobody can do this for you.\n 对于你自己的选择，你必须自己做出并且把自己的任何选择作为自己生命过程的一部分。这个选择至少会决定你未来几年的生活。\n Your time is scarce, non-renewable resource so spend care in deciding. On the other hand it is difficult to make a choice because as they say, it is difficult to make predictions, especially about the future. It\u0026rsquo;s even harder to foresee consequences, especially on your first couple jobs when you are learning how everything works. But if you end up making a choice that works out poorly, then figure out the lesson to learn and switch to something else.\n 你自己的时间是很宝贵的，一去不复返，不可再生，所以做选择时一定要花费一些心思。 然而，另一方面，做出抉择是很困难的事情。就像有些人说的，预测未来是很难的，而预测未来的结果更是难上加难，尤其是在当自己还处在最初的几个工作中开始学习基本工作能力的阶段。 但是，如果你不幸地发现自己做出了很不好的选择，那么就得仔细分析，吸取其中的教训，并且换个新的选择。\n Take a look at how the job fulfills or supports your needs on Maslow\u0026rsquo;s Hierachy (https://en.wikipedia.org/wiki/Maslow%27s_hierarchy_of_needs). Some of us live to work; some work to live. There is no one right answer, but at least this gives you a simple checklist of what you want to be provided by the job \u0026ndash; and what you don\u0026rsquo;t. If you\u0026rsquo;re signing up for a 12 hour x 7 day type job, it had better go a long way to filling up that pyramid in an acceptable, non-destructive way while you\u0026rsquo;re at work, because you\u0026rsquo;ll always be at work.\n 你可以参考一下马斯洛的需求层次理论(https://zh.wikipedia.org/wiki/需求层次理论)。 我们当中有些人是为了工作而生活，有些人是为了生活而工作。 这里面没有对错，但至少你有了多种类型的样例，可以参考他们制定自己的奋斗方向，以及自己不想去奋斗的方向。 比如，如果你接受了一个12小时x七天的工作，由于你将无时无刻不在工作，那么你最好在你工作的时候，探究出一种你自己可以接受的、不会产生破坏的方法来填充起属于你自己的那个马斯洛需求金字塔。\nMaslow\u0026rsquo;s hierarchy of needs, represented as a pyramid with the more basic needs at the bottom. (https://en.wikipedia.org/wiki/Maslow%27s_hierarchy_of_needs)\n(从下到上：生理的需求，安全的需求，爱与归属的需求，尊严的需求，自我实现的需求)\n All organizations have dysfunction. Figure out if this organiation\u0026rsquo;s dysfunction are going to be irritating to you or get in the way of satisfying your needs (see previous item). Most people can stand an irritating environment less well than they think they can.\n 任何的组织都会有不足的地方。 进入一个组织后，你需要确认这个组织是否对你填充自己的需求金字塔造成坏影响甚至阻碍。 对大多数人，他们忍受恼人环境的能耐比自己想象的要底一些。\n When you are young there is a lot to be said for working in a structured, mature organization. You learn a lot. Later on you might want less structure. Skipping right to an unstructured job at an immature company will teach you a lot of bad habits that it can take a lifetime to unlearn and leave many holes in your practical education. (Some jump right to a startup company with no \u0026ldquo;graybeards\u0026rdquo;. Some skip college. Some get rich by winning the lottery. Some don\u0026rsquo;t. I can only tell you how to stack the odds in your favor.) Consider availability of mentors.\n 在你年轻的时候，可能会听到很多关于在大公司工作的言论，这些大公司往往是如何组织分明，管理有素。你会学到很多东西。 而到后来，你可能对这样的井井有条的组织结构变得不那么推崇。 而立即转向一个组织比较随意的小公司也是有风险的。 你可能会染上一些坏习惯，这些习惯可能一辈子都抹不掉，还会有一些难以弥合的弱点不断出现在你未来的工作实践中。 （当然，有些人年纪轻轻就下海创业，而且成功赚了很多钱，就像中彩票一般。然而，也要看到，有些人并不会这样。而我最多只能大概地告诉你如何给自己多一些助力，少一些阻碍）。 如果可能，就尽量找到一些在职场上能指导你的人。\n Ask if the level of responsibility \u0026amp; authority is a fit both in terms of scope and structure. My experience has ranged from military office (highly structure) to consultant (freedom but few safety nets). Where you want to be likely changes as your career progresses.\n 需要扪心自问，你当前工作的责任和位置能否在宏观的事业观和组织结构中适合你的需求。 我的经验很广阔，从军事职员（高度结构化）到咨询员（比较自由但是难以有稳定的组织结构作为后盾）。 事业总会发展，你需要知道你希望将自己的事业在哪一方面获得发展。\n Read the general job hunting advice for things such as the realities of accepting a low paying first job and trying to get raises later. The classic is \u0026ldquo;what color is your parachute\u0026rdquo; but no doubt there are others, keeping in mind that highly skilled workers are a bit different than the general work force. It helps to have a realistic understanding of what you are worth, and to get some objective advice from someone you trust on whether you are getting taken advantage of in a job offer.\n 你可以搜寻一些大家都可以读到的提升找工作技巧的资料来读一读。比如，如果一开始找到了工资很低的职位，该如何让自己涨工资，这期间要面临什么现实问题，等等。 一个比较经典的一本书是《你的降落伞的颜色是什么》。当然，还有很多其他的资料。 需要注意的是，具有很高技能的工作人员跟普通的工作是有些区别的。 这会帮助你对你自己的价值有所了解，并且会从你信任的人那里获取建议， 衡量出你是否能在这个offer中获取自己想要的。\n After you\u0026rsquo;ve considered the above, IMHO (in my humble opinion) only then should you worry about the more common philosophical areas you see mentioned on this topic. (And really, most of them end up on the upper levels of Maslow\u0026rsquo;s Hierarchy.) My personal preferences are:\n 在我看来，只有考虑了上述几点之后，就可以从更一般的、哲学性的角度来考虑找工作这个话题。 （事实证明，大多数这么做的人都能够成功让自己达到马斯洛金字塔的顶端）。 我自己总结的重要的几点有：\n  Surround yourself with the smartest, most capable people you can (but stopping short of jerks). Work for good leaders that support and empower those who work with them. Take advantage of any opportunity you can get to improve your communication skills and soft skills. If you\u0026rsquo;re taking a job purely for the money, go into that situation with an exit plan and target exit date. And make sure that is really how you want to spend a part of your life. If you\u0026rsquo;re stressed out, it\u0026rsquo;s time to find a new job. (Or re-invent your job). If you\u0026rsquo;re stressed out about your career, it\u0026rsquo;s time to reinvent yourself and find a new career. If you strive to be the absolute best at what you do, opportunities will find you. If most days you wake up and are eager to get to work, reflect on how fortunate you are to have that.    跟自己认为最聪明，最能干的人在一起（远离jerks）； 如果老板能支持并让自己的员工不断提升自己，那你就选对老板了； 对于能提升自己沟通能力和软实力的机会，一定要抓住； 如果你工作只是为了钱，那你找到工作后就应该有自己的退出计划，并且有明确的退出时间。并且，你要清楚，这就是你想要的生活； 如果你感到被榨干了，是时候寻找新工作了（或者重新创造自己的工作）； 如果你正在努力让自己变成你所在领域中最好的，你的机会会自动上门； 如果大多数日子里，你醒来后就渴望自己投入工作当中，这足够反映出你是最幸运的人之一。   Don\u0026rsquo;t forget the part that you own your choice. Your preferences will probably differ.\n 不要忘了，你的选择，是自己永久的资产。想想这一点，你对各个offer的喜好可能会有不同。\n Please do not contact me with questions about your particular individual situation. The hours in my day are already too few to accomplish what I\u0026rsquo;d like for my personal goals. I took some time to write this to help as many people as I can (one of my goals), but I lack the time to provide individual responses. So if I don\u0026rsquo;t respond to a personal query, please understand (and better yet, send the personal query to a trusted friend instead).\nI hope this is helpful, and wish you the best of luck in your job choices and your career!\n More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/booting/",
	"title": "Booting",
	"tags": [],
	"description": "",
	"content": " Q \u0026amp; A  where is the tagged memory being partitioned?  The call path:\nboot2 -\u0026gt;\n? -\u0026gt; locore.S: _locore/_start/unknown/btext -\u0026gt; platform_start()\n? cheri_cpu_startup() in mips/cheri/cheri.c\nconf/ldscript.mips.mips64:34 ENTRY(_start) ?\nThe BERIpad tablet: open-source construction, CPU, OS and applications:\n A small built-in ROM in BERI is able to relocate a FreeBSD kernel out of flash, or, if a DIP switch is set, make use of a kernel loaded directly into DRAM using JTAG. After relocation, the boot ROM interprets the kernel’s ELF header, passing in information on DRAM configuration when it jumps to the kernel’s start routine.\nWe describe BERI board configurations using Flat Device Trees (FDT), which are also used on PowerPC and ARM-based systems [12]. FDT files describe the bus topology, generally simple for system-onchip configurations, including memory addresses and interrupt information for peripherals available to the operating system.\n beri_machdep.c: platform_start // sys/mips/beri/beri_machdep.c: 182  void platform_start(__register_t a0, __register_t a1, __register_t a2, __register_t a3){ ... #ifdef CPU_CHERI  /* Ensure that we don\u0026#39;t write to the tag memory */ if (memsize \u0026gt; 2ul * 1024 * 1024 * 1024) panic(\u0026#34;invalid memsize 0x%lx\u0026#34;, memsize); /* * The memory size reported by miniboot is wrong for CHERI: * The tag memory always starts at 3EFFC000, so we mustn\u0026#39;t * write to any addresses higher than 3EFFC000. */ memsize = MIN(memsize, 0x3EFFC000); #endif  ... } locore.S Where to call locore.S:_start:\nconf/ldscript.mips.mips64:34 ENTRY(_start)\n_start/_locore/unkown/btext\n Enable FPU (COP_1); Enable CHERI (COP_2);\n/sys/mips/mips/locore.S #if defined(CPU_CHERI)  CHERI_LOCORE_ROOT_CAPS /* * Create the parent kernel sealing capablity. */ cmove CHERI_REG_C27, CHERI_REG_C28 REG_LI t0, CHERI_SEALCAP_KERNEL_BASE csetoffset CHERI_REG_C27, CHERI_REG_C27, t0 REG_LI t0, CHERI_SEALCAP_KERNEL_LENGTH csetbounds CHERI_REG_C27, CHERI_REG_C27, t0 REG_LI t0, CHERI_SEALCAP_KERNEL_PERMS candperm CHERI_REG_C27, CHERI_REG_C27, t0 PTR_LA t0, _C_LABEL(kernel_sealcap) csc CHERI_REG_C27, t0, 0($ddc) ... #endif   boot2 who calls locore.S:_start?\n_start In sys/mips/mips/locore.S: ASM_ENTRY(_start), from about line 125 to 214:\n enable coprocessor 2; derive DDC/KDC, PCC/KCC, in CHERI_LOCORE_ROOT_CAPS (sys/mips/include/cheriasm.h). create the parent kernel sealing capability; derived from macro CHERI_SEALCAP_KERNEL_BASE, etc.; stored as kernel_sealcap; create a capability covering all of userspace from which to derive new capabilities in execve(), etc; stored as userspace_cap; create a user space sealing capability; derived from macro CHERI_SEALCAP_USERSPACE_BASE, etc.; stored as user_sealcap; user space seal cap is also used as swap_restore_cap;  _start -\u0026gt; mi_startup(frame)\ninitial DDC/KDC The capabilities derived for DDC/KDC and for PCC/KCC cover the entirety of the kernel. (Acutally changing base/length requires changes in linkage).\nIt is done in a macro CHERI_LOCORE_ROOT_CAPS (sys/mips/include/cheriasm.h), defined as follows:\n#define CHERI_LOCORE_ROOT_CAPS \\ \t/* Grab the initial omnipotent capability */ \\ cgetdefault\tCHERI_REG_C28; \\ \t\\ /* Create a reduced DDC. */ \\ cmove\tCHERI_REG_C27, CHERI_REG_C28; \\ \tREG_LI\tt0, CHERI_CAP_KERN_BASE; \\ \tcsetoffset\tCHERI_REG_C27, CHERI_REG_C27, t0; \\ \tREG_LI\tt0, CHERI_CAP_KERN_LENGTH; \\ \tcsetbounds\tCHERI_REG_C27, CHERI_REG_C27, t0; \\ \tREG_LI\tt0, CHERI_PERMS_KERNEL_DATA; \\ \tcandperm\tCHERI_REG_C27, CHERI_REG_C27, t0; \\ \t\\ /* Preserve a copy in KDC for exception handlers. */ \\ csetkdc\tCHERI_REG_C27; \\ \t\\ /* Install the new DDC. */ \\ csetdefault\tCHERI_REG_C27; \\ \t\\ /* Create a reduced PCC. */ \\ cgetpcc\tCHERI_REG_C27; \\ \tREG_LI\tt0, CHERI_CAP_KERN_BASE; \\ \tcsetoffset\tCHERI_REG_C27, CHERI_REG_C27, t0; \\ \tREG_LI\tt0, CHERI_CAP_KERN_LENGTH; \\ \tcsetbounds\tCHERI_REG_C27, CHERI_REG_C27, t0; \\ \tREG_LI\tt0, CHERI_PERMS_KERNEL_CODE; \\ \tcandperm\tCHERI_REG_C27, CHERI_REG_C27, t0; \\ \t\\ /* Preserve a copy in KCC for exception handlers. */ \\ \\ csetkcc\tCHERI_REG_C27; \\ \t\\ /* Install the new PCC. */ \\ REG_LI\tt0, CHERI_CAP_KERN_BASE; \\ \tcgetpcc\tCHERI_REG_C28; /* 0 */ \\ \tcgetoffset\tt1, CHERI_REG_C28; /* 1 */ \\ \tPTR_SUBU\tt1, t1, t0; /* 2 */ \\ \tPTR_ADDIU\tt1, t1, (4 * 7); /* 3 */ \\ \tcsetoffset\tCHERI_REG_C27, CHERI_REG_C27, t1; /* 4 */ \\ \tcjr\tCHERI_REG_C27; /* 5 */ \\ \tnop; /* 6 */ \\ \t/* 7 (land here) */ From above code:\nKDC and DDC are set to be the same, whose offset: CHERI_CAP_KERN_BASE, bounds CHERI_CAP_KERN_LENGTH, perm CHERI_PERMS_KERNEL_DATA.\nKCC is set with offset CHERI_CAP_KERN_BASE, bounds CHERI_CAP_KERN_LENGTH, permission CHERI_PERMS_KERNEL_CODE.\nPCC is set with offset -CHERI_CAP_KERN_BASE + 4*7, bounds, permission, and finally set by cjr. NO BOUNDS, PERMS are set for PCC???\nAfter above executed, C28 stores PCC with offset at line /* 0 */, C27 stores KCC with offset at line /* 7 */.\nInit kernel sealing capability In the previous step, C27 stores PCC with offset at line /* 7 */; C28 stores PCC with offset at line /* 0 */. Next these two will be reused to create kernel sealing capability.\nin file: sys/mips/mips/locore.S: ASM_ENTRY(_start):\nCHERI_LOCORE_ROOT_CAPS /* set default DDC/KDC; also stored in C27 (DDC), C28*/ /* * Create the parent kernel sealing capablity. */ cmove CHERI_REG_C27, CHERI_REG_C28 /* C27 = C28 */ REG_LI t0, CHERI_SEALCAP_KERNEL_BASE /* li load immediate to t0*/ csetoffset CHERI_REG_C27, CHERI_REG_C27, t0 REG_LI t0, CHERI_SEALCAP_KERNEL_LENGTH csetbounds CHERI_REG_C27, CHERI_REG_C27, t0 REG_LI t0, CHERI_SEALCAP_KERNEL_PERMS candperm CHERI_REG_C27, CHERI_REG_C27, t0 PTR_LA t0, _C_LABEL(kernel_sealcap) csc CHERI_REG_C27, t0, 0($ddc) Here kernel_sealcap is initialized to have PCC with offset CHERI_SEALCAP_KERNEL_BASE, bounds CHERI_SEALCAP_KERNEL_LENGTH, perms CHERI_SEALCAP_KERNEL_PERMS. Then the sealing cap is stored to memory as kernel_sealcap.\nNote that how address of kernel_sealcap, t0, is used to store a capability by csc CHERI_REG_C27, t0, 0($ddc).\nIn order to store a capability to memory, we need a capability, usually $ddc, to grant permissions, an address, here t0 must be a valid address within this capability.\nmi_startup(frame)  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/",
	"title": "Compilers",
	"tags": [],
	"description": "",
	"content": "Reference:\n Language Reference Programmer\u0026rsquo;s Manual LLVM Bitcode File Format  Reading list:\n Build A Simple Interpreter\n Books:\n \u0026ldquo;Optimizinig Compilers for Modern Architectures: A Dependence-based Approach\u0026rdquo;. By Randy Allen, and Ken Kennedy. 2001. \u0026ldquo;Compilers: Principles, Techniques, and Tools\u0026rdquo;. By Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman. 2nd ed. 2007. \u0026ldquo;Advanced Compiler Design and Implementation\u0026rdquo;. By Steven S. Muchnick. 1997. \u0026ldquo;Engineering A Compiler\u0026rdquo;. By Keith D. Cooper, and Linda Torczon. 2nd ed. 2012.    Basics  Reference 1 DAG - Directed Acyclic Graph Directed Acyclic Graph (DAG) is a tool that depicts the structure of basic blocks, helps to see the flow of values flowing among the basic blocks, and offers optimizatino too. 1 A directed acyclic graph (DAG) for a basic block: Leaf nodes represent identifiers, names or constants. Interior nodes are labeled by an operator symbol. Nodes are also given a sequence of identifiers for labels to store the computed value.\n Verify  Reference: Fully Abstract Compilation. a little bit Sec Gap Reference 1 The correctness-security gap in compiler optimization. By Vija D\u0026rsquo;Silva, Mathias Payer, Dawn Song. LangSec, 2015. ↩ Next700 Reference 1 The Next 700 Compiler Correctness Theorems (Functional Pearl). By Daniel Patterson, Amal Ahmed. ICFP, 2019. ↩ CompCert Reference 1 CompCert: A realistic, verified compiler. By verified, we mean a compiler that is accompanied by a machine-checked proof of a semantic preservation property: the generated machine code behaves as prescribed by the semantics of the source program.\n Learning LLVM  Q \u0026amp; A What is the LLVM address space? John: better name \u0026lsquo;namespace\u0026rsquo;: one namespace for memory load/store; another namespace for IO port load/store. What is data layout string in LLVM? What kind of change we need to make to enable fat pointers for a legacy code? Exceptions References: reference More Landingpad References: LLVM Exception Handling A landing pad corresponds roughly to the code found in the catch portion of a try/catch sequence.\n Auto Parallel  Reference 1 HELIX: auto parallel loops. Janus: Automatic binary parallelisation. reference ↩  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/vghost/",
	"title": "Virtual Ghost",
	"tags": [],
	"description": "",
	"content": " Virtual Ghost1:\n Compiler instrumentation of operating system code: creating ghost memory, which kernel cannot access;\n A thin hardware abstraction layer (SVA-based): kernel must use to be restricted; user application use them to protect themselves via ghost memory management, encryption, signing, and key management;\n  Compiler Instrumentation  ghost memory protection. LLVM bitcode translation and validation. CFI on kernel code: ensures the compiler instrumentation is not bypassed.  Evaluation Implimentation:\nFreeBSD 9.0; Three OpenSSH applications: ssh, ssh-keygen, ssh-agent: share same application key, exchange data securely.\nSecurity Evaluation: defeats rootkit attacks.\n .svamem  Q\u0026amp;A Why not all sva code be put into svamem section, instead, just a selected portion of data structures in libsva? Linker Script .svamem section // file // sys/conf/ldscript.amd64 /* Create the SVA data section */ _svastart = ALIGN(0x1000); .svamem ALIGN(0x1000) : { SVAPTPages = .; . = . + 4194304; *(svamem) _svaend = .; } Variables: _svastart, _svaend, SVAPTPages, Used in\n  Virtual Ghost: Protecting Applications from Hostile Operating Systems. ASPLOS, 2014. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-cc/",
	"title": "Cheri Concentrate",
	"tags": [],
	"description": "",
	"content": " Reference:\n CHERI concentrate\n [ISAv9-draft, Chapter 3.5.4, CHERI Concentrate Compression]()\n  Overview Cheri Concentrate(CC) is a compression scheme applied to CHERI. CC achieves the best published region encoding efficiency, solves important pipeline problems caused by a decompressed register file.\nProblem The object bounds and permission information encoded in capability pointers cause the largest overhead among all overheads. Thus need a new encoding scheme to reduce overhead, i.e a method for compression and decompression.\nChallenge  Pipeline optimization in terms of the hardware changes for the encoding scheme. Minimize the delay of bound checking for integration with standard processor designs. Minimize the semantic restrictions to support legacy code.  Solution  Floating-point bounds encoding. Full toolchain support: compilers, binaries, runtime environment. Representable Region with power-of-two bounds, beyonds object bounds. Representability Check with low delay, comparable to a pointer add.  Design 64-bit address + 16 permission bits (4 user defined + 12 hardware defined) + 18-bit object type + 27 bits that encode the bounds relative\n $MW$: mantissa width, a parameter of the encoding that determines the precision of the bounds. For 128-bit capabilities we use $MW=14$, but this could be adjusted depending on the number of bits available in the capability format.\n $B$ and $T$ are $MW$-bit values that are substituted into the capability address to form the base and top. They are stored in a slightly compressed form in the encoding, in one of the two formats depending on the $I_E$ bit.\n $I_E$ is the internal exponent bit selects between two formats.\n $I_E=0$: the exponent is implied to be zero and the full width of $B$ and $T$ are used; $I_E=1$: an exponent is stored instead of the lower three bits of $B$ and $T$ fields, reducing the precision available by three bits.  $E$ is the 6-bit exponent. It determines the position at which $B$ and $T$ are inserted in $a$. Larger values allow larger regions to be encoded but impose stricter alignment restrictions on the bounds.\n  Address $a$ is splitted into three parts:\n $a_{top}=a[63:E+14]$ $a_{mid}=a[E+13:E]$ $a_{low}=a[E-1:0]$.  Replace $a_{mid}$ with $B$ and $T$, and clearing the lower $E$ bits.\nAdjust $a_{top}$ with corrections $c_b$ and $c_t$.\nEvaluation Representability Mac OS X 10.9 dtrace framework, collect traces from every allocator found in six real-world applications:\n Chrome 38.0.2125 Firefox 31 Apache 2.4 iTunes 12 MPlayer build #127 mySQL 5.  Allocators included many forms of malloc(), serveral application-specific allocators, driver internal allocators, and many other variants.\nInstruction Frequency Study  Duktape Javascript interpreter running Splay benchmark from the Octane suite SQLite benchmark for LevelIDB project P7Zip benchmark from LLVM boot of FreeBSD with all user-space processes compiled in a pure-capability mode.  Each case we traced around 1 billion user-space instructions from the FPGA implementation, about 10 seconds of exection time on our 100MHz processor, sampled throughout the benchmark.\nResults:\n Pointer-size loads constitue up to 12% of common programs.  pointer loads should minimize additional delay caused by an unpack operation to decode capabilities into the register file or else risk greatly impacting performance.  Poniter arithmetic commonly constitutes over 10% of executed instructions.  pointer add must remain simple, fast, and energy-efficient, in the face of new requirements imposed by capabilities.  Load and stores of data and capabilities constituting as much as 35% of common programs.  The bounds check on the offset addressing operation must not impede the critical path, or else would risk greatly impacting program performance.   Concentrate pipeline Unpack, pointer add, bounds check.\nComplete bounds decoding (unpack):\n 2013 CCS LowFat 1, on Altera Stratix V 5SGXEA7N2F45C2 FGPA: 4.47ns.  on their Xilinx Virtex 6: 4ns Too complex to be performed after memory load and before register write back  CHERI CC, on Altera Stratix V 5SGXEA7N2F45C2 FGPA: 1.70ns  Pointer add: 2.74ns \u0026ndash;\u0026gt; 2.89ns: slightly longer than Low-fat\u0026rsquo;s pointer add.\nBounds check: 1.88ns \u0026ndash;\u0026gt; 3.85ns: longer than lowfat (but \u0026ldquo;fits comfortably into the execution path of our pipeline (which is parallel to cache lookup)\u0026rdquo;).\nExecution performance Security policies:\n Spatial memory safety: use capabilities for all data pointers (including heap and stack allocations) CFI: use capabilities for return addresses and function pointers 2  Small benchmarks:\n MiBench Olden suite  Larger benchmarks:\n P7Zip 16.02 Octane with Duktape 1.4.0 Sqlite3 3.21.0 SPECint 2006   ↩ ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/",
	"title": "The LLVM Target Independent Code Generator",
	"tags": [],
	"description": "",
	"content": " Reference: LLVM Code Generator\nDesign of Code Generator  Instruction Selection. Expression LLVM code input in the target instruction set.  Initial code in the target ISA; required register assignments due to target constraints or calling conventions; turns LLVM code into a DAG of target instructions: SelectionDAG.  Scheduling and Formation. Take DAG as input.  determine order of instructions; emit code as MachineInstrs;  SSA-based Machine Code Optimizations. Machine code optimization on SSA-form.  eg. Modulo-scheduing; peephole optimization.  Register Allocation. Transform the code from infinite virtual register file in SSA form to the concrete register file used by the target.  spill code eliminates all virtual register reference from the program  Prolog/Epilog Code Insertion. Once the machine code has been generated for the function and the amount of stack space required is known (used for LLVM alloca\u0026rsquo;s and spill slots), the prolog and epilog code can be inserted.  eliminate the \u0026ldquo;abstract stack location references\u0026rdquo; e.g. OPTs such as frame-pointer elimination and stack packing.  Late Machine Code Optimizations. operates on \u0026ldquo;final\u0026rdquo; machine code.  e.g. spill code scheduling and peephole optimizations.  Code Emission. either in assembler format or in machine code.  To work on any of the above components, it is necessary to be familiar with the two classes:\n Target Description classes. Machine Code Description classes.  Code Overview  include/llvm/Target/. Defines the Target Description classes. They capture important properties about various aspects of the machine, independently of how they will be used.\n include/llvm/CodeGen/: Define Machine Code Description classes used to represent the code being generated for a target, both SSA form and Non-SSA form representation for machine code. These classes are intended to be abstract enough to represent the machine code for any target machine. At this level, concepts like \u0026ldquo;constant pool entries\u0026rdquo; and \u0026ldquo;jump tables\u0026rdquo; are explicitly exposed.\n include/llvm/MC/: define classes and algorithms used to represent code at the object file level, the MC layer. These classes represent assembly level contructs like labels, sections, and instructions. At this level, concepts like \u0026ldquo;constant pool entries\u0026rdquo; and \u0026ldquo;jump tables\u0026rdquo; don\u0026rsquo;t exist.\n lib/CodeGen/: Define the target-independent algorithms used to implement various phases of native code generation.\n register allocation scheduing, stack frame representation \u0026hellip;  lib/Target/: Implement the abstract target description interfaces for particular targets. These machine descriptions make use of the components provided by LLVM, and can optionally provide custom target-specific passes, to build complete code generators for a specific target.\n lib/ExecutionEngine/JIT: defines the target independent JIT components. The LLVM JIT is completely target independent. It uses the TargetJITInfo structure to interface for target-specific issues.\n  The components in CodeGen Note: need to focus on the following parts:\n code emission prolog/epilog code insertion.  Required components in the CodeGen Two pieces: high-level interface to the code generator \u0026amp; set of reusable components that can be used to build target-specific backends.\nTwo most important interfaces, TargetMachine and DataLayout, are the only ones that are required to be defined for a backend to fit into the LLVM system, but the others must be defined if the reusable code generator components are going to be used.\nThis design allows to implement radically different code generator that do not make use of any of the built-in components. This could be required for radically different target that do not fit into the LLVM machine description model: FPGAs for example.\nTarget Description Classes Located in include/llvm/Target/. Provides an abstract description of the target machine independent of any particular client. Designed to capture the abstract properties of the target, such as the instructions and registers it has. It does not incorporate any particular pieces of code generation algorithms.\n TargetMachine DataLayout TargetLowering TargetRegisterInfo TargetInstrInfo TargetFrameLowering TargetSubtarget TargetJITInfo  Machine Code Description Classes LLVM code is translated to a machine specific representation formed out of instances of the following classes:\n MachineFunction. MachineBasicBlock. MachineInstr.  However, this reprentation is completely target agnostic, representing instructions in their most abstract form: an opcode and a series of operands. The representation is designed to support both an SSA form for machine code, as well as a register allocated, non-SSA form.\nMachineInstr class Used to represent target machine instructions. Only keep track of an opcode number and a set of operands.\n Does not have any information about how to interpret the instruction (i.e., what the semantics of the instruction are); for that you must refer to the TargetInstrInfo class. MachineInstr\u0026rsquo;s are initially selected in SSA-form, and are maintained in SSA-form until register allocation happens.  To create a MachineInstr, use BuildMI functions (in include/llvm/CodeGen/MachineInstrBuilder.h):\n// Create a \u0026#39;DestReg = mov 42\u0026#39; (rendered in X86 assembly as \u0026#39;mov DestReg, 42\u0026#39;) // instruction and insert it at the end of the given MachineBasicBlock. const TargetInstrInfo \u0026amp;TII = ... MachineBasicBlock \u0026amp;MBB = ... DebugLoc DL; MachineInstr *MI = BuildMI(MBB, DL, TII.get(X86::MOV32ri), DestReg).addImm(42); // Create the same instr, but insert it before a specified iterator point. MachineBasicBlock::iterator MBBI = ... BuildMI(MBB, MBBI, DL, TII.get(X86::MOV32ri), DestReg).addImm(42); // Create a \u0026#39;cmp Reg, 0\u0026#39; instruction, no destination reg. MI = BuildMI(MBB, DL, TII.get(X86::CMP32ri8)).addReg(Reg).addImm(42); // Create an \u0026#39;sahf\u0026#39; instruction which takes no operands and stores nothing. MI = BuildMI(MBB, DL, TII.get(X86::SAHF)); // Create a self looping branch instruction. BuildMI(MBB, DL, TII.get(X86::JNE)).addMBB(\u0026amp;MBB);  MachineBasicBlock class Contains a list of MachineInstr instances.\nRoughly corresponds to the LLVM IR basic block, but there can be one to many mapping: one LLVM basic block map to multiple machine basic blocks.\nHas a getBasicBlock method, which returns the LLVM basic block that it comes from.\nMachineFunction class Contains:\n a list of MachineBasicBlocks instances, a MachineConstantPool a MachineFrameInfo, represents an abstract stack frame until prolog/epilog is inserted. a MachineFunctionInfo a MachineRegisterInfo  Corresponds one-to-one with the LLVM IR function input.\nPasses in CodeGen MachineFunctionPass:\n~ 265 passes lives in llvm/include/llvm/CodeGen and llvm/lib/Target/*\n class AsmPrinter; a driving class for all asm writers. class MachineFunctionPrinterPass; a pass to dump the IR of a machine function. class MIRPrintingPass; a pass prints out LLVM IR to an output stream using the MIR serialization format. class PeepholeOptimizer class IRTranslator class InstructionSelect, SelectionDAGISel, FinalizeISel class PEI, prolog epilog inserter. // llvm/lib/CodeGen/PrologEpilogInserter.cpp class RegAllocFast, RegAllocPBQP, class RegisterCoalescer class ReachingDefAnalysis, LiveIntervals, LiveRegMatrix class LiveStack, LiveVariables, Localizer \u0026hellip;  Initialization code in llvm/lib/CodeGen/CodeGen.cpp   llvm::initializeCodeGen()   // llvm/lib/CodeGen/CodeGen.cpp  /// initializeCodeGen - Initialize all passes linked into the CodeGen library. void llvm::initializeCodeGen(PassRegistry \u0026amp;Registry) { initializeAtomicExpandPass(Registry); initializeBranchFolderPassPass(Registry); initializeBranchRelaxationPass(Registry); initializeCFIInstrInserterPass(Registry); initializeCheriBoundAllocasPass(Registry); initializeCodeGenPreparePass(Registry); initializeDeadMachineInstructionElimPass(Registry); initializeDetectDeadLanesPass(Registry); initializeDwarfEHPreparePass(Registry); initializeEarlyIfConverterPass(Registry); initializeEarlyIfPredicatorPass(Registry); initializeEarlyMachineLICMPass(Registry); initializeEarlyTailDuplicatePass(Registry); initializeExpandMemCmpPassPass(Registry); initializeExpandPostRAPass(Registry); initializeFEntryInserterPass(Registry); initializeFinalizeISelPass(Registry); initializeFinalizeMachineBundlesPass(Registry); initializeFuncletLayoutPass(Registry); initializeGCMachineCodeAnalysisPass(Registry); initializeGCModuleInfoPass(Registry); initializeHardwareLoopsPass(Registry); initializeIfConverterPass(Registry); initializeImplicitNullChecksPass(Registry); initializeIndirectBrExpandPassPass(Registry); initializeInterleavedLoadCombinePass(Registry); initializeInterleavedAccessPass(Registry); initializeLiveDebugValuesPass(Registry); initializeLiveDebugVariablesPass(Registry); initializeLiveIntervalsPass(Registry); initializeLiveRangeShrinkPass(Registry); initializeLiveStacksPass(Registry); initializeLiveVariablesPass(Registry); initializeLocalStackSlotPassPass(Registry); initializeLowerIntrinsicsPass(Registry); initializeMIRCanonicalizerPass(Registry); initializeMIRNamerPass(Registry); initializeMachineBlockFrequencyInfoPass(Registry); initializeMachineBlockPlacementPass(Registry); initializeMachineBlockPlacementStatsPass(Registry); initializeMachineCSEPass(Registry); initializeMachineCombinerPass(Registry); initializeMachineCopyPropagationPass(Registry); initializeMachineDominatorTreePass(Registry); initializeMachineFunctionPrinterPassPass(Registry); initializeMachineLICMPass(Registry); initializeMachineLoopInfoPass(Registry); initializeMachineModuleInfoPass(Registry); initializeMachineOptimizationRemarkEmitterPassPass(Registry); initializeMachineOutlinerPass(Registry); initializeMachinePipelinerPass(Registry); initializeModuloScheduleTestPass(Registry); initializeMachinePostDominatorTreePass(Registry); initializeMachineRegionInfoPassPass(Registry); initializeMachineSchedulerPass(Registry); initializeMachineSinkingPass(Registry); initializeMachineVerifierPassPass(Registry); initializeOptimizePHIsPass(Registry); initializePEIPass(Registry); initializePHIEliminationPass(Registry); initializePatchableFunctionPass(Registry); initializePeepholeOptimizerPass(Registry); initializePostMachineSchedulerPass(Registry); initializePostRAHazardRecognizerPass(Registry); initializePostRAMachineSinkingPass(Registry); initializePostRASchedulerPass(Registry); initializePreISelIntrinsicLoweringLegacyPassPass(Registry); initializeProcessImplicitDefsPass(Registry); initializeRABasicPass(Registry); initializeRAGreedyPass(Registry); initializeRegAllocFastPass(Registry); initializeRegUsageInfoCollectorPass(Registry); initializeRegUsageInfoPropagationPass(Registry); initializeRegisterCoalescerPass(Registry); initializeRenameIndependentSubregsPass(Registry); initializeSafeStackLegacyPassPass(Registry); initializeScalarizeMaskedMemIntrinPass(Registry); initializeShrinkWrapPass(Registry); initializeSlotIndexesPass(Registry); initializeStackColoringPass(Registry); initializeStackMapLivenessPass(Registry); initializeStackProtectorPass(Registry); initializeStackSlotColoringPass(Registry); initializeTailDuplicatePass(Registry); initializeTargetPassConfigPass(Registry); initializeTwoAddressInstructionPassPass(Registry); initializeUnpackMachineBundlesPass(Registry); initializeUnreachableBlockElimLegacyPassPass(Registry); initializeUnreachableMachineBlockElimPass(Registry); initializeVirtRegMapPass(Registry); initializeVirtRegRewriterPass(Registry); initializeWasmEHPreparePass(Registry); initializeWinEHPreparePass(Registry); initializeXRayInstrumentationPass(Registry); } void LLVMInitializeCodeGen(LLVMPassRegistryRef R) { initializeCodeGen(*unwrap(R)); }   \nCode Emission reference LLVM CodeGen - Code Emission\nCode emission is responsible for lowering from code generator abstractions (MachineFunction, MachineInstr, etc) down the the abstractions used by the MC Layer (MCInst, MCStreamer, etc). This is done by the following classes:\n the (misnamed) target-independent AsmPrinter class.  It implements the general lowering process converting MachineFunction\u0026rsquo;s into MC label constructs. target-specific subclasses of AsmPrinter, such as SparcAsmPrinter, MipsAsmPrinter  the .td files used to generate instruction printer automatically.  add $dst, $src, $src2 Need routines to print operands. Where???  \u0026lt;target\u0026gt;MCInstLower.cpp: code that lowers a MachineInstr to an MCInst  often target specific is responsible for turning jump table entries, constant pool indicies, global variable address, etc, into MCLabels as appropriate. is responsible for expanding pseudo ops used by the code generator into the actual machine instructions they corresponding to. The MCInst that are generated by this are fed into the instructtion printer or the encoder.  the TargetLoweringObjectFile class  MC layer works at the level of abstraction of object files, it does not have a notion of functions, global variables, etc. Instead, it thinks about labels, directives, and instructions.\nMore info at MC Layer\nCodeGen [MachineInstr] \u0026ndash;\u0026gt; MC [MCInst] \u0026ndash;\u0026gt; Object [ISA]\nAutomatic Instruction Emission  Target.td TargetSelectionDAT.td XXXInstrFormats.td XXXInstrInfo.td XXX.td  Prolog/Epilog insertion Reference\n Relocations in CodeGen  References: [](#) Relocation basics Relocation Sections in ELF Relocation during Linking in LLD ELFRelocationEntry // llvm/include/llvm/MC/MCELFObjectWriter.h struct ELFRelocationEntry { uint64_t Offset; // Where is the relocation. const MCSymbolELF *Symbol; // The symbol to relocate with. unsigned Type; // The type of the relocation. uint64_t Addend; // The addend to use. const MCSymbolELF *OriginalSymbol; // The original value of Symbol if we changed it.\n lld  Reference [lld/ELF/Driver.cpp] lld/ELF/LinkerScript.cpp lld xxx.o -o xxx.exe lld \u0026ndash;verbose How to determine which sections to write to exe LinkerDriver::link\u0026lt;ELFT\u0026gt; is the driving entry for the link to prepare different sections needed for the final executable. inputSecions hold a list of all sections from all object files. outputSections tracking sections in/out // lld/ELF/Driver.cpp // Do actual linking. Note that when this function is called, // all linker scripts have already been parsed.\n Prolog Epilog  Q\u0026amp;A/Top Where is the return address being spilled? Where is the allocated stack frame being \u0026lsquo;destroyed\u0026rsquo;? Reference reference llvm/lib/CodeGen/PrologEpilogInserter.cpp Pass overview PEI (Prolog Epilog Inserter) pass creation: // void TargetPassConfig::addMachinePasses() { //... // Insert prolog/epilog code. Eliminate abstract frame index references... if (getOptLevel() != CodeGenOpt::None) { addPass(\u0026amp;PostRAMachineSinkingID); // sink COPY instructions which should be handled after RA. addPass(\u0026amp;ShrinkWrapID); // determine where the safe point to insert the prologue and epilogue.\n Core ISel  References: llvm/lib/CodeGen/TargetPassConfig.cpp TargetPassConfig::addCoreISelPasses() will create the core passes needed for instruction selection in LLVM. It will choose one of three instruction selectors (FastISel, SelectionDAG, or GlobalISel) for the compilation, whichever is available or meets the configuration options. add finalization pass addPass(\u0026amp;FinalizeISelID); to expand pseudo-instructions emitted by ISel. print and verify the instructions selected machine code: printAndVerify(\u0026quot;After Instruction Selection\u0026quot;);. code TargetPassConfig::addCoreISelPasses() ```C++\n Stack Frame  References: Target Code Generation Class of variables: Temporary variables: Local variables: Global variables: Stack Frame Layout Frame pointer (FP): ptr to beginning of stack frame (fixed) Stack pointer (SP): ptr to end of stack (can move). Stack frame hold space for: formals local variables return addresses (maybe) dynamic link (ptr to calling stack frame) (maybe) static link (ptr to lexically-enclosing stack frame) other run-time data (e.\n ELF (OS side)  References: ELF specification ELF Tutorial (i386). 目的档格式（ELF）. two ELF views: linking and execution. a list of widely used sections in ELF. Linker and Libraries Guide \u0026ndash; Object File Format CTOR/DTOR CFI (Call Frame Information) directives .cfi_personality directives, etc. Exception Frames .eh_frame section. Format is similar to .debug_frame section specified by DWARF standard. The .eh_frame and .eh_framehdr describes the call frames\n Calling Convention  References: LLVM Language Reference \u0026ndash; Calling Conventions Writing an llvm backend \u0026ndash; Calling Convention TableGen for Calling Convention TargetCallingConv.td Calling convention from writing an llvm backend: To support target-specific calling conventions, _XXX_GenCallingConv.td uses interfaces (such as CCIfType and CCAssignToReg) that are defined in lib/Target/TargetCallingConv.td. TableGen uses the target descriptor file _XXX_GenCallingConv.td to generate the header file _XXX_GenCallingConv.inc, which is typically included in _XXX_ISelLowering.cpp. The inferfaces in _XXX_GenCalllingConv.\n Linkers Loaders  References: Assemblers, Linkers, and Loaders, slides from Hakim Weatherspoon, Cornell, 2013. linkers and loaders, blog post. How to add a new target to LLD, slides from Peter Smith, Linaro, 2016. a figure of calling dynamic libraries over PLT/GOT Linker/Loader: binds more abstract names to more concrete names. Example: getline \u0026ndash;\u0026gt; \u0026ldquo;the location 612 bytes from the beginning of the executable code in module iosys\u0026rdquo;. \u0026ldquo;the location 450 bytes beyond the beginning of the static data from this module\u0026rdquo; \u0026ndash;\u0026gt; numberic address.\n The `MC` Layer in LLVM  Q \u0026amp; A Where is the symbol table section being composed and written to the object file? References: llvm-mc LLVM the x86 disassembler LLVM CodeGen The LLVM MC Project This section is mostly from: llvm-mc, with partial info from LLVM CodeGen. Instruction Printer. MCInstPrint: MCInst -\u0026gt; textual representation. Not aware of sections/directives, so independent of object file format. A new lowering pass: MachineInstr -\u0026gt; MCInst.\n Machine IR  Q\u0026amp;A How does it handle .got addressing? References: Machine IR Language Reference Welcome to the back end: the LLVM Machine Representation Tasks for LLVM Machine Representation: Resource Allocation: registers, stack space, \u0026hellip; Lowering: ABI, Exception Handling, Debug Info, \u0026hellip; Optimization: Peephole, Instruction/Block Scheduling, .. Basics Pass Manage Setup Pass manager pipeline is setup in TargetPassConfig. Target overrides methods to add, remove or replace passes.\n Reg Alloc  Reference 1 https://web.stanford.edu/class/archive/cs/cs143/cs143.1128/lectures/17/Slides17.pdf Silhouette: https://github.com/jzhou76/Silhouette/blob/silhouette_llvm9/lib/Target/ARM/ARMSilhouetteLabelCFI.cpp#L59 https://github.com/jzhou76/Silhouette/blob/silhouette_llvm9/lib/Target/ARM/ARMSilhouetteSFI.cpp#L148 https://github.com/jzhou76/Silhouette/blob/silhouette_llvm9/lib/Target/ARM/ARMSilhouetteSTR2STRT.cpp#L65 reference ↩  Arch - Basics - Assembly  Assembler Directives Reference: GNU AS - assembler directives Pseudo Op-Codes .cpload directives, etc. CFI (Call Frame Information) directives .cfi_personality directives, etc. Exception Frames .eh_frame section. TI - MSP430 - Assembler Directives Assembler directives supply data to the program and control the assembly process. Directives are commands that are part of the assmbler syntax but are not related to the processor ISA. Assembler directives enable you to do the following:\n Creating Backend for Cpu0  Q\u0026amp;A How to create a new section and store instruction and data\u0026rsquo;s metadata? like a new symbol table section? how to implement a new calling convention? Intrinsics? what is tablegen .td file? How it is used in LLVM infra? A domain specific language that describes functional modules and can be used to generate C++ code autotmatically. In LLVM, current usage of TableGen is to generate LLVM code generation code, and clang diagnostics and attributes; Instrinsics; Calling conventions; Register set, instruction set; More at TableGen what is regression test and how does it work?\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/process/",
	"title": "Process",
	"tags": [],
	"description": "",
	"content": " e.g. PCC initialization Every userspace PCC get default bound as 2^39.\nhybridabi_capability_set_user_entry() creates the code capability with entry address. The PCC base is default as CHERI_CAP_USER_CODE_BASE, length is CHERI_CAP_USER_CODE_LENGTH, perm is CHERI_CAP_USER_CODE_PERMS.\n CHERI_CAP_USER_CODE_BASE (sys/mips/include/cherireg.h):  0x000000  CHERI_CAP_USER_CODE_LENGTH (sys/mips/include/cherireg.h):  (VM_MAXUSER_ADDRESS - VM_MINUSER_ADDRESS) = 0x0000,0080,0000,0000 = 2^39 see tracking code below.  CHERI_CAP_USER_CODE_PERMS (sys/mips/include/cherireg.h):\n CHERI_PERMS_USERSPACE | CHERI_PERM_EXECUTE\n#define CHERI_PERMS_USERSPACE \\ (CHERI_PERM_GLOBAL | CHERI_PERM_LOAD | CHERI_PERM_LOAD_CAP | \\ CHERI_PERM_CCALL | (CHERI_PERMS_SWALL \u0026amp; ~CHERI_PERM_CHERIABI_VMMAP))// file // sys/mips/include/vmparam.h #define VM_MINUSER_ADDRESS ((vm_offset_t)0x00000000)  #ifdef __mips_n64 #define VM_MAXUSER_ADDRESS (VM_MINUSER_ADDRESS + (NPDEPG * NBSEG)) // 8 byte entry: 512 * 2^30 = 2^39 = 0x0000,0080,0000,0000 // 256-bit/32 byte entry: 128 * 2^30 = 0x0000,0020,0000,0000 #else #define VM_MAXUSER_ADDRESS ((vm_offset_t)0x80000000) #endif  // file // sys/mips/include/param.h #define NPTEPG (PAGE_SIZE/(sizeof (pt_entry_t))) // 512 for 8 byte ptrs #define NPDEPG (PAGE_SIZE/(sizeof (pd_entry_t)))  #define PAGE_SHIFT 12 /* LOG2(PAGE_SIZE) */ #if defined(__mips_n32) || defined(__mips_n64) /* PHYSADDR_64_BIT */#define NPTEPGSHIFT 9 /* LOG2(NPTEPG) */#else #define NPTEPGSHIFT 10 /* LOG2(NPTEPG) */#endif  #ifdef __mips_n64 #define NPDEPGSHIFT 9 /* LOG2(NPTEPG) */#define SEGSHIFT (PAGE_SHIFT + NPTEPGSHIFT + NPDEPGSHIFT) // 12 + 9 + 9 = 30 #define NBSEG (1ul \u0026lt;\u0026lt; SEGSHIFT) // 2^30 #else #define NPDEPGSHIFT 10 /* LOG2(NPTEPG) */#define SEGSHIFT (PAGE_SHIFT + NPTEPGSHIFT) #define NBSEG (1 \u0026lt;\u0026lt; SEGSHIFT) /* bytes/segment */#endif// file: // sys/mips/cheri/hybridabi_machdep.c  /* * Common per-thread CHERI state initialisation across execve(2) and * additional thread creation. */ static void hybridabi_thread_init(struct thread *td, unsigned long entry_addr) { struct cheri_signal *csigp; struct trapframe *frame; /* * We assume that the caller has initialised the trapframe to zeroes * -- but do a quick assertion or two to catch programmer error. We * might want to check this with a more thorough set of assertions in * the future. */ frame = \u0026amp;td-\u0026gt;td_pcb-\u0026gt;pcb_regs; KASSERT(*(uint64_t *)\u0026amp;frame-\u0026gt;ddc == 0, (\u0026#34;%s: non-zero initial $ddc\u0026#34;, __func__)); KASSERT(*(uint64_t *)\u0026amp;frame-\u0026gt;pcc == 0, (\u0026#34;%s: non-zero initial $epcc\u0026#34;, __func__)); /* * XXXRW: Experimental CheriABI initialises $ddc with full user * privilege, and all other user-accessible capability registers with * no rights at all. The runtime linker/compiler/application can * propagate around rights as required. */ hybridabi_capability_set_user_ddc(\u0026amp;frame-\u0026gt;ddc); hybridabi_capability_set_user_csp(\u0026amp;frame-\u0026gt;csp); hybridabi_capability_set_user_idc(\u0026amp;frame-\u0026gt;idc); hybridabi_capability_set_user_entry(\u0026amp;frame-\u0026gt;pcc, entry_addr); hybridabi_capability_set_user_entry(\u0026amp;frame-\u0026gt;c12, entry_addr); /* * Initialise signal-handling state; this can\u0026#39;t yet be modified * by userspace, but the principle is that signal handlers should run * with ambient authority unless given up by the userspace runtime * explicitly. */ csigp = \u0026amp;td-\u0026gt;td_pcb-\u0026gt;pcb_cherisignal; bzero(csigp, sizeof(*csigp)); hybridabi_capability_set_user_ddc(\u0026amp;csigp-\u0026gt;csig_ddc); hybridabi_capability_set_user_csp(\u0026amp;csigp-\u0026gt;csig_csp); hybridabi_capability_set_user_csp(\u0026amp;csigp-\u0026gt;csig_default_stack); hybridabi_capability_set_user_idc(\u0026amp;csigp-\u0026gt;csig_idc); hybridabi_capability_set_user_pcc(\u0026amp;csigp-\u0026gt;csig_pcc); csigp-\u0026gt;csig_sigcode = cheri_sigcode_capability(td); /* * Set up root for the userspace object-type sealing capability tree. * This can be queried using sysarch(2). */ cheri_capability_set_user_sealcap(\u0026amp;td-\u0026gt;td_proc-\u0026gt;p_md.md_cheri_sealcap); } } static void hybridabi_capability_set_user_entry(void * __capability *cp, unsigned long entry_addr) { /* * Set the jump target regigster for the pure capability calling * convention. */ *cp = cheri_capability_build_user_code(CHERI_CAP_USER_CODE_PERMS, CHERI_CAP_USER_CODE_BASE, CHERI_CAP_USER_CODE_LENGTH, entry_addr); } // for cheriabi:  // sys/mips/cheri/cheriabi_machdep.c  /* * Common per-thread CHERI state initialisation across execve(2) and * additional thread creation. */ void cheriabi_newthread_init(struct thread *td) { struct cheri_signal *csigp; struct trapframe *frame; /* * We assume that the caller has initialised the trapframe to zeroes * and then set idc, and pcc appropriatly. We might want to check * this with a more thorough set of assertions in the future. */ frame = \u0026amp;td-\u0026gt;td_pcb-\u0026gt;pcb_regs; KASSERT(frame-\u0026gt;pcc != NULL, (\u0026#34;%s: NULL $epcc\u0026#34;, __func__)); /* * Initialise signal-handling state; this can\u0026#39;t yet be modified * by userspace, but the principle is that signal handlers should run * with ambient authority unless given up by the userspace runtime * explicitly. The caller will initialise the stack fields. * * Note that some fields are overwritten later in * exec_setregs() for the initial thread. */ csigp = \u0026amp;td-\u0026gt;td_pcb-\u0026gt;pcb_cherisignal; bzero(csigp, sizeof(*csigp)); /* Note: csig_{ddc,idc,pcc} are set to NULL in the pure-capability abi */ csigp-\u0026gt;csig_sigcode = cheri_sigcode_capability(td); /* * Set up root for the userspace object-type sealing capability tree. * This can be queried using sysarch(2). */ cheri_capability_set_user_sealcap(\u0026amp;td-\u0026gt;td_proc-\u0026gt;p_md.md_cheri_sealcap); }   cheri_capability_build_user_code(perms, basep, length, off) is a macro mapped to _cheri_capability_build_user_code(perms, basep, length, off, __func__, __LINE__) (in sys/cheri/cheri.h).\n// file // sys/mips/cheri/cheri.c  /* * Build a new userspace capability derived from userspace_cap. * The resulting capability may include both read and execute permissions, * but not write. */ void * __capability _cheri_capability_build_user_code(uint32_t perms, vaddr_t basep, size_t length, off_t off, const char* func, int line) { KASSERT((perms \u0026amp; ~CHERI_CAP_USER_CODE_PERMS) == 0, (\u0026#34;%s:%d: perms %x has permission not in CHERI_CAP_USER_CODE_PERMS %x\u0026#34;, func, line, perms, CHERI_CAP_USER_CODE_PERMS)); return (_cheri_capability_build_user_rwx( perms \u0026amp; CHERI_CAP_USER_CODE_PERMS, basep, length, off, func, line)); }  _cheri_capability_build_user_rwx is defined as\n// sys/cheri/cheri_usercap.c: 83  /* * Build a new userspace capability derived from userspace_cap. * The resulting capability may include read, write, and execute permissions. * * This function violates W^X and its use is discouraged and the reason for * use should be documented in a comment when it is used. */ void * __capability _cheri_capability_build_user_rwx(uint32_t perms, vaddr_t basep, size_t length, off_t off, const char* func __unused, int line __unused) { void * __capability tmpcap; tmpcap = cheri_setoffset(cheri_andperm(cheri_csetbounds( cheri_setoffset(userspace_cap, basep), length), perms), off); KASSERT(cheri_getlen(tmpcap) == length, (\u0026#34;%s:%d: Constructed capability has wrong length 0x%zx != 0x%zx: \u0026#34; _CHERI_PRINTF_CAP_FMT, func, line, cheri_getlen(tmpcap), length, _CHERI_PRINTF_CAP_ARG(tmpcap))); return (tmpcap); }   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/intrin/",
	"title": "Intrinsics",
	"tags": [],
	"description": "",
	"content": "Reference:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/",
	"title": "Arch",
	"tags": [],
	"description": "",
	"content": " Ongoing (as of 2022-03-28)  Formal Verification in EDA  theory: the book practice: ?  Formal Verification in OS(SeL4)  theory: the paper; methodology/workflow/tools; practice: sel4 testing/verification code examples; test run;  Architectural design in SonicBoom/C910  theory: pipeline/cache/mem design practice: read code examples; test run;   Reference:\n Basics  Reference 1 Two Types of Logic Blocks Combinational Logic Blocks without memory are called combinational; the output of a combinational block depends only on the current input. Can be defined by truth table, boolean algebra. Decoders: n-bit input -\u0026gt; 2^n outputs Multiplexors: a selector: output is one of the inputs that is selected by a control. Sequential Logic Sequential logic is logic including state. In blocks with memory, the outputs can depends on both the inputs and the value stored in memory, which is called the state of the logic block.\n Secure Virtual Architecture  Todos Where is the pool metadata created/used in SAFECode passes? Where is the runtime check instrumentation in SAFECode passes? Learn the code from SVA on FreeBSD and propose a solution for the policy to be ported/re-implemented on CheriBSD: sosp 2007 booting signal handler dispatch code I/O instructions. kernel allocators. for analysis(ch6.3): int to pointer casts, stack usage, sys_iotctl, initial task structure, stack pointer to structure. sec 2009\n Pump  Q\u0026amp;A How to init tags? LLM: developer writes rules in a special language; software handler computes the rule and generates mappings of tags (as policy) 2018sp-stack: Compiler + adding instructions into programs. 2018sp-stack: Lazy tagging (first write) + Lazy clearing (on all write, check only on read) How to propagate tags? LLM: mapping of tags (policy rules) will be used to propagagte tags during execution of PUMP.\n Neverland  Reference 1 Neverland: Lightweight Hardware Extensions for Enforcing Operating System Integrity. Montivations Current solutions has draw backs: Secure Boot, driver signing Secure Boot is not enough to protect kernel from being tempered: attackers could exploit software vulnerabilities to perform malicious actions such as overwriting kernel memory, executing malware in kernel-mode, or disabling driver integrity checks (example attacks can be seen in [^c64] [^c8] [^c16] [^c41] [^c62] [^c54] [^c48] [^c44]).\n Secure TLBs  Reference 1 Secure TLBs. ISCA, 2019. ↩  AI Chips  References: AI Chips: What They Are and Why They Matter. Saif M. Khan, April 2020. General-purpose Chips (CPU) vs. Specialized Chips (GPU, FPGA, ASIC) Different types of AI chips are useful for different tasks. GPUs are most often used for initially developing and refining AI algorithms; This process is known as \u0026ldquo;training\u0026rdquo;. FPGAs are mostly used to apply trained AI algorithms to real-world data inputs; This is often called \u0026ldquo;inference\u0026rdquo;.\n Fpga   References: reference FPGA vs ASIC CBB: Common Building Block. Timing Constraints: Tsu: Time of Set up Th: Time of Hold SDC: Synopsys Design Constraints STA: Static Timing Analysis More  Vivado Usage Tips  Out of date One can \u0026lsquo;force up to date\u0026rsquo; if changes are detected by vivado but those changes can be ignored (unrelated to the regarding operation). Out of date \u0026ndash; force up to date Out of Context Modules Vivado IP的两种综合方式：Global 和 Out-Of-Context More\n Rtl Verification   References: reference More UVM - Universal Verification Methodology References: UVM shizhan, juan I IC design process design: Verilog/VHDL verification: Verilog, SystemVerilog, SystemC, More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/intrumentation/",
	"title": "Intrumentation",
	"tags": [],
	"description": "",
	"content": "Reference:\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/",
	"title": "Languages",
	"tags": [],
	"description": "",
	"content": " Top Wonderings  What we can do to enable everyone writing a new OS kernel as easily as a user applications?\n What is the difference between applications and OS kernels? Is kernel just a special application? A new language designed for easy coding for OS kernels, just as other domain specific languages?  A single application written using a mix of different languages and how can we securely compile/link them together without sacrafices the security properties of each language?\n How to capture all the side effects of C functions and effectively turn it into a functional-like language where all side effects are made explicitly made as \u0026lsquo;returned value\u0026rsquo;.\n so that we can make formal verification of C as easy as in Haskell, Ocaml, etc. C\u0026ndash;?    Closure  Reference 1 reference ↩  Lambda  Reference 1 Lambda: Syntactically, lambda refers to a form for describing anonymous functions. But a lambda does not become a function pointer. It becomes a closure. Closures are data structures with both a code and a data component. Two strategies to compile lambdas into closures: Flat closures Linked (or shared) Closures Closure Conversion: flat closure is top-down compilation; and linked(or shared) closure is bottom-up compilation. Lambda Lifting Reference [^wiki-lambda-lifting] 1982 by Thomas Johnsson.\n Langs  Reference 1 Sequoia Reference 1 http://web.stanford.edu/group/sequoia/ http://web.stanford.edu/group/sequoia/cgi-bin/ reference ↩ C \u0026amp; C\u0026#43;\u0026#43; Reference 1 Copy Elision when return a struct. Mesh: Fragmentation in C/C\u0026#43;\u0026#43; Reference 1 MESH: Compacting Memory Management for C/C++ Applications, PLDI, 2019. ↩ reference ↩ NesC Reference: Go Reference: Concurrency Setup Environment Variables Reference: GOPATH: environment variable that specifies the location of your workspace. If no GOPATH is set, it is assumed to be $HOME/go on Unix systems and %USERPROFILE%\\go on Windows.\n Tensors  Reference 1 Why tensor? What is a tensor? From datacamp: Vectors: ordered collection of numbers; one column matrices; a scalar magnitudes that have been given a direction, where direction is relative to the reference direction. Vector space: two-space: (x,y); three space (x,y,z); Unit Vectors: $\\hat x$, a magnitude of one. Tensor: a mathematical representation of a physical entity that may be characterized by magnitude and multiple directions.\n Mix Langs  Reference 1 FunTal Reference 1 FunTAL: Reasonably Mixing a Functional Language with Assembly ↩ All the languages together ↩  Tapl  Reference 1 Semantic Style Semantic Styles (chapter 3.4 in 1) There are three basic approaches to formalizing semantics: Operational semantics. Specifies the behavior of a programming language by defining a simple abstract machine on it. For simple languages, a state of the machine is just a term, and the machine\u0026rsquo;s behavior is defined by a transition function that, for each state, either gives the next state by performing a step of simplification on the term or declares that the machine has halted.\n Aspect Oriented Programming  Reference: what is aop  Class PLDI  Q \u0026amp; A Does functional programming have object oriented programming style? What is essential part for a domain specific language? References: CSC 2\u0026frasl;454 Programming Language Design and Implementation, by Prof. Micheal Scott Aug 28. names of PLs (IMPERATIVE) C#, C, Swift, Java, Ada, Rust, Pascal, scala, Algol, Go, Obj-C, Fortan, C++, B, PL/I, X, (SCRIPTING) Kotlin, Python, Julia, Javascript, PHP, R, Ruby, small talk, (FUNC) Lisp, Scheme, ML, Haskell, Erlang,\n Typed Assembly Language  Reference1: Statically typed intermediate languages are effective tools for staging the compilation of high-level languages. Types express invariants that help programmers understand their programs, and strongly typed languages prevent many common programming errors. Compiler writers can use these properties to debug sophisticated program transformations such as closure conversion and optimizations like datatype specialization. Furthermore, types not only help check the correctness of transformations but enable analyses or optimizations that are extremely difficult without them.\n Types  Reference 1 Gradual Typing Reference 1 RUST \u0026mdash;\u0026mdash;\u0026ndash;buffer\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt; Ocaml \u0026lt;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; Escape Hatches: ML:C FFI Rust:unsafe Java: JNI All type soundness(safety) guarranttes are gone. Instead, use Principled FFIs: ML: linear types. Linking types: support safe initeroperability with other languages. Only need linking types extensions to interact with behavior/features inexpressible in your language. SNAPL\u0026rsquo;172: Linking Types for Multi-language Software: Have your cake eat it too. Teach Ocaml with ownership in Rust: Linking Type: linear type: cannot keep it and give it away at the same time.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/",
	"title": "CheriBSD",
	"tags": [],
	"description": "",
	"content": " References:\n[1] CHERI ISA v5 (2016), v6(2017), v7 (2019).\n[2] CheriBSD, github, link.\n 2016 v5: Initial in-kernel privilege limitation\n 2017 v6: Mature kernel privilege limitation\n  [3] CHERI programmer\u0026rsquo;s guide, UCAM-CL-TR-877, 2015.\nQuestions/Proposals  Kernel has no capability state during context switch: kernel state\n How does CheriBSD do memory partition for physical memory tags?\n  In details  Kernel Change List\n Kernel Capability\n CheriBSD Context Switch\n Trusted Stack\n Signal Handling\n Copying Memory\n Booting\n Process\n   Cheri Tlb  Reference 1 ISAv7 ch3.8.3 Virtual Memory -\u0026gt; Authorizing MMU Control CHERI controls the use of privileged instructions and control registers that configure the MMU: Access_System_Registers permission must be present on PCC; for software managed-TLB, retrieving and inserting TLB entries also requires above permission on PCC/KCC/KDC; for hardware page-table walker, CHERI currently does not control memory acecesses performed by the walker via physical addresses. Page-Table Entry \u0026amp; TLB entry Permissions ISAv7 ch3.\n Trusted Stack  References: [1] CHERI programmer\u0026rsquo;s guide, UCAM-CL-TR-877 Chapter 8.4, 2015. One trusted stack for each thread: pcb_cheristack. Initialized to empty when first thread in a process is created. Stack updates/inspections in the following situations: CCall exception CReturn exception CHERI_GET_STACK via sysarch system call CHERI_SET_STACK via sysarch system call cheri_stack_unwind: if a signal is delivered to a thread that is executing sandboxed code, and suitable signal-handling configuration has not been set up to safely receive the delivered signal, then for certian signals the kernel will automatically unwind the stack back to the caller of the sandbox.\n Booting  Q \u0026amp; A where is the tagged memory being partitioned? The call path: boot2 -\u0026gt; ? -\u0026gt; locore.S: _locore/_start/unknown/btext -\u0026gt; platform_start() ? cheri_cpu_startup() in mips/cheri/cheri.c conf/ldscript.mips.mips64:34 ENTRY(_start) ? The BERIpad tablet: open-source construction, CPU, OS and applications: A small built-in ROM in BERI is able to relocate a FreeBSD kernel out of flash, or, if a DIP switch is set, make use of a kernel loaded directly into DRAM using JTAG.\n Process  e.g. PCC initialization Every userspace PCC get default bound as 2^39. hybridabi_capability_set_user_entry() creates the code capability with entry address. The PCC base is default as CHERI_CAP_USER_CODE_BASE, length is CHERI_CAP_USER_CODE_LENGTH, perm is CHERI_CAP_USER_CODE_PERMS. CHERI_CAP_USER_CODE_BASE (sys/mips/include/cherireg.h): 0x000000 CHERI_CAP_USER_CODE_LENGTH (sys/mips/include/cherireg.h): (VM_MAXUSER_ADDRESS - VM_MINUSER_ADDRESS) = 0x0000,0080,0000,0000 = 2^39 see tracking code below. CHERI_CAP_USER_CODE_PERMS (sys/mips/include/cherireg.h): CHERI_PERMS_USERSPACE | CHERI_PERM_EXECUTE #define CHERI_PERMS_USERSPACE \\ (CHERI_PERM_GLOBAL | CHERI_PERM_LOAD | CHERI_PERM_LOAD_CAP | \\ CHERI_PERM_CCALL | (CHERI_PERMS_SWALL \u0026amp; ~CHERI_PERM_CHERIABI_VMMAP))// file // sys/mips/include/vmparam.\n Cheri Userspace  Change List libprocstat(3) library and procstat(1) command: extended to inspect sandbox statistics. libcheri(3): a sandbox API, and a set of system-class objects that can be delegated to sandboxes. Currently (1), this consists of a singleton system object that provides the ability to print to stdout, and a file-descriptor class that allows delegation of individual kernel-provided file descriptors to sandboxes. libc_cheri(3): core C-language APIs and services within sandboxes.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freebsd/cheri-user/",
	"title": "Cheri Userspace",
	"tags": [],
	"description": "",
	"content": " Change List  libprocstat(3) library and procstat(1) command: extended to inspect sandbox statistics.\n libcheri(3): a sandbox API, and a set of system-class objects that can be delegated to sandboxes. Currently (1), this consists of a singleton system object that provides the ability to print to stdout, and a file-descriptor class that allows delegation of individual kernel-provided file descriptors to sandboxes.\n libc_cheri(3): core C-language APIs and services within sandboxes. This library is able to use the system and file-descriptor classes to provide access to APIs such as printf().\n cheritest: test cases for capability-related functions including sandboxing; cheritest relies on cheritest-helper.bin to provide sandboxed code.\n cheri_tcpdump, sandboxed sniffing and parsing; cheri_tcpdump relies on tcpdump-helper to provide sandboxed code.\n libz-cheri(3): compression routines with fine-grained memory protection.\n  Source code CheriBSD userspace source directories:\n   Filename Description     bin/cheritest/ Command-line utility exercising CHERI and CheriBSD features, including sandboxing CTSRD-project demo code   ctsrd/ CTSRD-project demo code   lib/libc_cheri/ In-sandbox C library/runtime   lib/libcheri Library implementing the CHERI sandbox API; the CHERI system class implementation   libexec/cheritest-helper/ Sandboxed components for cheritest   libexec/tcpdump-helper/ Sandboxed components for cheri_tcpdump, initialization and context management   lib/libz-cheri Version of libz compiled with CHERI memory protection   usr.sbin/tcpdump/cheri_tcpdump Version of tcpdump able to use CHERI sandboxing   lib/libprocstat/ Extensions to this library allow procstat(1) to monitor libcheri sandboxes   usr.bin/procstat/ procstat(1) command extended to monitor libcheri sandboxes     CHERI programmer\u0026rsquo;s guide, 2015. (may be outdated) ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-freertos/",
	"title": "Cheri FreeRTOS",
	"tags": [],
	"description": "",
	"content": " Reference 1 2\nMakefile change FreeRTOS/Demo/RISC-V_Galois_P1/Makefile\nMakefile fix for Clang/LLVM tools\nInitial Update\n  Github: CHERI-FreeRTOS ↩ Using FreeRTOS on RISC-V Microcontrollers ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-rtos/",
	"title": "Cheri RTOS",
	"tags": [],
	"description": "",
	"content": " CHERI-aware real-time operating system, CheriRTOS.\n Fine-grained memory protection Secure centralized heap management; Dynamic task loading; Low-latency and direct domain crossing; Distributed trusted stacks to protect return contexts; Secure peripherals.  Current limitations MPU limitation  MPU is a kernel space device, each register takes multiple cycles to configure;  usually configured only globally at system start-up, which makes per-task memory access control difficult; user space cannot leverage it for intra-task protection;  MPU entries are limited. Fine grained memory protection is impractical; MPU lookups involve associative searches of all entries.  Assuming 8 MPU entries, accounting for both instruction fetch and data, EACH CYCLE can potentially require up to 32 comparisons.???? Inefficient in terms of power and die area.   TrustZone limitation Secure and non-secure worlds; constrained control-flow; A certain degree of CFI, which avoids ROP attacks.\n Non-secure code can jump only to valid entry points on the secure side, and secure code calls non-secure functions after clearing registers and pushing the return address on the secure stack.  Limitations:\n scalability issues: further isolation within a world is not possible. Separating the entire system into only two worlds may not be a wise design choice.  EA-MPU Execution-Aware MPU: links data and code entries to distinguish between different tasks; control memory access on a per-task basis.\nBuilt in TrustLite1 and TyTan2.\nLimitations:\n Inheris MPU flaws: restricted number of simultaneous tasks; restricted inter-task memory sharing.  CFI and ROP defense approaches  In 3 4, they use dedicated instructions for function calls, exposing only valid entry points, hiding return addresses in protected spaces, etc. Sanctus 5 6 builds tasks into Self-Protecting Modules (SPMs) to restrict access and enforce control flow.  sacrifices software flexibility incurs high hardware cost by implementing SPM loading, measurement, and runtime identification in the trusted CPU.   PL level for embeded devices nesCheck7 modifies the language and compiler to perform stronger type safety, static analysis, and run-time checks.\nSafeCode8 develops new compiler frameworks to address stack, array, and pointer safety, and implement new heap allocation techniques.\n  TrustLite: A Security Architecture for Tiny Embedded Devices, EuroSys, 2014. New York, NY, USA. ↩ TyTAN: Tiny trust anchor for tiny devices. DAC, 2015. ↩ HAFIX: Hardware-Assisted Flow Integrity eXtension. DAC, 2015. ↩ Hardware-assisted fine-grained control-flow integrity: Towards efficient protection of embedded systems against software exploitation. DAC, 2014. ↩ Sancus: Low-cost Trustworthy Extensible Networked Devices with a Zerosoftware Trusted Computing Base. USENIX Security, 2013. ↩ Efficient Isolation of Trusted Subsystems in Embedded Systems. SPCN, 2010. ↩ nesCheck, Asia CCS, 2017; ↩ SafeCode, ACM Transactions on Embedded Computing Systems (TECS), 2005; ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-hypervisor/",
	"title": "Cheri Hypervisor",
	"tags": [],
	"description": "",
	"content": "Reference 1\nGoogle Hafnium.\nProject Oak\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/parallel/",
	"title": "Parallel",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Memory Consistency Models  References: Memory Consistency Models: A Tutorial Memory Consistency: the problem of defining how parallel threads can observe their shared memory state. A memory consistency model is a contract between the hardware and software. The hardware promises to only reorder operations in ways allowed by the model, and in return, the software acknowledges that all such reorderings are possible and that it needs to account for them. Sequential Consistency Sequential consistency (SC): single main memory + program order.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/formal/",
	"title": "Formalization for Privilege Separation",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Reasoning About a Machine with Local Capabilities: Provably Safe Stack and Return Pointer Management Formalizing the Security Guarantees of Compartmentalizing Compilation   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-cloud/",
	"title": "Cheri Cloud",
	"tags": [],
	"description": "",
	"content": "Reference 1\nPCIe to SATA breakout board\nCHERI Cloud: Bluehive\n  ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pro-ana/basics/complexity/",
	"title": "Complexity",
	"tags": [],
	"description": "",
	"content": " Reference:\nReferences:\n[1] Static Program Analysis, Anders Moller, and Micheal I. Schwartzbach, 2018.\nQuestions/Proposals  To decide whether any given a program will halt or not is undecidable. However, there are many programs (probably small or large) that we already know it will halt, or will never halt. How many are there? What is the common feature of these programs? Could we statically describe some (not all) of them?   Undecidability of Program Correctness  \n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/safecode/passes/",
	"title": "Passes",
	"tags": [],
	"description": "",
	"content": " Stack Check  Reference1 safecode/include/StackSafety.h: This file defines checks for stack safety. struct checkStackSafety : public ModulePass { public : ... virtual bool runOnModule(Module \u0026amp;M); virtual void getAnalysisUsage(AnalysisUsage \u0026amp;AU) const { AU.addRequired\u0026lt;DataLayout\u0026gt;(); AU.addRequired\u0026lt;EQTDDataStructures\u0026gt;(); AU.setPreservesAll(); } private : // // Tracks the DSNodes that have already been analyzed by an invocation of // markReachableAllocas(). // std::set\u0026lt;DSNode *\u0026gt; reachableAllocaNodes; bool markReachableAllocas(DSNode *DSN, bool start=false); bool markReachableAllocasInt(DSNode *DSN, bool start=false); }; } } safecode/lib/StackSafety/CheckStackPointer.\n Static Array Bound Checks  lib/ArrayBoundChecks: This library contains serveral analysis passes for static array bounds checking1. safecode/lib/ArrayBoundChecks/ArrayBoundCheckLocal.cpp: \u0026ldquo;ArrayBoundsCheckLocal - It tries to prove a GEP is safe only based on local information, that is, the size of global variables and the size of objects being allocated inside a function.\u0026rdquo; Code sinppets: Entry: bool ArrayBoundsCheckLocal::runOnFunction(Function \u0026amp; F) { // // Get required analysis passes. // TD = \u0026amp;F.getParent()-\u0026gt;getDataLayout(); SE = \u0026amp;getAnalysis\u0026lt;ScalarEvolution\u0026gt;(); // // Look for all GEPs in the function and try to prove that they\u0026#39;re safe.\n Pass: Insert Pointer Checks  Reference1 C Zero Security Checks: \u0026ldquo;This transformation ensures that the code emitted (if there are no warnings) poses no security threat to the target system.\u0026rdquo; Free Removal Pass: \u0026ldquo;FIXME: This pass needs to be cleaned up and better understood. Some of the functionality seems to be addressed with poolcheckalign() in the Check Insertion pass; we should ensure that the functionality there is present in mainline and supercedes what is implemented here.\n Pass: Insert Pool Checks  lib/InsertPoolChecks. This library contains the transform passes for inserting run-time checks and for inserting code to register memory objects within individual pools. the CompleteChecks pass which implements the Check Completion Phase. Alignment Checks: \u0026ldquo; This pass instruments the code with alignment checks. This is required when load/store checks on type-safe memory objects are optimized away; pointers to type-safe memory objects that are loaded from type-unsafe memory objects may not point to a valid memory object or may not be alignment properly within a valid memory object.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/linux/",
	"title": "Linux",
	"tags": [],
	"description": "",
	"content": "Reference1\n reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-fm/",
	"title": "Cheri Formal",
	"tags": [],
	"description": "",
	"content": " References:\n[1] CHERI ISA v5 (2016).\n Existing formal methodology applied to software security has significant problems with multi-address-space security models; formal approaches have relied on the usefullness of addresses(pointers) as unique names for objects. Whereas this weakness in formal methods is a significant problem for traditional CPU designs, which offser security primarily through rings and address-space translation, CHERI\u0026rsquo;s capability model is scoped within address spaces. This offers the possibility of applying existing software proof methodology in the context of hardware isolation (and other related properties) in a manner that was previously infeasible.\n\u0026ndash; Formal Methodology, CHERI ISA v5, chapter 1.6.\n Questions/Proposals More  2019 Rigorous  Q\u0026amp;A Is there any bug that cannot (or hard to) be found without the formal model in the paper? In section VI, subtle bugs are found in CHERI ISA: CLC instruction: load data without permission check; bug in arch document and L3 model. legacy MIPS store allowed writing one byte past the region of the memory the code had permission to, and, if the code had access to the end of the address space, stores could write to the beginning of the address space.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-link/",
	"title": "Cheri Link",
	"tags": [],
	"description": "",
	"content": "  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/ai-chips/",
	"title": "AI Chips",
	"tags": [],
	"description": "",
	"content": " References:\n AI Chips: What They Are and Why They Matter. Saif M. Khan, April 2020.  General-purpose Chips (CPU) vs. Specialized Chips (GPU, FPGA, ASIC)\n Different types of AI chips are useful for different tasks. GPUs are most often used for initially developing and refining AI algorithms; This process is known as \u0026ldquo;training\u0026rdquo;. FPGAs are mostly used to apply trained AI algorithms to real-world data inputs; This is often called \u0026ldquo;inference\u0026rdquo;. ASICs can be designed for either training or inference.\n \u0026ldquo;An AI chip a thousand times as effcient as a CPU provides an improvement equivalent to 26 years of Moore\u0026rsquo;s Law-driven CPU improvements.\u0026rdquo;\nGPU Vendors:\n Nvidia AMD 景嘉微电子  FPGA Vendors:\n Xilinx Intel 上海复旦微电子（1998） 安路科技（2011） 紫光同创（2013） 高云半导体（2014）  ASIC Vendors:\n Google, TPU Tesla,  2021-06, 72 TOPS. 2021-08-19, D1 chip (362 TOPS), used in Dojo supercomputer (25 chips per tile, 120 tiles)  Amazon, Alibaba, Tencent, Baidu, 昆仑  昆仑1，2019.12，256TOPS-Int8, 150W，Samsung代工。 昆仑2，2021.8.18，7nm量产，2~3倍性能提升。   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/call-conv/cc-cheri-ccall/",
	"title": "The calling convention of CC_CHERI_CCall",
	"tags": [],
	"description": "",
	"content": " References:\n llvm/lib/Target/Mips/MipsCallingConv.td build/lib/Target/Mips/MipsGenCallingConv.inc  CHERI_CCall calling conv:\nDefinition Defined in .td file, code generated (during build) as MipsGenCallingConv.inc\n// llvm/lib/Target/Mips/MipsCallingConv.td  def CC_CHERI_CCall : CallingConv\u0026lt;[ CCIfType\u0026lt;[iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR512], CCAssignToReg\u0026lt;[C1, C2, C3, C4, C5, C6, C7, C8, C9, C10]\u0026gt;\u0026gt;, CCIfType\u0026lt;[i64], CCAssignToReg\u0026lt;[V0_64]\u0026gt;\u0026gt;, CCDelegateTo\u0026lt;CC_MipsN\u0026gt; ]\u0026gt;; def CC_MipsN : CallingConv\u0026lt;[ CCIfType\u0026lt;[i8, i16, i32, i64], CCIfSubtargetNot\u0026lt;\u0026#34;isLittle()\u0026#34;, CCIfInReg\u0026lt;CCPromoteToUpperBitsInType\u0026lt;i64\u0026gt;\u0026gt;\u0026gt;\u0026gt;, // All integers (except soft-float integers) are promoted to 64-bit.  CCIfType\u0026lt;[i8, i16, i32], CCIfOrigArgWasNotFloat\u0026lt;CCPromoteToType\u0026lt;i64\u0026gt;\u0026gt;\u0026gt;, // The only i32\u0026#39;s we have left are soft-float arguments.  CCIfSubtarget\u0026lt;\u0026#34;useSoftFloat()\u0026#34;, CCIfType\u0026lt;[i32], CCDelegateTo\u0026lt;CC_MipsN_SoftFloat\u0026gt;\u0026gt;\u0026gt;, // Integer arguments are passed in integer registers.  CCIfType\u0026lt;[i64], CCAssignToRegWithShadow\u0026lt;[A0_64, A1_64, A2_64, A3_64, T0_64, T1_64, T2_64, T3_64], [D12_64, D13_64, D14_64, D15_64, D16_64, D17_64, D18_64, D19_64]\u0026gt;\u0026gt;, // f32 arguments are passed in single precision FP registers.  CCIfType\u0026lt;[f32], CCAssignToRegWithShadow\u0026lt;[F12, F13, F14, F15, F16, F17, F18, F19], [A0_64, A1_64, A2_64, A3_64, T0_64, T1_64, T2_64, T3_64]\u0026gt;\u0026gt;, // f64 arguments are passed in double precision FP registers.  CCIfType\u0026lt;[f64], CCAssignToRegWithShadow\u0026lt;[D12_64, D13_64, D14_64, D15_64, D16_64, D17_64, D18_64, D19_64], [A0_64, A1_64, A2_64, A3_64, T0_64, T1_64, T2_64, T3_64]\u0026gt;\u0026gt;, // All stack parameter slots become 64-bit doublewords and are 8-byte aligned.  CCIfType\u0026lt;[f32], CCAssignToStack\u0026lt;4, 8\u0026gt;\u0026gt;, CCIfType\u0026lt;[i64, f64], CCAssignToStack\u0026lt;8, 8\u0026gt;\u0026gt;, CCIfType\u0026lt;[iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR512], CCAssignToReg\u0026lt;[C3, C4, C5, C6, C7, C8, C9, C10]\u0026gt;\u0026gt;, CCIfType\u0026lt;[iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR512], CCDelegateTo\u0026lt;CC_MipsCheriCapOnStack\u0026gt;\u0026gt; ]\u0026gt;;    Tracking CC_CHERI_CCall   // build/lib/Target/Mips/MipsGenCallingConv.inc  static bool CC_CHERI_CCall(unsigned ValNo, MVT ValVT, MVT LocVT, CCValAssign::LocInfo LocInfo, ISD::ArgFlagsTy ArgFlags, CCState \u0026amp;State) { if (LocVT == MVT::iFATPTR64 || LocVT == MVT::iFATPTR128 || LocVT == MVT::iFATPTR256 || LocVT == MVT::iFATPTR512) { static const MCPhysReg RegList1[] = { Mips::C1, Mips::C2, Mips::C3, Mips::C4, Mips::C5, Mips::C6, Mips::C7, Mips::C8, Mips::C9, Mips::C10 }; if (unsigned Reg = State.AllocateReg(RegList1)) { State.addLoc(CCValAssign::getReg(ValNo, ValVT, Reg, LocVT, LocInfo)); return false; } } if (LocVT == MVT::i64) { if (unsigned Reg = State.AllocateReg(Mips::V0_64)) { State.addLoc(CCValAssign::getReg(ValNo, ValVT, Reg, LocVT, LocInfo)); return false; } } if (!CC_MipsN(ValNo, ValVT, LocVT, LocInfo, ArgFlags, State)) return false; return true; // CC didn\u0026#39;t match. } //  static bool CC_MipsN(unsigned ValNo, MVT ValVT, MVT LocVT, CCValAssign::LocInfo LocInfo, ISD::ArgFlagsTy ArgFlags, CCState \u0026amp;State) { if (LocVT == MVT::i8 || LocVT == MVT::i16 || LocVT == MVT::i32 || LocVT == MVT::i64) { if (!static_cast\u0026lt;const MipsSubtarget\u0026amp;\u0026gt;(State.getMachineFunction().getSubtarget()).isLittle()) { if (ArgFlags.isInReg()) { LocVT = MVT::i64; if (ArgFlags.isSExt()) LocInfo = CCValAssign::SExtUpper; else if (ArgFlags.isZExt()) LocInfo = CCValAssign::ZExtUpper; else LocInfo = CCValAssign::AExtUpper; } } } if (LocVT == MVT::i8 || LocVT == MVT::i16 || LocVT == MVT::i32) { if (!static_cast\u0026lt;MipsCCState *\u0026gt;(\u0026amp;State)-\u0026gt;WasOriginalArgFloat(ValNo)) { LocVT = MVT::i64; if (ArgFlags.isSExt()) LocInfo = CCValAssign::SExt; else if (ArgFlags.isZExt()) LocInfo = CCValAssign::ZExt; else LocInfo = CCValAssign::AExt; } } if (static_cast\u0026lt;const MipsSubtarget\u0026amp;\u0026gt;(State.getMachineFunction().getSubtarget()).useSoftFloat()) { if (LocVT == MVT::i32) { if (!CC_MipsN_SoftFloat(ValNo, ValVT, LocVT, LocInfo, ArgFlags, State)) return false; } } if (LocVT == MVT::i64) { static const MCPhysReg RegList1[] = { Mips::A0_64, Mips::A1_64, Mips::A2_64, Mips::A3_64, Mips::T0_64, Mips::T1_64, Mips::T2_64, Mips::T3_64 }; static const MCPhysReg RegList2[] = { Mips::D12_64, Mips::D13_64, Mips::D14_64, Mips::D15_64, Mips::D16_64, Mips::D17_64, Mips::D18_64, Mips::D19_64 }; if (unsigned Reg = State.AllocateReg(RegList1, RegList2)) { State.addLoc(CCValAssign::getReg(ValNo, ValVT, Reg, LocVT, LocInfo)); return false; } } if (LocVT == MVT::f32) { static const MCPhysReg RegList3[] = { Mips::F12, Mips::F13, Mips::F14, Mips::F15, Mips::F16, Mips::F17, Mips::F18, Mips::F19 }; static const MCPhysReg RegList4[] = { Mips::A0_64, Mips::A1_64, Mips::A2_64, Mips::A3_64, Mips::T0_64, Mips::T1_64, Mips::T2_64, Mips::T3_64 }; if (unsigned Reg = State.AllocateReg(RegList3, RegList4)) { State.addLoc(CCValAssign::getReg(ValNo, ValVT, Reg, LocVT, LocInfo)); return false; } } if (LocVT == MVT::f64) { static const MCPhysReg RegList5[] = { Mips::D12_64, Mips::D13_64, Mips::D14_64, Mips::D15_64, Mips::D16_64, Mips::D17_64, Mips::D18_64, Mips::D19_64 }; static const MCPhysReg RegList6[] = { Mips::A0_64, Mips::A1_64, Mips::A2_64, Mips::A3_64, Mips::T0_64, Mips::T1_64, Mips::T2_64, Mips::T3_64 }; if (unsigned Reg = State.AllocateReg(RegList5, RegList6)) { State.addLoc(CCValAssign::getReg(ValNo, ValVT, Reg, LocVT, LocInfo)); return false; } } if (LocVT == MVT::f32) { unsigned Offset7 = State.AllocateStack(4, 8); State.addLoc(CCValAssign::getMem(ValNo, ValVT, Offset7, LocVT, LocInfo)); return false; } if (LocVT == MVT::i64 || LocVT == MVT::f64) { unsigned Offset8 = State.AllocateStack(8, 8); State.addLoc(CCValAssign::getMem(ValNo, ValVT, Offset8, LocVT, LocInfo)); return false; } if (LocVT == MVT::iFATPTR64 || LocVT == MVT::iFATPTR128 || LocVT == MVT::iFATPTR256 || LocVT == MVT::iFATPTR512) { static const MCPhysReg RegList9[] = { Mips::C3, Mips::C4, Mips::C5, Mips::C6, Mips::C7, Mips::C8, Mips::C9, Mips::C10 }; if (unsigned Reg = State.AllocateReg(RegList9)) { State.addLoc(CCValAssign::getReg(ValNo, ValVT, Reg, LocVT, LocInfo)); return false; } } if (LocVT == MVT::iFATPTR64 || LocVT == MVT::iFATPTR128 || LocVT == MVT::iFATPTR256 || LocVT == MVT::iFATPTR512) { if (!CC_MipsCheriCapOnStack(ValNo, ValVT, LocVT, LocInfo, ArgFlags, State)) return false; } return true; // CC didn\u0026#39;t match. }    Usage Calling convention is set via setCallingConv().\nCC_CHERI_CCall is called in CC_Mips_FixedArg:\n// llvm/lib/Target/Mips/MipsCallingConv.td  def CC_Mips_FixedArg : CallingConv\u0026lt;[ // Mips16 needs special handling on some functions.  CCIf\u0026lt;\u0026#34;State.getCallingConv() != CallingConv::Fast\u0026#34;, CCIfSpecialCallingConv\u0026lt;\u0026#34;Mips16RetHelperConv\u0026#34;, CCDelegateTo\u0026lt;CC_Mips16RetHelper\u0026gt;\u0026gt;\u0026gt;, CCIf\u0026lt;\u0026#34;State.getCallingConv() == CallingConv::CHERI_CCall\u0026#34;, CCDelegateTo\u0026lt;CC_CHERI_CCall\u0026gt;\u0026gt;, CCIfByVal\u0026lt;CCDelegateTo\u0026lt;CC_Mips_ByVal\u0026gt;\u0026gt;, // f128 needs to be handled similarly to f32 and f64 on hard-float. However,  // f128 is not legal and is lowered to i128 which is further lowered to a pair  // of i64\u0026#39;s.  // This presents us with a problem for the calling convention since hard-float  // still needs to pass them in FPU registers. We therefore resort to a  // pre-analyze (see PreAnalyzeFormalArgsForF128()) step to pass information on  // whether the argument was originally an f128 into the tablegen-erated code.  //  // f128 should only occur for the N64 ABI where long double is 128-bit. On  // N32, long double is equivalent to double.  CCIfType\u0026lt;[i64], CCIfSubtargetNot\u0026lt;\u0026#34;useSoftFloat()\u0026#34;, CCIfOrigArgWasF128\u0026lt;CCBitConvertToType\u0026lt;f64\u0026gt;\u0026gt;\u0026gt;\u0026gt;, CCIfCC\u0026lt;\u0026#34;CallingConv::Fast\u0026#34;, CCDelegateTo\u0026lt;CC_Mips_FastCC\u0026gt;\u0026gt;, CCIfSubtarget\u0026lt;\u0026#34;isABI_O32()\u0026#34;, CCDelegateTo\u0026lt;CC_MipsO32_FP\u0026gt;\u0026gt;, CCDelegateTo\u0026lt;CC_MipsN\u0026gt; ]\u0026gt;;  CC_Mips_FixedArg is called in CC_Mips:\n// llvm/lib/Target/Mips/MipsCallingConv.td  def CC_Mips : CallingConv\u0026lt;[ CCIfVarArg\u0026lt;CCIfArgIsVarArg\u0026lt;CCDelegateTo\u0026lt;CC_Mips_VarArg\u0026gt;\u0026gt;\u0026gt;, CCDelegateTo\u0026lt;CC_Mips_FixedArg\u0026gt; ]\u0026gt;;  Now we have call path: CC_Mips -\u0026gt; CC_Mips_FixedArg -\u0026gt; CC_CHERI_CCall. The generated code is MipsGenCallingConv.inc.\nMipsGenCallingConv.inc is included in\n MipsISelLowering.cpp: calls CC_Mips, CC_Mips_FixedArg, RetCC_Mips; MipsFastISel.cpp: lib/Target/Mips/CMakeLists.txt: tablegen(LLVM MipsGenCallingConv.inc -gen-callingconv)  Since FastISel is not enabled by default, the default implementation of calling convention should be in MipsISelLowering.cpp.\n///////////////////////////////// // Overview of Call paths:  SelectionDAGISel::LowerArguments() // --\u0026gt; MipsCallLowering::lowerFormalArguments() --\u0026gt; MipsTargetLowering::CCAssignFnForCall() --\u0026gt; return CC_Mips_FixedArg; SelectionDAG/{SelectionDAG.cpp/SelectionDAGBuilder.cpp/LegalizeDAG.cpp/LegalizeIntegerType.cpp} --\u0026gt; TargetLowering::LowerCallTo() // return pair\u0026lt;SDValue, SDValue\u0026gt;  --\u0026gt; MipsCallLowering::lowerCall() // return  --\u0026gt; MipsTargetLowering::CCAssignFnForCall() --\u0026gt; return CC_Mips_FixedArg; CCAssignFnForReturn() --\u0026gt; return RetCC_Mips; MipsTargetLowering::LowerCall() --\u0026gt; CCInfo.AnalyzeCallOperands(Outs, CC_Mips, CLI.getArgs(), ES ? ES-\u0026gt;getSymbol() : nullptr); //////////////////////////////// // Implementations:  // CCAssignFnForCall():  //llvm/lib/Target/Mips/MipsISelLowering.cpp  CCAssignFn *MipsTargetLowering::CCAssignFnForCall() const{ return CC_Mips_FixedArg; } // CCAssignFnForReturn():  // LowerCall():  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/",
	"title": "Logics",
	"tags": [],
	"description": "",
	"content": " Top Wonderings  Can all the logic systems be manually re-created in the form of some artificial intellegence tools such as computers?\n Are all the human knowlege representable in some form of logics?\n Can the human capability of finding new knowledge be representable in some form of logics?\n  Reference 1\nA pursuit for the principles of logics, before computers exist.\n Logic, Languages, Compilation, and Verification\n Match 220, Formal Methods, Pepper\n  Code Reasoning Fundamentals  Imagine it\u0026rsquo;s your first internship, and you are asked to write a max() method for an IntList class. You write this code and bring it to your boss. She says, \u0026ldquo;Prove to me that it works.\u0026rdquo; OK\u0026hellip; how do you do that? You could (and surely would) run some tests on sample input, but there\u0026rsquo;s effectively an infinite number of possible IntLists. Tests are useful, but they can\u0026rsquo;t prove that your code works in all possible scenarios.\n This is where reasoning about code comes in.\n Instead of running your code, you step back and read it. You ask:\u0026ldquo;What is guaranteed to be true at this point in the program, based on the statements before it?\u0026rdquo; Or, going in the other direction:\u0026ldquo;If I want to guarantee that some fact Q is ture at this point in the program, what must be true earlier to provide that guarantee?\u0026rdquo; You have surely done some of this naturally. Now you\u0026rsquo;ll learn to do it in a more structured way with techniques to help.\n More  Software Foundations  References: Software Foundations [Video Class, Benjamin C. Pierce]() Video Class2, Micheal Ryan Clarkson @ Cornell Peking, Software foundations Building reliable software is really hard \u0026ndash; really hard. The scale and complexity of modern systems, the number of people involved, and the range of demands placed on them make it challenging to build software that is even more-or-less correct, much less 100% correct. At the same time, the increasing degree to which information processing is woven into every aspect of society greatly amplifies the cost of bugs and insecurities.\n Concrete Semantics  References: Concrete Semantics Imperative language Statement: declaration of fact or claim. e.g. \u0026ldquo;Semantics is easy.\u0026rdquo; 声明/断言：对一个事实或者断言的声明。比如，“语义学是简单的”。 Command：order to do something. e.g. \u0026ldquo;Study the book until you have\n Modern Logic 89  Top Wonderings Formal logic vs informal logic, how can they assist the artificial intelligence/life in general? The representation of the knowledge(model, data, algorithms, problems, etc)? What kind of representations under the hood? Reference 1： 逻辑学从哲学中独立出来的趋势以后便被人们发现是属于数学。因此当把作为数\n FM  Reference: An Overview of Formal Methods Tools and Techniques. Rigorous Software Development: An Introduction to Program Verification. 2011. Survey of Approches for Security Verification of Hardware/Software Systems. Onur Demir, Wenjie Xiong, Faisal Zaghloul, Jakub Szefer. 2016. pdf Wiki: Formal Verification Formal Methods 一文读懂基于SCADE模型的形式化方法 形式化方法是一种用\n Fm in Arch  Q\u0026amp;A How formal methods are used in the architectural design (IC/ASIC/FPGA)? References: Part8: The 2018 Wilson Research Group Functional Verification Study IC/ASIC adoption trends for formal property checking (e.g., model checking), as well as automatic formal applications: formal property checking: Model checking; automatic formal application tools: SoC integration connectivity checking; deadlock detection; X semantic safety checks; coverage reachability analysis; many other properties that can be automatically extracted and then formally proven.\n Tools/Methods  References: More More Kami References Kami: A Platform for High-Level Parametric Hardware Specification and Its Modular Verification Kami: A Framework for (RISC-V)HW Verification Coq Reference: The Coq Proof Assistant Isabelle advantages over Coq: From Benjamin Pierce notion of equality is extensional; it eliminates a lot of low-level tedium in proofs of involves equality. a much better story about variable binding; formalizing sth that involves binding variables.\n Class Logic  Intro Logic 2nd Ph.D. student. (Germany) 6 and 3 and another one on the way. Text book: Statement Logic Predicate Logic Logic is the study of methods for evaluating whether the premises of an argument adequately support its conclusion. An argument is a set of propositions where some of the propositions are intended to support another one in the set. A proposition a truth or falsehood that may or may not be expressed in a sentence.\n Class Math220  References: Match 220, Formal Methods, Stan Warford @ Pepperdine University. State: a list of variables and there values. Textual substitution (x + 2y) [x,y := y,x] is not the same as (x + 2y) [x := y] [y := x] ==\u0026gt; the property of textual substitution. Example: ((a + b) x ) [b:=x] [x:=b] ==\u0026gt; (a + b) b ((a + b) c) [b:=x] [x:=b] ==\u0026gt; (a + b) c \u0026mdash;\u0026gt; Provisal (provided that\u0026hellip;)\n Math Symbols Basic Math Symbols\nSet Symbols Set Symbols\nLogic Symbols Logic Symbols\n reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/class-logic/",
	"title": "Class Logic",
	"tags": [],
	"description": "",
	"content": " Intro Logic\n2nd Ph.D. student. (Germany) 6 and 3 and another one on the way.\nText book:\n Statement Logic Predicate Logic  Logic is the study of methods for evaluating whether the premises of an argument adequately support its conclusion.\nAn argument is a set of propositions where some of the propositions are intended to support another one in the set.\nA proposition a truth or falsehood that may or may not be expressed in a sentence.\nExamples:\n There is a table in a room.\n Em Tisch rst im Zimmer.\n predicate logic: $\\exists x, T x \\wedge R x$\n  True/False def:\n True: a proposition is true it represents things as they are\n False: a proposition is true it represents things as they are not.\n Examples:\n Go sit down! \u0026ndash;\u0026gt; no true/false You are sitting down. \u0026ndash;\u0026gt; can be evaluated to true/false. Evolution happens. \u0026ndash;\u0026gt; Vague propositions: the room is hot. Torthering paper for fun is wrong.   Premises: a proposition in an argument that is intended to support conclusion.\nConlusion: a proposition in a argument that is intended to be supported by the premises.\nDeductive argument: arguments where the premises guarrentte that the coclusion is true.\nInductive argument: arguments where the premises make the conclusion probable.\n P1: most choice in the room is occupied. Conclusion: a chair in the room chosen at random will be occupied.  Vague.\nSep 04, 2019. Deductive arguments.\nValid Valid argument: is valid when it is necessary that if the premises are true then the conclusion must be true.\nInvalid argument: is invalid when it is not necessary that\n(Valid and invalid is specificly used for arguments. Not for statements, etc..)\nModus ponens.\nValid arguments:\n1. If A then B; ( if grass is purple, then the moon is made of cheese) 2. A. (grass is purple) Therefore, 3. B.  Validity: don\u0026rsquo;t care whether the premises are true or not; only care if the premises are true, can we reach the conclusion from the premises.\nInvalid arguments:\n1. If A, then B (if we are in a classroom, then we are having class) 2. B. (we are having class) Therefore, A. (we are in classroom)  Sound Sound argument: is a valid argument with true premises.\nUnsound argument: is invalid argument or valid argument with false premises.\nLogic: study of methods to evaluating arguments.\nArgument form: A pattern of reasoning from premises to a conclusion.\nSubstitution instance: An argument that results from uniformly replacing variables of an argument form with propositions.\n(Statement vs. Propersition. Same propersition can have different statements.)\nFormally Valid: an argument is formally valid when it is valid \u0026hellip; of its form.\nI am a rhino.  Truth-functional operator: An operator that takes propositions as input and the output values depends only on the truth values of the input.\nOperators: if-then; negation;\nConditional: An if-then proposition, it states that the \u0026lsquo;then-part\u0026rsquo; is true if the \u0026lsquo;if-part\u0026rsquo; is true.\nIf True then True; // true statement If True then False; // false statement If F then F; // true statement If F then T; // true statement  if A then B: A is called antecedent; B is called consequent.\nNegation: the negation of proposition states the denial of the negated proposition.\nHow to show an argument form is invalid?\nBy counter example, first substitute.\n1. if A, then not B; (if you study, you won\u0026#39;t fail)/(if we are having an afternoon shower, it is not early morning) 2. not A; (you don\u0026#39;t study)/(we are not having an afternoon shower) Therefore, 3. B. (you will fail)/(it is early morning) next time: truth tables.\nPythagoras /pi\u0026rsquo;θægәræs/ theorem.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/class-pldi/",
	"title": "Class PLDI",
	"tags": [],
	"description": "",
	"content": " Q \u0026amp; A  Does functional programming have object oriented programming style? What is essential part for a domain specific language?  References:\n CSC 2\u0026frasl;454 Programming Language Design and Implementation, by Prof. Micheal Scott  Aug 28. names of PLs\n(IMPERATIVE) C#, C, Swift, Java, Ada, Rust, Pascal, scala, Algol, Go, Obj-C, Fortan, C++, B, PL/I, X,\n(SCRIPTING) Kotlin, Python, Julia, Javascript, PHP, R, Ruby, small talk,\n(FUNC) Lisp, Scheme, ML, Haskell, Erlang,\n(LOGIC) XLST, Prolog, SQL,\nAssembler\nWhy so many?\n Commercial differentiation Diff goals: speed, safety, ease of programming, space, size of compiler,  prob domains  Expressiveness vs. Efficiency vs. Ease of learning Programming preference. Getting better at it over time. backing by sponsors: C#, Kotlin, Go, Swift (Apple), Ada (US defence), Cobol (IBM, US Defence, Greece Mary Hopper?).  What is a PL for ? - means of expressive algorithms. - tell computer hw do what you want. - way of organizing thoughts: func vs imperative. - \u0026mdash;\u0026mdash;- awaying ideas to others. - Knuth: Programming: art of telling another person what you want the computer to do.\nTo verify: Bubble sort n^2; insert sort n;\nInsertion sort:\nimperative:\ninsertion_sort (A) for i in len(A) -2 down to 0 v = A[i] for j in i+1 to len(A) -1 // A[j..len(A) - 1] is sorted if A[j] \u0026gt; v break A[j-1] = a[j] A[j-1] = v  functional lang:\nsort(A): if len(A) \u0026lt; 2 return A; else let v be A[0] + R be A[1..] return insert (v, sort (R)) where insert (v, S): if len(S) == 0 return {v} else let w be S[0] + T be S[1..] if v \u0026lt;w return v, S else return w.insert(v,T)  Rules Read book before class\nInitial assignment\nGet book.\nRead chapter 1.\nCSUG account.\nGo to blackboard to take T0.\nCheckout A(1) on the web.\nin C: 275 chars Compiler:\nInterpreter:\nJava \u0026ndash; bit code \u0026mdash; can be interpreted (early state); or be JIT compiled to binary executable (modern ways).\nX86 processor: interpreter inside. for slow instructions. old instructions?\nFront end. Interpreter as an example: AST trees + symbol table ~= intepreters. Walk through AST and execute it with symbol table storing the data.\nCompiler backend:\nCompiler \u0026ldquo;Middle end\u0026rdquo;: 90% of a compiler. Optimization.\nSep 04, 2019 Overview of Compilation Bootstrap: write compiler of C using C lang; originally used by Pascal, x86.\n Tiny subset of lang. compiler in C. Rewrite the compiler in new language. Add features using tiny subset of lang. \u0026ndash;\u0026gt; efficiency?  Output of langs:\nJava language -\u0026gt; web pages -\u0026gt; java byte code, small size. WebAssembly.\nLatex -\u0026gt; pdf. VLSI -\u0026gt; circuits.\nCompiler vs Interpreter.\nWhat is hard about compilers?\nDynamic typing, even if strong typing. (strongly typed =~ type safe)\n saving the time of proving the type to compilers. easier to program quickly without the need for programmers to type setting everything. Late binding. Python: strongly typed. Check types while it is running.  Phases of Compilation:\nFront END: (program chars) -\u0026gt; scanner -\u0026gt; (tokens) -\u0026gt; parsing -\u0026gt; (parse tree) -\u0026gt; semantic analysis (static) -\u0026gt; (abstract syntax tree, or syntax tree) -\u0026gt; intermediate language generation -\u0026gt; (Intermediate form, IF) Middle: (IF) -\u0026gt; Optimization (IF) Back END: (IF) -\u0026gt; target code generation -\u0026gt; (**tive lang) -\u0026gt; native speficfic opt. -\u0026gt; (native code).\nTheory: Regular experssion, context-free grammar, and everything else.\n Regular expression is generator of reg language; Scanner is recognizer for reg language (valid tokens).\n CFG is generator of CFL; Parser is recongnizer.\n  Parser vs semantic analyzer.\nSyntax: grammar in context-free languages. Linguist: John Roundski? language hierachy.\nSemantic analysis: everything else?\nSLR(1) grammar, not LL(1) grammar.\nSep 09 Scanning.\nTurning Machine Automata\nScanners to recognize tokens by regular expressions.\nStephen Kleene; U of Wisc; Mathcn; Recursion theory; Kleene star (Kleene closure). Church-Turning Theory: computability.  Scanner generators:\n write REs by hand build NFA from REs build DFA from NFA minimize DFA add extra logic for  \u0026hellip;   Sep 11 Production: LHS -\u0026gt; RHS\n\u0026lsquo;Derivation\u0026rsquo;: proof of syntactic correctness.\nright-most derivation = canonical derivation.\nCan parse anything in O(n^3) time; need to parse in O(n) time:\n LR family: left-to-right, rightmost derivation; ==\u0026gt; bottom-up pasing (parse tree); shift-reduce;  Cannot match any rules; parse error; Cannot find RHS expansions for a token; predictive error;  LL family: left-to-right, leftmost derivation; ==\u0026gt; top-down parsing (parse tree); predictive, LL(1) with 1 token next examined to determine matchings; (RR/RL: read from end of file to start (not used).)  both LR/LL are PDA. push down automata; forest and trees; shift in tokens, build tree, and combine trees ;\nSLR; SALR; (full) LR\nRecursive decent vs. Table-driven topdown parsing:\n Recursive decent. handwritten; ANTLR;\n Table-driven. FMQ.\n  Program parsing:\n match (expected_token) subrountine for each non-terminal.  Syntax tree: associativity and precedence.\n1 program -\u0026gt; stmt_list $$ 2 stmt_list -\u0026gt; stmt_list stmt | E 3 stmt -\u0026gt; ID := expr | READ ID | WRITE expr 4 expr -\u0026gt; term | expr add_op term 5 term -\u0026gt; factor | term mult_op factor 6 factor -\u0026gt; ( expr ) | ID | LITERAL 7 add_op -\u0026gt; + | - 8 mult_op -\u0026gt; * | /  Sep 16 LL Parser Generators EPS (a) = {true, false}\nFIRST(a) = { t: t can start a };\nFOLLOW(A) = { t: t can follow A in some sent. form };\nPREDICT (A-\u0026gt;a) = { t: t $\\in$ FIRST(a) , or t $\\in$ FOLLOW(A) if EPS(A)==true, or EPS if EPS(A) = false }\n Compute first + EPS for non-terminals; Compute follow sets for non-terminals; this requires first sets for some strings; Compute PREDICT sets for productions; this requires EPS for some strings; Predict(A-\u0026gt;$\\alpha$) = FIRST ($\\alpha$) $\\cup$ (if EPS($\\alpha$) then FOLLOW(A) else $\\phi$);  Error detection Wirths algorithm\nfor syntax error recovery:\n match does insertions. match()); RD (recursive descent) routine  Context-aware \u0026lsquo;smart\u0026rsquo; paser: context-specific follow set: local follow set in addition to global follow set.\nTable driven LL Parsing Recursive descent\nstack of table-driven top-down parser contains the expected future program. \u0026lsquo;stack contains the future\u0026rsquo;\ntable:\nstack: (top on left) P ; -\u0026gt; SL $$; -\u0026gt; S SL $$; -\u0026gt; read id SL $$; -\u0026gt; SL $$; -\u0026gt; S SL $$; -\u0026gt; read id SL $$; -\u0026gt; S SL $$; -\u0026gt; id := E SL $$\ninput: read A read B sum:= \u0026hellip;\nSep 18 Semantic analysis:\n check static semantics build AST  Attribute Grammar attribute grammars (AG): labels on nodes;\nrelationships between nodes;\n AGs work on trees \u0026ndash; like parse trees or syntax trees. They assume that some nodes start out with interesting annotations: e.g., textual values of tokens for identifiers, strings, and numbers; built-in names and other \u0026ldquo;environmental\u0026rdquo; information in a table attached to the root (program) node. The AG then says how the annotations on other nodes depend on those of their children and/or parents. In a well-formed grammar, if you apply all the rules, you can decorate the entire tree.\n EG: arch info on root node\nEG: use attribute to describe how parser will build parse tree while parsing.\nEG: use attribute to describe\nAST_node expr() case input_token of id, literal, (: T := term() return term_tail(T) else: error AST_node term_tail(T1) case input_token of +,-: op:=addop() T2:= term() N := new node(op, T1, T2) return term_tail(N) ), id, read, write, $$: return T1 else error  EG: bottom-up grammar: Below grammar is bottom up. All attributes are \u0026ldquo;synthesized\u0026rdquo; \u0026ndash; they depend only on things below them in the tree.\nIt annotates the root of the parse tree with the value of the overall expression.\nE =\u0026gt; E + T E1.n = new bin_op(+, E2.n, T.n) // .n -\u0026gt; .node E =\u0026gt; E - T E1.n = new bin_op(-, E2.n, T.n) E =\u0026gt; T E.n = T.n T =\u0026gt; T * F T1.n = new bin_op(*, T2.n, F.n) T =\u0026gt; T / F T1.n = new bin_op(/, T2.n, F.n) T =\u0026gt; F T.n = F.n F =\u0026gt; - F F1.n = new un_op(-, F2.n) F =\u0026gt; (E) F.n = E.n F =\u0026gt; const F.n = new num(const.val) F =\u0026gt; id F.n = new ident(id.name)  \u0026lt;\u0026lt; show how this handles, for example, (a + 1) * b \u0026gt;\u0026gt;\nAction Routines Action Routines (AR)\n If you can decorate an entire parse tree in one pass while parsing (that\u0026rsquo;s a big \u0026ldquo;if\u0026rdquo;), then the AG can be written in the form of ACTION ROUTINES \u0026ndash; code fragments embedded in the RHSs of productions, with references to the \u0026ldquo;attributes\u0026rdquo; of the symbols in the current production. In this case you can actually get away with not building the parse tree explicitly \u0026ndash; you just deal with the local neighborhood while parsing.\nIn principle, you can do all semantic analysis by decorating the parse tree (maybe while parsing; more likely in a separate pass [which would require that you actually build the parse tree]). It\u0026rsquo;s typically a lot easier, though, to write an AG for the parse tree that serves only to build an AST \u0026ndash; to tag the root with a pointer to an AST. Construction of the AST can almost always be done with ARs (during parsing), allowing us to skip actual construction of a parse tree. Then we can use another AG to decorate the AST.\n Attribute rules:\nEG: attribute grammars on parse tree, to generate AST finally.\n.n and .st are attributes. Uses n again, but also st, which is \u0026ldquo;inherited\u0026rdquo; \u0026ndash; doesn\u0026rsquo;t depend only on things below. This st attribute serves the role of the left operand passed into term_tail in the example above.\nE =\u0026gt; T TT E.n = TT.n TT.st = T.n TT1 =\u0026gt; + T TT2 TT1.n = TT2.n TT2.st = new bin_op(+, TT1.st, T.n) TT =\u0026gt; - T TT TT1.n = TT2.n TT2.st = new bin_op(-, TT1.st, T.n) TT =\u0026gt; TT.n = TT.st T =\u0026gt; F FT T.n = FT.n FT.st = F.n FT =\u0026gt; * F FT FT1.n = FT2.n FT2.st = new bin_op(*, FT1.st, F.n) FT =\u0026gt; / F FT FT1.n = FT2.n FT2.st = new bin_op(/, FT1.st, F.n) FT =\u0026gt; FT.n = FT.st F =\u0026gt; - F F1.n = new un_op(-, F2.n) F =\u0026gt; ( E ) F.n = E.n F =\u0026gt; const F.n = new num(const.val) F =\u0026gt; id F.n = new ident(id.name)  Sep 23 Semantic analysis.\nType checking.\nDynamic type checking. Java array bounds. a = B[f(x)]\nRuntime optmization. can only do when it can prove it is safe.\n Alias analysis: x := 5; y:= 4 ; a:=x; (whether to keep x in register depends on whether x or y alias.) Escape analysis: Ocaml can return local variables. Unlimited ???. Different version of compile code.  loop nest optimization.   Definite Assignment: (Java, C#): machemism to check uninit vars. If anyone of paths has potential (does not reason about actual condition values) to use an uninit var, then compile would fail.\nSanity check on byte code. make sure come from authorized compilers.\nAttibute grammars Rules for annotating a tree, e.g. the AST.\nEG: Typing rules:\na := b + c\nRule1: :={stat} = if L{type} = R{type} then OK else error;\nRule2: +{t} = if L{type} == int and R{type} == int then int; else if Lt,Rt \\in {int, float} then fp; else error.\nAttribute flow:\n Bottom up: S-attributed: synthesized attribute only.\n A-\u0026gt;BCD: B-\u0026gt;A, C-\u0026gt;A, D-\u0026gt;A;  Top-down \u0026amp; Left-right: DFS L-R while parsing. L-attributed. More general:\n A-\u0026gt; BCD: B-\u0026gt;C, B-\u0026gt;D, C-\u0026gt;D, B-\u0026gt;A, C-\u0026gt;A, D-\u0026gt;A;   attri for syntax tree Given a AST, and attribute rules.\nAttribute rules: define the labels/relationships/attributes-propagations of nodes/neiboughhood.\nFormal verified compiler. Attribute grammars. DoD set. hundreds of code. Automatically generated. grammars.\nFloat int cast: user-kernel cast?\nP -\u0026gt; I int dec: I real dec: I read: I write: I assign: I -\u0026gt; id E I '+': E -\u0026gt; E E  Enforce rules in local neighbourhoods of a parse or syntax tree.\nEG: A + B:\n look up A/B in symtable, update with types.  Dont need a parse tree if you have other place to store atributes of active productions\n local var in rec descent. Inherit \u0026ndash; pass as parameter (vs Synthesized \u0026ndash; return value) attri stack in table driven parser. Stack  Action routines.\nSep 25 Function Programming lambda calculus 1930s Church\nLisp ~1960 McCarthy\nML Milner - OCaml, by INRIA of French - SML, - Miranda, \u0026ndash; Haskell.\nRecursion instead of loops.\ngcd(a,b) = a, if a=b gcd(a-b, a), if a\u0026gt;b gcd(a, b-a), if b\u0026gt;a\n -- Euclid algorithm.  let rec gcd a b = if a = b then a else if a \u0026gt; b then gcd (a-b) b else gcd a (b-a) if-then-else: whole expression has a value. Everyone have an else; or return assumed to return nothing on else if no else in some language.\nTail recursive call: Tail recursion equal to loop iterations. Return value at tail.\nBut not all recursion can be converted to loop iteration.\nAssembly implementation of tail recursion is a loop:\n gcd(a, b) { top: if a == b return a elsif a \u0026gt; b a := a - b goto top else b := b - a goto top }  Make a non-tail recursive call into a tail recursive.\ncontinuation passing style: avoid all returns. compiler need to determine when to pass the function body.\nlet rec sum1 f low high = if low = high then f low else (f low) + (sum1 f (low + 1) high);; // changed to let rec sum2 f low high st = if low = high then st + (f low) else sum2 f (low + 1) high (st + (f low));; To get rid of the extra parameter st, defining a helper func:\nlet sum3 f low high = let rec helper low st = let new_st = st + (f low) in if low = high then new_st else helper (low + 1) new_st in helper low 0;; let a = 3 and b = 5 in expr.\nEG:\nlet rec f = .. g .. and rec g = .. f .. in expr lambda exporession: first class functions: can pass, can return,\nFibonacci Num:\nlet rec fib n = match n with | 0 -\u0026gt; 1 | 1 -\u0026gt; 1 | _ -\u0026gt; fib (n-1) + fib(n-2) // tail rec version: let fib2 n = let rec helper f1 f2 i = if i = n then f2 else helper f2 (f1 + f2) (i + 1) in helper 0 1 0;; A constant time fib(n) \u0026lsquo;algorithm\u0026rsquo;:\nF(n) = nearest whole number to ($\\phi ^ n$)/(\\squa {5}), where $\\phi = (1 + \\squa{5})/(2)$  What is func program? Requires\n recursion first class functions  Higher-order function: func takes func as parameter.  polymorphism list aggregates structural returns garbage collection: too many temprary stuff under the scenes  Lisp:\n homoiconography self-definition read-eval-print (interactive interpreter)  ML:\n Milner type inference: Ocaml is statically typed; Milner: never use two things in non-compatible ways.  EG: polymorphism: the type of function len is polymorphism:\nlet rec len l = match l with | [] -\u0026gt; 0 | [_] -\u0026gt; 1 | hd::tl -\u0026gt; 1 + len tl;; \u0026gt; _: len = `a list -\u0026gt; int \u0026lt;func\u0026gt; Sep 30 Ocaml REPL\n#load \u0026ldquo;str.cma\u0026rdquo;\n3+4 -: 7: int\n#use \u0026ldquo;prog.ml\u0026rdquo;\ntypes in ocaml:  bool, int, float, strings tuples lists: [1;2;6;4], []  Equality:  structural eq. (deep eq.) = \u0026lt;\u0026gt;  act the same. expensive; traversal entire tree; not for functions; 2 = 2; \u0026ldquo;foo\u0026rdquo; = \u0026ldquo;foo\u0026rdquo;  physical eq. (shallow eq.) == !=  is this the same object? cheap: comparing the pointers of tree root. ok for functions; 2 == 2; (a = \u0026ldquo;foo\u0026rdquo;) != (b = \u0026ldquo;foo\u0026rdquo;);   Ordering: \u0026lt; \u0026gt; \u0026lt;= \u0026gt;= work on everything except functions.\nOcaml: * comment *, inherited from Pascal.\n$\\lambda$ notation: let f = func a1 a2 a3 -\u0026gt; \u0026hellip;\npattern matching match expr with | var -\u0026gt; | var2 -\u0026gt; | _ -\u0026gt;\narrays let primes5 = [| 2; 3; 5; 7; 11 |];;\nprimes5.(2) =\u0026gt; 5\nprimes5.(2) \u0026lt;- 1234 * assignment *\nrecords g = {};;\nvariants type \u0026lsquo;a bin_tree = | Empty | Node of \u0026lsquo;a * \u0026lsquo;a bin_tree * \u0026lsquo;a bin_tree;;\ntype \u0026lsquo;a option = | None | Some \u0026lsquo;a\nExceptions try expr1 with Foo -\u0026gt; expr2\nDFA simulation on textbook \u0026ndash; important High order functions map (fun x-\u0026gt; x*x)[2;3;5;7] =\u0026gt; [4;9;25;49]\nmap: (a -\u0026gt;a) -\u0026gt; a list -\u0026gt;a list\ncompose f g x = f (g x);;\nlet h = compose f g;; // Currying: apply partial parameter of functions and later apply of rest parameters. (compose hd tl) [1;2;3] = hd (tl [1;2;3]) = 2\n(*) 2 3 =\u0026gt; 6\nfold_left (*) 1 [2;3;4;5;7]\nlet rec fold_left f i l = match l with | [] -\u0026gt; i | h::t -\u0026gt; fold_left f (f i h) t;;\nCurrying: if func has 3 parameters, then only 2 are given; a new function will be returned which takes only 1 parameter, which is the third parameter in original function.\nPowerful exmples:\nlet total_all = map total;;\ntotal_all [[1;2;3;4;5]; [2;4;6;7;20]; [4;5;3;6;0] ];;\n ==\u0026gt; [15;]  unlimited extent let plusn n = func k -\u0026gt; n + k;;\nn has unlimited extent\nOct 02 Currying: ( + ) : int -\u0026gt; int -\u0026gt; int\nint -\u0026gt; (int -\u0026gt; int): given one int, it returns a function that is (int -\u0026gt; int)  let f x y = if y then x else 0;\nf (g a) b\nif g a is very expensive and b is false: passing function around without evaluating the function.\nNormal-order evaluation: passing unevaluated. Haskell. non-strict language.\napplicative-order evaluation: passing evaluated. Ocaml, Java, C/C++; strict language.\nChurch-Rosser thereom: if application-order work, then normal order will work;\n infinite list: lazy evaluation, an optimized version of normal-order evaluation.  type a stream = Cons ofa * (unit -\u0026gt; `a stream);;\nlet hd: a stream -\u0026gt;a = function | Cons(h,_) -\u0026gt; h;;\nlet tail: a stream -\u0026gt;a stream = function | Cons(_, t) -\u0026gt; t();;\nLazy evaluation can incurr \u0026lsquo;wrong\u0026rsquo; or different result compared with non-lazy evaluation: Imperative side-effects in a Functional style language: lazy computed once and store it for use in future, but imperative statement could change original compuation parameters and invalide the previous results. (Haskell has no such side effects); Ocaml allows lazy by lazy library.\nName, Scope, Binding Scope of a binding is a region of the program in which the binding is active.\nRegion can be:\n textual region: static scoping \u0026ndash; most lang; (different concept with typing).\n temporal region: dynamic scoping \u0026ndash; early Lisp, tcl, shell script language (what variable depends on where and who calls it, like bash env variable)\n  Scope:\nfunc() { int a; int b; // b scope starts in C; but starts block start in C# }\nBinding: name vs the things it names.\ncreation/destroy of object/bindings. deactive/reactive of bindings.\nelaboration of declaration.\nreference environment of an stmt or expr = set of active bindings.\nPassing function A to another function B: whose data, or whose environment we want to use.\nClosest enclosing scope.\nDeclaration vs Definition\n Declaration: names and binding Definition: gives full info needed by compilers to generate code.  .h files: declarations;\n efficient dev. avoid non-delcared recursive calls function p1; p2; function p2; p1  Oct 07 Storage management Three main categries of data: static, stack, heap.\nCompiler implements them.\nStatic: lifetime = whole program; e.g.\n static variables; scope is smaller than global (e.g. in C, static only in same file). most code are static allocated; global variables, whose scope is the entire program; constants: strings, others. compiler produced data/tables: e.g.  symbol stable (type of variables,etc); exceptions (table of entries);   Stack: lifetime = single function; e.g.\n local variables; argument; return value; return address; saved registers other bookkeeping info  Stack figure:\n---------------------------------------- || || | | || || || | | || ----------------------------------------  frame, as known as \u0026lsquo;activation record\u0026rsquo;\nframe pointer, compiler use this to find contents in the frame (e.g. arguments)\nbookkeeping info: e.g old frame pointers; return address;\nstack pointer, top of stack. last used words or first unused words. - Used for compute arguments address in a frame. - Because size of locals ad temps can be unknown at compile time.\ncalling sequence: Usually determined by ISA vendors, including HW features \u0026amp; conventions.\nE.g push instructions in ISA: change stack pointer + do stores. E.g caller and callee saved registers. E.g. stack conventions: if compilers obey the convention: different code generated from different languages \u0026amp; different compilers can call each other.\nTwo reasons why static allocated stack frame size is not good:\n ???? not same frame size recursion  Heap: \u0026lsquo;new\u0026rsquo;-ed stuff (or implicit)\nNested subroutines, access local variables of another function\u0026rsquo;s frame. Offset might not be known at compile time(e.g. due to recursion of some routine between);\nSolution: static links: every frame contain a stack link to its enclosing routine\u0026rsquo;s frame.\nSubroutines: OCaml vs C vs C++\n Ocaml: useful such as subtotal C: no subroutines.  Nested scope:\n Compiler sometimes avoid the dynimcally free of stack variables to save time; and reuse them for future nested scope that mutually exists, i.e. will never exists at same time. For example the a b in the following:\n void foo(){ int x; { int a; } { int b; } } frame: --------- a,b x ---------   deep binding\nwhen pass subroutine as an argument, need to remember the argument value when it is created.\nlet foo l k = let rec helper l f i b = match l with | [] -\u0026gt; raise (Failure \u0026#34;list too short\u0026#34;) | h :: t -\u0026gt; if i = k then f h else if (b \u0026amp;\u0026amp; h \u0026lt; 0) then helper t (( + ) h) (i + 1) false else helper t f (i + 1) b in helper l (fun x -\u0026gt; x) 0 true;; This captures the \u0026#34;right\u0026#34; h in foo [1; -3; 2; -4; 5] 4;; ------------ f -----\u0026gt; ? h helper ... helper helper foo ------------ subroutines:\n1st class: pass and return;\n2nd class: can pass cannot return;\n3rd class: no pass no return;\nTo implement 1st class funcs: \u0026ldquo;unlimited extent\u0026rdquo;\nlet g p = p 2; let d() = let x = 3 in ( + ) x;; g (d());; ==\u0026gt; 5 // where to find x?  Oct 09 Today: Dynamic Scope; more on binding rules; lambda expressions; overloading, aliases, etc; Intro to scripting.\nstatic/dynamic scope int a proc first: a = 1 proc second: int a first() a := 2; second(); write(a)  static scope: 1 (use) dynamic scope: 2 (use latest recent name on the stack/association list/)\nToday, most in static scope; but dynamic in few langs:\n shell languages, env variable: setenv TERMCAP vt100; Tcl, TK(part of tcl used in graphic libraries)  Binding rules nested procedures.\ndeep-binding: whenever passed, capture the reference environemt;\nshallow binding:\ndeep/shallow binding can be combined freely with static/dynamic scopes.\nobject closures (of subrountine closures) subrtin closure: (code + ref env)\nobject closures: a static/manual way to pass a subroutine around instead of using nested subroutines.\nsubroutines: bar{ int x; foo{ y = x // this x is said to capture the x from the surrounding context, declared in bar; } }\nLambda expressions What is good to use lambda?\n higher order functions: map, fold, transactional memory: pass a lambda expression into a library: tell it this lambda need to run in a transaction. right click mouse action: a lambda expression is called when you click; a function binding to the event;  \u0026ldquo;capture things\u0026rdquo; in lambda expressions:\nfun x -\u0026gt; x * y // y is captured from surrounding context.\ndef plus x = fun y -\u0026gt; x + y;; def plus3 = plusx 3;; // subroutine closure = |plusx | 3 |; // plus3 5;; // ==\u0026gt; 8 lambda in imperative language: ruby, scala, C#, Java, C++ (Java and C++ does not have unlimited extent).\nIn C++, capture list when define a lambda expression.\nauto plusx (int x) { return [x](int y){return x + y;}; // lambda expression, a function with no name; a body of func; a capture list [x]  //return [\u0026amp;x](int y){return x + y;}; // \u0026amp;x here is not safe. } //... auto plus3 = plusx(3); count \u0026lt;\u0026lt; plus3(5); // ==\u0026gt; 8  C++: capture list\n empty: everything not in para is in capture list; can be captured by value x or by reference \u0026x; but reference in a lambda \u0026amp;x capture list can cause dangling pointer; but safe in Ocaml since \u0026amp;x can be in \u0026lsquo;unlimited extent\u0026rsquo;, and in C++ x is put on the stack;  Aliases More than one name for the same thing.\nint x; void foo(int \u0026amp;y){ count \u0026lt;\u0026lt; x \u0026lt;\u0026lt; y \u0026lt;\u0026lt; x + y ; } foo (\u0026amp;x);  The opposite of aliases: Overloading\nOverloading The same name for more than one thing. (not exactly the same as polymorphism.)\nint a = square(3) float b = square(3.14)\nPolymorphism Things (function or object) that works with multiple types.\nSometimes: Overloading is refered as \u0026ldquo;ad hoc polymorphism\u0026rdquo;; ad hoc means manually created several things then you give them the same name; can be seen as a poor variant of polymorphism.\nAn implict parametric polymorphic function:\nlet len l = match l with | [] -\u0026gt; 0 | h::t -\u0026gt; 1 + len t;; len: `a list -\u0026gt; int  `a is called type parameter, which is a hidden parameter to the function.\nsubtype polymorphism: class t of its derived classes;\n    Info flow: \u0026lsquo;Less than\u0026rsquo; intrinsics for user to use?\n    parametric:\n implict. e.g. Ocaml. Let S = ..... explict. eg. generics. set\u0026lt;string\u0026gt; S.  Scripting languages Motivations:\n A language that can glue together many other programs written in other languages; For extension: photoshop, automate a large amount of small tasks that can be done by big programs; Text processing; Web;  Dynamic typing.\nOct 16 (missed) Midterm review.\nOct 21 Midterm Oct 23  A bit of scripting Chapter 6: control flow  Chapter 1-4, 11, 13\nScripting language The most distinguish feature: Dynamic typing;\nwrite code without declaring variables; good for small programs;\nStatic scoping: looking outward for declarations; but scripting does not have declarations!\nPerl: global unless declared otherwise; $foo = 1; is global by default; local foo; my foo2; are local variable; local foo is using dynamic scope; my foo is using static scope; our foo, the same;\nLLM: dynamic/static typing vs dynamic/static scoping.\nPHP: local unless imported;\nPyhton: local if written; (if you assign to any variable, this variable will be local; if you only read it, its global ??? )\nRuby: foo is local; $foo is global; @foo is instance of a class; @@foo is a class;\nR: foo \u0026lt;\u0026ndash; 3 ; foo \u0026lt;\u0026lt;\u0026ndash; 3;\nPattern Matching regular expression.\ngrep/sed/awk/egrep: extended regular expressions: quantifiers: * + ; exact three instances: {3};\n2 to 5 instance: {2,5} ; {3,}; ^ for begin; $ for end of line; \\;\nadvanced REs: $foo ~=s/ab/cd/g\nCapture grab pieces of string.\n$_ default syntax for matches in perl;\n$_ = \u0026quot;-3.14e5\u0026quot; if (/^[+-]?((\\d+)\\.|(\\d*))\\.(\\d+))(e([+-]?\\d+))?$){ 1 2 3 4 5 6 7 } // ? means optional; [] one char; \\d digits; // use $1, $2, $3, ... for the matching parts  Statements vs expressions Statements: no value; executed for its side effects;\nExpressions: has value;\nf(a+b, g\u0026copy;, d(e,h), h)\nIn which order to evaluate? : first a+b, first h?, first g\u0026copy; ?\nCompiler might reorder the evaluation order to reduce the register pressure.\nWhat if g\u0026copy; can change the behavior of d(e,h)? Language manual does not have specifications on the order; and compiler want freedom to reorder the evaluation order;\n==\u0026gt; therefore, do not write code where g\u0026copy; can influence the behavior of d(e,h); otherwise, it will result in to undefined behavior;\nS = T() + TT();\nCompiler can evaluate TT() first then T() as optimizations;\na + b + c Associativity is considered unsafe (to reorder): overflow/underflow can zero some operands (b is extra large floating point and c is extra small float point, then c can be zero out with no effects to final addition result);\nShort-circuit evaluation One ad-hoc implementation case of Lazy evaluation\u0026rsquo;\nQ: reorder the multiple or conditions: c1 | c2 | c3 | c4 | c5: which one should be evaluated first in order to make faster decision.\nControl flow Seqencing\nSelection\nIteration\nSubroutines\nNon-determisim: order does not matter;\nConcurrency\nSelection if\ncase/switch\n if c1 then if c2 then else ... (which if is this else belongs to) // solution - match the closest ones; - use terminators: end  case/switch:\nfast implementaiton: a dictionary match constance (address) to lambda expressioni (code)\nA dictionary abstract data type; data structure are implementations; which data structures should we use to implement case/switch?\nOct 28 Impl of switch If no match\n C and its desendents: no-op require coverage: ada, etc. (must use otherwise, or enumerate all values in a type) exception: Ocaml, Pascal, \u0026hellip;  For cases with single value:\n// bad decision to have break in switch stmts in C; // most other language don\u0026#39;t have notion of fall through  switch (x) { 3: 5: 7: 9: } // characteristic array: array[0, max-value], each element is empty (if no such case) or stores a pointer (code pointer for that case)  // hash table: compiler knows all the possible hash values --\u0026gt; can pick (a perfect) hash func with no collisions.  // linear search array: arrary of \u0026lt;case, code-ptr\u0026gt;  For cases with ranges: case expr of 1 .. 48: 97 .. 283: 900 .. 1024: 1234 .. 2302: esac // decision tree O(log(n)), no insert/deletion, can do redistribution if not even tree; // or binary search O(log(n)),  Iteration While, repeat .. until, do .. while\nAda: bread to the second/third innerest loop. break B;\nconditionial top: r1:=condition // \u0026gt;=1 inst if !r1 goto continue \u0026lt;body\u0026gt; goto top continue: // improve 01 r1:=condition if r1 goto continue top: \u0026lt;body\u0026gt; r1:=condition if r1 goto top skip: // improve 02 goto test top: \u0026lt;body\u0026gt; test: r1:=condition if !r1 goto top enumeration for (i = first; i\u0026lt;= last; i++){ // body } ==\u0026gt; i = first while (i \u0026lt;= last){ // body  ++i; } // but got complicated in newer C, where for (int i=first;...), the i is local to body. Built in iterators for the language, like\nTrue iterators: Clue, Python, C#\nIterator objects: Java~, C++~,\nlambdas: Ocaml, Ruby, Lisp, ML\nopen Printf;; let show n = printf \u0026#34;%d\\n\u0026#34; n;; let upto lo hi = fun f -\u0026gt; let rec helper i = if i \u0026gt; hi then () else (f i ; helper (i + 1)) in helper lo;; upto 1 10 show;; =\u0026gt; 1 2 3 4 5 6 7 8 9 10 - : unit = ()sum = 0 # =\u0026gt; 0 [ 1, 2, 3 ].each { |i| sum += i } # =\u0026gt; [1, 2, 3] # array itself sum # =\u0026gt; 6 # or sum = 0 for i in [1, 2, 3] do # \u0026#39;do\u0026#39; is optional sum += i end sum True iterators Python, Clue, C#\ndef uptoby(lo, hi, step): while True: if (step \u0026gt; 0 and lo \u0026gt; hi) or (step \u0026lt; 0 and lo \u0026lt; hi): return yield lo lo += step # ignore overflow # call it for i in uptoby(1,10,2): # body Clue put the iterator\u0026rsquo;s stack just at the top of caller\u0026rsquo;s function; if other function called in the body of loop, then the stack frame would just be put on top of the iterator\u0026rsquo;s stack frame; However, this violates the calling convention defined by the ISA vendor that is used by other languages.\npositive and negative step condition can be hard to figure out whether \u0026lt;= or \u0026gt;= if the sign of step is not known statically.\n figure out how many time going to iterate. use the counters instead. Architectural instructions for if c-- \u0026gt; 0 goto top.  Oct 30 Today:\niterator objects;\ntype system.\nIterators in Java:\nList\u0026lt;foo\u0026gt; myList= ...; for (foo o: mylist){ // use o } ==\u0026gt; a syntax sugar of underlying: for (Iterator\u0026lt;foo\u0026gt; i = myList.iterator(); i.hasNext()){ foo o = i.next(); // use o } ==\u0026gt; for a iterator, must have three functions: iterator(), hasNext(), next(); (LLM: will we have buffer overflows in these data structures, i.e. iterators? Or can buffer overflows elsewhere can change the behavior of iterators? How?)\nin C++:\nlist\u0026lt;foo\u0026gt; my_list; ... for (list\u0026lt;foo\u0026gt;:: const_iterator i = my_list, begin(); i != my_list.end(); i++){ // use i } // iterator =~ (smart) pointer // .end() is a pointer that has just passed the last element.  in C#\nforeach(foo o in myList){ // use o } ==\u0026gt; for (IEnumerator\u0026lt;foo\u0026gt;i = myList.GetEnumerator(); i.moveNext();){ foo o = i.Current; // accessor  // use o } // The interface implemented as  class List : IEnumerable { ... public IEnumerator GetEnumerator() { node n = head; while (n != null) { yield return n.content; n = n.next; } // NB: no return stmt  } } // ==\u0026gt; the compiler define IEnumerator class as a special calss; in facing of this and `yield return` statement inside; the compiler will automatically create // - the new version of .GetEnumerator() // - the .MoveNext(); // - the .Current // // iterator stored on heap? implicit iterator object.  Type System What is a type?\n one way: primi. type or a combinational of simpler type \u0026ndash; structural approach (ML, ) another way: set of values \u0026ndash; denotational approach(mathimatical way defining domains; ) third way: set of methods \u0026ndash; object oriented approach. fourth: organization/interpretation of bit streams \u0026ndash; implementations perspective  What are types for?\nAssembly does not have types. BCPL (before C), untyped. Can do anything on any bit streams.\n Error checking; Complexity hinding (abstraction); Inference based on context;  Type check:\ntype of \u0026lsquo;Prime\u0026rsquo;: assigned a value, make sure it is a prime number; ==\u0026gt; can be expensive.\nType System Contain three things:\n type equivalence: what type is everything? What contains in a type? type compatibility: when can a value of type A be used in a context that expects type B? Directional. Coercion (implicit convert one type to another); compiler will call built-in to convert data type (a:=float(b)) and then choose proper instructions (fadd, add) type inference - what is the type of the expression.  Unification in type inference and in general Ada: does not have Coercion /kouezshen/; safe is more important.\nLLM: capkernel\ndifferent types in capkernel does not have expression. a mixed op of differnt types.\ndata of different types in an expression? what we should do in capkernel?\ncode of differnt types in an expression? what we should do in capkernel?\ncode and data in differnt types in an expression: error;\nccall \u0026ndash;\u0026gt; a cast from one type to another type? No. code and data changed to another set;\nif x then e1 else e2 e1: 'a * int e2: char list * b ==\u0026gt; expression inferred as \u0026lt;char, int\u0026gt;  Unification in aritificial intelligence.\nProglog: unification.\nC++: template. Turing complete by statically compiling: can do any computation.\ne.g. Prime x.\nType equivalence Structural equivalence:\n substructures all same; problem: can be too coarse; ftemp = 32; ctemp = 0; ftemp == ctemp?  Name equivalence:\n every lexical decloration regarded as name.  Nov 04 Type Systems\nPolymorphism\nTypes (continued)  equivalence compatibility inference  Structural vs. Name equivalence\ne.g.\nstruct{ age: integer name: string } college; person;\nstructural equ: college type is the same as person type; but name equ does not.\ntype temp = integer; // alias type; whether it introduce new type depends on the language. Yes or no or your choice (in Ada; type temp = new integer;)\nvar A: temp;\nvar B: integer;\nconversion/coercion/cast\n conversion: safe\n coercion: safe, implicit converstion\n cast: language impl. dependent; bit there, and pretend as a certain type.\n  Union { t1 a; t2 b; }\nd = (double)n\nstatic_cast (x)\ndynamic_cast (x): cast a parent ptr to child\nreinterpret_cast  (x) : the real cast.\nconst_cast(x): remove the const qualifier; after can change the x.\nPolymorphism Subtype: parent code works for child.\nParametric: type of parameter can be viable.\n like length(\u0026lt;list of type x\u0026gt;), implicit in C++, explicit: class list \u0026lt;T\u0026gt; { };\ntemplate \u0026lt;class T\u0026gt; class stack { T[100] contents; int tos = 0; // first unused location public: T pop(); void push(T); ... } ... stack\u0026lt;double\u0026gt; S;   can also be:\n class stack { void*[100] contents; int tos = 0; public: void* pop(); void push(void *); ... }  but will lose type checking (use cast all over the place, not type safe in C++)\nImplementation C#: reification.\nstack S;\nstack R; // compiler will generate code using pointers the store a \u0026lsquo;Person\u0026rsquo; record;\nstack Q; // compiler will probably reuse same code by just changing pointer values.\nin C# struct and class are different; struct on stack; class objects on heap;\nJava: erasure\nin Java: struct and class objects/instance are all on the heap.\nJVM does not have to know whether you are using generics or not; (avoid JVM changes when introducing generics (since v5));\nJava compiler will give JVM the void * version, with all static checked safe properties, and also all run-time checked safe properties shipped with the bitcode.\nin both C# and Java: compiler type-checked generic.\nC++: no type check in generic; but elobration-time instantiation; very powerful. (turing complete template). but ugly error message (content timing); C++20 \u0026ldquo;concepts\u0026rdquo;\nWhen do instantiation, like stack R, the compiler will plug the type Person into the code and compiler it; report erros if compilation fail.\nPrime n;\nC++20 \u0026ldquo;concepts\u0026rdquo;\nJava/C# use Interfaces to check generic types:\npublic static \u0026lt;T implements Comparable\u0026lt;T\u0026gt;\u0026gt; void sort(T A[]) { ... if (A[i].compareTo(A[j]) \u0026gt;= 0) ... ... } ... Integer[] myArray = new Integer[50]; ... sort(myArray); Conformance (subtype polymorphism) interface Comparator\u0026lt;T\u0026gt; { public Boolean ordered(T a, T b); } class Sorter\u0026lt;T\u0026gt; { Comparator\u0026lt;T\u0026gt; comp; public Sorter(Comparator\u0026lt;T\u0026gt; c) { // constructor  comp = c; } public void sort(T A[]) { ... if (comp.ordered(A[i], A[j])) ... ... } } class IntComp implements Comparator\u0026lt;Integer\u0026gt; { public Boolean ordered(Integer a, Integer b) { return a \u0026lt; b; } } Sorter\u0026lt;Integer\u0026gt; s = new Sorter\u0026lt;Integer\u0026gt;(new IntComp()); s.sort(myArray); Nov 06 Heat and power for single core processors.\nHuman brain\u0026rsquo;s efficiency: pattern matching.\nMulticores (since 2004).\nMore and more specialization. GPU, compression/decompression engine (chips), encryption/decryption, multi-media engine (radio signals).\nAmdahl\u0026rsquo;s Law Amdahl\u0026rsquo;s Law: GENE. is a law. (csci 258). limit of the making your program faster. optimization part.\nProcessor vs Cores\nProcessor: one socket.\nCore: one core with multiple HW threads \u0026ndash; \u0026ldquo;hyperthread\u0026rdquo;\nruntime app: program with language threads. More language threads than the kernel threads serving this program. \u0026ndash; Scheduler 01 (this class)\nOS kernel: kernel threads, process (~= address space, multiple threads). More kernel threads than hardware hyperthreads. \u0026ndash; Scheduler 02 (256 OS class)\nHW: hyper-threads.\nShared memory and message passing Two programming models for communications between threads.\nshared memory tends to be faster than message passing.\nProblem with shared memory:\nint x = 0;\nT1: x++; // in asm: r1 = x; r1++ ; x = r1\nT2: x++; // in asm: r1 = x; r1++ ; x = r1\nx == ?\nSynchronization: exclude bad interleavings.\n Atomicity:  locks. monitors (abstract from locks) transactions (abstraction of atomicity)  Condition synchronization. Specifiy the order using condition: will not do until something is done.  ?   Four-way world of mechanism\n atomic condition  busy-wait keep asking\nsched sleep/wakeup, such as interrupts.\nA scheduler keeping track of all threads\u0026rsquo; state (which is ready to run).\nA scheduler usually implemented with busy-wait sync; and it can enable application to use either busy-wait or scheduler based sync.\n Interrupt in hardware: keep looking at the external event.  Nov 11 Thread creation\nThread implementation\nData-race free programming\nSpin locks\nConcurrency \u0026ndash; Thread Thread creation:\nstatic set\nco-begin: Algol 68, Occam, SR\n* parallel loops\n iteration. fortan  lanuch-on-elaboration: Ada, SR\nfork(join): Ada, Modula-3, Java, C#, OpenMP.\nimplicit receipt: DP, Lynx, RPC systems. (like a func call, but sends to server for execute)\nearly reply: SR, Lynx. Cf. separated new() and start() in Java.\nA thread in Java ******************************(LLM: a trampoline code? a new calling convention? )\nE.g Java: extends Thread: you implement td.run(), you call td.start()/join(); td.start() will do everything necessary to fork/finish a thread.\n=\u0026gt; Early Return:\n// define it f(){ ... reply(); ... } // call it f();  Lang for parallel Lanuages: Java, C#, Ada, Go\nOpenMP: parallel loops\nlibraries: pthreads, winthreads (on Windows)\nOne researcher? problems if parallel in a lib but not in language.\nRace-free code data races: bad.\nsync races: may be good.\n\u0026ldquo;ordinary data\u0026rdquo; vs. synch data.\nProcessor is designed to provide an \u0026lsquo;illusion\u0026rsquo; that the program/thread are executed at once.\ninitialization example\n// ready == false p = new foo(args) ready = true while (!ready) {} // use *p  x86: store always in order;\nARM: store can out-of-order. ************************\nOne way to solve: Java: volatile (C/C++ atomic): hardware will not do ooo stores.\nAnother way: Sync block.\n==\u0026gt; Data-race free code\nSpin locks Faster than scheduler based locks.\nSL needs something else to be atomic.\nAtomic load/store.\nSL:\n acquire release  RMW: read-modify-write; fetch t $\\phi$\ntest-and-set; compare and swap; or load-linked / store-conditional (ARM);\nswap; fetch-and-add.\ntest and set  acquire: while (tas(L)); // test and set. out of loop until change from false to true.\n release: L = false;\n  Problem: contention.\nmemory ---------------------------- cash cash cash cash cash (privilage cache; a write will kick out any other's cache) p p p p p  Variant: test and test and lock:\n acquire: while (tas(L)) repeat until !L; release: L = false;  Schedulers  coroutines run-until-block threads/ cooperatively-scheduled preemption true parallelism  Coroutines Voluntary yields.\nEvery thread and its coroutines, has its own stack.\nA \u0026lsquo;transfer\u0026rsquo; function: exe from one stack to another.\nTransfer function (a context switch between coroutines):\n save regs in stack; save current sp into current context block; change current pointing to other (the new thread\u0026rsquo;s context block); update sp from new thread\u0026rsquo;s context; pop registers. return;\n// single processor reschedule: t : cb := dequeue(ready_list) transfer(t) yield: enqueue(ready_list, current) reschedule sleep_on(q) enqueue(q, current) reschedule   LLM: === Automatically split sequential program into multi-threads using program analysis??\npreemption not yield by itself, but force one thread to yield. Use timer interrupts (in OS) or signals (in library package) to trigger involuntary yields.\nRequires that we protect the scheduler data structures:\nyield: disable_signals() enqueue(ready_list, current) reschedule re-enable_signals()  Multicore add lock\nDisabling signals doesn\u0026rsquo;t suffice:\nyield: disable_signals() acquire(scheduler_lock) // spin lock enqueue(ready_list, current) reschedule release(scheduler_lock) re-enable_signals() disable_signals() acquire(scheduler_lock) // spin lock if not \u0026lt;desired condition\u0026gt; sleep_on \u0026lt;condition queue\u0026gt; release(scheduler_lock) re-enable_signals()  Nov 13 concurrency Scheduler-based synch\nJava concurrency\nBounded buffer\nSpin lock in C++/C: data race in the lock when doing test and set: must make the operation atomic.\nScheduler based sync mechanisms Semaphores  still widely used in OS, and languages  A special counter: two methods: P, V. originated from two dutch words.\n P, reduce counter / consume credits, sleep on queue. V, add counter / produce credits, wake up.  Example impl:\ntype semaphore = record N : integer -- initialized to something non-negative, the counter. Q : queue of threads procedure P(ref S : semaphore) : // reduce counter disable_signals() acquire(scheduler_lock) if S.N \u0026gt; 0 S.N -:= 1 else sleep_on(S.Q) -- give processor to others release(scheduler_lock) re-enable_signals() procedure V(ref S : semaphore) : // add counter disable_signals() acquire(scheduler_lock) if S.Q is nonempty enqueue(ready_list, dequeue(S.Q)) // wake up one thread in the queue. else S.N +:= 1 release(scheduler_lock) re-enable_signals()  shared buf : array [1..SIZE] of data shared next_full, next_empty : integer := 1 shared mutex : semaphore := 1 shared empty_slots, full_slots : semaphore := SIZE, 0 procedure insert(d : data) : P(empty_slots) P(mutex) buf[next_empty] := d next_empty := next_empty mod SIZE + 1 V(mutex) V(full_slots) function remove returns data : P(full_slots) P(mutex) d : data := buf[next_full] next_full := next_full mod SIZE + 1 V(mutex) V(empty_slots) return d  Monitors  mostly used in languages  1965 - semaphors 1970 - what could be better than semaphors: Monitors.\nCombine the data and lock together; rather than in different places.\nA monitor: Association between the lock and data; a class with its own data and lock.\nTony Hoare.\nEntering queue;\nCondition queues;\nUrgent queue (most language does not use it):\nif !cond wait(Q1) // being put in urgent queue\n// another thread cond = T signal(Q) // wake up urgent queue and run immediately by giving up core by sleep().\n// This can be inefficient: sleep() to give up cores is not necessary: can run on other cores; ==\u0026gt; do double checks\nwhile !cond wait(Q1)\n |  \u0026ndash;Queue \u0026ndash; | Monitor | \u0026ndash;\nJava 2 synchronization // LLM: how the monitor implemented? // class BB { final private int SIZE = 10; private Object[] buf = new Object[SIZE]; private int nextEmpty = 0; private int nextFull = 0; private int fullSlots = 0; synchronized public void insert(Object d) throws InterruptedException { while (fullSlots == SIZE) { wait(); } buf[nextEmpty] = d; nextEmpty = (nextEmpty + 1) % SIZE; ++fullSlots; notifyAll(); // explain why! } synchronized public Object remove() throws InterruptedException { while (fullSlots == 0) { wait(); } Object d = buf[nextFull]; nextFull = (nextFull + 1) % SIZE; --fullSlots; notifyAll(); // explain why! return d; } }  BB solution in Java 2 without using notifyAll is quite a bit harder: class BB { final private int SIZE = 10; private Object[] buf = new Object[SIZE]; private Object producerMutex = new Object(); // waited upon only by producers // protects the following: private int nextEmpty = 0; private int emptySlots = SIZE; private Object consumerMutex = new Object(); // waited upon only by consumers // protects the following: private int nextFull = 0; private int fullSlots = 0; public void insert(Object d) throws InterruptedException { synchronized (producerMutex) { while (emptySlots == 0) { producerMutex.wait(); } --emptySlots; buf[nextEmpty] = d; nextEmpty = (nextEmpty + 1) % SIZE; } synchronized (consumerMutex) { ++fullSlots; consumerMutex.notify(); } } public Object remove() throws InterruptedException { Object d; synchronized (consumerMutex) { while (fullSlots \u0026lt; 0) { consumerMutex.wait(); } --fullSlots; d = buf[nextFull]; nextFull = (nextFull + 1) % SIZE; } synchronized (producerMutex) { ++emptySlots; producerMutex.notify(); } return d; } }  Solution using Java 5 locks is efficient and arguably more elegant:\nFind a clean point that a thread can be kicked to run.\nclass BB { final private int SIZE = 10; private Object[] buf = new Object[SIZE]; private int nextEmpty = 0; private int nextFull = 0; private int fullSlots = 0; Lock l = new ReentrantLock(); // new final Condition emptySlot = l.newCondition(); // new final Condition fullSlot = l.newCondition(); // new public void insert(Object d) throws InterruptedException { l.lock(); // new try { // new while (fullSlots == SIZE) { emptySlot.await(); } buf[nextEmpty] = d; nextEmpty = (nextEmpty + 1) % SIZE; ++fullSlots; fullSlot.signal(); } finally { // new l.unlock(); // new } } public Object remove() throws InterruptedException { l.lock(); try { while (fullSlots == 0) { fullSlot.await(); } Object d = buf[nextFull]; nextFull = (nextFull + 1) % SIZE; --fullSlots; emptySlot.signal(); return d; } finally { l.unlock(); } } }  Nov 18 (Sree) Scalar One to one corresponding to machine types (Still valid in CHERI?)\nIntegers (8/16/32/64/):\n long in C: length depends on OS, (ILP64,LP64, LLP64); 10 years later: 1999 in C99: with type has exact sizes.  Addresses: pointers (next class)\nFloating-point numbers (IEEE 754 std)\n half 16 / single 32-bit / double 64-bit problems in fp machines: can not always be used as real numbers. E.g associativity: (a+b)+c ?= a + (b+c) ===\u0026gt; actually in machine: round(a+b) + c != a + round (b+c)  Multibyte Characters:\n e.g. Unicode, usually 4 bytes. Java, Python3.  Bigints:\n Python: no wrap back. (LLM: How can we add this feature to C?) e.g. Encryption: big prime numbers;  Multiprecision Arithmetic:\n Exact arithmetic with reals must be provided by the language e.g. numbers in Unix bc  Some exotic Scalar Machine types: Decimal Numbers (binary coded decimal)\nComposite Types  Arrays: same type elements (Python list not arrays, diff types); Records: diff types elements; Variants/Unions: diff type elements, but only one valid one time; Bitsets: (Bit field in C); Sets, Types, Dict/Maps;  ? - functions? - classes - objects - tensors\nArrays [] : 3[a] in C. \u0026ndash;\u0026gt; C does not have array impl, but just treated as pointer arithmetics.\n() : matlab\n shall we track the size of arrays?\n multi-dimensions\n  The layout of arrays:\n Z-order curve, and Hilbert Curves ==\u0026gt; image processing: near in memory, near in image.  address calculations:\n row/col major: O(1). array of pointers: deref(a + 1) + 2 \u0026lt;== a[1][2]: expensive. indirect address. Z-curve/Hilbert? more computation, but better locality.  Bounds checking return addr overwritten attack\nDyn arrays malloc\nStrings C: ASCII vs Unicode. UTF-8: 0-127 use a single byte; 128+ use multiple bytes (up to 4).\n problem: indexing is slow (from O(1) to O(n), since length of chars are different).  Java: change Unicode representation to fix bytes length.\nRecords layout rearranged\n in Rust (not in C)  Variants All fields occupy same space\n same space, different names in C: does not track which field name is currently active. Can use additional tags ==\u0026gt; tagged unions. in ML families: do not allow access to union members except in a separate match construct.  Nov 20 (Sandya)  Reference Pointers/Recursive Types  Memeory management\n dangling references memory reclaimation.  address space. Address, Pointers (a language notion of addresses), Reference\nRecursive Type: e.g trees.\nAn exercise in Pointers: int i[10], *pi, **ppi; ** (ppi + 1) ==\u0026gt; seg fault, * (* ppi + 1) ==\u0026gt; value of second element.\nExplit memory Management:\n Tombstones1975: extral level of indirection; modify tombstone when object is reclaimed.  extra gabage, the tombstone.  Locks and Keys. ==\u0026gt; LLM: Hardware types? Cheri extension??? Smartpointers?  Garbage Collection.\n Functional languages: use GC largely because data not on stack. Variants of GC for C/C++: cannot collect all garbage. LLM: CHERI can collect all for C; can we do similarly for C on legacy architectures???\n in general we cannot know what is going to be used in the future since it depends on conditions\n safe approximate: no reference to the object\n need to distinguish pointers and integers\n  Impl. of GC:\n Reference counting Tracing collectors\n mark and sweep collection. stop and copy generational: generations of data.\nStack | Heap | stooges ptrs | objects/blocks |    next time: prologue, epilogue, calling conventions. parameter passing modes: call by value/reference/result/name; var num of arguments.\nNov 25 (missed) Nov 27 Regiter Window: e.g. 32 regs window in 128 physical regs.\nFinish Parameters language\u0026rsquo;s value model vs reference model of variables\npass by\n value/value-result (value model) reference (value model) sharing.  Default Parameters;\nNamed Parameters: print(3, color=red) =\u0026gt; compiler will pass all other parameters.\nVariable # of parameters: printf;\n some compilers will understand printf: can check the types in the constant string.\n if printf(str_var, ...): compiler cannot check for unknown variable strings.\n int printf(...){ while(1){ switch(next % marker): real: float f = next_arg(float); int: int i = ... (int) bool: ... } } // IN Java, C#: variable parameters with known types.    Exceptions nonlocal returns.\nGoodenough paper: a replacement model of exceptions. try/throw/catch.\ntry{ } catch (exception_type1 ex1){ } catch (exception_type2 ex2){ }  Three implementations:\n C++: push handler address when entering a protected block. (OK) a map: addresses to handlers. need to augment linker with a global map. (right way) C: (bad way): setjmp(), longjmp().\nif (!setjmp(\u0026amp;jmpbuf)){ // long jump back here when exception, and setjmp will be pretended to return true. // normal execution // volatile int n; // n++; // will write to memory; otherwise, longjmp will restore old reg values and this will be ignored. // ----\u0026gt;---\u0026gt;---\u0026gt; longjmp(\u0026amp;jmpbuf) =\u0026gt; has to know jumbuf to specify where it jump to. }else{ // exception handler }   Events/Signals External events.\nLegacy way and modern way.\n Modern: Create symatric handler threads during initialization. E.G. Graphic systems. Lambda expression as handler function.\nclass PauseListener implements ActionListener { public void actionPerformed(ActionEvent e) { // do whatever needs doing } } ... JButton pauseButton = new JButton(\u0026#34;pause\u0026#34;); pauseButton.addActionListener(new PauseListener()); // semantically equal to // pauseButton.add(lambda(e){...})  Sequential handlers:\n trampoline main program | '-----------------------------------------\u0026gt; kernel | event signal \u0026lt;-------------' handler trampoline rti | \u0026lt;----------' | '---------\u0026gt;, | ,\u0026lt;------------------------' | // may cause deadlock (priority invertion: handler\u0026gt;main but main holds lock)  Dec 02, 2019 Object Orientation.\n encapsulation inheritance dynamic method binding  Simular: 1979? have all above features.\nObject-based langs:\nJavascript: create new object by saying \u0026ldquo;make something like that\u0026rdquo;\ntype extensions:\nDynamic binding // Java Parent p ; Child c = new Child(); P = c; p.f(); // which version do we get? dynamic binding: child methods. However, in C++: Abstract type vs concrete type. ===\u0026gt; virtual methods.\n// C++ Parent *p; Child c; p = \u0026amp;c; p -\u0026gt; f(); // which version? virtual vs non-virtual ==\u0026gt; abstract vs concrete type.  Visibility Golbals, locals, heap, modules, objects, \u0026hellip;\nPublic.\nPrivate.\nProtected. Slightly diff in C++ vs Java: Java visible to current package.\nHeader files:\n declarations: everything you need to know in order to invoke a class. The interfaces. expanded objects.  Mangling: extra information to encode the types/methods. myclass$#adfdsafsagfhiuhoi not found.\nConstructors/Destructors LLM: Is the heap removable? Heap is not included in the C semantics. why not have everything on stack? a dynamic sized stack at runtime? To remove the heap completely?\nGarbage collection: stop the world and search the memory: can we use this \u0026lsquo;inspection\u0026rsquo; capability to inspect the memory states?\nstd::mutex my_lock { std::lock_guard _(\u0026amp;my_lock); break; return; thrown; // can break out anywhere but the desctructor always be called thanks to my_lock; }  Initialization \u0026amp; Assignment super(a,b,c) in Java;\nvoid Child(\u0026hellip;): parent(\u0026hellip;), member1(a), member2(\u0026hellip;,member1,\u0026hellip;){ // ^ copy constructor go called // ^ will still call empty constructor if empty.\nmember1 = a; // assignment operator got called;  }\n==\u0026gt; Difference:\nfoo b; // initialization to b foo f = b; // assignment to f without initialization\nfoo f, b; // init to both b and f f = b; // assignment.\nVTables Parent vs Child methods, VTable for virtual methods\nA struct with methods:\n------- a vtable for each class ---\u0026gt; Vtable: ------- parent methods ------- parent methods ------- parent methods ------- child methods ------- child methods ------- child methods ------- child methods VTable: ------- virtual method ------- virtual method  Interfaces // Example in text book  Class widget{ interface sortable { } interface graphable{ } } Class named_widget extends widget implement sortable { } Class augmented_widget extends named_widget implements graphable { } // augmented_widget  --------- a pointer --\u0026gt; augmented/widget/vtable --------- --------- --------- // sortable, at distance \u0026#39;offset\u0026#39; from augmented_widget --------- a pointer --\u0026gt; sortable --------- --------- (=offset) --------- --------- // graphable --------- a pointer --\u0026gt; graphable --------- --------- --------- Dec 04 Move constructors C++ constructors and destructors.\nFoo f; // f() //  class{ foo() = delete; // if you do not want default constructor, do this. compiler will check all declarations are not using default constructor. } foo f = g; // f(g); f g same type; copy constructor.??  gg = my_func(f); fun(my_func(f)); void my_func(foo x){ //==\u0026gt; copy constructor is called when passing f by value.  foo t; return t; //==\u0026gt; copy constructor can be called during return;  a,b,c = ...; return foo(a,b,c); //==\u0026gt; this is an object somewhere; manual says this object should be created where this parent func is being called, to avoid a call to copy constructor; impl: a callback pointer to the caller i.e. in `gg=my_func(f)` or in `fun(my_func(f)) ; side effects. }  f(foo(a,b),...)\nf(y, ...)\nfoo: temporary constructor, pass it by copy constructor, destroy old one. ===\u0026gt; waste.\nC++11: move constructor.\nCopy constructor: foo(const foo\u0026amp; other){}\nMove constructor: foo (foo\u0026amp;\u0026amp; other){} // foo\u0026amp;\u0026amp; is r-value reference. move constructor will copy the scalars and pointers to new object, and also nil the pointers in the old temporary object during \u0026lsquo;copying\u0026rsquo;. When destructor of the old temporary object get called, it will do nothing since already a nil, this will save time, since the object on the heap is not freed/re-created.\nLLM: linear capabilities! cannot be copied; caller gives out the capability\nx = y; // l/r value: l value has a location in memory; r value might not have location in memory;  p = \u0026amp;4; // 4 is not an l-value, but an r-value, and it does not have an address so invalid stmt;  E.G.\nstd::move\u0026lt;T\u0026gt;() foo f = ....; A.insert(f); // a copy constructor, f still valid after this line; A.insert(move(f)); // a move constructor, f will be 'moved' and passed to A.insert; and f will not be valid after this line;  Nested classes class widget{ interface sortable{ interface graphable{ class named_widget implements sortable{ // xyz(sortable s) { s.compare(T); }  class augmented_widget implements graphable{ aug/named widget view +++++++++ --\u0026gt; vtable --- widget --plain-- ------------- --------- ------------- --------- --------- +++++++++ --\u0026gt; vtable --- sortable for named_widget - named - -- offset to named_widget, a --------- ------------- --------- +++++++++ --\u0026gt; vtable --- graphable - augm - ------------- --------- ------------- --------- named_widget w; xyz(w); // passed in the sortable view of the object w; i.e. srtable = w + a; inside xyz, will get back to w by srtable - a;  xyz(sortable s){ s.compare(T); // assembly translation:  r1 = this; // this of sortable;  r2 = *r1 ; // get the vtable;  r1 -= *r2 ; // get the this of named_widget; the concrete obj.this  r2 += 3 * wordsize ; // get the method of third  r2 = *r2; call(r2) } class X: public P; class Y: public P; class Z: public X, public Y{ } X P Z Y =\u0026gt; P X Y Z or P Y X Z or P X Z P Y  Default methods in interface allow old classes to be compatible.\ndefalut methods in interface vtable ?\nDec 09 JVM (missed)  Concurrent Langs  Reference 1 Widely used parallel programming systems: Shared Memory Message Passing Distributed Computing Language Java, C# Extension OpenMP Remote Procedure Call Library pthreads, Win32 threads MPI Internet libraries Library augmentation for legacy languages still dominate today. While the library approach requires no changes to the syntax of languages that use it, compilers must refrain from performing optimizations that may introduce races into programs with multiple threads.\n Workshops  Reference: 09/08 Hello world from diff languages: Ada Haskell Ocaml Prolog Scheme \u0026hellip; Interpreter: better error reports: have source code at runtime. 09/22 FIRST(each_rightHS); Follow(LHS); PREDICT(production of each rules) 11\u0026frasl;10 C#/Python/Ruby: iterator permutations. def it(n) for i in 1 .. n yield i Stack push and pop. Hash table.  Ch1  It is not yet clear to what extent, and in what problem domains, we can expect compilers to discover good algorithms for problems stated at a very high level of abstraction. In any domain in which the compiler cannot find a good algorithm, the programmer needs to be able to specify one explicitly. Q/A What distinguishes the front end of a compiler from the back end? What is the purpose of a compiler\u0026rsquo;s symbol table?\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/boxsw/nacl/",
	"title": "Google Native Client Sandboxing",
	"tags": [],
	"description": "",
	"content": " Reference: NaCl1, PNaCl2\nOriginal NaCl Inner sandbox, the NaCl module:\n code section is read-only and statically linked; code section is conceptually divided into fixed sized bundles of 32 bytes. All valid instructions are reachable by a dissassembly starting at a bundle beginning. All indirect control flow instructions are replaced by a multiple-instruction sequence (pseudo-instruction) that ensures target address alignment to a bundle boundary. No instructions or pseudo-instrucitons in the binary crosses a bundle boundary.\n All rules above are checked by a verifier brefore a program is executed. This verifier with the runtime system comprise NaCl\u0026rsquo;s trusted computing base (TCB).\n  Outer sandbox: system call interposition\n mediates system calls at the process boundary; similar to prior stuctures: systrace3 and Janus 4.  Thread model of original NaCl  code for untrusted module: confirms to validity rules, reject otherwise. NaCl module may  execute any reachable instruction block in the validated text segment; \u0026ndash;\u0026gt; weak control flow exercise the NaCl ABI to access runtime servies in any way: passing invalid arguments, etc. send arbitrary data via our intermodule communication interface; allocate memory and spawn threads up to resource limits. ??? how to limit the resource of a sandbox?   (From Chapter 2, page 3) Native Client is ideal for application components requiring pure computation. It is not appropriate for modules requiring process creation, direct file system access, or unrestricted access to the network.\nInterfaces of NaCl to communicate outside of sandbox  Inter-Module Communications (IMC) for general inter-component communication;used by both trusted and untrusted components, such as the trusted JavaScript components, NaCl browser plugin, and untrusted NaCl modules.\n send/receiving datagrams, contains: untyped arrays, along with optional: NaCl Resource Descriptors for sharing of files, shared memory objects, communication channels, etc.  Communicate between Browser and NaCl module:\n Simple RPC facility (SRPC) Netscap Plugin Application Programming Interface (NPAPI) Both based on IMC  \u0026ldquo;service runtime\u0026rdquo; and NaCl module:\n memory management operations; thread creation; other system services. sysbrk(), mmap(), malloc()/free() Analogous to the system call interface of a conventional OS. System call interception.   Attack surface  Inner sandbox: binary validation Outer sandbox: OS system-call interception Service runtime binary module loader Service runtime trampoline interfaces IMC communication interface NPAPI interface  (From 2.3, page 4): In addition to the inner and outer sandbox, the system design also incorporates CPU blacklist and NaCl module blacklist. ==\u0026gt; ??? What is the CPU black-list, NaCl black-lists????\nNaCl dev environment  Linux based GCC 4.2.2  Related work Native Client applies concepts of software isolation and proof-carrying code that have been extensively discussed in the research literature.\n NaCl data integrity scheme is a straightforward application of segmented memory as implemented in the Intel 80386.\n NaCl control flow integrity technique builds on the seminal work by Wahbe, Lucco, Anderson and Graham5. Native Client extends this previous work with specific mechanisms to achieve safety for the x86 ring-3 instruction set archtecture, using several techniques first described by McCamant and Morrisett6.\n NaCl uses a static validator rather than a trusted compiler, similar to validators described for other systems 6 7 8 9, applying the concept of proof-carrying code10.\n  Compare with CFI11:\n CFI: finer-grained control flow integrity. NaCl: only guarantees indirect control flow will target an aligned address in the text; Finer-grained CFI is not useful for Native Client:\n NaCl intends to permit quite arbitrary control flow, even hand-coded assembler, as long as execution remains in known text and targets are aligned.  CFI 15% on SPEC 2000. Three times higher than NaCl 5%.\n XFI 9 add data dandboxing to CFI control flow checks. with additioinal overhead; NaCl get data integrity for free from x86 segments\n  NaCl descriptors similar mechanisms:\n EROS [^55] capabilities. Singularity [^30] channel. DTrace[^11], Systemtap8, XFI9.  Interrupt Handling  Hardware exceptions (segmentation faults, floating point exceptions) and external interrupts are not allowed, due in part to distinct and incompatible exception models in Linux, MacOS and Windows. Both Linux and Windows rely on the x86 stack via %esp for delivery of these events. Regrettably, since NaCl modifies the %ss segment register, the stack appears to be invalid to the operating system, such that it cannot deliver the event and the corresponding process is immediately terminated. The use of x86 segmentation for data sandboxing effectively precludes recovery from these types of exceptions.\n Portable Native Client  Portable NaCl  Portable Native Client 1: control flow and memory integrity with average performance overhead of under 5% on ARM and 7% on x86-64. Introduction About previous SFI on CISC Control+store SFI on x86-32, which we considered excessive, indicates about 25% overhead. \u0026ldquo;As we continued our exploration of ARM SFI and sought to understand ARM behavior relative to x86 behavior, we could not adequately explain the observed performance gap between ARM SFI at under 10% overhead with the overhead on x86-32 in terms of instruction set differences.\n  Native Client: A Sandbox for Portable, Untrusted x86 Native Code. SP 2009. ↩ Adapting Software Fault Isolation to Contemporary CPU Architectures. USENIX SEC, 2010. ↩ N. Provos. Improving host security with system call policies. USENIX Security, 2003. ↩ A secure environment for untrusted helper applications. USENIX Security, 1996. ↩ Efficient software-based fault isolation. By R. Wahbe, S. Lucco, T.E. Anderson, and S.L. Graham. ACM SIGOPS Operating System Review. 1993. ↩ Efficient, verifiable binary sandboxing for a CISC architecture. By S. McCamant and G. Morrisett. MIT-CSAIL-TR-2005-30, 2005. ↩ Evaluating SFI for a CISC architecture. By S. McCamant and G. Morrisett. USENIX Security, 2006. ↩ Locating system problems using dynamic instrumentation. Ottawa Linux Symposium, 2005. ↩ XFI: Software guards for system address spaces. OSDI, 2006. ↩ G. Necula. Proof carrying code. Principles of Programming Languages. 1997. ↩ Control flow integrity: Principles, implementations, and applications. By M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. CCS, 2005. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/stores/ssh/",
	"title": "SSH",
	"tags": [],
	"description": "",
	"content": "References:\n[1]\n"
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/",
	"title": "Cheri ISA Semantic",
	"tags": [],
	"description": "",
	"content": " References:\n[1] ISA Semantics for ARMv8-A, RISC-V, and CHERI-MIPS. POPL, 2019\n[2] CHERI ISA v8, 2020.\nBasics Architecture specifications define the fundamental interface between hardware and software: the envelope of allowd behaviour for processor implementations, and the basic assumtions for software development and verification.\n In practise, they are typically prose and pseudocode documents, not rigorous or executable artifacts, leaving software and verification on shaky ground.  Sail: an ISA semantic language with dependent type system.\n supports automatic generation of emulator code in C and OCaml; automatic generation of proof-assistant definitions for Isabelle, HOL4, and (currently only for MIPS) Coq.  Overview A rigorous semantic models for the sequential behaviour of large parts of mainstream ARMv8-A, RISC-V, and MIPS archtitectures, and the research CHERI-MIPS architecture.\n These architectures are complete enough to boot operating systems, variously Linux, FreeBSD, or seL4.\n ISA semantics defined in Sail.\n Sail definition for validation;\n Sail definition to assess specification coverage.\n Functional correctness proof in Isabelle, for ARMv8-A address translation.\n RMEM tool for (user-mode) relaxed-memory concurrency exploration, of RISC-V model.\n Proof of the soundness of the core Sail type system.\n  CHERI RISCV  Merged register files  Capability encoding mode Questions/Proposals A semantic for os-app interactions?\n POSIX, libc? ABI?  More  Regs   CHERI-MIPS From CHERI ISA v7. 2019. Conventions Specialregs Permissions is required to read special purpose capability registers, but CR3 is not included since it is not a capability register.  Sail Desc  References: CHERI ISAv9 draft, 20221121 Sail is a domain specific imperative language designed for describing processor architectures. Sail in RISC-V instr. descriptions Constant Definitions Constants for 64-bit ISA with 128 bit capability: type xlen : Int = 64 type cap_addr_width : Int = xlen type cap_len_width : Int = cap_addr_width + 1 type cap_size : Int = 16 type cap_mantissa_width : Int = 14 type cap_hperms_width : Int = 12 type cap_uperms_width : Int = 4 type cap_uperms_shift : Int = 15 type cap_flags_width : Int = 1 type cap_otype_width : Int = 18 let cap_max_otype = MAX(cap_otype_width) - reserved_otypes Function Definitions Functions for integer and bit vector manipulation func 1:\n Instructions  MIPS pseudo instructions RISC-V Instructions Instructions dependent on encoding modes More Csc (ISAv7: Ch 7, p240) Format CSC cs, rt, offset(cb) CSCR cs, rt(cb) CSCI cs, offset(cb) Capability register cs is stored at memory location [cb.base + cb.offset + rt + 16 * offset], and the bit in the tag memory associated with this address is set to the value of cs.tag. Capability cb must contain a capability that grants permission to store capabilities.\n Inst Encoding  Q\u0026amp;A Reference 1 ISA instructions MIPS encoding MIPS-IV encoding: MIPS-IV encoding.pdf R4000 Encoding.pdf I-Type (Immediate), 6 (op) + 5r + 5r + 16(i) J-Type (Jump), 6 (op) + 26 (index) R-Type (Register), 6 (op) + 5r + 5r + 5r + 5 (shift) + 6 (func) CHERI MIPS encoding ISAv7 Summary: all three-register-operand, non-memory-accessing CHERI-MIPS instructions using the following encodeing: | Bit | size | value | |\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;-| | 31-26 | 6 | 0x12 | | 25-21 | 5 | 0x00 | | 20-16 | 5 | r1 | | 15-11 | 5 | r2 | | 10-6 | 5 | r3 | | 5-0 | 6 | func |\n CHERIoT  References: OS: https://github.com/Microsoft/cheriot-rtos Sail Model: https://github.com/Microsoft/cheriot-sail RTL: https://github.com/Microsoft/cheriot-ibex Blog: https://msrc-blog.microsoft.com/2022/09/06/whats-the-smallest-variety-of-cheri/ News 202302: https://www.microsoft.com/en-us/research/publication/cheriot-rethinking-security-for-low-cost-embedded-systems/ Whitepaper: https://www.microsoft.com/en-us/research/uploads/prod/2023/02/cheriot-63e11a4f1e629.pdf Overview Smallest CHERI (Portmeirion Project) RISC-V32. C extension required. 15 registers 32-bit address space A signle privilege level: Machine mode only. No virtual memory. Optional PMP. Optional floating point. Based on ibex. Ibex Implementation cite: https://github.com/Microsoft/cheriot-ibex RV32IMCB + CHERI. Either with 2-stage or 3-stage pipeline, configurable.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-tag/",
	"title": "Cheri Tagged Memory",
	"tags": [],
	"description": "",
	"content": " Q \u0026amp; A  How two layers tag cache work? How to update the nodes in the layers?\n How is the tag being set?\n all caps being originated from one cap: the cap covers entire address space. Each new pointer is created via explict capability. Local pointers Pointers to Global Pointers to Heap  How can we propagate the tag?\n  2017 paper:\nTags is cached with the memory they describe within the cache hierarchy.\nSBT: single-bit tag\nMBT: multi-bit tag. 1,2,3,[^2c15],4,5\n\u0026ldquo;We rebuilt the tag controller engine in the open-source CHERI processor (http://www.bericpu.org/), and added perfor- mance counters to the CHERI cache. CHERI is instantiated with 32KiB L1 caches and a 256KiB L2 cache, all 4-way set associative with 128-byte lines. CHERI requires a tag bit for each 256-bit word, resulting in a natural caching amplification factor of 256. Our new tag controller includes a lookup engine backed by a 32KiB 4-way set-associative cache with 128-byte lines, matching the burst size in the CHERI system. Since each cached tag bit covers 256 bits of data memory, each 128- byte line in the tag-table cache provides tags for 32 kilobytes of data memory. We restricted ourselves to a standard cache instantiation for the tag controller which did not allow silent- write elimination so this feature was not evaluated in hardware\u0026rdquo;\nCLoadTags Since ISAv7:\n alpha2: \u0026ldquo;We have added a new experimental CLoadTags instruction that allows tags to be loaded for a cache line without pulling data into the cache.\u0026rdquo;\nalpha3: \u0026ldquo;It is clarified that CLoadTags instruction must provide cache coherency consistent with other load instructions. We recommend “non-temporal” behavior, in which unnecessary cache-line fills are avoided to limit cache pollution during revocation.\u0026rdquo;\n Inspecting Tags ISAv7 Ch6.6.3 instructions that stored a capability will set the tag bit of the stored capability.\nTagged Mem on reset ISAv7 ch3.5.2 : should be cleared on CPU reset.\n\u0026ldquo;We instead rely on firmware or software supervisors to ensure that pages placed into use, especially with untrustworthy code, have been properly cleared\u0026rdquo;\nISAv7 ch4.6: \u0026ldquo;the firmware, hypervisor, or operating system can in principle ensure that tags are cleared on memory before it is exposed to untrustworthy software, in much the same way that they will normally ensure that memory is cleared to prevent data leaks before memory reuse.\u0026rdquo;\nTagged mem on process creation CheriABI6 ch4.3 execve system call.\nLegacy programs: store on initial stack: argument, environment, ELF auxiliary argument arrays; adjust initial stack pointer [^3c16], [^3c47]\nCheriABI process: all pointers are bounded capabilities.\n C run-time altered to take a pointer to the ELF auiliary argument array and extend it to contain pointers to the argument and environment arrays (argv, environ) as well as argument and environment counts (argc, envc), rather than using knowledge of the stack layout and walking off the end of the environment array to find the auxiliary argument vector. after loaded, the address spaces are futhur changed(including dynamic laoding) via system calls.\n// sys/compat/cheriabi/cheriabi_syscalls.c: 68 \t\u0026#34;cheriabi_execve\u0026#34;,\t/* 59 = cheriabi_execve */ // compat/cheriabi/cheriabi_misc.c: 178 int cheriabi_execve(struct thread *td, struct cheriabi_execve_args *uap) { struct image_args eargs; struct vmspace *oldvmspace; int error; error = pre_execve(td, \u0026amp;oldvmspace); if (error != 0) return (error); error = exec_copyin_args(\u0026amp;eargs, uap-\u0026gt;fname, UIO_USERSPACE, uap-\u0026gt;argv, uap-\u0026gt;envv); if (error == 0) error = kern_execve(td, \u0026amp;eargs, NULL); post_execve(td, error, oldvmspace); return (error); }   Pointer provenance  \u0026ldquo;Every valid pointer is derived from precisely one object\u0026rdquo;\n malloc() stack allocation  Bounds are never implicitly changed\n  Capability: Provenance-carrying integers\nsearching, storing, and updating big dataflow tags. 2008. MICRO.\n  Secure program execution via dynamic information flow tracking. 2004, ASPLOS. ↩ A small cache of large ranges: Hardware methods for efficiently ↩ Hardware enforcement of application security policies using tagged memory. 2008, OSDI. ↩ E. Witchel, J. Cates, and K. Asanović, Mondrian memory protection. ACM, 2002, vol. 30, no. 5 ↩ D. Y. Deng, Flexible and efficient accelerator architecture for runtime monitoring. Cornell University, 2016. ↩ CheriABI UCAM-CL-TR-932, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-elf/",
	"title": "Cheri ELF",
	"tags": [],
	"description": "",
	"content": " Reference 1\ngABI\nMorello AArch64 ABI\nELF for dynamic linking As in gABI(retrieve date 20221117)\nNote Section\n   Type Name     0x0 [NT_CHERI_GLOBALS_ABI]   0x1 [NT_CHERI_TLS_ABI]   0x80000000 - 0xffffffff \u0026ndash; (Reserved for processor-specific use)    NT_CHERI_GLOBALS_ABI, this note describes the ABI variant in use for accessing globals. Capabilities for globals can be obtained in the following different ways.\n 0x0: CHERI_GLOBALS_ABI_PCREL. By indexing a table relative to the program counter. 0x1: CHERI_GLOBALS_ABI_PLT_FPTR. By indexing a table pointed to by a reserved register or equivalent that is defined on entry to functions.  Function pointers are sealed entry capabilities to trampolines that install the correct value for the target.  0x2: CHERI_GLOBALS_ABI_FDESC. By indexing a table pointed to by a reserved register or equivalent that is defined on entry to functions.  Function pointers are capabilities to function descriptors, the format of which is processor-specific.   NT_CHERI_TLS_ABI, this note describes the ABI variant in use for accessing thread-locals.\n 0x0: CHERI_TLS_ABI_TRAD. Capabilities for thread-locals are obtained using traditional TLS Variant I or II with pointers implemented using capabilities.  ARM Morello RISC-V MIPS ([CheriABI TR932] ch4.6) The dynamic linker (RTLD) is extended to initialize external symbol references using new dynamic relocations that initialize and bound the capability.\n a new ELF relocation R_MIPS_CHERI_CAPABILITY for external symbol references; for local (non-preemptible) symbols, use a special section (__cap_relocs) GOT (Global offset table) in binary contains global variables and functions. CheriABI changes this table to contain tightly bounded capabilities:  parse ELF symbol table and use the st_size field in the Elf_Sym structure as the size of global variables. st_size is emitted by the compiler and will correspond to the size of the C/C++ declaration; and for functions it is the size of all instructions in that function. However, \u0026ldquo;we only use exact bounds for data symbols and bound function symbols to the containing shared object\u0026rsquo;s code segment\u0026rdquo;. This wide bound for code will : preserve the ability of code to use branches in place of jumps between functions. facilitate the existing practice of referencing global variables using program-counter-relative addressing. Same logic for dlsym() API.   readelf -a .exe\nExamples: hello.elf kernel.elf\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/beri/",
	"title": "Beri",
	"tags": [],
	"description": "",
	"content": " Configure simulator ./memoryconfig (or $CHERI_MEMORY_CONFIG), describes how the hardware should be simulated.\nIndividual simulated hardware periperals are built as shared libraries; The simulator will use dlopen() to load the libraries; Any module specific options are passed to the module at load-time.\nC-like syntax in the configuration file.\nmodule statement to load the simulated device module.\ndevice blocks to declare devices by declaring a class.\n class selects the simulated device type. the base address (addr) and length (length) must be specified; optional: irq, class-specific parameters (sockets types, file paths, etc.) conditionally define device using ifdef ifndef can use getenv to set options.\n// configure example module ../../cherilibs/trunk/peripherals/dram.so module ../../cherilibs/trunk/peripherals/ethercap.so module ../../cherilibs/trunk/peripherals/uart.so device \u0026quot;dram0\u0026quot; { class dram; addr 0x0; length 0x40000000; }; ifdef \u0026quot;CHERI_KERNEL\u0026quot; device \u0026quot;kernel\u0026quot; { class dram; addr 0x100000; length 0xff00000; option path getenv \u0026quot;CHERI_KERNEL\u0026quot;; option type \u0026quot;mmap\u0026quot;; option cow \u0026quot;yes\u0026quot;; }; ifdef \u0026quot;CHERI_SDCARD\u0026quot; device \u0026quot;sdcard0\u0026quot; { class sdcard; addr 0x7f008000; length 0x400; option path getenv \u0026quot;CHERI_SDCARD\u0026quot;; option readonly \u0026quot;yes\u0026quot;; }; ifndef \u0026quot;CHERI_CONSOLE_SOCKET\u0026quot; device \u0026quot;uart0\u0026quot; { class uart; addr 0x7f000000; length 0x20; irq 0; option type \u0026quot;stdio\u0026quot;; } ifdef \u0026quot;CHERI_CONSOLE_SOCKET\u0026quot; device \u0026quot;uart0\u0026quot; { class uart; addr 0x7f000000; length 0x20; irq 0; option type \u0026quot;socket\u0026quot;; option path getenv \u0026quot;CHERI_CONSOLE_SOCKET\u0026quot;; }   Simulation sim: the simulator binary.\nmem64.hex: the physical memory image loaded into the simulator; used to populate memory contents for BRAM; the one generated from sw contain a small interactive test suite that communicates via a simulated serial I/O hooked up to the simulator\u0026rsquo;s standard input and output streams.\nTo run the simulator, we need a mem64.hex file in the current working directory. Can copy one from a software build such as cheri/trunk/sw or simboot; alternatively, the test target will build the simulator and then run the test suite with suitable options.\nArguments:\n+debug: all debug information (debug, debug2, trace) +xxxx: for use by debug2(\u0026ldquo;xxxx\u0026rdquo;, display/actions\u0026hellip;)\n+trace: +cTrace:\n+regDump:\nTesting TODO: testing infra \u0026amp; result analysis\nBefore run: build the simulator under cheri/trunk\nTo run:\n cheritest/trunk: test suite to exercise processor features: initial register values, memory access, jump instruction, exceptions, and so on. make test in cheritest/trunk will run the test suite  Two categories of tests:\n raw tests.  exercise basic CPU features such as the register file. prefixed 1 with raw_.  higher-level tests.  depends on common CPU initialization code and a support library, such as memcpy. prefixed 1 with test_. relying on init.s framework to setup the stack, dump register state on completion, and terminate the simulator.   Test structure  each high level test implement a global test function. Nose test framework will check the register after test terminates. Test framework will change the program counter, $PC, after test returns. No other register changes will be made. 1K stack. cached, unmapped region: 0x9800,00000,4000,0000 \u0026ndash; 0x9800,0000,8000,8000 (stack from here down) uncached, unmapped region: 0x9000,0000,4000,0000 \u0026ndash; 0x9000,0000,8000,0000 (stack from here down) cached, mapped memory regions, and CP0 MMU operations can also be used. Each test with 100,000-cycle limit to terminate.  can catch infinite loops, exception cycles, etc. can be changed. ??? where ???   Add new tests  write Nose test files begin with test_ as high-level test begin with test_raw as low-level test add src to TEST_FILES var in Makefile; can use subset such as TEST_ALU_FILES add dir to TESTDIRS in Makefile  Python Attributes in test Default no attributes: expected to work on any processor that compiles with mips r4000 isa.\nFPGA board Terasic DE4 Building BERI for Synthesis make verilog COP1=1 ./sim\nThe BERI verilog build will generate a set of Verilog files in the ip/ directory, with mkTopAxi.v containing the top level module.\nSynthesizing BERI for Terasic Board Terasic directory: cheri/trunk/boards/terasic_de4\nbuild targets:\n all. Build everything except download. build_cheri. Builds the BERI processor. build_peripherals. Builds the peripherals. build_miniboot. Builds miniboot ROM and copy initial.hex here build_qsys. Builds Qsys project containing BERI, etc. build_fpga. Synthesize, map, fit, analyze timing, and generate FPGA image. report_critical. Scans build_fpga reports for critical warnings report_error. Scans build_fpga reports for errors. download. Attempts to download the FPGA (.sof) image to the FPGA but the chain file (.cdf) may need to be updated for your configuration (e.g. USB port number). clean. Removes Quartus and Qsys build files. cleanall. clean + clean peripherals, BERI and miniboot.  BERI configuration Communication with external I/O devices, such as NICs, is accomplished via a blend of memory mapped I/O, interrupts, and (eventually) DMA.\nBERI processor and operating system stack supports a variety of peripherals ranging from Altera \u0026ldquo;soft\u0026rdquo; cores, such as the JTAG UART and SD Card IP cores, to \u0026ldquo;hard\u0026rdquo; peripherals provided by Terasic on its DE4 development board.\nBERI HW refrence (2015 UCAM-CL-TR-868) describes available peripherals and their configuration on the Avalon system-on-chip bus as configured in the BERI reference designs.\nAltera IP Cores BERI and FreeBSD support a number of Altera \u0026ldquo;soft\u0026rdquo; IP cores on Terasic tPad and DE4 platforms.\n JTAG UART core Avalon-MM and Avalon-ST bus attachments (Embedded Peripherals IP User Guide) Altera Triple-Speed MAC (Triple-Speed Ethernet MegaCore Function User Guide) SD Card IP core (Altera University Program Secure Data Card IP Core)  Cambridge IP Cores Two \u0026lsquo;soft\u0026rsquo; peripheral devices:\n the count device. A memory-mapped register that is incremented on every read(intended for cache testing)\n soft core for DE4 Multitouch LCD. A memory-mapped interface to the LCD panel, contains support for a pixel frame and a VGA-like text frame buffer suitable for use as a system console.\n Hardware: a parallel interface to drive the LCD + an I2C interface to obtain touhc information. (HW) MTL_LCD_Driver: IN - AvalonStream of pixel values; OUT - mapped pixels to the MTL (Multi-touch) LCD color screen (800x480). 24 bits pixel. 33MHz (mtl_dclk). A dual clock FIFO between this module and the MTL_Framebuffer_Flash. (HW) MTL_LCD_HDMI: an alternative to the MTL_LCD_Driver. Mirror to HDMI, then to VGA. 720x480; 27MHz. A dual clock FIFO between this module and the MTL_Framebuffer_Flash. (HW) MTL_Framebuffer_Flash: provides a memory-mapped frame buffer using the DE4\u0026rsquo;s off-chip SSRAM to store the frame buffer and provides access to the Flash (which is on the same bus as SSRAM). Provides an Avalon memory-mapped interface that allows a processor to write to the SSRAM. 100MHz. (HW) Libraries AlteraROM (a font ROM initialized from fontrom.mif) VerilogAlteraROM.v (provides Verilog wrapped by AlteraROM) Avalon2ClientServer (provides the Avalon memory-mapped interface) AvalonStreaming (provides the Avalon streaming interface). Software: MTL_Framebuffer, 8MB = 0-2MB SSRAM + 4-8MB control registers mtl_test_small.c is an example which drives the MTL-LCD using a NIOS for some helper functions, and so on.  HDMI Chip Configuration via I2C\n Terasic HDMI_TX_HSMC daughter card on the DE board to obtain output mirroring via an I2C interface I2C master interface from OpenCore. Wrapped in an Avalon interface(cherilibs/trunk/peripherals/i2c/i2c_avalon.sv, cherilibs/trunk/peripherals/i2c/i2c_rev03.pdf).   Standalone HDMI Output HDMI_Driver\nsupport multiple resolutions.\nTemperature and fan control two read-only 32-bit registers.\n addr. 0x0 -\u0026gt; last temperature in degrees Centigrade. addr. 0x4 -\u0026gt; the power to the fan as a range from 0 to 255.  Peripherals  Intel StrataFlash 64M NOR flash  Trouble shooting cheri/trunk/Makefile Errors to build:\n ./DMV/*.bsv not found; disable it in Makefile.  target sim sim sim.dtb sim.so: $(BUILD_DIR_SIM)/sim $(BUILD_DIR_SIM)/sim.so $(BUILD_DIR_SIM)/sim.dtb FORCE rm -f sim sim.dtb sim.so ln -s $(BUILD_DIR_SIM)/sim sim ln -s $(BUILD_DIR_SIM)/sim.dtb sim.dtb ln -s $(BUILD_DIR_SIM)/sim.so sim.so $(BUILD_DIR_SIM)/sim $(BUILD_DIR_SIM)/sim.so: $(BSV_FILES) $(PISM_LIB) $(EXTRA_LINK) rm -f $(CHERILIBS_DIR)/MEM.bo mkdir -p $(BUILD_DIR_SIM) CXXFLAGS=-D_GLIBCXX_USE_CXX11_ABI=0 MAKEFLAGS= $(BSC) $(BSC_SIM_FLAGS) $(BSC_SIM_LIBS) -simdir $(BUILD_DIR_SIM) -bdir $(BUILD_DIR_SIM) -u -sim $(BLUESPEC_FLAGS) $(BLUESPEC_SIM_FLAGS)-show-schedule $(SIM_BSV_TOPLEVEL) CXXFLAGS=-D_GLIBCXX_USE_CXX11_ABI=0 MAKEFLAGS= $(BSC) $(BSC_SIM_FLAGS) $(BSC_SIM_LIBS) -sim -e $(SIM_TOPLEVEL_MODULE) -simdir $(BUILD_DIR_SIM) -bdir $(BUILD_DIR_SIM) -o $(BUILD_DIR_SIM)/sim $(BUILD_DIR_SIM)/*.ba $(EXTRA_LINK) $(BUILD_DIR_SIM)/sim.dtb: $(BUILD_DIR_SIM)/sim.dts dtc -O dtb -o $@ -b 0 $\u0026lt;  Design overview BERI (without CHERI extension) pipeline:\nBERI with CHERI coprocessor extension:\n2014-isca paper: Note: cap coprocessor is tightly coupled with the Execute and Memory Access stages of the pipeline. PCC is validated in the Execute stage to simplify both forwarding and instruction address calculation.\n2012-deconflating paper: Source code overview cheri source code notes\nIn Verilog TODO\nReference 2\n Piccolo  Reference 1 reference ↩  Flute  Reference 1 reference ↩  Beri ISA  Reference 1 Coprocessor 0: system control, MMU Coprocessor 1: FPU. Coprocessor 2: CHERI capability feature. Smaller caches motivated by the performance trade-offs in the FPGA substrate, which provides comparatively high-speed main memory, as well as a desire for simpilicity. Features omitted from MIPS 4000 ISA: only 64-bit, no 32-bit addressing support; only big endian support; no variable-endian features; BERI is usually configured as a single-core, single-threaded processor; Multiprocessor (BERI1) and multithreading (BERI2) are experimental.\n Cheri Source Code reading  TODOs cpu instructions; l2cache; icache; dcache; tagCache; init done; compilation passed. Q\u0026amp;A Memory partitioned in ? see MultiLevelTagLookup.bsv. Possible bugs Bursts is 8 or 4? From TagController.bsv: peekMemResponse: one tagCache response is used for all bursts (frame as index), but the tagCache response only contain tags for 4 flits data\u0026rsquo;s tags. But somewhere says burst can be up to 8? Does dCache/iCache calls the tag controller?\n  the build framework use these prefixes to identify assembly and linking requirements, so they must be used. ↩ github repo, beri. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/fpga/",
	"title": "Fpga",
	"tags": [],
	"description": "",
	"content": " References:\n reference  FPGA vs ASIC\nCBB: Common Building Block.\nTiming Constraints:\n Tsu: Time of Set up Th: Time of Hold  SDC: Synopsys Design Constraints\nSTA: Static Timing Analysis\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-x86/",
	"title": "Cheri X86",
	"tags": [],
	"description": "",
	"content": " Capability Registers vs. Segments.\nx86 segments (CHERI ISA v7, Chapter 6)\nThe x86 arch first added virtual memory support via relocatable and variable-sized segments. Each segment was assigned a mask of permissions. Memory references were resolved with respect to a specific segment including relocation to a base address, bounds checking, and access checks. Special segments types permitted transitions to and from different protection domains.\nKey differences with CHERI:\n x86 addresses are stored as a combination of an offset and a segment spanning two different registers. General purpose registers (GPRs) are used to hold offsets, and dedicated segment selector registers are used to hold information about a single segment. The x86 architecture provides six segment selector registers \u0026ndash; three of which are reserved for code, stack, and general data access. A fourth register is typically used to define the location of thread-local storage (TLS). This leaves two segment registers to use for fine-graind segments such as separate segments for individual stack variables. These registers do not load a segment descriptor from arbitrary locations in memory. Instead, each register selects a segment descriptor from a descriptor table with a limited number of entries. One could treat the segment descriptor tables (or portions of these tables) as a cache of active segments. More fine-grained segments are not derived from existing segments. Instead, each entry in a descriptor table is independent. Write access to a descriptor table permits construction of arbitrary segments (including special segments that permit privilege transitions). Restricting descriptor-table write access to kernel mode does not protect against construction of arbitrary segments in kernel mode due to bugs or vulnerabilities. (LLM: is this argue reasonable, since every security solution is evaluated under assumptions??? If kernel does not have write access, then this would be a reasonable assumption, which does not consider any cases that kernel can do write to the descriptor-table.) As a result, segment descriptors are not able to provide the same provenance guarantees are tagged capabilities.(LLM: How can cheri tagged caps being integrated with segments???) existing segment descriptors do not havve available bits for storing types or permissions more expressive than the existing read, write, and execute. x86 segmentation is typically not used in modern operating systems. Software for x86 systems stores only the offset portion of virtual addresses in pointer variables. Segment registers are set to fixed values at program startup, never change, and are largely ignored.  32-bit x86: generally create infinite bounds and use a non-zero base for TLS. 64-bit x86: codifies this by removing segment bounds entirely and supporting non-zero-base addresses only for two segment registers. LLM: what is the codify here mean? Hardcoding??.   CHERI on x86 (CHERI ISA v7, Chapter 6) Approaches to providing CHERI capability features on x86:\n Non-taken approach: extending the existing segment primitives to accomodate some of these differences.\n Descriptor-table entires could be tagged. Loading an untagged segment would trigger an exception. Decision to make: shall segment selectorsstore an index to a table, or a logical virtual addresses of a segment descriptor? ability to share code and algorithms are limited.  CHERI-taken approach: extending existing general-purpose integer registers.\n  (CHERI ISA v7, Chapter 6.2-6.3):\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/proofcc/",
	"title": "Proof Carrying Code",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  What is the threat model in PCC?  What if the proof and binary are changed at the same time by malicious compiler?   PCC @ POPL\u0026rsquo;97 1, Necula Thesis\u0026rsquo;98 2.\n  Proof-Carrying Code. George C. Necula. POPL, 1997. ↩ Compiling with Proofs. PhD thesis by George Ciprian Necula. 1998. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-arm/",
	"title": "Cheri ARM -- Morello",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/vivado/",
	"title": "Vivado Usage Tips",
	"tags": [],
	"description": "",
	"content": " Out of date One can \u0026lsquo;force up to date\u0026rsquo; if changes are detected by vivado but those changes can be ignored (unrelated to the regarding operation).\n Out of date \u0026ndash; force up to date  Out of Context Modules  Vivado IP的两种综合方式：Global 和 Out-Of-Context  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-riscv/",
	"title": "CHERI RISC-V",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-mips/",
	"title": "CHERI MIPS",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/c910/",
	"title": "C910",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/",
	"title": "Secure Memory by Compiling",
	"tags": [],
	"description": "",
	"content": "A special case of building isolated software boxes.\nWith Static \u0026amp; Dynamic analysis and/or Compiler Instrumentations.\nExamples:\n Shadow Stacks\n SafeCode\n nesCheck\n  Reference 1\n 201904 Secswift  Reference 1 A compiler approach to cyber-security ↩  Sok: Shining Light on Shadow Stacks  Reference 1 SoK: Shining Light on Shadow Stacks. arXiv, 2019. ↩  Defending Embedded Systems Against Control Flow Attacks  A hardware controlled stack split: one for data, one for return; Reference 1 Defending Embedded Systems Against Control Flow Attacks. SecuCode, 2009. ↩  Efficient Detection of All Pointer and Array Access Errors  Reference 1 Efficient Detection of All Pointer and Array Access Errors. PLDI, 1994. ↩  Protecting Bare-metal Embedded Systems With Privilege Overlays  Reference 1 Protecting Bare-metal Embedded Systems With Privilege Overlays. SP. 2017. ↩  MINION: Securing Real-Time Microcontroller Systems through Customized Memory View Switching  Reference:  nesCheck  nesCheck1. Statically find all provable memory bugs and report them as errors; Statically find all potentially unsafe memory accesses, determine and exclude those that will never result in a memory corruption in a conservative way; report the remaining vulnerabilities as warnings; Dynamically instrument all remaining vulnerable location with runtime checks, and catch all memory errors at runtime. Related text with sil: Similar to CCured, nesCheck leverages more extensive static analysis and tailored runtime checks for wireless sensor network system (TinyOS)\n uXOM  $\\mu$XOM1: Efficient eXecute-Only Memory on ARM Cortex-M. USENIX Security, 2019. Background Code injection attacks: W$\\oplus$X. Since virtually all processors today are equipped with at least five basic memory permissions: read-write-execute (RWX), read-write (RW), read-execute (RX), read-only (RO) and no-access (NA). W$\\oplus$X can be efficiently enforced in hardware for a memory region solely by disabling RWX. Disclosure attacks: attemps to read part of or possibly the entire code. Code often contains intellectual properties (IPs) including core algorithems and sensitive data like cryptographic keys.\n Rest   References: reference More  Safemem   References: Qin, Feng, Shan Lu, and Yuanyuan Zhou. \u0026ldquo;SafeMem: Exploiting ECC-memory for detecting memory leaks and memory corruption during production runs.\u0026rdquo; 11th International Symposium on High-Performance Computer Architecture. IEEE, 2005. More  Asan  References: K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov, “Addresssanitizer: A fast address sanity checker,” in ATC, 2012. reference Overview \u0026ldquo;[AddressSanitizer]\u0026rdquo;: use shaow memory to record whether each byte of application memory is safe to access; use instrumentation to check the shadow memory on each application load or store; more efficient than AddrCheck in Valgrind: use a more efficent shadow mapping; a more compact shadow encoding.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-qemu/",
	"title": "Cheri Qemu",
	"tags": [],
	"description": "",
	"content": "References:\n [CHERI QEMU source code] QEMU Developer’s Guide   Translate  References: reference More CCall References: target/mips/translate.c // target/mips/translate.c mips_tr_translate_insn() --\u0026gt; gen_branch() // is_slot decode_opc() --\u0026gt; gen_compute_compact_branch() --\u0026gt; gen_branch() // bcond_compute == 0 --\u0026gt; gen_helper_copy_cap_btarget_to_pcc(cpu_env) // MIPS_HFLAG_BRCCALL/MIPS_HFLAG_BRC --\u0026gt; CHERI_HELPER_IMPL(copy_cap_btarget_to_pcc(CPUArchState *env)) More Syscall References: target/mips/translate.c mips_tr_translate_insn() --\u0026gt; decode_opc() // !(ctx-\u0026gt;hflags \u0026amp; MIPS_HFLAG_M16) --\u0026gt; decode_opc_special() --\u0026gt; generate_exception_end(ctx, EXCP_SYSCALL) generate_exception_end() -\u0026gt; generate_exception_err() // target/mips/translate.c // generate_exception_end(ctx, EXCP_SYSCALL) --\u0026gt; generate_exception_err(ctx, excp, 0) static inline void generate_exception_err(DisasContext *ctx, MipsExcp excp, int err) { TCGv_i32 texcp = tcg_const_i32(excp); TCGv_i32 terr = tcg_const_i32(err); save_cpu_state(ctx, 1); gen_helper_raise_exception_err(cpu_env, texcp, terr); tcg_temp_free_i32(terr); tcg_temp_free_i32(texcp); ctx-\u0026gt;base.\n Addr Trans  Reference reference All memory translation requests finally invokes a callback func env-\u0026gt;tlb-\u0026gt;map_address Example code: // target/mips/helper.c static int get_seg_physical_address(CPUMIPSState *env, hwaddr *physical, int *prot, target_ulong real_address, int rw, int access_type, int mmu_idx, unsigned int am, bool eu, target_ulong segmask, hwaddr physical_base) { int ret; int mapped = is_seg_am_mapped(am, eu, mmu_idx); if (mapped \u0026lt; 0) { /* is_seg_am_mapped can report TLBRET_BADADDR */ return mapped; } else if (mapped) { /* The segment is TLB mapped */ ret = env-\u0026gt;tlb-\u0026gt;map_address(env, physical, prot, real_address, rw, access_type); } else { /* The segment is unmapped */ *physical = physical_base | (real_address \u0026amp; segmask); *prot = PAGE_READ | PAGE_WRITE | PAGE_EXEC; ret = TLBRET_MATCH; } return ret; } env-\u0026gt;tlb-\u0026gt;map_address is assigned in translate_init.\n Instruction Fetch and PCC checks  References: QEMU source ~4.2.93 QEMU Detailed Study Translator Internals QEMU start to instruction fetch Some call paths for instruction fetch and decoding: // cpu_exec callers cpu_loop // linux-user/mips/cpu_loop.c =\u0026gt; cpu_exec qemu_tcg_init_vcpu // thread creation using fn pointer, cpus.c =\u0026gt; qemu_tcg_rr_cpu_thread_fn =\u0026gt; tcg_cpu_exec =\u0026gt; cpu_exec qemu_tcg_init_vcpu // thread creation using fn pointer, cpus.c =\u0026gt; qemu_tcg_cpu_thread_fn =\u0026gt; tcg_cpu_exec =\u0026gt; cpu_exec // cpu_exec ---\u0026gt; translator_loop cpu_exec =\u0026gt; tb_find =\u0026gt; if (not found): tb_gen_code // accel/tcg/translate-all.\n Guest RAM  Q\u0026amp;A How can we convert a virt addr in QEMU to a (faked) physical addr? Reference 1 2 Memory Regions Entire physical memory is modelled as an acyclic graph of MemoryRegion objects 1. Sinks(leaves) are RAM and MIMO regions. While other nodes represents buses, memory controllers, and memory regions that have been rerouted. In addition to MemoryRegsion objects, the memory API provides AddressSpace objects for every root and possibly for intermediate MemoryRegsions too.\n Memtrace  Reference 1 Simple Q\u0026amp;A What kind of operations the guest_mem_before_exec trace? trace the virtual address when the CPU access the memory Load cap: no mem trace when TLB hit(probe_read). A bug? probably no. A TLB hit means the table entry already loaded into TLB. Loading this entry can only be counted once as a memory access. guest_mem_before_exec Event format def The def of trace event: # tcg/tcg-op. reference ↩  Tag Mem  References: github/qemu, 202005. tagbit{set|get} tag_bit_set will create a new tag block if the indexed block does not exist. tag_bit_get will return zero tags if the inidexed tag block does not exist. This is how the tag (efficiently) stored: it exists only after the tag has been set/initialized. Otherwise, it is assumed to be always zero tags and will not have a tag block to store their values.\n Cheriops  ALL CHERI/MIPS Instructinos are declared as emulating functions in target/mips/helper.h, with macro DEF_HELPER_*. Implemented in target/mips/op_helper_cheri.c, using macro CHERI_HELPER_IMPL. For example, cseal instruction is declared as DEF_HELPER_4(cseal, void, env, i32, i32, i32), and implemented as void CHERI_HELPER_IMPL(cseal)(CPUMIPSState *env, uint32_t cd, uint32_t cs, uint32_t ct). capability runtime check instructions PCC check DEF_HELPER_2(ccheck_pc, void, env, i64) CHERI_HELPER_IMPL(ccheck_pc)(CPUMIPSState *env, uint64_t next_pc) DDC check will always be checked on ld/st without explicit instructions. see check_cap.\n Basics  TCG Frontend Ops1 implements supported operations for the targe CPU (what QEMU executes; not where QEMU executes). [tcg/tcg.h]() contains frontend helpers. // file // tcg/tcg.h ALL CHERI/MIPS Instructinos are defined as emulating functions in target/mips/helper.h // file // target/mips/helper.h // QEMU-CHERI extension: DEF_HELPER_1(mfc0_rtc64, i64, env) DEF_HELPER_2(mtc0_rtc64, void, env, i64) // BERI extension: DEF_HELPER_1(mfc0_coreid, tl, env) DEF_HELPER_2(cheri_debug_message, void, env, i64) #if defined(TARGET_CHERI) DEF_HELPER_2(mtc2_dumpcstate, void, env, tl) DEF_HELPER_1(ccheck_btarget, void, env) DEF_HELPER_2(ccheck_pc, void, env, i64) DEF_HELPER_3(ccheck_store, tl, env, tl, i32) DEF_HELPER_3(ccheck_store_right, tl, env, tl, i32) DEF_HELPER_3(ccheck_load, tl, env, tl, i32) DEF_HELPER_3(ccheck_load_right, tl, env, tl, i32) DEF_HELPER_5(cinvalidate_tag, void, env, tl, i32, i32, tl) DEF_HELPER_5(cinvalidate_tag_left_right, void, env, tl, i32, i32, tl) DEF_HELPER_5(cinvalidate_tag32, void, env, tl, i32, i32, i32) DEF_HELPER_4(candperm, void, env, i32, i32, tl) DEF_HELPER_3(cbez, tl, env, i32, i32) DEF_HELPER_3(cbnz, tl, env, i32, i32) DEF_HELPER_3(cbts, tl, env, i32, i32) DEF_HELPER_3(cbtu, tl, env, i32, i32) DEF_HELPER_3(ccall, void, env, i32, i32) DEF_HELPER_3(ccall_notrap, tl, env, i32, i32) DEF_HELPER_3(ccheckperm, void, env, i32, tl) DEF_HELPER_3(cchecktype, void, env, i32, i32) DEF_HELPER_2(cclearreg, void, env, i32) DEF_HELPER_3(ccleartag, void, env, i32, i32) DEF_HELPER_4(cfromptr, void, env, i32, i32, tl) DEF_HELPER_2(cgetaddr, tl, env, i32) DEF_HELPER_2(cgetbase, tl, env, i32) DEF_HELPER_1(cgetcause, tl, env) DEF_HELPER_2(cgetlen, tl, env, i32) DEF_HELPER_2(cgetoffset, tl, env, i32) DEF_HELPER_2(cgetpcc, void, env, i32) DEF_HELPER_3(cgetpccsetoffset, void, env, i32, tl) DEF_HELPER_2(cgetperm, tl, env, i32) DEF_HELPER_2(cgetsealed, tl, env, i32) DEF_HELPER_2(cgettag, tl, env, i32) DEF_HELPER_2(cgettype, tl, env, i32) DEF_HELPER_4(cincbase, void, env, i32, i32, tl) DEF_HELPER_4(cincoffset, void, env, i32, i32, tl) DEF_HELPER_3(cjalr, tl, env, i32, i32) DEF_HELPER_2(cjr, tl, env, i32) DEF_HELPER_1(creturn, void, env) DEF_HELPER_4(cseal, void, env, i32, i32, i32) DEF_HELPER_4(ccseal, void, env, i32, i32, i32) DEF_HELPER_4(csetbounds, void, env, i32, i32, tl) DEF_HELPER_4(csetboundsexact, void, env, i32, i32, tl) DEF_HELPER_2(crap, tl, env, tl) DEF_HELPER_2(cram, tl, env, tl) DEF_HELPER_3(csub, tl, env, i32, i32) DEF_HELPER_2(csetcause, void, env, tl) DEF_HELPER_4(csetlen, void, env, i32, i32, tl) DEF_HELPER_4(csetoffset, void, env, i32, i32, tl) DEF_HELPER_3(ctoptr, tl, env, i32, i32) DEF_HELPER_4(cunseal, void, env, i32, i32, i32) DEF_HELPER_4(cmovz, void, env, i32, i32, tl) DEF_HELPER_4(cmovn, void, env, i32, i32, tl) DEF_HELPER_4(cbuildcap, void, env, i32, i32, i32) DEF_HELPER_4(ccopytype, void, env, i32, i32, i32) DEF_HELPER_3(creadhwr, void, env, i32, i32) DEF_HELPER_3(cwritehwr, void, env, i32, i32) DEF_HELPER_3(csealentry, void, env, i32, i32) DEF_HELPER_3(cloadtags, tl, env, i32, i64) DEF_HELPER_3(ceq, tl, env, i32, i32) DEF_HELPER_3(cne, tl, env, i32, i32) DEF_HELPER_3(clt, tl, env, i32, i32) DEF_HELPER_3(cle, tl, env, i32, i32) DEF_HELPER_3(cltu, tl, env, i32, i32) DEF_HELPER_3(cleu, tl, env, i32, i32) DEF_HELPER_3(cexeq, tl, env, i32, i32) DEF_HELPER_3(cnexeq, tl, env, i32, i32) DEF_HELPER_4(csetaddr, void, env, i32, i32, tl) DEF_HELPER_3(cgetandaddr, tl, env, i32, tl) DEF_HELPER_4(candaddr, void, env, i32, i32, tl) DEF_HELPER_3(ctestsubset, tl, env, i32, i32) DEF_HELPER_5(cload, tl, env, i32, tl, i32, i32) DEF_HELPER_5(cstore, tl, env, i32, tl, i32, i32) DEF_HELPER_3(cloadlinked, tl, env, i32, i32) DEF_HELPER_3(cstorecond, tl, env, i32, i32) DEF_HELPER_3(cscc_without_tcg, tl, env, i32, i32) DEF_HELPER_5(csc_without_tcg, void, env, i32, i32, tl, i32) DEF_HELPER_5(clc_without_tcg, void, env, i32, i32, tl, i32) DEF_HELPER_3(cllc_without_tcg, void, env, i32, i32) #endif #if defined(TARGET_CHERI) /* cannot access EPC directly since it is the offset of EPCC */ DEF_HELPER_1(mfc0_epc, tl, env) DEF_HELPER_2(mtc0_epc, void, env, tl) DEF_HELPER_1(mfc0_error_epc, tl, env) DEF_HELPER_2(mtc0_error_epc, void, env, tl) #endif #if defined(TARGET_CHERI) DEF_HELPER_2(rdhwr_statcounters_icount, tl, env, i32) DEF_HELPER_1(rdhwr_statcounters_reset, tl, env) DEF_HELPER_1(rdhwr_statcounters_itlb_miss, tl, env) DEF_HELPER_1(rdhwr_statcounters_dtlb_miss, tl, env) DEF_HELPER_2(rdhwr_statcounters_memory, tl, env, i32) DEF_HELPER_2(rdhwr_statcounters_ignored, tl, env, i32) #endif New instruction TCG frontend.\n Build   Isaac: Just a quick FYI, since I just noticed this problem: Apparently, cheribuild hardcodes the git branch to use when building qemu, regardless of the \u0026ndash;qemu/git-revision setting. A manual clone is needed to override. (I was wondering why my change to how $DDC was handled wasn\u0026rsquo;t reflected in the simulator. It turns out that I was building CTSRD\u0026rsquo;s branch, not my branch.)  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/tal/",
	"title": "Typed Assembly Language",
	"tags": [],
	"description": "",
	"content": "Reference1:\n Statically typed intermediate languages are effective tools for staging the compilation of high-level languages. Types express invariants that help programmers understand their programs, and strongly typed languages prevent many common programming errors. Compiler writers can use these properties to debug sophisticated program transformations such as closure conversion and optimizations like datatype specialization. Furthermore, types not only help check the correctness of transformations but enable analyses or optimizations that are extremely difficult without them.\nThe goal of the TAL project is to extend the paradigm of type-directed compilation to its limit. We compile high-level languages that include features such as higher-order polymorphic functions, datatypes, modules, objects, and subtyping into a series of typed intermediate languages and finally into a Typed Assembly Language (TAL). Unlike any other compiler, we not only use typed intermediate languages but also typed target languages.\nWe seek to reveal the connections between the typed lambda calculi which give semantics to many modern languages and the Von Neumann machines that implement them.\n   TAL Overview ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/sva/hwsw/kcofi/",
	"title": "KCoFI",
	"tags": [],
	"description": "",
	"content": "Reference1\n reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/",
	"title": "Secure Memory by using Metadata for Pointers",
	"tags": [],
	"description": "",
	"content": "Bookkeeping the metadat for pointers, such as base,bounds,ownerships,lock/keys, etc., to secure the system. Examples:\n fat pointers and its variants.  Reference 1\n Code Pointer Integrity  References: Code Pointer Integrity Motivation CFI 1 2 3 4 5 is shown to be ineffective 6 7 8. Transactions on Information Forensics and Security, 6(4):1404–1417, Dec. 2011. More Code-Pointer Integrity References: Code-Pointer Integrity Goal Guarantees the integrity of all code pointers in a program, e.g. function pointers, saved return addresses), and thereby prevents all control-flow hijack attacks, including return-oriented programming. Challenges Hard to make Low level languages safe (C/C++) while preserving their benefits including performance and flexible programming patterns.\n Tagged Pointer  Reference 1 Folding tags into the pointer By alignment: Certain types of data will be aligned to the size of data, often a word or multiple thereof. This discrepancy leaves a few of the least significant bits of the pointer unused, which can be used for tags \u0026ndash; most often as a bit field (each bit a separate tag) \u0026ndash; as long as code that uses the pointer masks out these bits before accessing memory.\n Ptr Auth  References: ARM Pointer Authentication. LWN.net. April 2017. PAC it up: Towards Pointer Integrity using ARM Pointer Authentication.. USENIX Security, 2019. ARMv8-A Architecture Reference Manual Qualcomm Technologies, Inc. Pointer Authentication on ARMv8.3. 2017 Pointer Authentication (PA) Added in ARMv8-A. Purpose is to detect pointers created by an external entity. PA uses cryptographic message authentication codes (MACs) to protect the integrity of pointers. It attaches a cryptographic signature to pointer values; unused uppermost bits [62:48/42/39] of the address, could be used to hold auth code.\n Runtime Bound Checking  Reference1 Runtime Bounds Checking Reference: Runtime Defenses agains Memory Corruption, or here Three kinds of solutions: Modified pointer representation. Pointer keeps information about its referent object Incompatible with external code, libraries, etc. Special table maps pointers to referent objects Check referent object on every dereference What if a pointer is modified by external code? Keep track of address range of each object For every pointer arithmetic operation, check that the results points to the same referent object.\n CETS: Compiler Enforced Temporal Safety for C  Reference: CETS paper Temporal errors include: dangling pointer dereferences (referencing an object that has been deallocated), double frees (calling free() on the same object multiple times), invalid frees (calling free() with a non-heap address or pointer to the middle of a heap-allocated region). CETS: Compiler Enforced Temporal Safety. Movivation Temporal errors are challenging. Prior proposals suffer from one or more of the following deficiencies: high runtime overheads, high memory overheads, failure to detect all temporal errors (for example, to the stack, to reallocated heap locations, or in the face of arbitrary casts) requiring annotations inserted by the programmer, or altering memory layout (which breaks compatibility with existing C code).\n Low Fat Pointers  References: [1] Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-based Security. [paper] Low-fat Capability Format  SoftBound: Highly Compatible and Complete Spatial Memory Safety for C  Reference: SoftBound: Highly Compatible and Complete Spatial Memory Safety for C. PLDI, 2009. Background spatial violation detection and prevention. Object-Based Approaches. Pointer-Based Approaches. Comparison of Various Approaches. Design Associates base and bound metadata with every pointer. Disjoint metadata representation avoids memory layout changes and arbitrary casts. Metadata Propagation with Function Calls. When pointers are passed as arguments or returned from functions, their base and bound metadata must also travel with them.\n HardBound  References: [1] HardBound: Architectural Support for Spatial Safety of the C Programming Language. [paper] The C programming language is at least as well known for its absence of spatial memory safety guarantees (i.e., lack of bounds checking) as it is for its high performance. C\u0026rsquo;s unchecked pointer arithmetic and array indexing allow simple programming mistakes to lead to erroneous executions, silent data corruption, and security vulnerabilities. Many prior proposals have tackled enforcing spatial safety in C programs by checking pointer and array accesses.\n M-Mmachine  References: [1] Hardware support for fast capability based addressing. SIGPLAN, 1994. [2] CHERI Concentrate: Practical Compressed Capabilities, IEEE Transactions on Computers, 2019. M-Machine Capability Format  Intel MPX  Reference1 Arch support Instructions: BNDMK: saving bound pair for bounds register BNDCL: checking lower bound with bounds register value and operands BNDCU, BNDCN: checking upper bound with bounds register upper value and operands. BNDMOV: accessing bound register. BNDLDX: loading bounds reigister from memory. BNDSTX: saving bounds register to memory. Registers: BND0-3 Bound registers. BNDCFGU. configuration register for bound paging in ring 3.\n Intel Ccc   References: reference More   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/riscv/ibex/",
	"title": "Ibex",
	"tags": [],
	"description": "",
	"content": " References:\n ibex docs ibex rtl on github  RTL Coding  ibex core integration  Main module is ibex_top, defined in ibex_top.sv\n Core logic is split-out from the register file and RAMs under ibex_top. This is to facilitate a dual-core lockstep implementation.\n Register File RegFile defined in rtl/ibex_pkg.sv\nThree register file implementations, depending on different target technologies:\n ibex_pkg::RegFileFF: flip-flop-based, default; ibex_pkg::RegFileLatch: latch-based; ibex_pkg::RegFileFPGA: for FPGA target;  Identification CSRs Read-only CSRs, defined in rtl/ibex_pkg.sv, follows RISC-V Privileged Architecture.\n mvendorid, 0 by default.\n marchid, 22 for ibex.\n mimpid, 0 by default.\n  Primitives Modules Held outside rtl/ folder.\nCan implement your own primitives.\nSome primitives can be removed/ignored if not using in specific Ibex configurations.\n Mandatory primitives:\n prim_buf, a buffer used to avoid security critical logic being optimized away (by applying suitable constraints to prim_buf) prim_clock_gating, a clock gate.  Depends on configuration:\n see figure below.   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/auto-parallel/",
	"title": "Auto Parallel",
	"tags": [],
	"description": "",
	"content": "Reference 1\nHELIX: auto parallel loops.\nJanus: Automatic binary parallelisation.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/types/",
	"title": "Types",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Gradual Typing  Reference 1 RUST \u0026mdash;\u0026mdash;\u0026ndash;buffer\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt; Ocaml \u0026lt;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; Escape Hatches: ML:C FFI Rust:unsafe Java: JNI All type soundness(safety) guarranttes are gone. Instead, use Principled FFIs: ML: linear types. Linking types: support safe initeroperability with other languages. Only need linking types extensions to interact with behavior/features inexpressible in your language. SNAPL\u0026rsquo;172: Linking Types for Multi-language Software: Have your cake eat it too. Teach Ocaml with ownership in Rust: Linking Type: linear type: cannot keep it and give it away at the same time.\n Sec Type  Reference 1 A type system for expressive security policies. POPL, 2000. ↩  Info Flow Type  Reference 1 Language-based information-flow security. IEEE journal on selected areas in comm. 2003. ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/iot/",
	"title": "IOT",
	"tags": [],
	"description": "",
	"content": " Papers related to system support and security protection for IoT and Edge Computing.\nHardware Assisted System Protection A Hardware Monitor to Protect Linux System Calls. note\n Efficient AI with Tiny Resources  References: Song Han from MIT Evaluations NeurIPS\u0026rsquo;20: MCUNet: Tiny Deep Learning on IoT Devices Datasets: ImageNet, Visual Wake Words(VWW), Speech Commands. Devices: STM32F746 MCU (320kB SRAM/1MB Flash), STM32H743 (512kB SRAM/2MB Flash). 216MHz CPU. Youtube Demo 70.2% accuracy, record high, ImageNet recognition on microcontrollers. NeurIPS\u0026rsquo;20: Tiny Transfer Learning: Towards Memory-Efficient On-Device Learning Three benchmark datasets: Cars, Flowers, Aircraft Using ImageNet as the pre-training dataset. Neural network architecture: MobileNetV2 (lightweight), ResNet-50.\n 5g   Reference 1 ITU (International Telecommunications Union) Applications Internet, augmented, virtual reality.. wearable devices with integrated mobile communication system (smart watch), car communication system, household applicances, utility meters robotics, self-driving cars. massive IoT: one million devices per square km. Security Traditional mobiles: SIM(Subscriber Identity Module), Universal Integrated Circuit Card (UIUC) Cloud: tokenization, host card emulation(HCE), Trusted Execution Environment (TEE). 5G Explained. by Jyrki T. J. Penttinen. 2019. ↩  How can IoT help us to save the planet?   Rising Sea Level Fact: Sea-Level Report Cards and full report Reference 1 Artificial Leaves Reference 12 \u0026lsquo;Artificial leaf\u0026rsquo; successfully produces clean gas ↩ Virgil Andrei , Bertrand Reuillard and Erwin Reisner. ‘Bias-free solar syngas production by integrating a molecular cobalt catalyst with perovskite-BiVO4 tandems.’ Nature Materials (2019). DOI: 10.1038/s41563-019-0501-6 ↩ Unresolved. ↩  Batteryless Computing  Reference 1 Devices that survive using harvested enegy, store that energy in small cpacitors, and work opportunistically maintenance-free for decades. Devices that make the most of energy when it is available and get useful work done in the face of frequent power failures. Computational RFIDs2. Batteries Not Included. pdf ↩ A. N. Parks, A. P. Sample, Y. Zhao, and J. R. Smith. A wireless sensing platform utilizing ambient RF energy.\n Edge  Reference 1 Migration Science Fiction 1: 瞬间移动装置将他的大脑和身体逐个细胞地进行扫描并摧毁了他们，然后将信息传到火星，在火星上重新构建人体。 《一头想要被吃掉的猪》引自德里克 reference ↩  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-llvm/",
	"title": "Cheri LLVM",
	"tags": [],
	"description": "",
	"content": " Reference1:\nTodones  Passes to  tracking data with attributes, such as privileged;   Address space 200 data layout string (Programmer\u0026rsquo;s Guide, 2015)\nThe data layout string is modified to define the address space for alloca instructions. It is assumed that, within a compilation unit, every alloca returns a pointer in the same address space. By default, this address space is 0, but when targeting the pure-capability ABI, it is set to 200.\nIn the MIPS back end, a pass will replace each of these alloca (all all their uses) with one in address space 0, followed by calls to two intrinsics. The first intrinsic derives a $c11-relative capability from the integer value. The second sets its length to the size of alloca. (LLM: how does this look like in the code???)\nThis allows the normal MIPS stack pointer to be used as an offset within $c11.\nCompatability with other passes: A lots of optimizations, in particular scalar evolution and the SLP vectorizer, assume that the size of a pointer is the size of an integer that can express its range. As a result, they will attempt to create i256 operands to various pointer arithmetic operations. To avoid this, the DataLayout class now provides a few variants of getPointerBaseSize() methods, which get the size of the base of a fat pointer or capability. For non-capability pointer types, these simply return the size.\n(os_bench cheritypes/sandbox_hello/) In Cheri Hybrid compilation mode: Cheri LLVM will generate IR with the following layout specification:\ntarget datalayout = \u0026quot;E-m:e-pf200:128:128:128:64-i8:8:32-i16:16:32-i64:64-n32:64-S128\u0026quot;  LLVM language ref: data layout string.\n \u0026ldquo;E\u0026rdquo;: big-endian target data model; \u0026ldquo;m:e\u0026rdquo;: ELF mangling: private symbols get a .L prefix; \u0026ldquo;pf200:128:128:128:64\u0026rdquo;:  SelectionDAG types (Programmer\u0026rsquo;s Guide, 2015)\nQ1: Pointer size in code generator.\nIn LLVM, one of the early parts of the target-independent code generator replaces all pointers with an integer of the correct size. On CHERI, this would be an i256, which is not a valid type for the target and would cause other problems if the definition allowed the rest of the code generator to assume that 256-bit integers were supported.\nTo avoid this, we add an MVT::iFATPIR machine value type to the code generator. This can be used for any non-integer pointer and can be pattern matched by any of the tablegen-generated machine code.\nWe also add ISD::INTTOPTR and ISD::PTRTOINT SelectionDAG nodes. These represent conversions between MVT::iFATPTR and integer types and are generated from any address space cast instructions between address space 0 and 200, as well as inttoptr and ptrtoint IR instructions. In the MIPS back end, these expend to CToPtr and CFromPtr instructions.\nQ2: Type violation in pointer arithmetic.\nThe conventional way of expressing pointer arithmetic in the SelectionDAG is via normal arithmetic nodes. This works because the MVT::iPTR type is lowered to an integer type (typically MVT::i32 or MVT::i64) in the legalization phase. The ADD selectionDAG node has the invariant that the operands must be the same type. This does not work for pointer addition with fat pointers, because one operand is the pointer and the other is the integer value that is being added to the pointer, which will typically be MVT::iFATPTR and MVT::i64 respectively for CHERI.\nTo address this, we add another new SelectionDAG node: ISD::PTRADD. This is lowered to CIncOffset in MIPS back end, but may later be folded to use a complex addressing mode.\nLLVM IR Intrinsics (Programmer\u0026rsquo;s Guide, 2015)\nMIPS back end exposes a number of intrinsics in LLVM IR.\nclang/test/CodeGen/cheri/cheri128.c\n// CHECK128: target datalayout = \u0026quot;E-m:e-pf200:128:128:128:64-i8:8:32-i16:16:32-i64:64-n32:64-S128\u0026quot; // CHECK256: target datalayout = \u0026quot;E-m:e-pf200:256:256:256:64-i8:8:32-i16:16:32-i64:64-n32:64-S256\u0026quot;  LLVM changes in code grep cheri Frontend:\nIR level:\n include/llvm/IR/Cheri.h include/llvm/IR/CallingConv.h include/llvm/Transforms/Utils/CheriSetBounds.h \u0026mdash;\u0026mdash;\u0026mdash;- lib/Transforms/Utils/CheriLogSetBoundsPass.cpp \u0026mdash;\u0026mdash;\u0026mdash;- lib/Transforms/Utils/CheriSetBounds.cpp \u0026mdash;\u0026mdash;\u0026mdash;- lib/Transforms/Utils/SimplifyCFG.cpp lib/Transforms/CHERICap/PureCapABICalls.cpp\n lib/Transforms/CHERICap/FoldCapIntrinsics.cpp lib/Transforms/InstCombine/InstCombineAddSub.cpp lib/Transforms/InstCombine/InstCombineCalls.cpp lib/IR/Instructions.cpp \u0026mdash;\u0026mdash;\u0026mdash;- lib/IR/Function.cpp lib/IR/DataLayout.cpp \u0026mdash;\u0026mdash;\u0026mdash;- lib/IR/AsmWriter.cpp lib/IR/Verifier.cpp lib/Analysis/CaptureTracking.cpp lib/Analysis/ValueTracking.cpp lib/Analysis/ConstantFolding.cpp  Backend:\n include/llvm/MC/MCTargetOptions.h include/llvm/MC/MCAsmMacro.h include/llvm/MC/MCStreamer.h include/llvm/MC/MCDwarf.h include/llvm/BinaryFormat/ELF.h include/llvm/ADT/Triple.h include/llvm/Object/ELFObjectFile.h include/llvm/Object/RelocVisitor.h\n include/llvm/CodeGen/Passes.h ************\n lib/CodeGen/LLVMTargetMachine.cpp\n lib/CodeGen/ValueTypes.cpp\n lib/CodeGen/TargetLoweringObjectFileImpl.cpp\n lib/CodeGen/InlineSpiller.cpp\n lib/CodeGen/SelectionDAG/LegalizeDAG.cpp\n lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp\n lib/CodeGen/AsmPrinter/AsmPrinter.cpp\n lib/Target/Mips/Mips.h\n lib/Target/Mips/MipsFastISel.cpp\n lib/Target/Mips/MipsAsmPrinter.cpp\n lib/Target/Mips/MipsTargetMachine.h\n lib/Target/Mips/MipsTargetMachine.cpp\n lib/Target/Mips/MipsSubtarget.h\n lib/Target/Mips/MipsSubtarget.cpp\n lib/Target/Mips/MipsInstrInfo.cpp\n lib/Target/Mips/MipsRegisterInfo.cpp\n lib/Target/Mips/MipsExpandPseudo.cpp\n lib/Target/Mips/MipsISelLowering.h\n lib/Target/Mips/MipsISelLowering.cpp\n lib/Target/Mips/MipsSelectionDAGInfo.cpp \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\n lib/Target/Mips/MipsSEISelLowering.cpp\n lib/Target/Mips/MipsSEISelDAGToDAG.h\n lib/Target/Mips/MipsSEISelDAGToDAG.cpp\n lib/Target/Mips/MipsSEFrameLowering.cpp\n lib/Target/Mips/MipsSEInstrInfo.cpp\n lib/Target/Mips/MipsSERegisterInfo.cpp\n lib/Target/Mips/MipsMachineFunction.cpp\n lib/Target/Mips/MipsBranchExpansion.cpp\n lib/Target/Mips/MipsDelaySlotFiller.cpp\n lib/Target/Mips/MCTargetDesc/MipsAsmBackend.cpp\n lib/Target/Mips/MCTargetDesc/MipsFixupKinds.h\n lib/Target/Mips/MCTargetDesc/MipsABIInfo.h\n lib/Target/Mips/MCTargetDesc/MipsABIInfo.cpp\n lib/Target/Mips/MCTargetDesc/MipsABIFlagsSection.h\n lib/Target/Mips/MCTargetDesc/MipsELFObjectWriter.cpp\n lib/Target/Mips/MCTargetDesc/MipsELFStreamer.h\n lib/Target/Mips/MCTargetDesc/MipsELFStreamer.cpp\n lib/Target/Mips/MCTargetDesc/MipsMCExpr.hlib/AsmParser/LLParser.cpp\n lib/Target/Mips/MCTargetDesc/MipsMCExpr.cpp\n lib/Target/Mips/MCTargetDesc/MipsMCTargetDesc.h\n lib/Target/Mips/MCTargetDesc/MipsMCTargetDesc.cpp\n lib/Target/Mips/MCTargetDesc/MipsBaseInfo.h\n lib/Target/Mips/MCTargetDesc/MipsMCCodeEmitter.cpp\n lib/Target/Mips/MCTargetDesc/MipsTargetStreamer.cpp\n lib/Target/Mips/AsmParser/MipsAsmParser.cpp\n lib/Target/Mips/Disassembler/MipsDisassembler.cpp\n lib/Target/Mips/TargetInfo/MipsTargetInfo.cpp\n lib/Target/Mips/CheriStackInvalidatePass.cpp\n lib/Target/Mips/CheriExpandIntrinsicsPass.cpp\n lib/Target/Mips/CheriRangeChecker.cpp\n lib/Target/Mips/CheriPureCapABI.cpp\n lib/Target/Mips/CheriLoopPointerDecanonicalize.cpp\n lib/Target/Mips/CheriAddressingModeFolder.cpp\n lib/Target/Mips/Cheri128FailHard.cpp\n lib/MC/MCStreamer.cpp\n lib/MC/MCTargetOptions.cpp\n lib/MC/ELFObjectWriter.cpp\n lib/MC/MCAsmStreamer.cpp\n lib/MC/MCObjectFileInfo.cpp\n lib/MC/MCParser/AsmLexer.cpp\n lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp\n include/llvm/Support/CheriSetBounds.h\n include/llvm/Support/MipsABIFlags.h\n lib/Support/CheriSetBounds.cpp\n lib/Support/Triple.cpp\n lib/ObjectYAML/ELFYAML.cpp\n lib/AsmParser/LLParser.cpp\n  tools:\n tools/llvm-readobj/llvm-readobj.cpp tools/llvm-readobj/ObjDumper.h tools/llvm-readobj/ELFDumper.cpp tools/llvm-objdump/llvm-objdump.cpp tools/llc/llc.cpp tools/opt/opt.cpp  EG: BasicAA BasicAA.\nBasicAA: Analysis pass providing a never-invalidated alias analysis result.\n llvm/include/llvm/IR/DataLayout.h/.cpp\n getMaxPointerSize();// returns the maximum pointer size over all address space.     Builtin  Reference 1 From github/clang old repo Feb 2019: clang/include/clang/Basic/Builtins.def: __builtin_cheri_* clang/include/clang/Basic/BuiltinsMips.def: __builtin_mips_cheri_* reference ↩  Call Convention  Reference 1 calling convention in LLVM lib/Target/Mips/ ./CheriStackInvalidatePass.cpp ./CheriAddressingModeFolder.cpp ./MipsInstrCheri.td ./CheriRangeChecker.cpp ./Cheri128FailHard.cpp ./MipsInstrFormatsCheri.td ./CheriLoopPointerDecanonicalize.cpp ./cheri-compressed-cap ./cheri-compressed-cap/decompress_c128_cap.c ./cheri-compressed-cap/LICENSE ./cheri-compressed-cap/README.md ./cheri-compressed-cap/.editorconfig ./cheri-compressed-cap/.gitignore ./cheri-compressed-cap/cheri_compressed_cap.c ./cheri-compressed-cap/.gitrepo ./cheri-compressed-cap/cheri_compressed_cap.h ./cheri-compressed-cap/test ./cheri-compressed-cap/test/fuzz-decompress.cpp ./cheri-compressed-cap/test/decode_inputs.cpp ./cheri-compressed-cap/test/test_util.h ./cheri-compressed-cap/test/setbounds_test.cpp ./cheri-compressed-cap/test/random_inputs_test.cpp ./cheri-compressed-cap/test/simple_test.cpp ./cheri-compressed-cap/test/FuzzedDataProvider.h ./cheri-compressed-cap/test/catch.hpp ./cheri-compressed-cap/test/setbounds_inputs.cpp ./cheri-compressed-cap/.clang-format ./cheri-compressed-cap/CMakeLists.txt in MipsCallingConv.td CC_Mips -\u0026gt; CC_Mips_VarArg -\u0026gt; CC_MipsCheriPureCap_VarArg -\u0026gt; CC_Mips_ByVal -\u0026gt; CC_Mips_N_VarArg -\u0026gt; CC_Mips_FixedArg -\u0026gt; CC_CHERI_CCall -\u0026gt; CC_MipsN -\u0026gt; CC_Mips_ByVal -\u0026gt; CC_Mips_FastCC -\u0026gt; CC_MIpsN CC_CHERI_CCall CC_CHERI_CCall convention -\u0026gt; CC_MipsN -\u0026gt; CC_MipsCheriCapOnStack: // lib/Target/Mips/MipsCallingConv.td def CC_CHERI_CCall : CallingConv\u0026lt;[ CCIfType\u0026lt;[iFATPTR64, iFATPTR128, iFATPTR256, iFATPTR512], CCAssignToReg\u0026lt;[C1, C2, C3, C4, C5, C6, C7, C8, C9, C10]\u0026gt;\u0026gt;, CCIfType\u0026lt;[i64], CCAssignToReg\u0026lt;[V0_64]\u0026gt;\u0026gt;, CCDelegateTo\u0026lt;CC_MipsN\u0026gt; ]\u0026gt;; See definition in build/lib/Target/Mips/MipsGenCallingConv.\n Fatptr   Q\u0026amp;A How to distinguish capabilities? How does it parse __capability qualifier? Reference 1 reference ↩  Passes  llvm/lib/Target/Mips/Mips.h Cheri(Stack)InvalidatePass llvm/lib/Target/Mips/CheriStackInvalidatePass.cpp Pass Invoked at: llvm/lib/Target/Mips/MipsTargetMachine.cpp: void addPostRegAlloc() overide. Machine Function Pass: class CheriInvalidatePass : public MachineFunctionPass. Every function do: nothing; // all function code is disabled by #if 0 If enabled, for every function do: check if a sensitive function with metadata cheri.sensitive.functions; if current function is sensitive: get the set of storeToStackSlot(LLM: what is this mean) and return instructions for this function (by runOnMachineBasicBlock) if store set is empty, return; if have store instructions: enumerate all return instructions, for each return: zero all capability and non-capability spills.\n  CHERI Programmer\u0026rsquo;s Guide, 2015. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-sandbox/sandbox-loader/",
	"title": "Sandbox Loader",
	"tags": [],
	"description": "",
	"content": " // file: lib/libcheri/libcheri_sandbox_loader.c sandbox class load int sandbox_class_load(struct sandbox_class *sbcp)\nThis will set up the code capability for a new sandbox class; (CHERI todo) set up the code and data capabilities differently. Steps includes:\n parse the provided classes, required methods from the ELF binary. set bounds and mask permissions on code capabilities. set offset of rtld, invoke vectors.  sandbox object load int sandbox_object_load(struct sandbox_class *sbcp, struct sandbox_object *sbop)\nThis will create an initial reservation of space for the sandbox, and using anonymous memory that is neither readable nor writable. This ensures there is space for all the various segments we will be installing later. Steps includes:\n create a new CHERI system object for use with a specific sandbox object.  The rough memory map is as follows:\n// file: // lib/libcheri/libcheri_sandbox_loader.c  /* * J + 0x1000 [internal (non-shareable) heap] * J [guard page] * +0x600 Reserved vector * +0x400 Reserved vector * +0x200 Object-capability invocation vector * +0x0 Run-time linker vector * 0x8000 [memory mapped binary] * 0x2000 [guard page] * 0x1000 [read-only sandbox metadata page] * 0x0000 [guard page] * */"
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/libcheri-invoke/",
	"title": "libcheri_invoke: CCall Implementation in CheriBSD",
	"tags": [],
	"description": "",
	"content": " libcheri_invoke is defined in assembly code; two versions for different ABIs respectively.\nHybrid libcheri_invoke The Hybrid MIPS ABI (github):\n# file: lib/libcheri/mips/libcheri_invoke_hybrid.S  # # Assembly wrapper for CCall on an object-capability. Its function is to save # and restore any general-purpose and capability registers needed on either # side of CCall, but not handled by the compiler. This is done by creating an # on-stack frame which will be pointed to by $idc before CCall, and then # unwrapping it again. We rely on the compiler and CCall to sort out clearing # of registers that require it, since they have the information to do so. # # Calling conventions into libcheri_invoke: # # Registers\tDescription # $c0\tMIPS address space # $c1, $c2\tInvoked capabilities # $c3..$c10\tArgument capabilities # $c11..$c16\tCaller-save capabilities # $c17..$c26\tCallee-save capabilities # # Calling conventions implemented by CCall: # # $c1\tInvoked code capability # $c2\tInvoked data capability # $c3..$c10\tArgument capabilities; $c3 as return capability # $c11..$c16\tn/a # $c17..$c25\tn/a # $c26\tIDC # # XXXRW: Worries/TODO: # # - Floating-point registers. # - The compiler needs to handle unused argument/return registers. #  .text .global libcheri_invoke .global cheri_invoke .ent\tlibcheri_invoke libcheri_invoke: cheri_invoke: # \t# Wrap up all caller-save state suitable to be preseved by CCall and \t# restored by CReturn. This happens in two phases: \t# \t# 1. First, use the conventional stack to save as many caller-save \t# general-purpose and capability registers as possible. \t# \t# 2. Produce a value for $csp that bundles these up suitable to \t# bootstrap restoration. This will save the original $idc, $csp, \t# $sp, and $ddc. \t# \t# Then after CReturn, reverse these steps by first unwrapping $idc, \t# and then performing a more normal function return. \t# \t# The caller $csp will describe a stack fragment, which gives us a bit \t# of space to store useful things, such as $sp, that are otherwise \t# quite hard to restore (for obvious reasons). \t# \t# NB: This is still required for the hybrid ABI, unlike the \t# pure-capability ABI, because we need to save and restore $sp. \t# \t# Save callee-save general-purpose registers. \t# \t# Caller-save registers are: $s0..$s7, $gp, $sp, $s8 ($fp). \t# \t# Do also save $ra so that we can return properly. \t# \t# NB: Use 96 rather than 88 for the stack to ensure 32-byte alignment \t# for capabilities stored and loaded from it later. \t# \t# XXXRW: Possibly with the __ccall calling convention, the compiler \t# should be doing this? \t# libcheri_invoke_save_regs: daddiu\t$sp, -96 sd\t$s0, 0($sp) ... sd\t$s7, 56($sp) sd\t$gp, 64($sp) sd\t$fp, 72($sp) sd\t$ra, 80($sp) sd\t$t9, 88($sp) # \t# Save capability registers we later need to restore (that won\u0026#39;t be \t# handled by CCall for us). \t# libcheri_invoke_save_caps: cgetdefault\t$c11 daddiu\t$sp, -10*CHERICAP_SIZE csc\t$c17, $sp, 0($c11) csc\t$c18, $sp, 1*CHERICAP_SIZE($c11) ... csc\t$c26, $sp, 9*CHERICAP_SIZE($c11) # \t# Stash $sp in the offset of $c11 so that it will be saved and \t# restored by CCall. \t# \tcsetoffset\t$c11, $c11, $sp # \t# The compiler is responsible for scrubbing unused argument registers \t# (since only it has the information required to do so). CCall is \t# responsible for scrubbing all other registers. \t#  # \t# Construct link-address PCC. \t# \t# XXXRW: Do we want a CCall variant like CJALR that automatically \t# builds the desired capability? \t# \tdla\t$t0, libcheri_invoke_ccall_linkaddr cgetpcc\t$c17 csetoffset\t$c17, $c17, $t0 # \t# Invoke object capability. CCall/CReturn will save and restore $csp. \t# libcheri_invoke_ccall: CCALL($c1, $c2) libcheri_invoke_ccall_linkaddr: # \t# Unstash $sp from offset of $c11; restore $c11 offset to zero and \t# install as DDC. \t# \tcgetoffset\t$sp, $c11 csetoffset\t$c11, $c11, $zero csetdefault\t$c11 # \t# Restore capability registers from stack. \t# libcheri_invoke_restore_caps: clc\t$c17, $sp, 0($c11) clc\t$c18, $sp, 1*CHERICAP_SIZE($c11) ... clc\t$c26, $sp, 9*CHERICAP_SIZE($c11) ... # \t# CCall has conservatively cleared all non-return-value registers, and \t# so we don\u0026#39;t need to.  # \t# Restore general-purpose registers from the stack. \t# libcheri_invoke_restore_regs: ld\t$s0, 0($sp) ld\t$s1, 8($sp) ... ld\t$s7, 56($sp) ld\t$gp, 64($sp) ld\t$fp, 72($sp) ld\t$ra, 80($sp) daddiu\t$sp, 96 # \t# Return to C-language caller. \t# libcheri_invoke_return: jr\t$ra nop\t# Branch-delay slot Pure-cap libcheri_invoke The Pure-capability CheriABI: (github)\n# file: lib/libcheri/mips/libcheri_invoke_cabi.S  # Calling conventions into libcheri_invoke: # # Registers\tDescription # $c0\tMIPS address space # $c1, $c2\tInvoked capabilities # $c3..$c10\tArgument capabilities # $c11..$c16\tCaller-save capabilities # $c17..$c26\tCallee-save capabilities # # Calling conventions implemented by CCall: # # $c1\tInvoked code capability # $c2\tInvoked data capability # $c3..$c10\tArgument capabilities; $c3 as return capability # $c11..$c16\tn/a # $c17..$c25\tn/a # $c26\tIDC # # XXXRW: Worries/TODO: # # - Floating-point registers. # - The compiler needs to handle unused argument/return registers. #  #define LIBCHERI_INVOKE_FRAME_SIZE (11*CHERICAP_SIZE + 96)  NESTED(libcheri_invoke, LIBCHERI_INVOKE_FRAME_SIZE, _FRAME_RETURN_REG) XNESTED(cheri_invoke) # \t# Wrap up all caller-save state suitable to be preseved by CCall and \t# restored by CReturn. This happens in two phases: \t# \t# 1. First, use the conventional stack to save as many caller-save \t# general-purpose and capability registers as possible. \t# \t# 2. Produce a value for $csp that bundles these up suitable to \t# bootstrap restoration. This will save the original $idc, $csp, \t# and $ddc. \t# \t# Then after CReturn, reverse these steps by first unwrapping $idc, \t# and then performing a more normal function return. \t# \t# The caller $csp will describe a stack fragment, which gives us a bit \t# of space to store useful things that are otherwise hard to restore. \t# \t# NB: This is no longer required for the pure-capability ABI. \t# \t# Save callee-save general-purpose registers. \t# \t# Caller-save registers are: $s0..$s7, $gp, $s8 ($fp). \t# \t# NB: Use 96 rather than 88 for the stack to ensure 32-byte alignment \t# for capabilities stored and loaded from it later. \t# \t# XXXRW: Possibly with the __ccall calling convention, the compiler \t# should be doing this? \t# libcheri_invoke_save_regs: cincoffset\t$csp, $csp, -96 csd\t$s0, $zero, 0($csp) csd\t$s1, $zero, 8($csp) ... csd\t$s7, $zero, 56($csp) csd\t$gp, $zero, 64($csp) csd\t$fp, $zero, 72($csp) csd\t$ra, $zero, 80($csp) # \t# Save capability registers we later need to restore (that won\u0026#39;t be \t# handled by CCall for us). \t# libcheri_invoke_save_caps: cgetdefault\t$c12 cincoffset\t$csp, $csp, -11*CHERICAP_SIZE csc\t$c17, $zero, 0($csp) csc\t$c18, $zero, CHERICAP_SIZE($csp) ... csc\t$c26, $zero, 9*CHERICAP_SIZE($csp) csc\t$c12, $zero, 10*CHERICAP_SIZE($csp) # \t# The compiler is responsible for scrubbing unused argument registers \t# (since only it has the information required to do so). CCall is \t# responsible for scrubbing all other registers. \t#  # \t# Construct link-address PCC. \t# \t# XXXRW: Do we want a CCall variant like CJALR that automatically \t# builds the desired capability? \t# \tdla\t$t0, libcheri_invoke_ccall_linkaddr cgetpcc\t$c17 csetoffset\t$c17, $c17, $t0 # \t# Invoke object capability. CCall/CReturn will save and restore $csp. \t# libcheri_invoke_ccall: CCALL($c1, $c2) libcheri_invoke_ccall_linkaddr: # \t# Restore capability registers from stack. \t# libcheri_invoke_restore_caps: clc\t$c17, $zero, 0($csp) clc\t$c18, $zero, CHERICAP_SIZE($csp) ... clc\t$c26, $zero, 9*CHERICAP_SIZE($csp) clc\t$c12, $zero, 10*CHERICAP_SIZE($csp) csetdefault\t$c12 ... # Restore general-purpose registers from the stack. \t# \t# XXXRW: Possibly with the __ccall calling convention, the compiler \t# should be doing this? \t# libcheri_invoke_restore_regs: cld\t$s0, $zero, 0($csp) cld\t$s1, $zero, 8($csp) cld\t$s2, $zero, 16($csp) cld\t$s3, $zero, 24($csp) cld\t$s4, $zero, 32($csp) cld\t$s5, $zero, 40($csp) cld\t$s6, $zero, 48($csp) cld\t$s7, $zero, 56($csp) cld\t$gp, $zero, 64($csp) cld\t$fp, $zero, 72($csp) cld\t$ra, $zero, 80($csp) cincoffset\t$csp, $csp, 96 # \t# Return to C-language caller. \t# libcheri_invoke_return: cjr\t$c17 nop\t# Branch-delay slot  END(libcheri_invoke) CCALL is defined as a macro wrapper for ccall in CheriBSD, source code: (github)\n// file: sys/mips/include/cheriasm.h  #define CCALL(cb, cd)\t\\ .set push;\t\\ .set noreorder;\t\\ ccall cb, cd, 1;\t\\ nop; /* Fill branch delay slot for old harware*/\\ .set pop; The libcheri_invoke_ccall after compilation:\n128-bit mode are the same: Reference1\n reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/riscv/sonic-boom/",
	"title": "Sonic Boom",
	"tags": [],
	"description": "",
	"content": " Instruction Fetch References:\n Docs » Instruction Fetch  The Front-end fetches instructions and makes predictions throughout the Fetch stage to redirect the instruction stream in multiple fetch cycles (F0, F1\u0026hellip;)\nMisprediction:\n Detected in BOOM\u0026rsquo;s Back-end(execution pipeline); A request is sent to the Front-end;  ICache:\n Virtually indexed, physically tagged set-associative cache; To save power, the i-cache is only fired up again once the fetch register has been exhausted (or a branch prediction directs the PC elsewhere). Does not (currently) support fetching across cache-lines, nor does it support fetching unaligned relative to the superscalar fetch address; Does not (currently) support hit-under-miss;  If an i-cache miss occurs, the i-cache will not accept any further requests until the miss has been handled. This is less than ideal for scenarios in which the pipeline discovers a branch mispredict and would like to redirect the i-cache to start fetching along the correct path;   Fetch Buffer:\n Fetch packets from i-cache; parameterizable: num of entries; whether is a \u0026lsquo;flow-throug\u0026rsquo; queue or not;  Fetch Target Queue:\n holds PC received from from the i-cache and branch prediction info associated with that address; referenced during the executions of the pipleline\u0026rsquo;s Micro-Ops(UOPs); dequeued by the ROB once an instruction is committed and is updated during pipeline redirection/mispeculation;  Branch Prediction Two levels of prediction:\n A fast Next-Line Predictor (NLP)\n a Branch Target Buffer provides single-cycle predictions with a combinational logic; Rocket \u0026ldquo;BTB\u0026rdquo; is more complex; an amalgamation of: A fully associative Branch Target Buffer (BTB); Bi-Modal Table (BIM);  determine whether a branch taken or not taken;  A Return Address Stack (RAS);  A slower but more complex Backing Predictor (BPD);\n like a GShare predictor; predict result has a higher priority than NLP;   NLP Predictions  Match a PC tag with a BTB entry;\n The PC is the \u0026ldquo;Fetch PC\u0026rdquo;, not the PC of the branch itself \u0026ldquo;Fetch PC\u0026rdquo; is the PC corresponding to the head of a Fetch Packet instruction group; Each BTB entry corresponds to a single Fetch PC, but is helping to predict across an entire Fetch Packet.  other designs instead choose to provide a whole bank of BTBs for each possible instruction in the Fetch Packet.    On a hit:\n check BIM, determine whether a branch if return instruction, use RAS to predict return PC; fetch PC target next cycle;  for area-efficiency, the high-order bits of the PC tags and PC targets are stored in a compressed file.\n RAS update:\n if the taken instruction is a call, the return address is pushed onto the RAS; if the taken instruction is a return, then the RAS is popped;   Backing Predictor (BPD) To capture more branches and more complicated branching behaviors.\n Goal is to provide high accuracy in a (hopefully) dense area;\n Only provides taken/not-taken predictions;\n  Global History Register (GHR) todo\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/edu/csed/",
	"title": "CS for Education",
	"tags": [],
	"description": "",
	"content": " Top Wonderings  Can computer help to make the history book unfakable?\n Histories have mostly been written by the man in power and thus prone to be faked in a way that is good for themselves. Other histories are from man with bias, or men with relatively limited vision, which cannot reflect the real history. Similar to the (fake or inaccurate) news media nowadays. How to validate the information in the correct way before it is being released to us? And how to keep the right information out of being corrupted along the time? Is this a computational problem or a philosophical problem, or both, or more?  How computers can (help) teach human?\n History tells us that men in power tend to retain its power via a carefully crafted education system with twisted history stories. If computers are able to teach human, will the computer finally be the one with the real power of controlling all our humans by educating human mind according to its own best interests?\n Is this the really mattered race between computer and human?   References:\n Speeches at CS Education Site  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-lang/",
	"title": "Secure Memory by Language",
	"tags": [],
	"description": "",
	"content": "Design or leverage language features to secure a system.\nExample:\n Cyclone CCured nesC CheckedC  Reference 1\n CCured  Reference 1 CCured: Type-Safe Retrofitting of Legacy Software. ACM Transactions on PL and Systems. 2005. ↩  nesC  Reference 1 reference ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/vmi/",
	"title": "VMI",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Hwvmi  Reference 1 Introspection in hardware. To match network connections to the application-layer while being isolated and undetected from the operating system or the hypervisor. Motivation Firewalls: external firewall: external device only connected to network cannot see the content of the target computer\u0026rsquo;s physical memory, thus cannot make decision based on what code is accessing the traffic; software-based firewall: installed on a target computer. can be the target of attacks themselves.\n  reference. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/",
	"title": "Artificial Intelligence",
	"tags": [],
	"description": "",
	"content": " Top Wonderings Q/A  Human vs Machine: What is the goal of AI? Why do we need a machine to have intelligence?\n Use machine as a tool, to assist people achieve goal. Will machines have goals, and some day they use human as tools to achieve machine\u0026rsquo;s goal?  Human vs AI: What do we want to do using AI?\n Some really difficult tasks for human:  Compute $\\pi$ Go to the moon \u0026ndash;\u0026gt; space craft; Limited memory and processing power \u0026ndash;\u0026gt; Big Data storage and analysis;  to release human from labor:  driving \u0026ndash;\u0026gt; autonomous driving car, smart road?; manufacturing \u0026ndash;\u0026gt; hand-arm robitic pipelines; farming \u0026ndash;\u0026gt;   Artifitial Intellegence vs. Human intellegence: Now we know many human intellegence (object recognition for example) does not yield 100% correct ratio, it seems not good to follow human\u0026rsquo;s principle to do the same task and we should find new ways that can achieve a much better result, yes?\n e.g., counting animals using fingers and toes is hard sometimes, so we find new tools (such as stones?) to count instead of using our own organ. e.g., safeguards (or smart-doors) of a building cannot recognize everyone\u0026rsquo;s face in order to determine who is allowed to be in, so we have ID card for him to check instead of checking our face\u0026rsquo;s image. e.g., if a computer cannot recognize a car/wheel/lanes/stone/blocking on the road, why not just create new feature for each of them so that computers can detect them much easier with higher correct ratio?  How much Image and Voice processing based AI can be useful?\n Image/Voice as information media: does this solution as communication media have a ceiling limitation from its essence? (Human handle image/voice better than machine, but can still have mistakes)\n ceiling limitation of correct ratio, communication efficiency, etc. ceiling limitation of ??  What can be the enhancement of intelligence/learning if image/voice themselves is not enough?\n The language. We listen, hear, watch, but also read, write language as special encodings of information. Language is a media that can embed information for better communication. Draw a picture on the stones is an intermediate media form. But language has been developed to be a special media that can describe much more information than pictures or voices can represent. So, to enhace the machine that does not have good image/voice processing power, a powerful language can be used, especially for communication between machines (language does not work well cross species, but voice and image do.) Physical touch. Chemical reactions. Smell/Taste. Crafted tools: microscopes that can help us find living cells;  Any other usage of Image/Voice rather than as a information media of communication?\n  How to defend against (or recognize) Faked digital information by AI?\n Faked/Synthesized photos, voices, videos, etc. Digital signature? NO?   References:\n A list of PDF Books about Machine Learning on github  Tasty critiques on 5G and AI   More  AI Architectures   Autonomous Driving Cars   References: V2X: Vehicle to everything More  ML  References: reference More Reading Notes on Dr. Mi Zhang\u0026#39;s Publications References: Mi Zhang - Publications Publications in 2020 Mutual Net ECCV\u0026rsquo;20: MutualNet: Adaptive ConvNet via Mutual Learning from Network Width and Resolution Distream SenSys\u0026rsquo;20: Distream: Scaling Live Video Analytics with Workload-Adaptive Distributed Edge Intelligence WiFi SenSys\u0026rsquo;20: WiFi See It All: Generative Adversarial Network-augmented Versatile WiFi Imaging. SecWIR MobiSys\u0026rsquo;20: SecWIR: Securing Smart Home IoT Communications via WiFi Routers with Embedded Intelligence.\n History  References: 人工智能简史（图灵出品），尼克，人民邮电出版社，2017-11 人工智能是一门新学科，历史的读物并不多。波登的《认知科学历史》（Boden 2\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cert/",
	"title": "Cert",
	"tags": [],
	"description": "",
	"content": " References:\n More  More  Asil   References: reference More  Cc   References: reference More  PSA:    References: ARM PSA Certified PSA whitepaper online More  26262   References: reference More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/books/",
	"title": "Books Reading",
	"tags": [],
	"description": "",
	"content": " This is a collection of links to the reading notes of some books on this website.\nBook Shelf\nBooks Reading Notes  密码编码学与网络安全 编程之美   Book Shelf  Math.FM. \u0026ldquo;Software Foundations, Volumn 1 - 4\u0026rdquo;. By Benjamin C. Pierce, et al. 2019. html video/lectures by Pierece, UPenn, by Clarkson, Cornell, by Xiong, Peking U \u0026ldquo;Logical Foundations for Computing Science\u0026rdquo;. By Shen Enshao. 2006. \u0026ldquo;Logic for Computer Science.\u0026rdquo; By Steve Reeves and Mike Clarke. 2003. \u0026ldquo;Rigorous Software Development: An Introduction to Program Verification\u0026rdquo;. By Almeida, José Bacelar, Maria João Frade, Jorge Sousa Pinto,\n Formal Methods   Books: EDA for IC design, verification, and testing Mechanizing Proof: Computing, Risk, and Trust, by MacKenzie 2001. More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/",
	"title": "Practice",
	"tags": [],
	"description": "",
	"content": " Programming Practice. For interviews, job seeking, professional development skills, etc.\nHow to take notes efficiently    Linux  Reference: Lubuntu Lubuntu Split window Lubuntu default shortcuts to split window horizontally to half, putting current window on left/right/top/bottom: Super + $\\leftarrow$; Super + $\\rightarrow$; Super + $\\uparrow$; Super + $\\downarrow$; To change it manually by updating openbox configuration file ~/.config/openbox/lubuntu-rc.xml; see how. Lubuntu natural scrolling synclient VertScrollDelta=-100 source  Tools  Mscode References: StackOverflow: Vertical rulers in Visual Studio Code \u0026#34;editor.rulers\u0026#34;: [80,120] \u0026#34;workbench.colorCustomizations\u0026#34;: { \u0026#34;editorRuler.foreground\u0026#34;: \u0026#34;#ff4081\u0026#34; } Vim References: How can I set up a ruler at a specific column? set colorcolumn=80 Make Reference 1 %: one or more chars. used in matching patterns of targets, prerequests. $@: the target of the rule. $^: a list of the dependence files with their full paths. $\u0026lt;: the first dependence file.\n 编程之美  《编程之美》1 一句话：关键不在于答案，而在于思考问题的方法。 知己知彼：了解公司的文化、战略方向。 笔试是基础，需要扎实的理解和考虑完备的解答。\n Cnspp: Cryptography and Network Security: Principles and Practice  References: 密码编码学与网络安全\u0026mdash;原理与实践，William Stallings著，孟庆树等译，电子工业出版社，第四版。 信息安全、计算机安全\n Coding  References: reference More 错误笔记 反转括号子串 反转每对括号间的子串 使用最直接的解体思路： 定位一对括号（可从最里面开始） 反转括号内子串 去除括号（可替换为空格，或其他“非法”字符 Dynamic Programming References: Dynamic Programming How to solve a Dynamic Programming Problem Tabulation \u0026amp; Memoization What is dynamic programming Dynamic programming is mainly an optimization over plain recursion. Wherever we see a recursive solution that has repeated calls for same inputs, we can optimize it using dynamic programming. The idea is to simply store the results of subproblems, so that we do not have to re-compute them when needed later.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/",
	"title": "Attacks",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Overflow  Reference 1 Heart Bleed CVE-2014-0160 OpenSSL 1.0.1f, Fixed in 1.0.1g tlsl_process_heartbeat() in t1_lib.c // 2553 int tls1_process_heartbeat(SSL *s){ unsigned char *p = \u0026amp;s-\u0026gt;s3-\u0026gt;rrec.data[0], *pl; unsigned short hbtype; unsigned int payload; unsigned int padding = 16; /* Use minimum padding */ /* Read type and payload length first */ hbtype = *p++; n2s(p, payload); pl = p; if (s-\u0026gt;msg_callback) s-\u0026gt;msg_callback(0, s-\u0026gt;version, TLS1_RT_HEARTBEAT, \u0026amp;s-\u0026gt;s3-\u0026gt;rrec.data[0], s-\u0026gt;s3-\u0026gt;rrec.length, s, s-\u0026gt;msg_callback_arg); if (hbtype == TLS1_HB_REQUEST) { unsigned char *buffer, *bp; int r; /* Allocate memory for the response, size is 1 bytes * message type, plus 2 bytes payload length, plus * payload, plus padding */ buffer = OPENSSL_malloc(1 + 2 + payload + padding); bp = buffer; /* Enter response type, length and copy payload */ *bp++ = TLS1_HB_RESPONSE; s2n(payload, bp); memcpy(bp, pl, payload); bp += payload; /* Random padding */ RAND_pseudo_bytes(bp, padding); r = ssl3_write_bytes(s, TLS1_RT_HEARTBEAT, buffer, 3 + payload + padding); .\n Attack Data Op  Reference 1 2016 Sp Dop References: reference MINIDOP language: pattern \u0026ndash;\u0026gt; operations. Example: The attack that overwrites the data and convert a program from code1 to code2: Example code of addition: Example code of assignment and dereference: The attack model with DOP gadgets: More reference ↩  Attack Rop  Reference 1 Persistent Data-only Malware: Function Hooks without Code Reference 1 Persistent Data-only Malware: Function Hooks without Code. NDSS, 2014. ↩ reference ↩  Control Flow Bending: On the Effectiveness of Control-Flow Integrity  References: Control-Flow Bending: On the Effectiveness of Control-Flow Integrity, 2015 USENIX Security. Attacks on Fully-Precise Static CFI CFI with shadow stack. Dispatcher function/gadgets: Any function that contains a “write-what-where” primitive when the arguments are under the attacker’s control can be used as a dispatcher function. Alternatively, a function that can write to only limited addresses can still work as long as the return address is within the limits.\n Attack Jop  References: reference More Jujutsu References: [1] Control Jujutsu: On the Weaknesses of Fine-Grained Control Flow Integrity. CCS, 2015. A new attack on fine-grained CF that exploit the incompleteness of pointer analysis, when combined with common software engineering practices, to enable an attacker to execute arbitrary malicious code. Concepts: ICS: Indirect Call Site ACICS: Argument Corruptible Indirect Call Site RCE: Remote Code Execution DSA: Data Structure Analysis DEP: Data Execution Prevention ASLR: Address Space Layout Randomization SSP: Stack Smashing Protection ROP: Return-oriented Programming JOP: Jump-Oriented Programming Threat Model The threat model in this paper is a remote attacker trying to hijack control of a machine by exploiting memory vulnerabilities.\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/attack-data-op/",
	"title": "Attack Data Op",
	"tags": [],
	"description": "",
	"content": "Reference 1\n 2016 Sp Dop   References: reference MINIDOP language: pattern \u0026ndash;\u0026gt; operations. Example: The attack that overwrites the data and convert a program from code1 to code2: Example code of addition: Example code of assignment and dereference: The attack model with DOP gadgets: More   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/",
	"title": "Research",
	"tags": [],
	"description": "",
	"content": " Reference:\nResearch impact Mark Hill, Increasing your research impact.\n Taxonomies organize a problem or existing solutions into \u0026ldquo;boxes\u0026rdquo; that can expose new opportunites. Mendeleev\u0026rsquo;s Periodic Table that focused efforts on uncovering missing elements.\n Connections are key to research. Steve Jobs said, \u0026ldquo;Creativity is just connecting things.\u0026rdquo; Don\u0026rsquo;t unduly worry about dividing credit, but generously share credit as it often multiplies and leads to collaborations that can enable something even more worthwhile. \u0026ldquo;Sequential Consistency (SC) for Data-Race-Free (DRF) Programs\u0026rdquo; memory model is the result of a connection between data races and weak/relaxed memory models.\n  PhD Career suggestions Getting started as a PhD student. By Matt Welsh.\n Don\u0026rsquo;t let school get in the way of your education. Classes and program requirements are important but what is far more important is becoming an expert in your area. If that means taking fewer classes each term so you have time to do some real research, so be it. Just dive in and have no fear.  You cannot really understand the problem until you\u0026rsquo;ve tried to solve it. Just dive in and start doing some research \u0026ndash; anything \u0026ndash; even if you think it might be a dead end.  Don\u0026rsquo;t read too much at first.  The problem with reading too much papers (especially at first) is that it can make it look like all of the interesting problems have already been solved. Certainly you should never read anything from 1960\u0026rsquo;s or 70\u0026rsquo;s or you will realize that it all has been done before (LLM: this also means a rich resource of new ideas can come from here!) At some point, say 2 or 3 months into a project \u0026ndash; you should take a step back and compare your approach to what has come before, and correct course if necessary. Arguably, all great systems are just reinventing ideas and reevaulating assumptions in light of changing technology trends, but don\u0026rsquo;t let that stop you. I made my career that way, you can too!  Keep track of the papers that you do read.  Come up with a good system for tracking the papers you have read, need to read, and take notes on them that you can easily reference later. Printing them out and scribbling in the margions is OK, though there may be more environmentally-friendly approaches. Apply Mac application [Papers], like iPhoto for PDF file. Mendeley, CiteULike, Bibdesk In grad school I just kept a huge text file of every paper I read and my notes on it. When it came time to write my thesis, this was invaluable for putting together the related work list (same for papers I wrote).  Finally, take a lot of notes.  Hell, I am never going to remember what I told them from one week to the next, so they need to keep track. (LLM: sharing notes for every meeting is good!)   How to have a bad career\nJim Kurose, Pieces of advice I wish my PhD advisor had given me.\nThe persistence and shouting matches in AI turing awardee\n \u0026ldquo;The London-born Dr. Hinton, 71, first embraced the idea as a graduate student in the early 1970s, a time when most artificial intelligence researchers turned against it. Even his own Ph.D. adviser questioned the choice.\u0026rdquo; \u0026gt; “We met once a week,” Dr. Hinton said in an interview. “Sometimes it ended in a shouting match, sometimes not.”  Find directions TODO\nMore  Bios  References: reference More Margo Seltzer References: People of Systems \u0026amp; Architecture: Margo I. Seltzer Career jouney It\u0026rsquo;s a circuitous journey that had no pre-planning. One of the things that I always tell my graduating students, particularly undergrads, is don\u0026rsquo;t try to plan out the rest of your life; figure out what you\u0026rsquo;re doing next. In large part, that\u0026rsquo;s because I never could have predicted where I ended up.\n Reading   How to read papers: Summarizing 12 months of reading papers. By Alastair Reid, Google. ~100 papers per year. Conference paper collections: ACM OpenTOC More  Seminars  Reference 1 Oakland 2020 Reference 1 Videos: https://www.youtube.com/channel/UC6pXMS7qre9GZW7A7FVM90Q/videos Opening Missing Doug Tygar, from UC berkeley. Awards. 104 out of 8xx. ~12% Mem Safety xMP Data oriented programming xen altp2m ptr -\u0026gt; hash -\u0026gt; key Buddy allocator context switch read-only permissions from outside of xMP domain. Talk with P. seL4: no trust on hardware; verified safe. PSOS: layer ontop of layer; verify one layer ontop of a verified layer. CHERI: security in market in 3~4 years.\n Paper Writing  UChicago: The Craft of Writing Effectively Valuable to the audience Valueable is determined by people people in and out over time, knowledge in and out over time. knowledge will be \u0026lsquo;abondoned\u0026rsquo; after it is done. What make it be important? Words: neitherless, however, although, inconsistent, reported, \u0026hellip; Words creating value to the readers. Words signaling community: widely, reported, \u0026hellip; Words for flow/transition: and, but, however, Words for Instability (tension/contradiction): anomaly, inconsistent, but, however, The code shared in the community to create values.\n Conferences  Security and System Conferences Traditions Deadlines: conferences +/- 1 month January: SP, ATC, CCS, Feburary: UsenixSec-4, SP, CCS March: SP, April: SOSP, SP, SecDev May: UsenixSec-1, OSDI, SP, CCS, June: NDSS, July: POPL, August: UsenixSec-2, CCS, ASPLOS, Asia CCS September: NDSS, October: EuroSP, November: UsenixSec-3, VEE, DAC, PLDI, PLDI, EuroSys, December: AsiaCCS, DSN, SP, Upcoming Conference Paper/notifcn Poster Date \u0026amp; Location SP\u0026rsquo;21 Dec 3 / Feb 19 May 23-27, 2021 San Francisco, CA SP\u0026rsquo;21 Sep 3 / Nov 20 May 23-27, 2021 San Francisco, CA SP\u0026rsquo;21 Jun 13, 1st / Feb 1st May 23-27, 2021 San Francisco, CA ACSAC\u0026rsquo;20 Jun 12, 2020 December 7-11, 2020, Austin, Texas Passed Dues Conference Paper/notifcn Poster Date \u0026amp; Location SecDev\u0026rsquo;20 May 25, 2020 Sep 28-30, 2020.\n Job Choices  References: Job and Career Advice A connection on LinkedIn asked me for help deciding between job offers. I can\u0026rsquo;t provide personalize advice, but here are my thoughts in general. 在LinkedIn上有朋友私信让我帮他在几个工作offer之间做出选择。虽然我不能\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/hacking/",
	"title": "Hacking",
	"tags": [],
	"description": "",
	"content": "Quick pinning CHERI source, good for both lib and kernel:\n__has_feature(capabilities), used in sys/, bin/, lib/, libexec/, contrib/, include/, stand/, and *.h, *.c;\ndefined(__CHERI__), used in sys/, lib/, contrib/, and *.h, *.c, *.S;\nCheri Simulation:\nSpike: https://github.com/CTSRD-CHERI/TestRIG\n Cross  Reference 1 Cross-compiling for CheriBSD In order to cross-compile projects such as NGINX or PostgreSQL for CheriBSD you will first need a full SDK: cheribuild.py cheribsd-sdk. The you can then run cheribuild.py postgres-cheri or cheribuild.py nginx-mips, etc. By default these projects will be installed into your CheriBSD rootfs under /opt and will therefore be automatically included the next time you build a disk image. See cheribuild.py --list-targets for a full list of targets.\n Sandbox_user  Error: seal violation when no ccall attributes Error: Could not print inside sandbox using default PCC/DCC Outside sandbox the printf function address is 0x4026,b0b0; Inside sandbox the printf function address is 0x401d,6ec0,0000,0000, which invalid address. Problem The problem comes out to be an issue of the calling convention. By default, functions are called by instruction jalr $t9, where t9 stores the entry address for the target function. When the target function is executed, the compiler still uses t9 to compute the address of variables and global functions, such as printf.\n Hello   Hello World Makefile for cross compiling Execution in CheriBSD Error: relocation R_MIPS_HIGHEST cannot be used against local symbol; cheri-unknown-freebsd-ld: error: relocation R_MIPS_HIGHEST cannot be used against local symbol; recompile with -fPIC \u0026gt;\u0026gt;\u0026gt; defined in /root/cheri/output/rootfs-purecap128/usr/libcheri/libcheri.a(libcheri_invoke_cabi.o) \u0026gt;\u0026gt;\u0026gt; referenced by libcheri_invoke_cabi.S:156 (/root/cheri/cheribsd/lib/libcheri/mips/libcheri_invoke_cabi.S:156) \u0026gt;\u0026gt;\u0026gt; libcheri_invoke_cabi.o:(cheri_invoke) in archive /root/cheri/output/rootfs-purecap128/usr/libcheri/libcheri.a  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/edu/",
	"title": "教育",
	"tags": [],
	"description": "",
	"content": " References:\n 《孟子－尽心上》  “得天下英才而教育之，三乐也”　——　《孟子－尽心上》\n 孟子曰：“君子有三乐，而王天下不与存焉。父母俱存，兄弟无故，一乐也。仰不愧于天，俯不怍于人，二乐也。得天下英才而教育之，三乐也。君子有三乐，而王天下不与存焉。”\n More  CS for Education  Top Wonderings Can computer help to make the history book unfakable? Histories have mostly been written by the man in power and thus prone to be faked in a way that is good for themselves. Other histories are from man with bias, or men with relatively limited vision, which cannot reflect the real history. Similar to the (fake or inaccurate) news media nowadays. How to validate the information in the correct way before it is being released to us?\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/attack-rop/",
	"title": "Attack Rop",
	"tags": [],
	"description": "",
	"content": "Reference 1\n Persistent Data-only Malware: Function Hooks without Code  Reference 1 Persistent Data-only Malware: Function Hooks without Code. NDSS, 2014. ↩   reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ripe/",
	"title": "RIPE: Runtime Intrusion Prevention Evaluator",
	"tags": [],
	"description": "",
	"content": " 850 buffer overflow attack forms.\n RIPE 1 extends 2003 NDSS 2 paper from 20 attack forms to 850 attack forms.\nDimensions Location of the buffer in memory, target code pointer, overflow technique,\nD1: Location  Stack Heap BSS segment Data segment  D2: Target Code Pointer  Return address Old base pointer: The previous contents of the EBP register, which is used to reference functin arguments and local variables Functino pointers: Generic function pointers allowing programmers to dymanically call different functions from the same code Longjmp buffers: Setjmp/longjmp is a technique which allows programmers to easily jump back to a predefined point in their code. Vulnerale Structs: Structs which group a buffer and a function pointer and can be abused by attackers to overflow from one to the other.  D3: Overflow Technique  Direct overflow: target is adjacent to the overflowed buffer, or can be reached by sequentially overflowing from the buffer. Idirect overflow: use generic pointers to store target address, and overwrite the target with attack-controlled data. Such as ones used to bypass StackGuard canary.  D4: Attack Code  Shellcode without NOP sled: This option can be useful in testing the accuracy of attacks as well as challenge countermeasures that rely on the detection of specific code patterns (such as the presence of a set of 0x90 bytes (NOP)) in the process\u0026rsquo; address space. Shellcode with NOP sled: This is the most-used form of shell code that prepends the attacker\u0026rsquo;s functionality with a set of NO-oPeration instructions to improve the attacker\u0026rsquo;s chances of correctly redirecting the execution-flow of the program into his injected code. Shellcode with polymorphic NOP sled: In this case, the NOP sled is not the standard set of 0x90 bytes but a set of instructions that can be executed without affecing the correctness of the actual attack code. Akritidis et al. 3 conducted a study where, among others, they showed how obfuscation and encryption can be used by attackers to evade Network Intrusion Detection Systems (NIDS). Return-into-libc: e.g. using the system libc function to execute an interactive shell. RIPE uses system() for the spawning of an interactive shell and creat() for creating new files. ROP: ROP is the generalization of Return-into-libc, where chunks of functionality from existing code (gadgets) and combine them to create new functionality. RIPE implements a ROP attack, but does not implement stack-pivoting techniques.  D5: (n-contain) function Abused A user can choose to perform mthe buffer overflow with memcpy(), strncpy(), sprintf(), snprintf(), strcat(), strncat(), sscanf(), fscanf(), and also with \u0026ldquo;homebrew\u0026rdquo;, a loop-based equivalent of memcpy.\nn-containing functions are designed to take the target buffer size into account which should prevent buffer overflows. The size however, is provided by the developer (static or calculated) and thus a miscalculation can cancel-out the protection offered by these functions.\nKnown caveats include the fact that parameter n means total buffer size for strncpy() but remaining buffer space for strncat()4, and if n is undefined for instance because of a NULL value in the length caculation strncpy() will allow for buffer overflow as shown in CVE-2009-40355:\nline1 = getNext(line); // May return NULL if ((n=line1 -line) \u0026gt; 255) { n = 255; } strncpy(buf, line, n); // n undef or \u0026lt; 0 RIPE: Runtime Intrusion Prevention Evaluator. ACSAC, 2011. ↩ A comparative study of publicly available tools for dynamic buffer overflow prevention. NDSS, 2003. ↩ Akritidis et al. Stride: Polymorphic sled detection through instruction sequence analysis. 2005. ↩ Howard, M. Evils of strncat and strncpy - Answers. http://blogs.msdn.com/b/michael_howard/archive/2004/12/10/279639.aspx ↩ CVE-2009-4035 [22] ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/logs/",
	"title": "Logs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/stores/",
	"title": "Stores",
	"tags": [],
	"description": "",
	"content": "Reference:\n CCall Examples  References: [1] Stack Underflow //file: ./bin/cheritest/cheritest_libcheri_trustedstack.c /* * Perform a return without a corresponding invocation, to underflow the * trusted stack. */ void test_sandbox_trustedstack_underflow(const struct cheri_test *ctp __unused) { struct cheri_object returncap; void * __capability codecap /* currently ignored: asm (\u0026#34;$c1\u0026#34;) */; void * __capability datacap /* currently ignored: asm (\u0026#34;$c2\u0026#34;) */; returncap = libcheri_make_sealed_return_object(); codecap = returncap.co_codecap; datacap = returncap.co_datacap; /* * TODO: the branch delay slot has been removed.\n SSH  References: [1]\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/inst-encoding/cap-mode/",
	"title": "Cap Mode",
	"tags": [],
	"description": "",
	"content": " References:\n More  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-isa/cheriot/",
	"title": "CHERIoT",
	"tags": [],
	"description": "",
	"content": " References:\n OS: https://github.com/Microsoft/cheriot-rtos Sail Model: https://github.com/Microsoft/cheriot-sail RTL: https://github.com/Microsoft/cheriot-ibex\n Blog: https://msrc-blog.microsoft.com/2022/09/06/whats-the-smallest-variety-of-cheri/\n News 202302: https://www.microsoft.com/en-us/research/publication/cheriot-rethinking-security-for-low-cost-embedded-systems/\n Whitepaper: https://www.microsoft.com/en-us/research/uploads/prod/2023/02/cheriot-63e11a4f1e629.pdf\n  Overview Smallest CHERI (Portmeirion Project)\n RISC-V32. C extension required. 15 registers 32-bit address space A signle privilege level: Machine mode only. No virtual memory. Optional PMP. Optional floating point.  Based on ibex.\nIbex Implementation cite: https://github.com/Microsoft/cheriot-ibex\nRV32IMCB + CHERI.\nEither with 2-stage or 3-stage pipeline, configurable.\nPassed FPGA validation, and undergoing synthesization and PPA analysis (as of 20230204, commit)\nInstructions CHERI-ibex ISA: 30+ instructions, including:\n query or test capabilities (10)  cgetaddr, cgetbase, cgetlen, cgetperm, cgettag, cgettop, cgettype, ctestsubset, csetequalexact, csub  modify or derive capabilities (15)  auicgp, auipcc, candperm, ccleartag, cincaddr, cincaddrimm, cmove, cram, crrl, csetaddr, csetbounds, csetboundsexact, csetboundsimm, cseal, cunseal  load/store capabilities from memory (2)  clc, csc  control the program flow (2)  cjal, cjalr  access special cap registers (SCR): cspecailrw\n compressed instructions are extended for capabilities:\n c.incaddr4cspn c.incaddr16csp c.jal c.jalr RV64 c.ld reused for c.clc RV64 c.sd reused for c.csc   Register File Cheri-Ibex: cheri_regfile.sv, configurable number of general purpose registers -\u0026gt; CherIoT Capabilities.\nLoad-store unit Cheri-Ibex:\n data bus 33-bit, MSB 1-bit is used as a valid tag to differentiate between capabilities and normal integer data.\n modified LSU to support atomic capability load/store transactions.\n  Configuration and status registers CSRs defined in rtl/ibex_cs_registers.sv\nNewly added as in iot spec:\n MTCC (address 28), replaces mtvec MTDC (address 29) MScratchC (address 30) MEPCC (address 31) PCC (address?)  For debug support:\n CDPC (24) CDScratch0 (25) CDScratch1 (26) CDBGCTRL (27)  Backward Compatibility when cheri_pmode_i=1, CHERIoT instructions can still execute, however all access rules are disabled and any binary code generated by non-Cheri RV32 compilers can run unmodified in cheri-ibex.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/temporal-logic/ctl/",
	"title": "CTL",
	"tags": [],
	"description": "",
	"content": " References:\n Lecture 7, Computation Tree Logics  Path Quantifier $A$: for every path.\n$E$: there exists a path.\nLinear-time operators $\\boldsymbol{X}_p$: $p$ holds next time.\n$\\boldsymbol{F}_p$: $p$ holds sometime in the future.\n$\\boldsymbol{G}_p$: $p$ holds globally in the future.\n$p\\boldsymbol{U}q$: $p$ holds until $q$ holds.\nPath Formulas and State Formulas More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/upec/",
	"title": "UPEC",
	"tags": [],
	"description": "",
	"content": " References:\n Processor Hardware Security Vulnerabilities and their Detection by Unique Program Execution Checking. By Mohammad Rahmani Fadiheh, et. al. 2018 arXiv, 2019 DATE  UPEC: Unique Program Execution Checking.\nOrc Attack  Leverage the RAW(Read after write) hazard: load latency is longer when RAW happens. Assumptions: (simplified for easy understanding)  each cache line is selected based on lower 8 bits; a total of $2^8=256$ cache lines.  Attack:  guess a possible address #test_value; write a value at the #test_value load a secret to a register lw x4, 0(x1), where x1 is #protected_addr; ==\u0026gt; this will throw an exception, x4 will not have the secret value (not architectual visible). perform a load with secret as address: lw x5, 0(x4); ==\u0026gt; this will not be architecturally visible (x5 not updated), but the instruction already in the pipeline and will issue a cache transaction. If #test_value and 0(x4) in the same cache line, then a RAW hazard will happen, and  the instruction sequence will have higher latency due to the RAW hazard. ==\u0026gt; this timing latecy will be used to detect whether the possible hazard exists. their lower 8 bits are the same. ==\u0026gt; the secret will be leaked by 8 bits.    Design Unique Program Execution Checking.\nSecurity Property Definition Two sets of state variables  State variables associated with the content of its memory; State variables associated with all other parts of the hardware, the logic parts.  Microarchitectural State Variable: belonging to the logic part of the computing system\u0026rsquo;s microarchitecture.  Registers, buffers, flip-flops.  Architectural State Variable: subset of microarchitectural state variables that define the state of program execution at the ISA level (excluding the program state that is represented in the program\u0026rsquo;s memory).   Secret Data  Secret Data $D$, at Protected Location $A$.  Unique Program Execution  Unique Program Execution. A program executes uniquely w.r.t. a secret $D$ if and only if the sequence of valuations to the set of architectural state variables is independent of the values of $D$, in every clock cycle of program execution.  In other words, unique program execution means that different values of $D$ does not lead to different values of the program\u0026rsquo;s architectural state variables, nor lead to different time points when these values are assigned.   Confidentiality  Confidentiality/Observalibity. A set of secret data $D$ in a protected location $A$ is confidential if and only if any user-level program executes uniquely w.r.t. $D$. Otherwise, $D$ is observable.  Property Checking The requirement of unique program execution is formalized as a \u0026ldquo;property\u0026rdquo; expressed in a property language which is understood by a (commercially available) tool for property checking.\nChallenge: current tools for property checking are build for functional design verification. In order to make property checking applicable to UPEC, we present a tailor-made computational model and formulate a specific property to be proven on this model.\nUPEC Model  Automatically derived model: This model (in Figure 3) can be derived automatically from the RTL description of the design and only requires the user to provide the protected region.\n Two identical instrances: $SoC_1$ and $SoC_2$ are two identical instances of the logic part of the SoC under verification.\n Two almost same set of memory: $Memory_1$ and $Memory_2$ hold the same set of values except for the memory location of a defined secret data.\n  UPEC Property For a system to be secure w.r.t. convert channel attacks, the computational model derived from the design\u0026rsquo;s RTL description has to fulfill the following property expressed in the CTL property language [c36]:\n No Covert Channel Property: $\\boldsymbol{AG}$(secret_data_protected $\\wedge$ micro_soc_state_1 = micro_soc_state_2 $\\rightarrow \\boldsymbol{AG}$ soc_state_1 = soc_state_2)\n where $\\boldsymbol{AG}$: the following condition must be fulfilled at all times and for all possible runs of the system (\u0026ldquo;A for All paths, G for Globally\u0026rdquo;). Note: CTL symbols\n where micro_soc_state is a a vector of all microarchitecture state variables.\n where soc_state is some vector of state variables which includes, as a subset, all architectural state variables.\n where secret_data_protected is a constraint specifing that a protection mechanism in the hardware is enabled for the secret data memory location.\n   The property fails, if and only if, there exists a state, soc_state, such that the transition to the next state, soc_state\u0026rsquo;, depends on the secret data.\nUPEC outputs Counterexamples of unique program execution.\n $L-alert$, Leakage alert.\n $P-alert$, Propagation alert.\n  Evaluation (2019 DATE) Rocket/OneSpin 360 DV-Verify Rocketchip, a single-core SoC with in-order pipelined processors and separate data and instruction level-1 cache.\nOneSpin 360 DV-Verify, a commercial property checker.\n Original Rocketchip Variant a, with Meltdown;  Modified the design: a cache line refill is not canceled in case of an invalid access. Attack: the illegal access itself is not successful but raises an exception, the cache content is modified and can be analysed by an attacker. Highlight: this covert channel is based on an in-order pipeline, instead of an out-of-order as previous reports.  Variant b, with Orc attack.  Conditionally bypass one buffer.   Results:\n UPEC captured all vulnerabilities. found an ISA incompliance in the Physical Memory Protection (PMP) unit of the original design.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/riscv/j-ext/",
	"title": "J Extension",
	"tags": [],
	"description": "",
	"content": " References:\n Pointer Masking Proposal, 2022-10  Pointer Masking Feature of RISC-V: when enabled, the MMU will ignore the top N bits of the effective address. Then the application can use these top N bits in their own ways.\nMost commonly, those bits are used to store various type of tags, which can be leveraged by a number of hardware/software features, including sandboxing mechanisms and dynamic safety checkers such as HWASAN.\nThis extension only adds the pointer masking functionality. Extensions that make use of the masked bits will be ratified independently and layered on top of the basic pointer masking functionality.\nTerminologies Effective address. As defined in the RISC-V Base ISA.\nMasked bits. The top N bits of an address, where N is a configurable parameter (we will use N consistently throughout this document to refer to this parameter.)\nMasked address. An effective address after the ignore transformation has been applied to it.\nAddress translation mode. As defined in RISC-V privileged specification. Could be Base, Sv39, Sv48, and Sv57.\nAddress canonicity. As defined in RISC-V privileged spec. Defined based on the privilege mode and address translation mode. Canonicity requirement:\n for translated addresses all bits in the unused portion of the address must be the same as the Most Significant Bit (MSB) of the used portion (for virtual addresses).  Example: when page-based 48-bit virtual memory (Sv48) is used, instruction fetch addresses and load/store effective addresses, which are 64 bits, must have bits 63-48 all set to bit 47, or else a page-fault exception will occur.  for untranslated addresses (i.e., for Base and M-mode), the high bits must be all zeros.  NVBITS. The upper bits within an address that have no effect on addressing memory and are only used for canonicity checks. For example, in Sv48, these are bits 63-48.\nVBITS. The bits within an address that affect which memory is addressed.\nThe ignore transformation More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/intel-ccc/",
	"title": "Intel Ccc",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/class-math220/",
	"title": "Class Math220",
	"tags": [],
	"description": "",
	"content": " References:\n Match 220, Formal Methods, Stan Warford @ Pepperdine University.  State: a list of variables and there values.\nTextual substitution (x + 2y) [x,y := y,x]  is not the same as\n(x + 2y) [x := y] [y := x]  ==\u0026gt; the property of textual substitution.\nExample:\n((a + b) x ) [b:=x] [x:=b] ==\u0026gt; (a + b) b  ((a + b) c) [b:=x] [x:=b] ==\u0026gt; (a + b) c  \u0026mdash;\u0026gt; Provisal (provided that\u0026hellip;)\n$ If \\not occurs ( \u0026lsquo;x\u0026rsquo;, \u0026lsquo;E\u0026rsquo; )$, then\n$ E[y:=x][x:=y] = E $\n\u0026ndash; a property of textual substitution.\nInference rule  a horizontal line  premise or hypothesis above the the line. conclusion below the line.  The premise is assumed to be true in all states.  Example:\n$2x = 10$ / $x = 5$\nEquality four laws/properties of equality: R S T L.\n Reflexitivity: x = x. Symmetry: (x=y) = (y=x) ; also known as \u0026lsquo;commutative\u0026rsquo; law. Transitivity: (X=Y, Y=Z) / (X=Z) ; Leibniz. (X=Y) / (E(z:=X) = E(z:=Y))  Function Evaluation A function is a rule for computing a value from another value.\nUse dot . as function application g.z, in place of parenthesis: g(z).\ng(z) = 2*x + 6 g.z : 2*x + 6 . (function application) g(2 + 3) g.2 + 3  Function evaluation is based on textual substitution. Always do the t.s. simultaneously.\nAssignment Statement Textual substitution: :=.\nUses the same symbol as text substitution.\ny:= y+1\n   Math/formal methods c++ Java Python     := =   = ==    Hoare Tripple  {P} S {Q} P: precondition S: statement Q: postcondition  Assignment Definition of assignment.\n { R [ x := E]} x:=E {R} x := E : assignment statement, \u0026quot;:=\u0026quot; means \u0026quot;gets\u0026quot;, to be executed. R[x:=E] : textual substitution. \u0026quot;:=\u0026quot; means \u0026quot;replaced by\u0026quot;. The precondition is calculated from the postcondition.  Calculate the precondition from the postcondition:\n{??} x:=x+1 {x\u0026gt;4} \u0026ndash;\u0026gt; {x + 1 \u0026gt; 4} x:=x+1 {x\u0026gt;4} \u0026ndash;\u0026gt; {x \u0026gt; 3} x:=x+1 {x\u0026gt;4}\n{??} y:=6 {x*y \u0026gt; 0} \u0026ndash;\u0026gt; {x*6 \u0026gt; 0} y:=6 {x*y \u0026gt; 0} \u0026ndash;\u0026gt; \u0026hellip;\n{??} x:=x*2 { x=10 } \u0026ndash;\u0026gt; {x*2 = 10} x:=x*2 {x=10} \u0026ndash;\u0026gt; \u0026hellip;\n{??} x:=y { y=6 } \u0026ndash;\u0026gt; {y=6} x:=y {y=6} \u0026ndash;\u0026gt; \u0026hellip;\nDefinition of multiple assignments:\nx,y := y,x // Python: `x,y = y,x`  Hoare Triples for multiple assignments:\n{y \u0026gt; x} x,y := y,x {x \u0026gt; y} {x + i = 1 + 2 + ... + (i + 1 - 1)} x,i := x + i, i + 1 {x = 1 + 2 + ... + (i - 1)} {x + i = 1 + 2 + ... + (i + 1 - 1)} i,x := x + i, i + 1 {x = 1 + 2 + ... + (i - 1)}  Boolean Expressions Expressions: constants + variables\nBoolean expressions:\n Constants: true/T, false/T Unary operator: $\\neg$ Binary operators:  $=$, equals, for booleans or numbers. $\\equiv$, equivales, for booleans only. $\\neq$, $\\not\\equiv$ or and, =\u0026gt; implies \u0026lt;= follows from nand, not and nor, not or  Variables:  Truth Table Satisfied A boolean expression P is satisfied in a state, if\nP is satisfiable, if\nPredicate A predicate is a function that returns type boolean.\nValid Boolean expression P is valid if it is satisfied in every state.\nValid(P) is a predicate that returns true if P is a valid boolean expression and false otherwise.\ndual dual of a boolean expression P, $P_D$, is constructed from P by interchanging occurrences of\n true and false, $\\wedge$ and $\\vee$, $\\equiv$ and $\\not \\equiv$, $\\Rightarrow$ (implies) and $\\nLeftarrow$ (not follow from), $\\Leftarrow$ (follow from) and $\\not \\Rightarrow$ (not implies).  P and $\\neg P_D$ are not the same expression.\nMetatheorem Duality (2.3)\n$valid(P) \\equiv valid(\\neg P_D) $\n$valid(P\\equiv Q) \\equiv valid(P_D \\equiv Q_D)$\nSufficient/Sufficiency and Necessary/Necessity Equality vs. Equivalence $=$ and $\\equiv$ have the same truth table.\n$=$ is for numbers or booleans.\n$\\equiv$ is only for booleans.\nThree differences:\n $=$ has higher precedence than $\\equiv$.  Example: $x*y=0 \\equiv x=0 \\vee y=0$  $=$ is conjunctional while $\\equiv$ is not.  Example: $b=c\u0026lt;d$ means $b=c \\wedge c\u0026lt;d $ Example: $b=c=d$ means $b=c \\wedge c=d $  $\\equiv$ is associative while $=$ is not.  Example: suppose state (b, false) (c, false) (d, true) $(b\\equiv c) \\equiv d$ is the same as: $b \\equiv (c\\equiv d)$   Prove:\nSince $=$ is conjunctional, it cannot be associative.\n inside computer logic circuits, are $\\vee, \\wedge, \\equiv$, \u0026hellip; but mathematitions, do not use $\\equiv$.\n Propositional Calculus Calculus: process of reasoning by manipulating(calculating with) symbols.\nPropositional Calculus: a method of calculating with boolean expressions that involve propositional variables.\nSymbols: conjunctions, disjunctions, implies. \u0026hellip;\nProposition: a declarative sentence that is either true or false.\nAxiom: a boolean expression that defines the properties of boolean operators.\n Axioms are never proved. They are assumed to be valid.\nEuclidean Geometry: 13 Euclidean /wukliam/ axioms.\n Theorem: Either (1) an axiom or (2) a thorem that is proved equal to an axiom or a previously proved theorem.\nAxiom, Associativity of $\\equiv$: $((p \\equiv q)\\equiv r) \\equiv (p \\equiv (q \\equiv r))$. (3.1)\nAxiom, Symmetry of $\\equiv$: $p\\equiv q \\equiv q \\equiv$ p. (imagining as follows: $(p\\equiv q) \\equiv (q \\equiv p )$). (3.2)\nAxiom, Identity of $\\equiv$: $true \\equiv q \\equiv q$. (3.3)\nExercise:\nProve: $p \\equiv p \\equiv q \\equiv q$\nProof:\n$ p \\equiv p \\equiv q \\equiv q $\nstep1: apply 3.2 Aiom: $(p \\equiv q \\equiv q) \\equiv p $, replace $(p \\equiv q \\equiv q)$ with p.\n$ p \\equiv p $\nstep2: replace first p by $(p \\equiv q \\equiv q)$\n$p \\equiv q \\equiv q \\equiv p $\napply 3.2. //\nLatin: Q.E.D. it has been demostrated.\nidentity Identity:\ntrue is the identity of $\\equiv$.\np = (true $\\equiv$ p)\n(p $\\equiv$ true) = p.\nProve: true.\nstep1: apply 3.3. with $q\\equiv true$\n$true \\equiv true \\equiv true$ ==\u0026gt; $ true \\equiv true$\nstep2: apply 3.3, replace 2nd true with $q \\equiv q$\n$true \\equiv q \\equiv q$\napply 3.3. //\nProve: $p \\equiv p$\nstep1: apply 3.3. let p:=q\n$true$.\nstep2: apply 3.4. //\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/kami/",
	"title": "Kami",
	"tags": [],
	"description": "",
	"content": " References:\n Kami: A Platform for High-Level Parametric Hardware Specification and Its Modular Verification, 2017, ICFP Wednesday @ 1130, 2016. Kami A Framework for RISC V HW Verification Murali Vijayaraghavan, MIT  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/spec-sail/islaris/",
	"title": "Islaris: Verification of Machine Code Against Authoritative ISA Semantics",
	"tags": [],
	"description": "",
	"content": " References:\n Islaris: verification of machine code against authoritative ISA semantics  Problem Machine code verification:\n some critical code manipulates arch features that are not exposed in higher-level languages, e.g., to access system registers to install exception vector tables, or to configure address translation; this is necessarily written in assembly. verification without needing trust or verification of any compilation or assembly steps. verify the machine code after any modifications introduced by linking or initialisation (perhaps parametrically w.r.t. these). some code is written in assembly for performance reasons.  w.r.t. With Respect To.\nGrand Challenge:\nIn low-level code verification, it remains a grand challenge to develop tools that are demonstrably sound w.r.t. the underlying architecture and support reasoning about all of it, including all system features.\nKey aspects:\n Relaxed-memory concurrency.  underlying models for user code; systems concurrency; low-level-code verifications targeting relaxed memory, e.g., for hypervisors.  Fidelity and completeness w.r.t. the underlying instruction-set architecture (ISA), the sequential semantics of machine instructions.\n hand-write ISA semantics, for the fragment of the ISA needed \u0026ndash; typically a small user-level fragment of the ISA.  Typically are simplified in various ways, and have, at best, only limited validation with respect to the architectural intent or hardware implementations.  For x86, hand-written larger fragments in ACL2[c25], and empirical and hand-written models [c16,c17,c30]. Recently for Armv8-A and RISC-V:  Comprehensive: complete enough to boot an operating system or hypervisor Authoritative. Expressed in Sail [c6,c8,c9,c44,c53].  Problem:\n the fidelity and coverage also makes these models intimidatingly large and complex, and only sometimes practical for mechanised proof.\n Sail Armv8-A: 113k lines; RISC-V: 14K lines; (non-whitespace lines of specification) For Armv8-A:  Isabelle version (auto-generated from Sail) has been used for some metatheory [c6,chapter8], [c9], but not for program verification. Coq version even simple definition unfoldings take an unreasonabley long time or fail to terminate.   e.g. Armv8-A instruction add sp, sp, 64\n with 146 lines in Sail, in 9 functions; do much more than just computation:  compute arithmentic flags; support subtraction as well as addition; other registers; sp as a banked family of regitsers, selected based on the current exception level register value.   e.g. ldrb instruction to load a byte.\n over 2000 lines of specification (in Sail?) alignment checks; big/little endianness; tagged memory; different address sizes; exception levels; the store and prefetch instructions that are specified simultaneously.     This paper: focus on the fidelity and completeness of the model.\nThe challenge is how one can reason above such models while avoiding up-front idealisation, so that we retain the ability to reason about the whole architecture, and the confidence in the authoritative model.\nIslaris\u0026rsquo; Insight: the verification problem can be split into two subtasks, separating the irrelevant complexity from the inherent complexity, so that each can then be solved by techniques well suited for the respective task: SMT-based symbolic evaluation, and a mechanised program logic.\nIrrelevant Complexity Many aspects of the ISA definitions are irrelevant, because they do not influence the results of instructions or are ruled out by the system configuration.\nTo handle this irrelevant complexity, the Isla symbolic evaluation tool for Sail ISA specifications are extended.\nIsla:\n takes an opcode and SMT constraints, and symbolically evaluates the Sail model using an SMT solver. e.g.  Input: the exception-level register has a specific value or some general-purpose register is aligned. Output: a trace of the instruction\u0026rsquo;s register and memory accesses, constrained by the SMT formulas.  This can be much simpler than the full Sail definition, without irrelevant and unreachable parts, and is in a much simpler language.  Inherent Complexity Problem Scope:\n Address and memory manipulation. Higer-order reasoning with code-pointers. Reasoning about the relevant aspects of the systems architecture. Modular reasoning about user-defined specifications.  Islaris:\n define a higer-order separation logic for the Isla traces that produces machine-checkable proofs, based on Iris[c32].\n adapts Lithium, to design proof automation that makes the verification practical.\n Lithium: an automated (separation) logic programming language originally designed for the RefinedC type system[c56]. Lithium\u0026rsquo;s efficiency:  can be retained even without the type information relied on by RefinedC. retained by using the separation logic context to guide proof search.    Overall automation Proof automation is comparable to previous foundational approaches [c13] [c41], but for full ISA semantics rather than a simple intermediate language.\nworkflow Inputs:\n Binary machine code to verify Constraints (sys configuration, used for pruning) user-defined specificatino in Islaris separation logic. (Used for Coq proof) manual proof steps in Coq.  Tool Dependencies:\n Coq. ISA Sail Model. SMT solver. Iris. Lithium.  ISA spec pruning and Trace generation:\n Islaris frontend  invokes Isla to generate a trace describing the effects of the instructions based on the Sail ISA model. Isla symbolic evaluation prunes the part of ISA specification that cannot be reached under the given constraints. Traces generated by Isla is simplified based on the ISA model. Islaris output a deep embedding of this trace in Coq.   Coq generation:\n Isla trace in Coq. Sail ISA model in Coq. Translatino validation between Isla trace in Coq and Sail ISA model in Coq.  Islaris proof automation in Coq:\n Islaris higher-order separation logic implemented based on Iris. Lithium-based proof automation.  produces machine-checkable proofs.   Outputs:\n Proof result.  Limitations  Islaris currently assumes single-threaded execution.\n Supporting a sequentially consistent concurrency semantics would not be hard. Armv8-A or RISC-V relaxed-memory concurrency models requires a more sophisticated separation logic, the subject of active research.  Islaris also does not currenlty support self-modifying code or address translation, which involve additional forms of relaxed-memory concurrency, likewise subjects of active research [c60] [c61]\n Our underlying ISA semantics includes translation-table walks, but here we only use machine configurations that turn translation off. ???  Focus on 64-bit little-endian cases.\n on small but tricky examples.\n scaling remains future work.\n  Evaluation More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/separation-logic/",
	"title": "Separation Logic",
	"tags": [],
	"description": "",
	"content": " References:\n Separation Logic, Peter O\u0026rsquo;Hearn  Separation logic, first developed by O\u0026rsquo;Hearn and Reynolds, is an extension of Hoare\u0026rsquo;s logic which addresses reasoning about program that access and mutate data structures.\nIt includes a \u0026ldquo;frame rule\u0026rdquo; which enables more compact proofs and specs of imperative programs than before because of its support for local reasoning, where specification and proofs concentrate on the portion of memory used by a program component, and not the entire global state of the system.\nLocal reasoning helps with the scalability of proofs done in automatic and semi-automatic verification and program analysis tools.\nSeparation logic has also been applied to concurrent systems, using the separation conjunction to divide reasoning amongst processes or threads in order to make reasoning more efficient.\nLocal Reasoning Reference:\n Local Reasoning about Programs that Alter Data Structures. Peter O\u0026rsquo;Hearn, John Reynolds, and Hongseok Yang.\n [A primer on Separation Logic (and Automatic Program Verification and Analysis)](). Peter W. O\u0026rsquo;Hearn.\n  Motivation Reasoning about pointers.\nPointer aliasing, arising from several pointers to a given cell. Then an alteration to that cell may affect the values of many syntactically unrelated expressions.\nInsights:\n We suggest that the source of this mismatch is the global view of state taken in most formalisms for reasoning about pointers. In constrast, programmers reason informally in a local way.\n Data structures algorithms typically work by applying local surgeries that rearrange small parts of a data structure, such as rotating a small part of a tree or inserting a node into a list.\nInformal reasoning usually concentrate on the effects of these surgeries, without picturing the entire memory of a system.\nAssumptions about the local reasoning viewpoint:\n To understand how a program works, it should be possible for reasoning and specification to the confined to the cells that the program actually accesses. The value of any other cell will automatically remain unchanged.\nLocal reasoning is intimately tied to the complexity of specifications. Often, a program works with a circumscribed collection of resources, and it stands to reason that a specification should concentrate on just those resources that a program accesses. For example, a program that inserts an element into a linked list need know only about the cells in that list; there is no need (intuitively) to keep track of all other cells in memory when reasoning about the program.\n Storage Model Pointer Arithmetic model.\nThe model has two components: the store and the heap.\nThe store is a finite partial function mapping from variables to integers.\nThe heap is indexed by a subset Locations of the integers, and is accessed using indirect addressing [E] where [E] is an arithmetic expression.\n$Ints \\triangleq \\{\u0026hellip;, -1,0,1,\u0026hellip;\\}$\n$Atoms, Locations \\subseteq Ints$\n$Variables \\triangleq \\{x,y,\u0026hellip;\\}$\nSpatial Conjunction  The central idea of the approach studied in this paper is of a \u0026ldquo;spatial conjunction\u0026rdquo;: P * Q, that asserts that P and Q hold for separate parts of memory. The conjunction provides a way to compose assertion that refer to different areas of memory, while retaining disjointness information for each of the conjuncts.\n In general, an assertion $P$ denotes a set of states, and $P*Q$ is true of a state just if its heap/RAM commponent can be split into two parts, one of which satisfies P and the other of which satisfies Q.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/tools/scade/",
	"title": "SCADE",
	"tags": [],
	"description": "",
	"content": " References:\n 一文读懂基于SCADE模型的形式化方法  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm/basic-concepts/monads/",
	"title": "Monads",
	"tags": [],
	"description": "",
	"content": " References:\n Monad Brian Beckman: Don\u0026rsquo;t fear the Monad What is a Monad? - Computerphile Haskell: Monads. A 5-minute introduction  Monads Monad: a software design pattern.\n In functional programming, a monad is a software design pattern with a structure that combines program fragments (functions) and wraps their return values in a type with additional computation.\nGeneral purpose languages use monads to reduce [boilerplate code] needed for common operations (such as dealing undefined values of fallible functions, or encapsulating bookkeeping code.)\nFunctional languages use monads to turn complicated sequences of functions into succint pipelines that abstract away control flow, and side-effects.\n Boilerplate code: In computer programming, boilerplate code, or simply boilerplate, are sections of code that are repeated in multiple places with little to no variation. When using languages that are considered verbose, the programmer must write a lot of boilerplate code to accomplish only minior functionality.\n All about monads: https://wiki.haskell.org/All_About_Monads\n Monads is a way to structure computations in terms of values and sequences of computations using typed values. Monads are strategies for solving coding problems that recur often, regardless of what you are writing. More than this, monads help make strategies composable: Combining computations into more complex computations. Examples: Maybe type, the List, and I/O are monads (in Haskell).  List solves a common problem: you need a very basic collection of items of the same type, with some easy-to-understand behavior and performance characteristics. Maybe type: rescues you from having to write lots of null pointer checks \u0026ndash; or else debug code that does not have enough of them. I/O makes it possible to interact with a program at all.   a monadic function is a function with a single argument, written to its right. cite\n A short and simple answer: a monadic function is one whose return data signature/type is the same as its input data signature/type. cite\n Monad \u0026ndash; Computation Builder: monad is a pattern for chaining operations. It looks a bit like method chaining in object-oriented languages, but the mechanism is slightly different. The pattern can be used in any language which support higher-order functions (that is, functions which can take other functions as arguments). cite\n For those comming from language where the semicolon is a statement separator in imperative control flow, the metaphor of \u0026ldquo;Programmable Semicolon\u0026rdquo; has helped many understand the advantages of monads. The monad determines how combined computations form a new computation and frees the programmer from having to code the combination manually each time it is required. Think of monads as \u0026ldquo;statically typed filters\u0026rdquo; (in the Unix sense of \u0026ldquo;pipes and filters\u0026rdquo;) and you may be halfway there.\n  Origin  Both the concept of a monad and the term originally come from category theory, where a monad is defined as a [functor] with additional structure.\n functor: In functional programm, a functor is a design pattern inspired by the definition from category theory that allows one to apply a function inside a generic type without changing the structure of the generic type.\nUsage Scenarios More exactly, a monad can be used where unrestricted access to a value is inappropriate for reasons specific to the scenario.\nIn case of Maybe monad, it is because the value may not exist.\nIn case of IO monad, it is because the value may not be known yet, such as when the monad represents user input that will only be provided after a prompt is displayed.\nIn all cases the scenarios ???\nIn Haskell I/O In Haskell, monads play a central role in the I/O system. It is not essential to understand monads to do I/O in the Haskell, but understanding the I/O monad will improve your code and extend your capabilities.\nThree Properties that are useful  Modularity. They allow computations to be composed from simpler computations and separate the combination strategy from the actual compuations being performed. Flexibility. They allow functional programs to be much more adaptable than equivalent programs written without monads. This is because the monad distills the computational strategy into a single place instead of requiring it be distributed throughout the entire program. Isolation. They can be used to create imperative-style computational structures which remain safely isolated from the main body of the functional program. This is useful for incorporating side-effects (such as I/O) and state (which violates referential transparency) into a pure functional language like Haskell.  Monad Components Monadic type + Unit operation + Bind operation (Monadic functions).\nMonadic Type: A type (Maybe)\nUnit Operation: A type converter (Just (x))\nBind Operation: A combinator for monadic functions (\u0026gt;\u0026gt;= or .map())\nExample: the Maybe type.\nExample in Rust // enum Maybe\u0026lt;T\u0026gt; { Just(T), Nothing, } // return nothing when the function fails. fn divide(x: Decimal, y: Decimal) -\u0026gt; Maybe\u0026lt;Decimal\u0026gt; { if y == 0 { return Nothing } else { return Just(x / y) } } // divide(1.0, 4.0) -\u0026gt; returns Just(0.25) // divide(3.0, 0.0) -\u0026gt; returns Nothing  // use if to test whether Maybe has a value. let m_x = divide(3.14, 0.0); // see divide function above // The if statement extracts x from m_x if m_x is the Just variant of Maybe if let Just(x) = m_x { print!(\u0026#34;answer: \u0026#34;, x) } else { print!(\u0026#34;division failed, divide by zero error...\u0026#34;) } // use pattern matching let result = divide(3.0, 2.0); match result { Just(x) =\u0026gt; print!(\u0026#34;answer: \u0026#34;, x), Nothing =\u0026gt; print!(\u0026#34;division failed, we\u0026#39;ll get em next time.\u0026#34;), } // Use Monads to compose functions that returns `Maybe` together: fn chainable_division(maybe_x: Maybe\u0026lt;Decimal\u0026gt;, maybe_y: Maybe\u0026lt;Decimal\u0026gt;) -\u0026gt; Maybe\u0026lt;Decimal\u0026gt; { match (maybe_x, maybe_y) { (Just(x), Just(y)) =\u0026gt; { // If both inputs are Just, check for division by zero and divide accordingly  if y == 0 { return Nothing } else { return Just(x / y) } }, _ =\u0026gt; return Nothing // Otherwise return Nothing  } } chainable_division(chainable_division(Just(2.0), Just(0.0)), Just(1.0)); // inside chainable_division fails, outside chainable_division returns Nothing  // Use a `bind` operator (also known as `map`, `flatmap`, or `shove`), to remove a lot of boilerplate (all those `Just` expressions) // Rust example using \u0026#34;.map\u0026#34;. maybe_x is passed through 2 functions that return Maybe\u0026lt;Decimal\u0026gt; and Maybe\u0026lt;String\u0026gt; respectively. // As with normal function composition the inputs and outputs of functions feeding into each other should match wrapped types. (i.e. the add_one function should return a Maybe\u0026lt;Decimal\u0026gt; which then can be unwrapped to a Decimal for the decimal_to_string function) let maybe_x: Maybe\u0026lt;Decimal\u0026gt; = Just(1.0) let maybe_result = maybe_x.map(|x| add_one(x)).map(|x| decimal_to_string(x))  Haskell Type Constructors -- Maybe is a type constructor; Nothing and Just are data constructors. data Maybe a = Nothing | Just a -- Just is a data constructor. You can construct a data value by applying the Just data constructor to a value: country = Just \u0026#34;China\u0026#34; -- Maybe is a type constructor. You can construct a type by applying the Maybe type constructor to a type: lookupAage :: DB -\u0026gt; String -\u0026gt; Maybe Int Type Constructors \u0026ndash; Type Polymorphic \u0026ndash; Type Container:\nPolymorphic types are like containers that are capable of holding values of many different types. So Maybe Int can be thought of as a Maybe container holding an Int value (or Nothing) and Maybe String would be a Maybe container holding a String value (or Nothing).\nMake Type of Type Containers Polymorphic:\nUse m a to represent a container of some type (m) holding a value of some type (a) !\nExample in Haskell halve :: Int -\u0026gt; Maybe Int halve x | even x = Just (x `div` 2) | odd x = Nothing -- This code halves x twice. it evaluates to Nothing if x is not a multiple of 4 halve x \u0026gt;\u0026gt;= halve -- ???  chainable_division(mx,my) = mx \u0026gt;\u0026gt;= ( λx -\u0026gt; my \u0026gt;\u0026gt;= (λy -\u0026gt; Just (x / y)) ) Haskell do notation A pattern that used many times \u0026ndash; abstract out as monad\nm \u0026gt;\u0026gt;= f = case m of Nothing -\u0026gt; Nothing Just x -\u0026gt; f xeval :: Expr -\u0026gt; Maybe Int eval (Val n) = return n eval (Div x y) = do n \u0026lt;- eval x m \u0026lt;- eval y safediv n m  The Maybe monad:\nreturn :: a -\u0026gt; Maybe a \u0026gt;\u0026gt;= :: Maybe a -\u0026gt; (a -\u0026gt; Maybe b) -\u0026gt; Maybe b Points:\n work with other effects (not only failures, but also I/Os, ) pure programming with effects; explicit usage of effects in types; any effects: effect polymorphism.  Haskell IO Reference: Haskell for Imperative Programmers #15 \u0026ndash; IO IO actions.\ninput might be zero. Output something.\n ??? -----\u0026gt; IO ----\u0026gt; () | \\|/ environment  Monadic Function Monadic type + Monadic functions.\nMonadic type.\nMonadic function:\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/spec-hol4/",
	"title": "Spec HOL4 (x86-TSO...)",
	"tags": [],
	"description": "",
	"content": " References:\n Relaxed-Memory Concurrency\n x86-TSO: A Rigorous and Usable Programmer’s Model for x86 Multiprocessors\n  Relaxed-Memory Concurrency Multiprocessors are now pervasive and concurrent programming is becoming mainstream, but typical multiprocessors (x86, Sparc, Power, ARM, Itanium) and programming languages (C, C++, Java) do not provide the sequentially consistent shared memory that has been assumed by most work on semantics and verification. Instead, they have subtle relaxed (or weak) memory models, exposing behaviour that arises from hardware and compiler optimisations to the programmer. Moreover, these memory models have usually described only in ambiguous (and sometimes flawed) prose, leading to widespread confusion.\nThis page collects work by a group of people working to develop mathematically rigorous and usable semantics for multiprocessor programs. We are focussing on three processor architectures (x86, Power, and ARM), on the recent revisions of the C++ and C languages (C++11 and C11), and on reasoning and verification using these models.\nx86-TSO x86-TSO is sound with respect to actual processor behaviour, matches the current vendor intentions, and is a good model to program above.\nx86 concurrenc reasoning: TRF The low-level assembly-language implementations of the abstractions that support language-level concurrency, such as locks and concurrent data structures, are particularly interesting and challenging to reason about because they invariably contain data races.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/spec-psl/",
	"title": "Spec PSL",
	"tags": [],
	"description": "",
	"content": " References:\n reference\n EDA languages\n  PSL: Property specification language (EDA standard)  evovled from Sugar language; adopted as an IEEE standard (1850-2010); grafted onto both SystemVerilog and VHDL;  act as an add-on to SystemVerilog/VHDL;  Based on CTL/LTL; PSL is divided into four layers:  Boolean layer (lowest layer), consists of instantaneous boolean expressions on signals in the design under test; The syntax of this layer follows that of the HDL to which PSL is being applied;  Can be verilog, SystemVerilog, VHDL, or others; e.g. a[0:3] \u0026amp; b[0:3] and a(0 to 3) and b(0 to 3) represent the bitwise and of the four most significant bits of vectors a and b in the Verilog and VHDL flavors, respectively.  Temporal layer (second layer), allows a designer to state properties that hold across multiple clock cycles. e.g. always !(ena \u0026amp; enb) states that the signals ena and enb will never be true simultaneously in any clock cycle.  The always operator, which states that a Boolean expression holds in every clock cycle, is one of the most basic.  e.g. always(req -\u0026gt; next ack) states that in every cycle that the req signal is true, the ack signal is true in the next cycle.  The next operator, one of the operators that specify delays.  e.g. req -\u0026gt; next[2] ack means that ack must be true two cycles after each cycle in which req is true.  The -\u0026gt; symbol denotes implication, that is, if the expression to the left is true, that on the right must also be true.  e.g. always {req; ack; !cancel} is a syntactic sugar for always (req -\u0026gt; next (ack -\u0026gt; next !cancel)), means that ack must be true after any cycle in which req is true, and cancel must be false in the cycle after that. weak and strong property:  weak property can be checked in simulation; i.e., for safety properties; strong property: can only be checked formally; express liveness properties; strong property is marked with a trailing exclamation point !. some operators come in both strong and weak varieties. e.g. always (req -\u0026gt; eventually! ack) states that after req is asserted, ack will always be asserted eventually. eventually! operator illustrates the meaning of strong operators. This is not something that can be checked in simulation: if a particular simulation saw req but did not see ack, it would be incorrect to report that this property failed because running that particular simulation longer might have produced ack. This is the fundamental differences between safety and liveness properties: safety states something bad never happens; liveness states something good eventually happens;  Specify a property in which times moves backward.  always ((a \u0026amp;\u0026amp; next[3] (b)) -\u0026gt; c), states that when a is true and b is true three clock cycles later, c is true in the first cycle when a is true.  Verification layer (third layer), instructs a verification tool what tests to perform on a particular design; It amounts to a binding between properties defined with expressions from the Boolean and temporal layer, and modules in the design under test. The following example declares a \u0026ldquo;verification unit\u0026rdquo; called ex1a, binds it to the instance named top_block_i1_i2 in the design under test, and declares (the assertion named A1) that the signals ena and enb in that instance are never true simultaneously.\nvunit ex1a(top_block.i1.i2){ A1: assert never (ena \u0026amp;\u0026amp; enb); } use directives\n assert, assume, assume a given property; assume_guarantee, both assumes and tests a particular property; restrict, constraints the tool to only consider inputs that have a given property; cover, asks the tool to check whether a certain property was ever observed; fairness, which instructs the tool to only consider paths in which the given property occurs infinitely often, for example, only when the system does not wait indefinitely.  Modeling layer (fourth layer): allows Verilog, SystemVerilog, VHDL, or other code to be included inline in a PSL specification.\n The intention here is to allow addition details about the system under test to be included in the PSL source file.\n   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cert/asil/",
	"title": "Asil",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cert/cc/",
	"title": "Cc",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cert/psa/",
	"title": "PSA: ",
	"tags": [],
	"description": "",
	"content": " References:\n ARM PSA Certified PSA whitepaper online  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/seminars/2022-arm-tech-sym/",
	"title": "2022 Arm Tech Symposia",
	"tags": [],
	"description": "",
	"content": " References:\n Live link  CEO, Rene Haas.\nMohamed Awad. \u0026ldquo;the future is built on arm\u0026rdquo;\n World\u0026rsquo;s global infrastructure.  ARM Neoverse: E/N/Y-series.  E: Efficient throughput N: Scale Out Performance V:  Arm AMBA CHI (Chai)  CMN: Core Mesh Network.  Cloud, development for free: alibaba, aws, google 5G Solutions Lab.  Software defined vehicle on arm.\n 100M lines of code on a vehicle. engine, \u0026hellip;., adas corte x-a52  IoT:\n Fighting Fragmentation: Matter protocols, for Smarthome  Matter 1.0, 400+ companies  Project Cassini  TCS: Total Computing Solutions.\n ARM Coretex-X3\n Project Vetera.\n  李瞳，联想集团，云网融合\n 5G RAN协议栈  唐，小鹏汽车，\n G3,P7,P5,G9 扶摇，alibaba 计算平台架构 XEEA3.0 集中化车载数据中心\n 软件架构：\n 传统架构：面向信号；复杂，耦合性高， 面向服务的SOA架构，标准化的通信中间件，云端\u0026ndash;车Data Center\u0026ndash;车服务MCU  车新四化：ACES，\n 驾驶自动化；ASIL-D，Fail-operational 架构中心化： 座舱娱乐化： 软件服务化：SOA架构，软件可移植。  高通Ride Flex，2000FLOPS\n  Afternoon  ARM servers: neoverse\n ARM on Cars: Cortex A52+\n Cortex-M Mali-C78AE  ARM for Windows11\n ARM64EC: Emulation Compatible.  could mix with x64.    ARM Helium\n Corstone Solution for IoT.\n Cortext-M85/M55\n PSA certified,  Audio experience,\n ARM-2D, library, on all Cortex-M\n  汽车OS：诚迈科技\n AUTOSAR， 道法术器   圆桌会议：\n 手机市场：  赛道：摄影、跑分、游戏、互联互通、远距离通信…… 新玩法：折叠屏、桌面处理、影像。 vivo：  ARM PC： 此芯科技，低功耗优势。  苹果 ARM 笔记本 20小时续航。     More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/l4/sel4/camkes/",
	"title": "Camkes",
	"tags": [],
	"description": "",
	"content": " References:\n camkes-tool/docs/  CAmkES\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cert/26262/",
	"title": "26262",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/ada/",
	"title": "Ada",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/baby/unbully/",
	"title": "Unbully",
	"tags": [],
	"description": "",
	"content": " References:\n reference  女儿被男生持刀霸凌，这位妈妈上演了一场教科书级别的绝地反杀…\nExpression+MagicAttack+People\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/research/baby/",
	"title": "Baby",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Unbully  References: reference 女儿被男生持刀霸凌，这位妈妈上演了一场教科书级别的绝地反杀… Expression+MagicAttack+People More\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/books/shelf/",
	"title": "Book Shelf",
	"tags": [],
	"description": "",
	"content": " Math.FM. \u0026ldquo;Software Foundations, Volumn 1 - 4\u0026rdquo;. By Benjamin C. Pierce, et al. 2019. html video/lectures by Pierece, UPenn, by Clarkson, Cornell, by Xiong, Peking U\n\u0026ldquo;Logical Foundations for Computing Science\u0026rdquo;. By Shen Enshao. 2006.\n\u0026ldquo;Logic for Computer Science.\u0026rdquo; By Steve Reeves and Mike Clarke. 2003.\n\u0026ldquo;Rigorous Software Development: An Introduction to Program Verification\u0026rdquo;. By Almeida, José Bacelar, Maria João Frade, Jorge Sousa Pinto, and Simão Melo de Sousa. 2011.\n\u0026ldquo;Homotopy Type Theory: Univalent Foundations of Mathematics\u0026rdquo;. The Univalent Foundations Program, 2013.\nOnline Class Materials:\nPrinciples of Computer Systems. MIT 6.826. 2019, 2017, 2004.\nSystems Verification. Washington.edu CSE 599W. 2016.\nVerified Systems Software. UPENN CIS 670. 2015\nCertified System Software. MIT 6.888. 2015\nModels of Computation. UTAH, CS3100. 2018 youtube\nConstructive Logic. CMU, 15-317. 2019-fall\nSoftware Analysis. Peking University. 2022-fall\nLanguages \u0026ldquo;Practical Foundations for Programming Languages\u0026rdquo;. By Robert Harper. 2016.\n\u0026ldquo;Types and Programming Languages\u0026rdquo;. By Benjamin C. Pierce. 2002.\n\u0026ldquo;Advanced Topics in Types and Programming Languages\u0026rdquo;. By Benjamin C. Pierce, editor. 2004.\nOnline Class Materials\n\u0026ldquo;Programming Lauguage Design and Implementation\u0026rdquo;. UR CSC 2\u0026frasl;454. 2019.\n\u0026ldquo;Types and Programming Languages\u0026rdquo;. CMU, 15-814. 2019-fall\nProgram Analysis \u0026ldquo;Static Program Analysis\u0026rdquo;. By Anders Møller and Michael I. Schwartzbach. pdf/201911.\n\u0026ldquo;Principles of Program Analysis\u0026rdquo;. By Flemming Nielson, Hanne Riis Nielson, and Chris Hankin. 1998.\nComplexity \u0026ldquo;Introduction to Automata Theory, Languages, and Computation\u0026rdquo;. By John E. Hopcroft, Rajeev Motwani, and Jeffery D. Ullman. 2006.\n\u0026ldquo;Computers and Intractability: A Guide to the Theory of NP-Completeness\u0026rdquo;. By Micheal Garey and David S. Johnson. 1979.\nAlgorithms \u0026ldquo;Introduction to Algorithms\u0026rdquo;. By Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. 2009.\n\u0026ldquo;The Art of Multiprocessor Programming\u0026rdquo;. By Maurice Herlihy, and Nir Shavit. 2008.\nCompilers \u0026ldquo;Compilers: Principles, Techniques, and Tools\u0026rdquo;. By Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman. 2nd ed. 2007.\n\u0026ldquo;Advanced Compiler Design and Implementation\u0026rdquo;. By Steven S. Muchnick. 1997.\n\u0026ldquo;Engineering A Compiler\u0026rdquo;. By Keith D. Cooper, and Linda Torczon. 2nd ed. 2012.\n\u0026ldquo;Optimizinig Compilers for Modern Architectures: A Dependence-based Approach\u0026rdquo;. By Randy Allen, and Ken Kennedy. 2001.\nCom.Arch \u0026ldquo;Computer Organization and Design, The Hardware/Software Interface\u0026rdquo;. By David A. Patterson, and John L. Hennessy. 5th ed. 2014.\n\u0026ldquo;Computer Architecture: A Quantitative Approach\u0026rdquo;. By John L. Hennessy, and David A. Patterson. 5th ed. 2012.\n\u0026ldquo;Principles of Secure Processor Architecture Design\u0026rdquo;. By Jakub Szefer. 2018.\nCom.Sys \u0026ldquo;Computer Systems: A Programmer\u0026rsquo;s Perspective\u0026rdquo;. By Randal E. Bryant, and David R. O\u0026rsquo;Hallaron. 3rd ed, 2015.\n\u0026ldquo;The Design and Implementation of the FreeBSD Operating System\u0026rdquo;. By Marshall Kirk McKusick, George V. Neville-Neil, and Robert N.M. Watson, 2nd ed, 2014.\n\u0026ldquo;程序员的自我修养\u0026ndash;链接、装载与库\u0026rdquo;。 作者：俞甲子/石凡/潘爱民。2009。\n\u0026ldquo;Linkers and Loaders\u0026rdquo;. By John R. Levine. 1999.\n\u0026ldquo;Understanding the Linux Kernel\u0026rdquo;. By Daniel P. Bovet, and Marco Cesati. 3rd ed. 2005.\nComputer Security \u0026ldquo;Computer Security: Art and Sciences\u0026rdquo;. By Matt Bishop. 2nd edition, 2018.\n\u0026ldquo;Computer Security: A Hands-on Approach\u0026rdquo;. By Wenliang Du. 2017.\n\u0026ldquo;Cryptography and Network Security: Principles and Practices\u0026rdquo;. By William Stallings. 4th edition. 2006.\n\u0026ldquo;Security Engineering: A Guide to Building Dependable Distributed Systems\u0026rdquo;. Site, Third Edition, 2020, PDF, 2nd Edition, 2008, PDF, 1st Edition, 2001\nOnline Class Materials\n\u0026ldquo;Computer Systems Security\u0026rdquo;. MIT 6.5660\u0026frasl;6.858. Spring 2022, Spring 2023 by Nickolai Zeldovich; videos\n\u0026ldquo;Foundations of Computer Security\u0026rdquo;. MIT 6.1600. Fall 2022 by Nickolai Zeldovich;\nSoftware Engineering Practice \u0026ldquo;Design Patterns: Elements of Reusable Object-Oriented Software\u0026rdquo;. By GoF, 1994.\n《编程之美\u0026ndash;微软技术面试心得》，电子工业出版社，2008。\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/tools/z3/",
	"title": "Z3",
	"tags": [],
	"description": "",
	"content": " References:\n jfmc\u0026rsquo;s Z3 Playground Z3 wiki  Z3 is a state-of-the-art theorem prover from Microsoft Research. It can be used to check the satisfiability of logical formulas over one or more theories.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/mem-tag/2012-watchdog/",
	"title": "2012 Watchdog",
	"tags": [],
	"description": "",
	"content": " References:\n Watchdog: Hardware for Safe and Secure Manual Memory Management and Full Memory Safety, Nagarakatte, Santosh, Milo MK Martin, and Steve Zdancewic. In 2012 39th Annual International Symposium on Computer Architecture (ISCA), pp. 189-200. IEEE, 2012.  Identifier for all pointers:\n For pointers in registers: Watchdog extends every register with a sidecar identifier register. For pointers in memory: Watchdog provides a shadow memory that shadows every word of memory with an identifier for pointers.  Propagate and check the identifiers:\n insert uOps for every memory accesses in hardware: extends the load, store, add immediate and add instructions. call/return instructions.  Identifier = Key + Lock\n on stack: maintain an in-memory stack of lock locations. Top is stored at stack_lock control register.  call: generate a key \u0026ndash;\u0026gt; store key in lock stack mem[stack_lock] = stack_key \u0026ndash;\u0026gt; store id for the stack frame: rsp.id = (stack_key, stack_lock) return: ( when to check? ) pop stack_lock \u0026ndash;\u0026gt; get a new stack_lock position \u0026ndash;\u0026gt; set as id for the new stack frame: rsp.id = (current_key, stack_lock)  on heap  allocation: generate a key (64 bits) \u0026ndash;\u0026gt; allocate a lock_ptr \u0026ndash;\u0026gt; *lock_ptr = key \u0026ndash;\u0026gt; id = (key, lock_ptr) \u0026ndash;\u0026gt; q = setident(ptr, id) deallocation: id = getident(p) \u0026ndash;\u0026gt; use id to set invalid on the lock *(id.lock) = INVALID \u0026ndash;\u0026gt; add the deallocated memory into free list: add_to_free_list(id.lock)   Optimizations  Lock Location Cache\n Identifying Pointer Load/Store Operations - conservative: Watchdog conservatively assumes that only a 64-bit load/store to an integer register may be a pointer operation.\n  Impl. an x86-64 simulator, statically linked 64-bit programs.\nEval. Only use-after-free checking:\n 25% (conservative pointer identification) 15% (ISA-assisted pionter identification) (24% without Lock Location Cache)  With bound checking: 15% \u0026ndash; 18%\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/chisel/",
	"title": "Chisel",
	"tags": [],
	"description": "",
	"content": " References:\n Chisel Bootcamp Chisel教程汇总 Verilog vs Chisel Comparison  Scala Based on Java Virtual Machine (JVM).\nScala \u0026ndash; .class \u0026ndash; JVM\nScala designed for Domain-Specific Language developers: can build your own language based on Scala.\nChisel Type parameters class or function definition can have type paramters, in order to define class/functions with arbitrary types.\ne.g. the following defines a function myMux which accepts inputs of any type of tPath and fPath\ndef myMux [T \u0026lt;: Data ]( sel: Bool , tPath: T, fPath: T): T = { val ret = WireDefault (fPath) when (sel) { ret := tPath } r et } The expression in the square brackets [T \u0026lt;: Data] defines a type parameter T that is Data or a subclass of Data . Data is the root of the Chisel type system.\n// generators/chipyard/src/main/scala/HarnessBinders.scala  class HarnessBinder[T, S \u0026lt;: HasHarnessSignalReferences, U \u0026lt;: Data](composer: ((T, S, Seq[U]) =\u0026gt; Unit) =\u0026gt; (T, S, Seq[U]) =\u0026gt; Unit)(implicit systemTag: ClassTag[T], harnessTag: ClassTag[S], portTag: ClassTag[U]) extends Config((site, here, up) =\u0026gt; { case HarnessBinders =\u0026gt; up(HarnessBinders, site) + (systemTag.runtimeClass.toString -\u0026gt; ((t: Any, th: HasHarnessSignalReferences, ports: Seq[Data]) =\u0026gt; { val pts = ports.collect({case p: U =\u0026gt; p}) require (pts.length == ports.length, s\u0026#34;Port type mismatch between IOBinder and HarnessBinder: ${portTag}\u0026#34;) val upfn = up(HarnessBinders, site)(systemTag.runtimeClass.toString) th match { case th: S =\u0026gt; t match { case system: T =\u0026gt; composer(upfn)(system, th, pts) case _ =\u0026gt; } case _ =\u0026gt; } }) ) }) More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/cfi-bending/",
	"title": "Control Flow Bending: On the Effectiveness of Control-Flow Integrity",
	"tags": [],
	"description": "",
	"content": " References:\n Control-Flow Bending: On the Effectiveness of Control-Flow Integrity, 2015 USENIX Security.  Attacks on Fully-Precise Static CFI CFI with shadow stack.\nDispatcher function/gadgets:\n Any function that contains a “write-what-where” primitive when the arguments are under the attacker’s control can be used as a dispatcher function. Alternatively, a function that can write to only limited addresses can still work as long as the return address is within the limits.\n e.g. memcpy(). Assume we can control all the arguments to memcpy():\n point the source buffer to an attacker-controlled location; point the target buffer to the address where the memcpy()\u0026rsquo;s return address will be found; set the length to be the word size. invoke memcpy()  e.g. printf(): use %n format specifier, to write an arbitrary value to an arbitrary location \u0026ndash;\u0026gt; printf() to overwrite its own return address.\n??? how does printf() work? see Appendix B.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/attack-data-op/2016-sp-dop/",
	"title": "2016 Sp Dop",
	"tags": [],
	"description": "",
	"content": " References:\n reference  MINIDOP language: pattern \u0026ndash;\u0026gt; operations.\nExample:\nThe attack that overwrites the data and convert a program from code1 to code2:\nExample code of addition:\nExample code of assignment and dereference:\nThe attack model with DOP gadgets:\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/attacks/attack-jop/",
	"title": "Attack Jop",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Jujutsu  References: [1] Control Jujutsu: On the Weaknesses of Fine-Grained Control Flow Integrity. CCS, 2015. A new attack on fine-grained CF that exploit the incompleteness of pointer analysis, when combined with common software engineering practices, to enable an attacker to execute arbitrary malicious code. Concepts: ICS: Indirect Call Site ACICS: Argument Corruptible Indirect Call Site RCE: Remote Code Execution DSA: Data Structure Analysis DEP: Data Execution Prevention ASLR: Address Space Layout Randomization SSP: Stack Smashing Protection ROP: Return-oriented Programming JOP: Jump-Oriented Programming Threat Model The threat model in this paper is a remote attacker trying to hijack control of a machine by exploiting memory vulnerabilities.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/parallel/consistency/",
	"title": "Memory Consistency Models",
	"tags": [],
	"description": "",
	"content": " References:\n Memory Consistency Models: A Tutorial  Memory Consistency: the problem of defining how parallel threads can observe their shared memory state.\nA memory consistency model is a contract between the hardware and software. The hardware promises to only reorder operations in ways allowed by the model, and in return, the software acknowledges that all such reorderings are possible and that it needs to account for them.\nSequential Consistency  Sequential consistency (SC): single main memory + program order.  e.g. cannot print 00.   Total Store Ordering  Relaxed Memory Models\n models with multiple (private) memory but shared data: not single main memory due to cache hierachies (e.g. private L1/L2, and shared L3);  Total store ordering (TSO): on-core store buffer;\n writes in the buffer, and do not need to wait for writes to the shared memory (e.g. shared L3); hide the write latency (cache hierachy will pull the write from the store buffer and propagage it thought the caches so that it becomes visible to other threads); preserves single-thread behavior. e.g. can print 00    Litmus tests: small tests as above example to show the memory model. formalizing x86-TSO by Peter Sewell.  Weaker memory models ARM: weak ordering + barriers.\nARM memory model is notoriously underspecified, but is essentially a form of weak odering.\nBarrier: a barrier instruction forces all memory opertions before it to complete before any memory operation after it can begin. That is, a barrier instruction effectively reinstates sequential consistency at a particular point in program execution.\nRISC-V RVWMO RISC-V Weak Memory Ordering\nDefined in terms of the global memory order, a total ordering of the memory operations produced by all harts.\nUnder RVWMO, code running on a signle hart appears to execute in order from the perspective of other memory instructions in the same hart, but memory instructions from another hart may observe the memory instructions from the first hart being executed in a different order.\nTherefore, multithreaded code may require explicit synchronization to guarantee ordering between memory instructions from different harts.\n The base RISC-V ISA: FENCE instruction. Extension: \u0026lsquo;A\u0026rsquo; additionally defines load-reserved/store-conditional and atomic read-modify-write instructions. (AMO: atomic memory operation) Extension: \u0026lsquo;Zam\u0026rsquo; for misaligned atomics Extension: \u0026lsquo;Ztso\u0026rsquo; for total store ordering, with additional rules to augment RVWMO.  Languages\u0026rsquo; memory models Compilers also reorder memory operations.\nProgram 1:\nX = 0 for i in range(100): X = 1 print X Program 2 (an optimized version of 1):\nX = 1 for i in range(100): print X with parallel, another threads write X as 0 during the execution of Program 1\u0026frasl;2.\nProgram 1 outputs: 111011111... Program 2 outputs: 111000000...\nin C++/Java:\n In fact, languages such as C++ and Java offer a guarantee known as sequential consistency for data-race-free programs (or the buzzwordy version, “SC for DRF”). This guarantee says that if your program has no data races, the compiler will insert all the necessary fences to preserve the appearance of sequential consistency. If your program does have data races, however, all bets are off, and the compiler is free to do whatever it likes. The intuition is that programs with data races are quite likely to be buggy, and there’s no need to provide strong guarantees for such buggy programs. If a program has deliberate data races, the programmer likely knows what they’re doing anyway, and so can be responsible for memory ordering issues themselves.\n More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/langs/langs/c/",
	"title": "C",
	"tags": [],
	"description": "",
	"content": " References:\n reference  Setjump/Longjump https://www.embecosm.com/appnotes/ean9/html/ch04s01s02.html\nhttps://developer.51cto.com/article/643833.html\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/fs/",
	"title": "Fs",
	"tags": [],
	"description": "",
	"content": " References:\n 2018 thesis: Simulation of RISC-V based Systems in gem5, by Robert Scheffel  Full System:\n peripheral devices: UART, Timers  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/ruby/",
	"title": "Ruby",
	"tags": [],
	"description": "",
	"content": " References:\n Introduction to Ruby  SLICC: a domain-specific language (Specification Language including Cache Coherence) for specifying coherence protocols. Files end in .sm for state machine files.\nEach state machine file describes states, transitions from a begin to an end state on some event, and actions to take during the transition.\nCoherance protocol (in SLICC) --\u0026gt; SLICC compiler (in Python/gem5) --\u0026gt; C++ files with gem5 (SimObjects, etc.)  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/info-flow/lattice/",
	"title": "Lattice",
	"tags": [],
	"description": "",
	"content": " References:\n A Lattice Model of Secure Information Flow by Dorothy E. Denning, Purdue University. 1976.  An information flow model FM is defined as below:\nTo be secure, it requires:\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/mem-tag/2002-mondrian/",
	"title": "2002 Mondrian",
	"tags": [],
	"description": "",
	"content": " References:\n E. Witchel, J. Cates, and K. Asanovi´c. Mondrian memory protection. In Proceedings of the 10th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pages 304–316, Oct 2002.  MMP: Mondrian memory protection.\nIn constrast to earlier page-based systems, MMP allows arbitrary permissions control at granularity of individual words.\n a compressed permissions table to reduce space overheads employ two levels of permissions caching to reduce run-time overheads  Evaluation: zero-copy networking underneath the standard read system call interface, where packet payload fragements are connected together by the translation system to avoid data copying.\n Saves 52% of the memory references used by a traditional copying network stack.  Motivation More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/mem-tag/2005-safemem/",
	"title": "2005 Safemem",
	"tags": [],
	"description": "",
	"content": " References:\n reference  A novel use of ECC memory technology\nto detect first access to a user-directed memory region\n\u0026ndash;\u0026gt; can be used to detect memory leaks and memory corruption.\nECC 7 bits to protect 32 bits, or 8 bits to protect 64 bits [c18]\nFour modes:\n Disabled. Check-Only. detect single-bit and multi-bit errors. Correct-Error. + correct single-bit errors. Correct-and-Scrub. + Scrubs memory periodically to check and correct hardware errors.  Error Handling:\nECC-error interrupt, Linux/Windows -\u0026gt; panic/blue screen \u0026ndash;\u0026gt; reboot\nProblem/Challenges Advantages of using ECC:\n at cache line granularity instead of page granularity.  reduce the amount of false sharing and padding space.   Challenges of using ECC:\n leverage a standard off-the-shelf ECC memory controller  most do not allow software to directly access the ECC code.  unlike page protection faults, operating systems do not deliver the ECC-error interrupts to user-level programs.  Memory Corruption: damages memory content through buffer overflow, incorrect pointer arithmetic, or other types of program errors.\nMemory Leak: allocated memory is never accessed again.\nSafeMem New Linux System Calls:\n WatchMemory(address, size)  size cache line size aligned  DisableWatchMemory(address) RegisterECCFaultHandler(function)  register a user level ECC fault handler   Monitoring: the first access of the monitored region \u0026ndash;\u0026gt; ECC handler\n Memory Corruption: first access to a monitored location is a bug; Memory Leak: first access to a monitored location indicates a false positive.  Where to monitor? For memory leakage: todo\u0026hellip;\nFor Memory Corruption Detection: padding two ends of a buffer.\nSuggestions to ECC Cache-Line size is still a large granularity.\nWord granularity as in Mondrian Memory Protection (MMP) [c31]\n[c31]: E. Witchel, J. Cates, and K. Asanovi´c. Mondrian memory protection. In Proceedings of the 10th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pages 304–316, Oct 2002.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/tools/git/",
	"title": "Git",
	"tags": [],
	"description": "",
	"content": " Git submodule git submodule--helper list To change the url of a submodule\n# update the url in the .gitmodules file, then run git submodule sync --recursive Git rebase https://www.atlassian.com/git/tutorials/rewriting-history/git-rebase\ngit rebase \u0026lt;base\u0026gt; git rebase --interactive \u0026lt;base\u0026gt; Change base from oldbase to newbase\ngit rebase --onto \u0026lt;newbase\u0026gt; \u0026lt;oldbase\u0026gt; \u0026lt;featurebranch\u0026gt; More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/l4/sel4/last-mile/",
	"title": "Last Mile",
	"tags": [],
	"description": "",
	"content": " References:\n The Last Mile: An empirical study of timing channels on seL4,\n Leakage in Trustworthy Systems, by David Cock, August 2014.\n  Overview Side channel data collection.\nseL4 on Exynos4412 platform:\nScope serverl timing channels on seL4 based system with their defenses with low overhead.\nDo not consider noise-adding solutions (due to their overhead);\nOnly consider black box techniques (require no insight into the internals of software running on seL4, as retrofitting security into complex software is generally impossible);\nOnly on some example cases, not a comprenhensive converage of timing channels;\nTwo vulnerabilities:\n One local vul + two countermeasures:  the cache-contention channel high bandwidth e.g. cloud: learn encryption keys [Zhang et al., 2012] instruction-based scheduling [Stefan et al., 2013] cache colouring [Liedtke et al., 1997]  One remote vul:  Lucky 13 attack of AlFardan and Paterson [2013] against DTLS in OpenSSL 1.0.1c.   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/l4/sel4/",
	"title": "seL4",
	"tags": [],
	"description": "",
	"content": " References:\n About seL4 seL4 Documentation Klein, Gerwin, Kevin Elphinstone, Gernot Heiser, June Andronick, David Cock, Philip Derrin, Dhammika Elkaduwe et al. \u0026ldquo;seL4: Formal verification of an OS kernel.\u0026rdquo; In Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles (SOSP), pp. 207-220. 2009. Murray, Toby, Daniel Matichuk, Matthew Brassil, Peter Gammie, Timothy Bourke, Sean Seefried, Corey Lewis, Xin Gao, and Gerwin Klein. \u0026ldquo;seL4: from general purpose to a proof of information flow enforcement.\u0026rdquo; In 2013 IEEE Symposium on Security and Privacy, pp. 415-429. IEEE, 2013. Sewell, Thomas Arthur Leck, Magnus O. Myreen, and Gerwin Klein. \u0026ldquo;Translation validation for a verified OS kernel.\u0026rdquo; In Proceedings of the 34th ACM SIGPLAN conference on Programming language design and implementation, pp. 471-482. 2013. Trustworthy Systems Paper Publication  Source codes data:\n 8700 lines of C code and 600 lines of assembler; ( \u0026ndash; 2009 sosp paper)  Initially for ARMv6-based platform, with a subsequent port of the kernel to x86;  around 9500 lines of C source code; 11736 instructions on the (x86) binary level; \u0026ndash; (2013-translation validation paper)  Motivation \u0026ldquo;Complete formal verification is the only known way to guarantee that a system is free of programming errors.\u0026rdquo;\n\u0026ldquo;absence of bugs\u0026rdquo;\n \u0026ldquo;General wisdom has it that bugs in any sizable code base are inevitable. As a consequence, when security or reliability is paramount, the usual approach is to reduce the amount of privileged code, in order to minimize the exposure to bugs.\u0026rdquo;  Security kernels, separation kernels [38,54]; MILS approach [4]; microkernels [1,12,35,45,57,71]; isolation kernels [69]; small hypervisors [16,26,56,59]; Common Criteria [66] at the strictest evaluation level requires the system under evaluation to have a \u0026ldquo;simple\u0026rdquo; design;   seL4 overview Third generation microkernel, based on L4 [46], influenced by EROS [58];\nFeatures abstractions for virtual address spaces, threads, inter-process communication (IPC);\n Virtual address spaces have no kernel-defined structure; Page table faults are propagated via IPC to pager threads;  pager threads: responsible for mapping frames into virtual addr space;  Exceptions and non-native system calls are also propagated via IPC\n to support virtualization;  IPC:\n synchronous and asynchronous endpoints: port-like destinations without in-kernel buffering; for inter-thread communication; with RPC facilitated via reply capabilities;  Capabilities:\n segregated; stored in capability address spaces; capability container objects, CNodes;  Drivers: run as user-mode applications\n registers and memory are controlled by either by mapping the device to the virtual address space, or by controlled access to device ports on x86 hardware; Interrupts: via IPC receive notification of interrupts acknowledge their receipt  Explicit memory management:\n capability-based explicit management Guarantees all memory allocation in the kernel is explicit and authorised; both in-kernel objects and virtual addr spaces; Physical Memory: untyped capabilities \u0026ndash;\u0026gt; retyped as: kernel objects: thread control blocks, CNodes, endpoints frames for mapping in virtual addr spaces   Unlike most L4 kernels, seL4 features capabilities for authorization;\nPrivilege Modes:\nseL4 could run as an OS kernel (supervisor mode in RISC-V) or as a hypervisor (HS-mode in RISC-V, EL2 on ARM, Root Ring-0 on x86). \u0026ndash; Whitepaper 20210610.\nVerified Property Functional correctness:\n The implementation always strictly follows our high-level abstract specification of kernel behavior; e.g., kernel will never crash; e.g., kernel will never perform an unsafe operation; e.g., predict precisely how the kernel will behave in every possible situation;  Worst-Case Execution Time (WCET):\n Done for ARM v6 processors. \u0026ldquo;We did the WCET analysis of seL4 for Arm v6 processors. It has since fallen into abeyance, as Arm has stopped providing the required information on the worst-case latencies of instructions, and Intel never provided those of their architecture. However, with the advent of open-source RISC-V processors, we will be able to redo this analysis\u0026rdquo;  Assumptions Correctness of:\n compiler; assembly code; boot code; management of caches; the hardware.  Formal Methods in seL4 OS developers tend to take a bottom-up approach to kernel design. High performance is obtained by managing the hardware efficiently, which leads to designs motivated by low-level details. In contrast, formal methods practitioners tend toward top-down design, as proof tractability is determined by system complexity. This leads to designs based on simple models with a high degree of abstraction from hardware.\nseL4 methodology: an intermediate target.\n use Haskell to provide a programming language for OS developers; provide an artefact that can be automatically translated into theorem proving tool and reasoned about.  Square box: the formal artefacts;\nDouble arrows: represent impl. or proof effort;\nSingle arrows: represent design/impl. influence of artefacts on other artefacts;\nHaskell prototype of the kernel: the Central Artefact:\n (2009-sosp) Linked with software (derived from QEMU) that simulates the hardware platform;  normal user-level execution is enabled by the hardware simulator; traps are passed to the kernel model which computes the result of the trap; The prototype modifies the user-level state of the simulator to appear as if a real kernel had executed in privileged mode. e.g., a subset of the Iguana embedded OS37 on the simulator-Haskell combination;   C prototype of the kernel: the final production kernel:\n (2009-sosp) manually implemented in C;  for several reasons: Haskell runtime is hard to verify; Haskell GC not suitable for real-time environment; similar strategy used in SPIN[7] and Singularity [23]   Formal Verification Technique Use Isabelle/HOL\n interactive, machine-assisted, and machine-checked proof.  Interactive theorem proving vs Automated verification methods:\n Interactive theorem proving has the advantage that it is not constrained to specific properties or finite, feasible state spaces, unlike more automated methods of verification such as static analysis or model checking.\n Refinement Proof: functional correctness in the strongest sense.\n A refinement proof establishes a correspondence between a high-level (abstract) and a low-level (concrete, or refined) representation of a system.\n Security properties: abstract model \u0026lt;==\u0026gt; refined model:\n If a security property is proved in Hoare logic about the abstract model (not all security properties can be), refinement guarantees that the same property holds for the kernel source code.\n SOSP 09 paper: functional correctness property + security of seL4\u0026rsquo;s access-control system in Isabelle/HOL;\nTo verify the function correctness:\n its behavior is specified precisely, formally, at an abstract level;\n its formal design is used to prove desirable properties, including termination and execution safety;\n its implementation is formally proven to satisfy the specification;\n  Methodology of rapid kernel design and implementation:\nRun seL4 on RISC-V machines runs as supervisor-mode kernel on RISC-V platforms.\n verifying the RISC-V port of seL4, with proof of functional correctness (to the binary) expected to complete in Q1\u0026rsquo;20.\n Time protection with FPGA hardware prototype.\n  More  Camkes   References: camkes-tool/docs/ CAmkES More  Last Mile  References: The Last Mile: An empirical study of timing channels on seL4, Leakage in Trustworthy Systems, by David Cock, August 2014. Overview Side channel data collection. seL4 on Exynos4412 platform: Scope serverl timing channels on seL4 based system with their defenses with low overhead. Do not consider noise-adding solutions (due to their overhead); Only consider black box techniques (require no insight into the internals of software running on seL4, as retrofitting security into complex software is generally impossible);\n 2019 Time Protection  References: The last mile Time Protection: The Missing OS Abstraction, Qian Ge, Yuval Yarom, Tom Chothia, and Gernot Heiser. 2019. In Proceedings of the Fourteenth EuroSys Conference 2019 (Dresden, Germany) (EuroSys ’19). ACM, New York, NY, USA, Article 1, 17 pages. https://doi.org/10.1145/3302424.3303976; paper site \u0026ldquo;No security without time protection: We need a new hardware-software contract.\u0026rdquo;, Ge, Qian, Yuval Yarom, and Gernot Heiser. In Proceedings of the 9th Asia-Pacific Workshop on Systems, pp.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/eda-fm/fm-property-v/",
	"title": "Formal Property Verification",
	"tags": [],
	"description": "",
	"content": " References:\n Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition.  Chapter 20   Intro  1994, Intel spent $500 million to recall the Pentium CPU due to a functional bug that produced erroneous floating-point division results that were off by as much as 61/{1,000,000} [112]; Simulation-based logic verification is becoming less and less effective due to the growing complexity of the systems;  Large systems are often decomposed into blocks  each of these blocks is simulated separately in its own environment; full-chip/system simulation is carried out after block-level simulation is stable;  A dramatic increase in the effort invested in simulation-based verification  a complete simulation environment, including tests, checkers, coverage monitors, and environment models, is developed and maintained for each block; Half of the total design efforts is devoted to verification; The number of bugs is growing exponentially, and hundreds of billions of simulation cycles are consumed;  Only a negligible percentage of all possible executions of the design is actually being tested.  Formal property verification  major advantage: offers an exhaustive verification technology, which is orders of magnitude more efficient than scalar exhaustive simulation. all possible executions of the design are analyzed; no test inputs are required; main deficiency: its limited capacity compared with simulation. early 2000s, handle modles on the order of 10K memory elements; and 100-500K memory elements with complementary automatic model; nowadays: millions of gates and memory elements;   Example:\nInt x; read (x); if x \u0026lt; 0 then x = ~x; print (x);   Verification goal: assume x is a 32-bit integer, verify that every legal input the program prints a nonnegative number; Simulation methods: 2^{32} runs to cover the entire input space Formal approach: a single symbolic simulation\n INPUT: a set of n Boolean variables representing the input bits; OUTPUT: a Boolean expression that reflects the program computation over the input variables; CHECK: the result Boolean expression is nonnegative.  Property: a specification of some aspect of a system\u0026rsquo;s behavior that is considered necessary, but perhaps not sufficient for correct operation.\n Example: \u0026ldquo;A mutually exclusive pair of control signals is never asserted simultaneously\u0026rdquo;; Example: \u0026ldquo;a packet router chip connected to the PCI bus always conforms to the rules for correct signaling on the bus\u0026rdquo; Full functional specifications are rare, because of the difficulty in verifying them. More often, a collection of properties considered to be of crucial importance or difficult to check adequately by simulation.  In hardware design, formal property verification is used throughout the design cycle.\n  Table 20.1:\n Five major simultaneous activities (rows)\n Register-transfer level (RTL) Timing Circuit Layout Postsilicon  Early stage: architecture and microarchitecture are designed.\n formal models of the new idea and protocols are developed and formally verified against a set of requirements; Example: a new cache coherance protocol; Usually carried out by the validation team working closely with the architects;  RTL verification: while the RLT is being developed.\n Property can be: from high-level microarchitectural specifications;  e.g., the IEEE specificatino of the arithmetic operations;  from the implementation constraints that need to be verified on the RTL;  e.g., verifying that all timing paths are within the required range.   Constraints consumed by synthesis, static timing analysis, and power analysis are formally verified to be valid.\n Formal property verifiction products for HW:\n early 1990s, internal CAD groups from Intel, IBM, Motorola, Siemens, and Bell Labs. late 1990s, early 2000s, startups: @HDL, 0-in, Real Intent, Verplex, Jasper. large EDA companies.  During the 5 years or so after 2000, intensive efforts have been directed to finding new and fully automatic ways to apply formal methods to software verification.\n Simulation is currently the main verificatino tool for software; But the increased frequency of fatal and catastrophic software errors is driving the electronic design community to look for better, more exhaustive verification solution.  Formal property verification of software:\n 2000s, Microsoft, verifying Windows NT drivers; Static Driver Verifier Platform from Microsoft, for device vendors; 2000s, EDA startup, Calypto, C-to-Verilog translation validation.   FM Verification Methods and Technologies  Automata-theoretic approach Symbolic model checking Satisfiability analysis Interpolation Symbolic simulation Theorem proving  Formal Property Specification  Reactive Systems: systems that interact continuously with their environment, receiving input and produce output.\n Both the hardware design and embedded software generally fall into this class. In constrast to a computer program, such as a compiler, that receives input once, then executes to termination, producing output once.  To specify a reactive system: need the valid input/output sequences, not just the correct function from input to output.\n Use Temporal Logic  Temporal Logic\n assert the truth of a propersition at certain times relative to the present time. e.g., Fp states that p is true at some time in the future; Gp states that p is true at all times in the future. e.g., \u0026ldquo;it is never the case that signals grant1 and grant2 are asserted at the same time\u0026rdquo;  \u0026ndash;\u0026gt; a safety property (some bad condition never occurs).  e.g., \u0026ldquo;if req1 is asserted now, eventually (at some time in the future) grant1 is asserted\u0026rdquo;  \u0026ndash;\u0026gt; a liveness property (some good property must eventually occur).  To reason about the liveness: must consider infinite executions of a system \u0026ndash; only way to violate the property is the execute indefinitely without the occurance of the good condition.   Model Checking  verify temporal properties; provide counterexamples that for properties that are false; fully automated verification of temporal properties is generally referred to as \u0026ldquo;model checking\u0026rdquo;, in reference to the first such technique developed by Clarke and Emerson[22];  Automata-Theoretic Approach Property \u0026ndash;\u0026gt; Automaton \u0026ndash;\u0026gt;\n Property: a set of acceptable input/output traces of a system; Finite Automaton: accepts exactly the set of traces accepted by the property[33];\n automaton is a state graph: edges are labeled with input/output pairs; the language of the automaton: the set of input/output traces being accepted; different languages can be defined by defining different notions of the accepting path;\n e.g., a set of finite traces: define a legal inital and final states; e.g., an accepting infinite path: define the initial states, and the sets of states that may occur infinitely often on an accepting infinite path;  Most algorithms for model checking work by translating the property into a finite automaton;\n  System: also represented by an equivalent automaton.\n Check: \u0026ldquo;every trace of the system automaton is a trace of the property automaton\u0026rdquo;\n Combining the automaton for the complement of the property with the system automaton to produce a product automaton if the product automaton accepts any traces, then the system does not satisfy the property. If finite traces: Can search the state graph of the product automaton for an accepting path;  Tools to search in Finite Traces (Brute force way, \u0026ldquo;explict state\u0026rdquo;):\n COSPAN[34] SPIN[6] Murphi[7] quite effective at verifying software-based protocols, cache coherence protocols, and other systems with relatively small state spaces.  Problem: state graphs can be prohibitively large.\n worse case: the number of states == the number of possible configurations of the registers (or other state-holding elements) in the system.  Solution: heuristic methods, avoid explicit construction of the state graph.\n Symbolic model checking   Symbolic Model Checking SMC\n Introduced in late 1980s[35,75], in a tool SMV[36]; use logical formula to replace concrete values; transitions of a sequential machine becomes a set of Boolean equations (Figure 20.1)\n   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/books/formal-methods/",
	"title": "Formal Methods",
	"tags": [],
	"description": "",
	"content": " Books:\n EDA for IC design, verification, and testing\n Mechanizing Proof: Computing, Risk, and Trust, by MacKenzie 2001.\n  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/eda-fm/intro/",
	"title": "Intro",
	"tags": [],
	"description": "",
	"content": " References:\n Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition.  1.1 Introduction\n Modern integrated circuits (ICs) are enormously complicated, sometimes containing billions of devices. The design of these ICs would not be humanly possible without software (SW) assistance at every stage of the process. The tools and methodologies used for this task are collectively called electronic design automation (EDA).\nEDA tools span a very wide range, from logic-centric tools that implement and verify functionality to physically-aware tools that create blueprints for manufacturing and verify their feasibility. EDA methodologies combine multiple tools into EDA design flows, invoking the most appropriate software packages based on how the design progresses through optimizations. Modern EDA methodologies can reuse existing design blocks, develop new ones, and integrate entire systems. They not only automate the work of circuit engineers, but also process large amounts of heterogeneous design data, invoke more accurate analyses and more powerful optimizations than what human designers are capable of.\n EDA工具是很多种类工具的集成，既包含以逻辑为中心的用于实现和验证逻辑功能的工具集，也包含可理解物理电路特性、可用于电路生产和电路可行性验证的工具。\n在EDA的设计流程中，集成了多种工具并根据设计过程中的优化需求自动选择合适的工具做处理。\n目前的EDA方案中，既包含已有的设计模块，也有新开发的模块，并把他们集成到整个EDA系统中。\n他们不仅仅让电路相关工程实现自动化，也让多种多样的设计层面的数据实现自动处理，这使得EDA工具能够提供比人工更为准确和强大的优化能力。\nAs the number of design rules, number of layers, and chip size continued to increase, it became increasingly difficult to verify by hand that a layout met all the manufacturing rules and to estimate the parasitics of the circuit. \u0026hellip; Increasing numbers of interconnect layers made the process more complex, and the original analytic approximations to R, C, and L values became inadequate, and new techniques for parasitic extraction were required to determine more accurate values, or at least calibrate the parameter extractors. (Chapter 20 and 25 of Volume 2)\nThe next bottleneck was in determining the precise location of each polygon and drawing its detailed geometry. Placement and routing programs for standard-cell designs allowed the user to specify only the gate-level netlist \u0026ndash; the computer would then decide on the location of the gates and route the wires connecting them. This greatly improved productivity (with a moderate loss of silicon efficiency), making IC design accessible to a wider group of electronics engineers. (Chapter 5 and 8 of volume 2)\nQ\u0026amp;A  What is the \u0026lsquo;design rules\u0026rsquo;, what is the \u0026lsquo;manufacturing rules\u0026rsquo; for a layout? What is layers? the interconnect layers? The original analytic approximations to R, C, and L values ?  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/eda-fm/",
	"title": "Formal methods in EDA",
	"tags": [],
	"description": "",
	"content": " References:\n Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition.  Chaper 15-20   More  Logic Verification -- languages  References: Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition. Chaper 15 Steps of IC design design in C/C++ model \u0026ndash;\u0026gt; simulators, func good design in RTL \u0026ndash;\u0026gt; simulating, and compare with the C/C++ reference model Synthesis: Translate RTL to gate-level netlist. Place and Route: netlist as input, generates polygons that will become wires and transistors on the chip.\n Logic Verification -- Digital Simulation   References: Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition. Chapter 16 Simulation: when the program (or model) runs correctly, then one can be reasonably assured that the logic of the design is correct, for the cases that have been tested in the simulation. More  Formal Property Verification  References: Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition. Chapter 20 Intro 1994, Intel spent $500 million to recall the Pentium CPU due to a functional bug that produced erroneous floating-point division results that were off by as much as 61/{1,000,000} [112]; Simulation-based logic verification is becoming less and less effective due to the growing complexity of the systems; Large systems are often decomposed into blocks each of these blocks is simulated separately in its own environment; full-chip/system simulation is carried out after block-level simulation is stable; A dramatic increase in the effort invested in simulation-based verification a complete simulation environment, including tests, checkers, coverage monitors, and environment models, is developed and maintained for each block; Half of the total design efforts is devoted to verification; The number of bugs is growing exponentially, and hundreds of billions of simulation cycles are consumed; Only a negligible percentage of all possible executions of the design is actually being tested.\n Intro  References: Electronic Design Automation for IC system Design, Verification, and Testing. By Luciano Lavagno, Igor L. Markov, Grant Martin, and Louis K. Scheffer. 2nd Edition. 1.1 Introduction Modern integrated circuits (ICs) are enormously complicated, sometimes containing billions of devices. The design of these ICs would not be humanly possible without software (SW) assistance at every stage of the process. The tools and methodologies used for this task are collectively called\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/o3cpu/",
	"title": "O3 CPU",
	"tags": [],
	"description": "",
	"content": " References:\n O3CPU  Out of order CPU model loosely based on the Alpha 21264.\n Fetch  Fetch instructions each cycle; Create DynInst Branch prediction  Decode  Decode instructions each cycle; Early resolution of PC-relative unconditional branches  Rename  Rename instructions using a physical register file with a free list Stall when no regs to rename to, or back-end resources have filled up  Issue/Execute/Writeback  Three stages combined in one stage, IEW, using execute() function  Dispatching instructions to the instruction queue Telling the instruction queue to issue instruction Executing and write back instructions   Commit  Commit instructions each cycle; Handling any faults that the instructions may have caused; Also handles redirecting the front-end in the case of a branch misprediction.   ISA dependence  The O3CPU has been designed to try to separate code that is ISA dependent and code that is ISA independent. The pipeline stages and resources are all mainly ISA independent, as well as the lower level CPU code.\n The ISA dependent code:\n AlphaO3CPU implements Alpha-specific functions, such as hardware return from error interrupt (hwrei()) or reading interrupt flags.  ISA independent code:\n FullO3CPU, handles orchstrating all of the pipeline stages and handling other ISA-independent actions.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/archs/",
	"title": "Arch Supports in gem5",
	"tags": [],
	"description": "",
	"content": " References:\nFrom the outdated docs:\n Architecture Support.\n x86\n A generic x86 CPU, with 64 bit extensions; More similar to AMD\u0026rsquo;s version of the arch than Intel\u0026rsquo;s but not strictly like either; Unmodified versions of Linux kernel can be booted in UP and SMP configurations; patches are available for speeding up boot; SSE/3dnow are implemented; no majority of x87 floating point; syscall emulation mode: both 64 and 32 bit binaries;  ARM\n ARMv8-A profile, with multi-processor extensions; AArch32: Thumb, Thumb-2; VFPv3(32 double register variant); NEON; Large Physical Addrss Extensions (LPAE); AArch64 Not supported yet: TrustZone ThumbEE Jazelle Virtualization  RISCV\n More\n Alpha POWER SPARC MIPS   From source code:\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/gem5/gem5-kvm/",
	"title": "Gem5 KVM",
	"tags": [],
	"description": "",
	"content": " References:\n x86 Full System Tutorial\n Tutorial: Run SPEC CPU 2017 / SPEC CPU 2006 Benchmarks in full System Mode with gem5art\n  \u0026ldquo;gem5 features a KVM-based CPU that uses virtualisation to accelerate simulation.\u0026rdquo;\n In this tutorial we will build an X86 simulation, capable of running a full-system simulation, booting an Ubuntu operating system, and running a benchmark. This system will utilize gem5’s ability to switch cores, allowing booting of the operating system in KVM fast-forward mode and switching to a detailed CPU model to run the benchmark, and use a MESI Two Level Ruby cache hierarchy in a dual-core setup.\n KVM will only work if the host platform and the simulated ISA are the same (e.g., X86 host and X86 simulation).\nExample execution of gem5 with KVM More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/windows/heap-protection/",
	"title": "Heap Protection",
	"tags": [],
	"description": "",
	"content": " References:\n Windows 8 Heap Internals, BlackHat, USA, 2012.\n Software Defense: Mitigating Heap Corruption Vulnerabilities\n  Heap for Windows Vista/Server2008/Windows7 The following features are enabled by default:\n Randomized heap base address\n The base address of a heap region is randomized as part of ASLR; 5 bits of entropy;  Function pointer encoding\n Function pointers in heap data structures are encoded with a random value; This will prevent them from being replaced with an untrusted value;  Algorithm variation\n Algorithm may shift depending on allocation patterns and policies;  Heap header cookie\n An 8-bit random value is associated with the header of each heap entry; For integrity checking of many fields; In many places: at the time that a heap entry is freed; \u0026hellip;  Heap entry metadata randomization\n The header associated with each heap is XORd with a random value in order to protect the integrity of the metadata; The heap manager then unpacks and verifies the integrity of each heap entry prior to operating on it.  Removal of commonly targeted data structures\n e.g. Lookaside lists have been replaced by the Low Framentation Heap (LFH).   Additions on Windows 8\u0026frasl;8.1 Reference: Software Defense: Mitigating Heap Corruption Vulnerabilities\nEnhanced heap integrity checks:\n Catch-all exception handling blocks have been removed; HEAP handle can no longer be freed; HEAP CommitRoutine encoded by a global key; Extended block header validation; Blocks cannot be allocated if they are already busy (in-use flag); Encoded FirstAllocationOffset and BlockStride (defense against corruption); Guard pages for certain types of sub-regions within the heap:  Large allocations: \u0026gt; 512KB (32-bit) or 1MB (64-bit) Heap segements: all heap segments. Maximally-sized subsegments.  Allocation order randomization  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/windows/",
	"title": "Windows",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Heap Protection  References: Windows 8 Heap Internals, BlackHat, USA, 2012. Software Defense: Mitigating Heap Corruption Vulnerabilities Heap for Windows Vista/Server2008/Windows7 The following features are enabled by default: Randomized heap base address The base address of a heap region is randomized as part of ASLR; 5 bits of entropy; Function pointer encoding Function pointers in heap data structures are encoded with a random value; This will prevent them from being replaced with an untrusted value; Algorithm variation\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/security/",
	"title": "Security Analysis of CHERI",
	"tags": [],
	"description": "",
	"content": " References:\n Security Analysis of CHERI ISA, 2021.\n Windows 8 Heap Internals, BlackHat, USA, 2012.\n Software Defense: Mitigating Heap Corruption Vulnerabilities\n An Armful of CHERIs, Security Research \u0026amp; Defense, By Saar Amar, January 20, 2022\n Type Confusion Attack\n   Heap Attacks  Software Defense: Mitigating Heap Corruption Vulnerabilities  Metadata Corruption and Type Confusion Attack  Assumption: the metadata is corrupted in some way.\n Having malloc return that same allocation multiple times or returning overlapping allocations.\n  Examples:\n \u0026ldquo;Block size attack\u0026rdquo;:    \u0026ldquo;Google Project Zero (GPZ) exploit\u0026rdquo;:  creates overlapping chunks with only an off-by-one of a null byte.   Pros  An Armful of CHERIs, Security Research \u0026amp; Defense, By Saar Amar, January 20, 2022  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/codegen/basic-elf/relocation/relro/",
	"title": "RELRO",
	"tags": [],
	"description": "",
	"content": " References:\n Hardening ELF binaries using Relocation Read-Only(RELRO)  RELRO ELF: Executable and Linkable Format.\nPIE: Position Independent Executables.\nRELRO: Relocation Read-Only.\nIn dynamic linked ELF:\n GOT: Global Offset Table.\n A look-up table, contains pointers that points to the actual location of dynamically resolved functions. Lives in .got.plt section. Located at a static address. Needs to be writable. \u0026mdash;\u0026gt; can be overflowed by attackers. dynamically populcated as the program is running:  first time GOT points back to PLT(inside a dynamic linker procedure), the dynamic linker finds the actual location, then written to GOT. second time when the shared function is called, GOT contains the actual function addr.   PLT: Procedure Linkage Table.\n Contains instructions that point directly to the GOT. Lives in .plt section. Located at a fixed offset from the .text section.  RELRO: Relocation Read-Only.\n Linker resolves all dynamically linked functions at the beginning of the execution, then makes GOT read-only. bin compiled with option -z,relro,-z,now: read-only for all GOT: Non-PLT part .got and PLT part .got.plt. bin compiled with option -z,relro: read-only for non-plt part .got; the PLT part .got.plt is still writable.   Tips Command checksec \u0026lt;binary\u0026gt; shows the section names:\n[huzaifas@babylon ~] $ checksec test [*] \u0026#39;/home/huzaifas/test\u0026#39; Arch: amd64-64-little RELRO: Full RELRO Stack: No canary found NX: NX enabled PIE: No PIE (0x400000) Command to check the GOT entry address of printf:\n$ objdump -R test | grep -i printf 0000000000600fe0 R_X86_64_GLOB_DAT printf@GLIBC_2.2.5 More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-cfi/",
	"title": "CFI with CHERI",
	"tags": [],
	"description": "",
	"content": " References:\n Security Analysis of CHERI ISA CHERI ISA V5.   From CHERI ISA V5:\nCHERI allows software privilege to be minimized at two levels of abstraction.\n architectural least privilege: memory capability.\n data pointers: against data-oriented vulnerabilities, such as buffer overflows. code pointers: support CFI by preventing corruption of code pointers/return addresses.  application-level least privilege: software compartmentalization using object capabilities.\n  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/l4/sel4/time-protection/",
	"title": "2019 Time Protection",
	"tags": [],
	"description": "",
	"content": " References:\n The last mile\n Time Protection: The Missing OS Abstraction, Qian Ge, Yuval Yarom, Tom Chothia, and Gernot Heiser. 2019. In Proceedings of the Fourteenth EuroSys Conference 2019 (Dresden, Germany) (EuroSys ’19). ACM, New York, NY, USA, Article 1, 17 pages. https://doi.org/10.1145/3302424.3303976;\n paper site  \u0026ldquo;No security without time protection: We need a new hardware-software contract.\u0026rdquo;, Ge, Qian, Yuval Yarom, and Gernot Heiser. In Proceedings of the 9th Asia-Pacific Workshop on Systems, pp. 1-9. 2018.\n paper site, pdf   Timing Channel Prevention\nProblem \u0026ldquo;Microarchitectural timing channels result from competition for hardware resources that are functionally transparent to software.\u0026rdquo;\n\u0026ldquo;The instruction-set architecture(ISA), i.e. the hardware-software contract, abstracts these resources away, as they are irrelevant for functional correctness. However, the abstraction leaks, as it affects observable execution speed, leading to timing channels.\u0026rdquo;\nThese hardware resources under competition include two categories:\n Microarchitectural state. Leverages temporal and spatial locality to improve average-case performance.\n data and instruction caches TLBs branch predictors instruction- and data- prefetcher state machines DRAM row buffers core-local resources  with hyperthreading: these are cocurrently accessed like shared caches; without hyperthreading: these are time-shared.   Stateless interconnects: Time sharing cannot produce interference on these, while concurrent access can be observed as a reduction of available bandwith.\n buses on-chip networks   Current Status Partition support for spatially/concurrently sharing\nResetting support for temporal/non-partitionable sharing\n x86:\n limited support for resetting microarchitectural state; no way of resetting only on-core state cache flush: wbinvd instruction: flushes the complete cache hierachy; overkill for time protection;  should be partitioned rather than reset;  worst-case cost measured at 12ms on an Intel Sandy Bridge system(including the indirect cost of subsequent misses). TLB flush: invpcid in 64-bit mode (reload CR3 and CR0 in 32-bit mode, to invalidate both non-global and global mappings) disable data prefetcher: updating MSR 0x1A4 [Viswanathan 2014] instruction prefetcher: no way to control instruction prefetcher indirect branch control (IBC): ???  Arm\n Cache: a selective flush of the L1 cache, without affecting lower levels in the cache hierarchy;  DCCISW ICIALLU  TLB:  TLBIALL: flush the TLB;  Branch predictor:  BPIALL: flush the branch predictor;  data prefetcher: platform-dependent  Hikey platform: CPU auxiliary control register  instruction prefetcher: no way to disable.   Attack evaluation Channels that cannot be closed making full use of any reset mechanisms provided the architecture.\nChannels exploiting L1 I-cache, Branch target buffer, and Branch history buffer.\nPrime+Probe \u0026ndash;\u0026gt; communication between Trojan and spy.\nChannels:\n L1 D-cache L1 I-cache, refer to [Acıiçmez 2007; Acıiçmez et al. 2010] and [Yarom 2016] BTB, refer to d [Milenkovic et al. 2004] and [Godbolt 2016] BHB, as in [Evtyushkin et al. 2016]  Countermeasures (Partition or Reset)\nOn stateful resources: partitioning spatially or temporally\n Spatial partitioning:\n page colouring  OS control the access to physically indexed caches (L2\u0026hellip;LLC) set selector bits in the address overlap with the page number. sets \u0026lt;\u0026ndash;\u0026gt; colour. Page size of P, cache size of S, associativity w:  num of colours: S/wP.   no L1 colour: L1 usually indexed by virtual address, which is not under OS control. Same applies to other on-core state: TLB, BP.  These on-core caches must be flused on a domain switch.  ARM cache partition:  Temporal partitioning: by time slices\n flushing all history-dependent state between time slices not possible where domains access a resource concurrently (instead of time sharing). Such as core-shared-caches.   Hardware-software contract Augmented ISA: aISA.\nFor all shared hardware state, they should be able to be reset or partitioned:\n security-enforcement: either partitionable or resettable; secure concurrent sharing: must be partitionable; secure virtually indexed state: must be resettable and not concurrently accessed;  this implies cannot share HW threads across security domains!  specified mechanisms allowing OS to partition or reset:  a complete spec/contract; constant time or bounded worst-case latency;  state provenance for resettable state: aISA must specify whether a rest operation acts on state derived from data, instructions, data addresses or instruction addresses;  OS must know if resettable state is derived from data, isntructions, data addresses or instruction addresses; for a more detailed reset operation to improve performance; a more abstract/general are legal: e.g., a single reset operation to reset all virtually-addressed microarchitectural state (caches, TLB, branch predictor ,and prefetcher);   OS mechanisms for time protection  Cache Colouring Kernel Cloning and Colouring  private kernel image + a small amount of shared static data   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/side-channel/2020-carrv-wistoff/",
	"title": "2020 Carrv Wistoff: Prevention of microarchitectural covert channels on an open-source 64-bit risc-v core",
	"tags": [],
	"description": "",
	"content": " References:\n Wistoff, Nils, Moritz Schneider, Frank K. Gürkaynak, Luca Benini, and Gernot Heiser. \u0026ldquo;Prevention of microarchitectural covert channels on an open-source 64-bit risc-v core.\u0026rdquo; arXiv preprint arXiv:2005.02193 (2020).  fence.t Temporal Fence Instruction fence.t\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/side-channel/",
	"title": "Side Channel",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  sel4: time protection   2020 Carrv Wistoff: Prevention of microarchitectural covert channels on an open-source 64-bit risc-v core   References: Wistoff, Nils, Moritz Schneider, Frank K. Gürkaynak, Luca Benini, and Gernot Heiser. \u0026ldquo;Prevention of microarchitectural covert channels on an open-source 64-bit risc-v core.\u0026rdquo; arXiv preprint arXiv:2005.02193 (2020). fence.t Temporal Fence Instruction fence.t More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/attacks/side-channel/",
	"title": "Side Channel",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Spectre Attacks   References: Survey of Transient Execution Atacks. Wenjie Xiong, Jakub Szefer. Arxiv, 2020. More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/riscv/iopmp/",
	"title": "IOPMP",
	"tags": [],
	"description": "",
	"content": " References:\n Syntacore IOPMP proposal. v.20210124, mailto:stanislav.zhelnio@syntacore.com  Proposal Overview \u0026ldquo;The block is designed to filter requests to memory and peripherals\u0026rdquo;\n\u0026ldquo;Requests are checked on the basis of request address (and size) and the request source ID (SID)\u0026rdquo;\nPossible usage scenarios:\n filtering the CPU requests when the CPU PMP managed by OS or hypervisor is not trusted; filtering the DMA requests when the IOMMU settings managed by hypervisor are not trusted; filtering all the requests to memory or peripheral device.  Proposed Features  Base IOPMP function\n SID entry point: iopmp rule number that the checking start from.\n always start from 0 if not implemented; help to reduce the number of rule checks.  Rule masking\n Jump rule\n Flexible unclock control\n Strong ordering\n Boot access\n  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/spec-sail/riscv-sail/",
	"title": "RISCV in Sail",
	"tags": [],
	"description": "",
	"content": " References:\n Sail RISCV Reading Guide Extending the model  RISCV Sail Definitions in directory model/\n ./model/ (files in dependency order)\n \u0026hellip; riscv_xlen32.sail: define xlen for RV32 riscv_xlen64.sail: define xlen for RV64 \u0026hellip; prelude.sail : constains Sail library functions prelude_mapping.sail : prelude_mem.sail : defines lowest level memory access primitives. These primitives will be implemented by the various Sail backends. This depends on the value of xlen prelude_mem_metadata.sail : \u0026hellip; riscv_types.sail : This contains basic definitions used throughout the specification  privilege levels, register indices, interrupt and exception definitions, enumerations, types used to define memory accesses.  riscv_reg_type.sail : register types. In a separate file so that it can be redefined in the extensions. riscv_regs.sail : contains base register file. Types is defined in riscv_reg_type.sail. \u0026hellip; riscv_pc_access.sail : functions to access and modify the program counter. \u0026hellip; riscv_sys_regs.sail : This describes the privileged architectural state:  M-mode and S-mode CSRs. helpers to interpret CSR content, such sa WLRL and WARL fields. WLRL/WARL fields are intended to capture platform-specific functionality, thus future versions of the model might separate their handling functions out into a separate platform-defined file. riscv_sys_control.sail : This describes interrupt and exception delegation and dispatch, and the handling of privilege transitions. riscv_sys_exceptions.sail : This defines the handling of the addresses involved in exception handling. riscv_sync_exception.sail : This describes the structure used to capture the architectural information for an exception.  \u0026hellip; riscv_platform.sail : contains platform-specific functionality for the model.  physical memory map local interrupt controller the MMIO interfaces to the clock timer and terminal devices externally selectable options for platform behavior, such as:  handling of misaligned memory accesses handling of PTE dirty-bit updates during address translation those implemented outside of sail model, e.g., C or Ocaml emulators.   \u0026hellip; riscv_mem.sail : converts physical address access into 1) physical memory access, or 2) MMIO access to the devices, or 3) access fault. riscv_vmem_*.sail : describes the S-mode address translation.\n riscv_vmem_types.sail and riscv_vmem_common.sail contain the definitions and processing of the page-table entries and their various permission and status bits.  riscv_addr_checks_common.sail and riscv_addr_checks.sail: hooks for address transformation.\n \u0026hellip;\n riscv_insts_*.sail : instruction definitions and their assembly language formats.\n riscv_insts_base.sail : base integer instruction set. riscv_insts_hints.sail : Hint instructions that are not implicitly handled elsewhere are explicitly handled here. each instruction is represented as a variant clause of the ast type the execution semantics are represented as a clause of the execute function mapping clauses specify the encoding and decoding of each instruction to and from their binary representations and assembly language formats.   riscv_fetch.sail : contains the instruction fetch function.\n riscv_step.sail : top-level fetch and execute loop.\n step function: instruction fetch, fetch error handling, decoding, dispatching, checking interrupts. loop function: the execution loop. Use the same HTIF(host-target interface) mechanism to detect the termination as Spike.  \u0026hellip;\n riscv_analysis.sail : This is used in the formal operational RVWMO memory model.\n \u0026hellip;\n main.sail : ?\n   Example:\nSRET instruction def in Sail:\nunion clause ast = SRET : unit mapping clause encdec = SRET() \u0026lt;-\u0026gt; 0b0001000 @ 0b00010 @ 0b00000 @ 0b000 @ 0b00000 @ 0b1110011 function clause execute SRET() = { match cur_privilege { User =\u0026gt; handle_illegal(), Supervisor =\u0026gt; if mstatus.TSR() == true then handle_illegal() else nextPC = handle_exception(cur_privilege, CTL_SRET(), PC), Machine =\u0026gt; nextPC = handle_exception(cur_privilege, CTL_SRET(), PC) }; false } mapping clause assembly = SRET() \u0026lt;-\u0026gt; \u0026quot;sret\u0026quot;  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/fm-in-arch/spec-sail/",
	"title": "Spec Sail",
	"tags": [],
	"description": "",
	"content": " References:\n RISCV Sail on Github\n Using Sail Specifications in Isabelle/HOL, August 29, 2018. pdf\n  Sail Goals: engineer-friendly, vendor-pseudocode-like language for describing instruction semantics.\nSail: a first-order imperative language, but with lightweight dependent typing for numeric types and bitvector lengths.\nSide-effects: Sail use its effect system to determine whether a function has side-effects and needs to be monadic.\nMonadic function:\n All about monads:\n Monads is a way to structure computations in terms of values and sequences of computations using typed values. Monads are strategies for solving coding problems that recur often, regardless of what you are writing. More than this, monads help make strategies composable: Combining computations into more complex computations. Examples: Maybe type, the List, and I/O are monads (in Haskell).  List solves a common problem: you need a very basic collection of items of the same type, with some easy-to-understand behavior and performance characteristics. Maybe type: rescues you from having to write lots of null pointer checks \u0026ndash; or else debug code that does not have enough of them. I/O makes it possible to interact with a program at all.   a monadic function is a function with a single argument, written to its right. cite\n A short and simple answer: a monadic function is one whose return data signature/type is the same as its input data signature/type. cite\n Monad \u0026ndash; Computation Builder: monad is a pattern for chaining operations. It looks a bit like method chaining in object-oriented languages, but the mechanism is slightly different. The pattern can be used in any language which support higher-order functions (that is, functions which can take other functions as arguments). cite\n  Sail with Isabelle Sail Spec:\n a decode function: map from raw instruction opcodes to a more abstract representation, an execute function specifying the behaviour of instructions, further auxiliary functions, and register declarations.\nSail --\u0026gt; Lem --\u0026gt; Isabelle/HOL |--\u0026gt; HOL4   Translate to lem from Sail using -lem option:\nsail -lem -o riscv_duopod -lem_mwords -lem_lib Riscv_extras preclude.sail riscv_duopod.sail\n-lem activates the generation of Lem def.\n-o riscv_duopod specifies the prefix of output, it will generate files:\n- `riscv_duopod_types.lem`, types used in the defs; - `riscv_duopod.lem`, main definitions, e.g., of the instructions; - `Riscv_duopod_lemmas.thy`, generated helper lemmas;  -lem_mwords: use the machine word representation of bitvectors.\n-lem_lib Riscv_extras: Lem lib to be imported.\nTranslate from Lem to Isabelle, using -isa option:\nlem -isa -outdir . -lib Sail=../src/lem_interp -lib Sail=../src/gen_lib riscv_extras.lem riscv_duopod_types.lem riscv_duopod.lem\nIsabelle Examples:\nAbstract syntax Abstract syntax:\ndatatype ast = ITYPE (12 word * 5 word * 5 word * iop) | LOAD (12 word * 5 word * 5 word) Decode function Decode function: decode :: 32 word ==\u0026gt; ast option.\n decode function is pure. (Sail use its effect system to determine whether a function has side-effects and needs to be monadic.)\ndecode opcode = (if-then-else-cascade)  Execute function Execute function: is monadic.\nexecute-LOAD imm rs rd = rX (regbits-to-regno rs) \u0026gt;\u0026gt;= ($\\lambda$w--0. let addr = add-vec w--0 (EXTS 64 imm) in MEMr0 addr 8 \u0026gt;\u0026gt;= wX (regbits-to-regno rd) ) ==\u0026gt; reads the base addr from the source register rs, then adds the offset in the immediate argument imm, calls the MEMr auxiliary function to read 8 bytes starting at the calculated address, and writes the result into the destination register d.\nAuxiliary functions Auxiliary functions: dispatch inputs to auxiliary functions.\nexecute (ITYPE (imm1, rs1, rd1, arg3.0)) = execute-ITYPE imm1 rs1 rd1 arg3.0 execute (LOAD (imm, rs, rd)) = execute-LOAD imm rs rd  Register declarations regstate record gets generated from register declarations in Sail source code:\nrecord regstate = Xs :: (64 Word.word) list nextPC :: 64 Word.word PC :: 64 Word.word  ==\u0026gt; In RISC-V spec, the general-purpose register file is declared as one register Xs containing the 32 registers and 64 bits each. It gets mapped to a list of 64-bit words.\nMonads for concurrent reasoning Concurrent: free monad of an effect datatype that provides fine-grained information about the register and memory effects of monadic expressions, suitable for integration with relatex memory models.\nMonads for sequential reasoning Sequential case: we use a state monad (with exceptions and nondeterminism)\nExample in Isabelle \u0026ndash; ADDI Goal: prove that the add instruction in RISC-V duopod actually performs an addition.\nThe ADDI def in isabelle:\nSequential case, use state monad.\nSail.Hoare:\n{|precondition P|} monadic expression f {| postcondition Q |}\n{|precondition P|} monadic expression f {| postcondition Q | exceptions E |}\nProof:\nStep1: Simplication: unfolds the definitions of the auxiliary functions rX and wX, performs the lifting from the free monad to the state monad;\nStep2: Apply the rule PrePostE-strengthen-pre (in backward manner) to allow a weaker precondition;\nStep3: Use the rules in PrePostE-compositeI and PrePostE-atomI to derive a weakest precondition;\nStep4: Use auto to show that it is implied by the given precondition.\nFor more serious proofs, one will want to set up specialized proof tactics. This example uses only basic proof methods, to make the reasoning steps more explicit.\nSail with Coq A direct Sail-to-Coq backend.\nMore  Islaris: Verification of Machine Code Against Authoritative ISA Semantics  References: Islaris: verification of machine code against authoritative ISA semantics Problem Machine code verification: some critical code manipulates arch features that are not exposed in higher-level languages, e.g., to access system registers to install exception vector tables, or to configure address translation; this is necessarily written in assembly. verification without needing trust or verification of any compilation or assembly steps. verify the machine code after any modifications introduced by linking or initialisation (perhaps parametrically w.\n RISCV in Sail  References: Sail RISCV Reading Guide Extending the model RISCV Sail Definitions in directory model/ ./model/ (files in dependency order) \u0026hellip; riscv_xlen32.sail: define xlen for RV32 riscv_xlen64.sail: define xlen for RV64 \u0026hellip; prelude.sail : constains Sail library functions prelude_mapping.sail : prelude_mem.sail : defines lowest level memory access primitives. These primitives will be implemented by the various Sail backends. This depends on the value of xlen prelude_mem_metadata.sail : \u0026hellip; riscv_types.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/attacks/side-channel/spectres/",
	"title": "Spectre Attacks",
	"tags": [],
	"description": "",
	"content": " References:\n Survey of Transient Execution Atacks. Wenjie Xiong, Jakub Szefer. Arxiv, 2020.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/asan/califorms/",
	"title": "Califorms",
	"tags": [],
	"description": "",
	"content": " References:\n Sinha, Kanad, and Simha Sethumadhavan. \u0026ldquo;Practical memory safety with REST.\u0026rdquo; 2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA). IEEE, 2018.  Overview REST: Random Embedded Secret Tokens (REST)\n 1-bit metadata per L1 data cache line a comparator to check for REST tokens during a cache fill software support based on AddressSanitizer  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/rest/",
	"title": "Rest",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/safemem/",
	"title": "Safemem",
	"tags": [],
	"description": "",
	"content": " References:\n Qin, Feng, Shan Lu, and Yuanyuan Zhou. \u0026ldquo;SafeMem: Exploiting ECC-memory for detecting memory leaks and memory corruption during production runs.\u0026rdquo; 11th International Symposium on High-Performance Computer Architecture. IEEE, 2005.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/sec-compile/asan/",
	"title": "Asan",
	"tags": [],
	"description": "",
	"content": " References:\n K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov, “Addresssanitizer: A fast address sanity checker,” in ATC, 2012. reference  Overview \u0026ldquo;[AddressSanitizer]\u0026rdquo;:\n use shaow memory to record whether each byte of application memory is safe to access; use instrumentation to check the shadow memory on each application load or store; more efficient than AddrCheck in Valgrind:  use a more efficent shadow mapping; a more compact shadow encoding.   8-byte memory \u0026ndash;\u0026gt; 9 different states, 1 byte encoding (first k bytes addressable, 0\u0026lt;= k \u0026lt;=8)\nHWASAN More  Califorms   References: Sinha, Kanad, and Simha Sethumadhavan. \u0026ldquo;Practical memory safety with REST.\u0026rdquo; 2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA). IEEE, 2018. Overview REST: Random Embedded Secret Tokens (REST) 1-bit metadata per L1 data cache line a comparator to check for REST tokens during a cache fill software support based on AddressSanitizer More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/rtl-v/uvm/",
	"title": "UVM - Universal Verification Methodology",
	"tags": [],
	"description": "",
	"content": " References:\n UVM shizhan, juan I  IC design process\ndesign: Verilog/VHDL\nverification: Verilog, SystemVerilog, SystemC,\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/rtl-v/",
	"title": "Rtl Verification",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  UVM - Universal Verification Methodology   References: UVM shizhan, juan I IC design process design: Verilog/VHDL verification: Verilog, SystemVerilog, SystemC, More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/capability/confused-deputy/",
	"title": "Confused Deputy",
	"tags": [],
	"description": "",
	"content": " References:\n N. Hardy, “The confused deputy (or why capabilities might have been invented),” ACM SIGOPS Operating Systems Review, vol. 22, no. 4, pp. 36–38, 1988.  Overview A story in a system much like Unix (of AT\u0026amp;T):\nRUN (SYSX)FORT, to invoke a compiler FORT.\n(SYSX)A_FILE, customized file from the invoker to write debug information to A_FILE.\n(SYSX)STAT, to write statistics as output, filename hardcoded in the compiler. In order to access STAT file, we give compiler home files license \u0026ndash;\u0026gt; to write files in the home directory (SYSX), then write (SYSX)STAT\n(SYSX)BILL, which contains billing information, should not be overwritten by a compiler.\nBut when (SYSX)BILL is passed to the compiler (SYS)FORT, the billing info will be overwritten.\n==\u0026gt; The compiler is a confused deputy. It runs with authority stemming from two sources.\n The invoker yields his authority to the compiler when he says \u0026ldquo;RUN(SYSX)FORT\u0026rdquo;; The compiler has another authority stems from the home files license.  ==\u0026gt; When the compiler produces statistics it intends to use the authority granted by its home files license;\nWhen it produces its debugging output it intends to use authority from its invoker;\nBut the compiler had no way of expressing these intents!\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/autocars/",
	"title": "Autonomous Driving Cars",
	"tags": [],
	"description": "",
	"content": " References:\n V2X: Vehicle to everything  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/ml/",
	"title": "ML",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  Reading Notes on Dr. Mi Zhang\u0026#39;s Publications  References: Mi Zhang - Publications Publications in 2020 Mutual Net ECCV\u0026rsquo;20: MutualNet: Adaptive ConvNet via Mutual Learning from Network Width and Resolution Distream SenSys\u0026rsquo;20: Distream: Scaling Live Video Analytics with Workload-Adaptive Distributed Edge Intelligence WiFi SenSys\u0026rsquo;20: WiFi See It All: Generative Adversarial Network-augmented Versatile WiFi Imaging. SecWIR MobiSys\u0026rsquo;20: SecWIR: Securing Smart Home IoT Communications via WiFi Routers with Embedded Intelligence. FlexDNN SEC\u0026rsquo;20: FlexDNN: Input-Adaptive On-Device Deep Learning for Efficient Mobile Vision.\n Intro Ml  Two Ways to Categorize ML algorithms References: A Tour of Machine Learning Algorithms Two ways: Group them by learning style, and by their similarity in form or function. By Learning Styles cite: https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/ Supervised learning: all training data with known labels. e.g. Logistic Regression, Back propagation neural network. Unsupervised learning: Input data is not labeled. e.g. Apriori algorithm, K-Means. Semi-Supervised learning: input data is a mixture of labeled and unlabelled examples.\n NAS  Neural Architecture Search (NAS) [49, 50, 32, 6, 42, 45] dominates efficient network design. From \u0026ldquo;MCUNet: Tiny Deep Learning on IoT Devices\u0026rdquo; by Lin, Ji, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, and Song Han; References: Citations of NAS from \u0026ldquo;NeurIPS\u0026rsquo;20: MCUNet: Tiny Deep Learning on IoT Devices\u0026rdquo; by Lin, Ji, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, and Song Han ICLR\u0026rsquo;17: Neural Architecture Search with Reinforcement Learning.\n Lane   ICLR\u0026rsquo;19: An Empirical study of Binary Neural Networks\u0026rsquo; Optimization. ECCV\u0026rsquo;20: Journey towards tiny perceptual super-resolution MobiCom\u0026rsquo;20: SPINN: Synergistic Progressive Inference of Neural Networks over Device and Cloud InterSpeech\u0026rsquo;20: Iterative Compression of End-to-End ASR Model using AutoML DAC\u0026rsquo;20: Best of Both Worlds: AutoML Codesign of a CNN and its Hardware Accelerator More 2020 SPINN References: reference Evaluation Server: 2x Intel Xeon Gold 6130, 128GB Memory, with GPU GTX 1080Ti Client: Nvidia Jetson Xavier AGX, 16GB Memory, with GPU 512-core Volta More  Songhan  TinyTL NeurIPS\u0026rsquo;20: Tiny Transfer Learning: Towards Memory-Efficient On-Device Learning Three benchmark datasets: Cars, Flowers, Aircraft Using ImageNet as the pre-training dataset. Neural network architecture: MobileNetV2 (lightweight), ResNet-50. Devices: Raspberry Pi 1. 256MB of memory. Once for all ICLR\u0026rsquo;20: Once-for-all: Train one network and specialize it for efficient deployment. ImageNet; Samsung S7 Edge, Note10, Google Pixel1, Pixel2, LG G8, NVIDIA 1080 Ti, V100 GPUs, Jetson TX2, Intel Xeon CPU, Xilinx ZU8EG, and ZU3EG FPGAs.\n Training Opt  Reference 1 2018 Mobile Crowd Reference 1 Anh, Tran The, Nguyen Cong Luong, Dusit Niyato, Dong In Kim, and Li-Chun Wang. \u0026ldquo;Efficient training management for mobile crowd-machine learning: A deep reinforcement learning approach.\u0026rdquo; IEEE Wireless Communications Letters 8, no. 5 (2019): 1345-1348. ↩ 2011 Realtime Train Reference 1 Choi, Kwontaeg, Kar-Ann Toh, and Hyeran Byun. \u0026ldquo;Realtime training on mobile devices for face recognition applications.\u0026rdquo; Pattern recognition 44, no.\n Optimizing Inference  Reference 1 2019 Jointdnn Reference 1 Eshratifar, Amir Erfan, Mohammad Saeed Abrishami, and Massoud Pedram. \u0026ldquo;JointDNN: an efficient training and inference engine for intelligent mobile cloud computing services.\u0026rdquo; IEEE Transactions on Mobile Computing (2019). ↩ 2019 Eurosys ULayer Reference 1 Kim, Youngsok, Joonsung Kim, Dongju Chae, Daehyun Kim, and Jangwoo Kim. \u0026ldquo;μLayer: Low Latency On-Device Inference Using Cooperative Single-Layer Acceleration and Processor-Friendly Quantization.\u0026rdquo; In Proceedings of the Fourteenth EuroSys Conference 2019, pp.\n Automl  Reference 1 2013 Kdd Auto WEKA Reference 1 Thornton C, Hutter F, Hoos HH, Leyton-Brown K (2013). Auto-WEKA: Combined Selection and Hyperparameter Optimization of Classification Algorithms. KDD \u0026lsquo;13 Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. pp. 847–855. ↩ reference ↩  Deep Learning  Top Wondering Besides deep learning, many other solutions exists for computers to discover informal knowledge by itself. How many do we know and how they are catergorized? Until now, is there any new knowledge have been discovered by deep learning? Ones in traditional style: any new mathematical/physical theories discovered yet? Ones in non-traditional style? For image-processing based AIs such as object detection: is the image a good source for feature extracting?\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/os/basics/rtos/",
	"title": "Real Time Operating System (Basics)",
	"tags": [],
	"description": "",
	"content": " References:\n RTOS Fundamentals  RTOS Fundamentals Reference: RTOS Fundamentals\n Multitasking  Mutitasking can simply file the system design by partition complex application into smaller tasks easier testing, code reuse, task breakdown (better team collaboration), os dedicated for timing and sequencing.  Scheduling  Non real time: \u0026ldquo;fair\u0026rdquo; proportion of processor time among tasks; Real Time:  Context Switching  Context: processor registers, stack, etc.  Real Time Applications  Timely response to real world events; A priority to each task assigned by the developers; RTOS ensures that the highest priority task that is able to execute is the task given processing time;  Real Time Scheduling  Priority based scheduling.   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2015-asplos-nested-kernel/",
	"title": "2015 Nested Kernel",
	"tags": [],
	"description": "",
	"content": " References:\n Dautenhahn, Nathan, Theodoros Kasampalis, Will Dietz, John Criswell, and Vikram Adve. \u0026ldquo;Nested kernel: An operating system architecture for intra-kernel privilege separation.\u0026rdquo; In Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 191-206. 2015.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/mpx/sec19-erim/",
	"title": "USENIX Security&#39;19 ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK)",
	"tags": [],
	"description": "",
	"content": " References:\n Vahldiek-Oberwagner, Anjo, Eslam Elnikety, Nuno O. Duarte, Michael Sammler, Peter Druschel, and Deepak Garg. \u0026ldquo;ERIM: Secure, efficient in-process isolation with protection keys (MPK).\u0026rdquo; In 28th USENIX Security Symposium (USENIX Security 19), pp. 1221-1238. 2019.  Background Intel MPK:\n 4-bits permission bits in page table entry; 16 disjoint domains. PKRU: 32-bit registers; 2-bits perms for each region. 11-260 cycles to update PKRU.  0.07 to 1.0% overhead per 100,000 switches/s on a 2.6 GHz CPU. 4.8% overhead on NGINX when isolating all session keys   Legacy API Memory Layout Evaluation SQLite, Node.js\nOpenSSL: - 4.8% overhead on NGINX when isolating all session keys - up to 6.3x, 13.5x, and 3x lower than the overhead of SFI (with Intel MPX), lwCs, and Intel VT-x.\nCPI\ndomain switch rates of the order of 10^5 or 10^6 times a second.\nUse cases partition details:\n OpenSSL: Isolating cryptographic keys in web services.\n isolating long-term SSL keys \u0026ndash;\u0026gt; less frequently e.g., against Heartbleed bug. isolating session keys \u0026ndash;\u0026gt; over 10^6 times a second per core in a high throughput web server like NGINX. session keys protect the confidentiality of individual users. partitioned OpenSSL\u0026rsquo;s low-level crypto library (libcrypto) to isolate the session keys and basic crypto routines, which runs as T, from the rest of the web server, which runs as U.  Node.js: Native libraries in managed runtimes.\n isolate Node.js from a native SQLite plugin(a third-party native library). Node.js: a state-of-the-art managed runtime for JavaScript; SQLite: a state-of-the-art database library written in C [^c1] [^c2].   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/cnspp/",
	"title": "Cnspp: Cryptography and Network Security: Principles and Practice",
	"tags": [],
	"description": "",
	"content": " References:\n 密码编码学与网络安全\u0026mdash;原理与实践，William Stallings著，孟庆树等译，电子工业出版社，第四版。  信息安全、计算机安全、网络安全 信息安全：\n 物理手段：如重要文件放在上锁的文件柜 行政手段：对员工的检查制度 借助自动工具保障计算机的安全。保护计算机中存储的文件和其他信息，尤其对共享系统，如时间共享系统，以及通过公共电话网、数据网或Internet可以访问的系统。 计算机网络中信息传输的保护。  计算机安全：\n保护计算机的数据、阻止黑客攻击，一般成为计算机安全。\n网络安全：\n随着分布式系统、终端用户与计算机之间以及计算机与计算机之间传送数据的网络和通信设施的应用，信息的传输需要有网络安全措施来保护。 事实上，术语“网络安全”容易引起误解，因为实际上所有的商业、政府和学术组织都将其数据处理设备与互联网相联，这些互联网可能相互独立，但都称为internet，并使用术语internet安全。\n计算机安全与网络安全没有明确的界限：例如，对信息系统最常见的攻击就是计算机病毒，它可能先感染磁盘或光盘，然后才加载到计算机上，从而进入系统，也可能是通过internet进入系统. 无论是哪一种情况,一旦病毒驻留在计算机系统中，就需要内部的计算安全工具来检查病毒并恢复数据。\n本书主要讨论internet的安全，包括如何预防、阻止、检测和纠正信息传输中出现安全问题。\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-temporal/sp20-cornucopia/",
	"title": "[2020 Oakland] Cornucopia: Temporal Safety for CHERI heaps",
	"tags": [],
	"description": "",
	"content": " References:\n N. Wesley Filardo et al., \u0026ldquo;Cornucopia: Temporal Safety for CHERI Heaps\u0026rdquo; 2020 IEEE Symposium on Security and Privacy (SP), 2020.  Motivation Language-level temporal safety.\nWith CHERI, the temporal safety can be achieved via one of the two ways:\n Table lookups. This is avoided for performance in the CHERI design. Identifying capabilities in memory to revoke them. This is similar to a garbage-collector sweep.  CHERIvoke: a prior feasibility study on latter, key aspects modeled on x86 machines.\nCornucopia: practical design and impl. of the CHERIvoke paper;\nOverview Cornucopia\n extends the CHERIvoke paper by:  cocurrent sweeping revocation that can be performed in parallel with application threads (III); cases in sweeping revocation beyond the user address space, including user capabilities in register files and kernel structures (IV-A); virtual memory techniques that facilitate tracking the spread of capabilities to efficiently prune pages from sweeping passes (IV-D); asynchronous revocation that enables multiple allocators to safely and efficiently share kernel-managed sweeping resources (Append. A and B).  new allocators and allocator-agnostic wrappers:\n dlmalloc, snmalloc; wrapper that can augment any existing allocator with temporal safety;  impl. on MIPS, FPGA, CheriBSD.\n  Cornucopia More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-domain/cheri-compart-papers/2013-sp-harris/",
	"title": "Declarative, Temporal, and Practical Programming with Capabilities",
	"tags": [],
	"description": "",
	"content": " References:\n William R. Harris, Somesh Jha, Thomas Reps, Jonathan Anderson, and Robert N. M. Watson. Declarative, Temporal, and Practical Programming with Capabilities, 2013, IEEE Security and Privacy (Oakland).  Motivation Network utilities process data read directly from a network connection, but execute vulnerable code (tcpdump1, wget2, etc.).\nTraditional OS environment, \u0026ldquo;if a programmer wants to verify that his program is secure, he typically must first verify that the program satisfies very strong properties, such as memory safety.\u0026rdquo;\n\u0026ldquo;However, recent work 3 4 5 6 has produced new operating systems that allow programmers to develop programs that execute untrusted code yet satisfy strong security requirements.\u0026rdquo;\n\u0026ldquo;Moreover, programmers can develop such programs with much less effort than fully verifying the program for a traditional operating system.\u0026rdquo;\n\u0026ldquo;The developers of such systems have manually modified applications to invoke security primitives so that the application satisfies strong security policies, even when the application contains untrusted code.\u0026rdquo;\nExample: Capsicum 5 on FreeBSD 7.\n \u0026ldquo;A capability is a file descriptor and an access right for the descriptor\u0026rdquo;. Defines \u0026ldquo;whether a process has the privilege to grant to itself further capabilities (i.e. open more files)\u0026rdquo;. (LLM: secure???) Provides each process a list of system calls that the process can invoke. \u0026ldquo;Trusted code in a program can first communicate with its environment unrestricted by Capsicum, and then invoke primitives to limit itself to have only the capabilities that it needs for the remainder of its execution.\u0026rdquo; \u0026ldquo;Untrusted code executes only the limitd capabilities defined by the trusted code.\u0026rdquo; In practice, \u0026ldquo;it is difficult for programmers to reason about the subtle, temporal effects of the primitives\u0026rdquo;:  tcpdump: difficulty results from the conflicting demands of (i) using low-level primitives, (ii) ensuring that the program satisfies a strong, high-level security requirement, and (iii) preserving the core functionality of the original program.   Overview describes capweave, a tool that\n takes as input\n An LLVM Program. A program that does not invoke Capsicum primitives A declarative, temporal policy, stated in terms of the capabilities that the program should hold over the course of its execution. (of the possibly-changing capabilities that a program must hold during its execution).  automatically rewrites the program to use Capsicum system calls to enforce the policy. (Compartmentalizes the program and instruments it to invoke Capsicum primitives so that it satisfies the policy when executed on Capsicum).\n  Challenges Two key challenges that a programmer faces when manually rewriting a program for Capsicum.\n To define what \u0026ldquo;secure behavior\u0026rdquo; means for his program. To write his program to be both secure and functional.  wget Separation  For each input URL, wget determines under what protocol the URL is addressed (line L1). Then wget runs protocol-specific functions to  (i) open a socket to the server holding the URL (line L2), (ii) download the data addressed by the URL over the socket (lines L3 and L4), and (iii) write the data to a file in the file system (line L5).   Security Vulnerability in wget 2:\n Versions through v.1.12 include a vulnerability that allows an attacker who controls a server with with which wget interacts to write data to any file on the host file system that can be written by the user who runs wget. It is exposed when wget processes a particular HTTP response from the server.  receive a redirect response from a server (which directs wgets to download data from a different network address); wget determines the path in its host file system to which it will write data directly from the information provided by the redict server.  A malicious server can exploit this behavior to craft a redirect response that causes wget to write data chosen by the attacker to a path in the file system chosen by the attacker2.  To defense:\n Traditional way:  \u0026ldquo;formally specify that wget must not demonstrate a vul. along the lines of the one described above\u0026rdquo; \u0026ldquo;rewrite wget so that it satisfies such a specification.\u0026rdquo; \u0026ldquo;requires detailed knowledge of both the structure of wget and of the HTTP protocol\u0026rdquo;.  This paper seek for ways:  \u0026ldquo;a developer could define an acceptable, if perhaps weaker, specification for wget in terms of commonly-used, well-understood operating-system objects, such as file descriptors\u0026rsquo;: e.g. \u0026ldquo;When wget executes read_http, it should always be able to open arbitrary files and sockets. But wget should execute write_data with the ability to open files if and only if it has not received an HTTP-redirect response\u0026rdquo;.   Evaluation More   “CVE-2007-3798,” http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2007-3798, July 2007. ↩ “CVE-2004-1488,” http://cve.mitre.org/cgi-bin/cvename.cgi?name=CAN-2004-1488, Feb 2005. ↩ P. Efstathopoulos, M. Krohn, S. VanDeBogart, C. Frey, D. Ziegler, E. Kohler, D. Mazières, F. Kaashoek, and R. Morris, “Labels and event processes in the Asbestos operating system,” in SOSP, 2005. ↩ M. Krohn, A. Yip, M. Brodsky, N. Cliffer, M. F. Kaashoek, E. Kohler, and R. Morris, “Information flow control for standard OS abstractions,” in SOSP, 2007. ↩ R. N. M. Watson, J. Anderson, B. Laurie, and K. Kennaway,“Capsicum: Practical capabilities for UNIX,” in USENIX Security, 2010. ↩ N. Zeldovich, S. Boyd-Wickizer, E. Kohler, and D. Mazières, “Making information flow explicit in HiStar,” in OSDI, 2006. ↩ “FreeBSD 9.0-RELEASE announcement,” http://www.freebsd.org/releases/9.0R/announce.html, Jan. 2012. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/mem-tag/mpk/",
	"title": "Memory Protection Keys",
	"tags": [],
	"description": "",
	"content": " References:\n Memory Protection Keys  Overview:\nUp to 16 protection domains with 4-bit tag on each page:\n Four (previously unused) bits in each page-table entry can be used to assign one of sixteen \u0026ldquo;key\u0026rdquo; values to any given page. A new 32-bit processor register with two bits for each key value.  Setting \u0026ldquo;write disable\u0026rdquo; bit for a given key will block all attempts to write a page with that key value; Setting \u0026ldquo;access disable\u0026rdquo; bit will block reads;  MPK feature thus allows a process to partition its memory into a maximum of sixteen regions and to selectively disable or enable access to any of those regions. Note: tags on virtual memory.  APIs to use the hardware feature:\n mprotect() with four new flags:  PROT_PKEY0 \u0026ndash; PROT_PKEY3   Benefits:\n Originally, changing the protections on a region of memory can require individually changing the page-table entries for thousands (or more) pages. Now with MPK, once the protections keys are set, a region of memory can be enabled or disabled with a single register write. For any application that frequently changes the protections on regions of its address space, the performance improvement will be large.  Usage scenario 1: handling sensitive cryptographic data. A network-facing daemon could use a cryptographic key to encrypt data to be sent over the wire, then disable access to the memory holding the key (and the plain-text data) before writing the data out. At that point, there is no way that the daemon can leak the key or the plain text over the wire; Protecting sensitive data in this way might also make applications a bit more resistant to attack. Usage scenario 2: protect regions of data from being corrupted by \u0026ldquo;stray\u0026rdquo; write operations. An in-memory database could prevent writes to the actual data most of the time, enabling them only briefly when an actual change needs to be made. In this way, database corruption due to bugs could be fended off, at least some of the time. Being able to turn off unexpected writes (quickly in large scale) could be essential useful when the underlying memory is a persistent memory device;   More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/mem-tag/mte/",
	"title": "MTE: Memory Tag Extension",
	"tags": [],
	"description": "",
	"content": " References:\n Memory Tagging Extension: Enhancing memory safety through architecture Armv8.5-A Memory Tagging Extension, White Paper The Arm64 memory tagging extension in Linux   MTE aims to increase the memory safety of code written in unsafe languages without requiring source changes, and in some cases, without requiring recompilation.\nMTE provides a mechanism to detect both main categories of memory safety violation (spatial \u0026amp; temporal). MTE assists the detection of potential vulnerabilities before deployment by increasing the effectiveness of testing and fuzzing. MTE also assists detection of vulnerabilities at scale after deployment.\n Sequential safety violations where memory is accessed immediately before or after the true bounds can always be detected. \u0026ldquo;Wild\u0026rdquo; violations to arbitrary locations in the address space can be detected probabilistically.\n In dynamic linked systems, legacy code benefits from MTE for heap allocations without recompilation;\n Application of MTE to the stack requires recompilation.\n MTE assumes stack pointer is trustworthy. combine MTE with Branch Target Identification (BTI) and Pointer Authentication Code (PAC) to reduce the probability that a gadget exists that would allow an attacker to take control of the stack pointer.  MTE 与 ARM Pointer Authentication 中的tag使用的是共同的指针比特区位。\n  MTE for Memory Safety Lock and Key:\n Locks on memory  4 bits to each 16 bytes of physical memory. Tag Granule.  Keys in poniters, checked on access.  Top Byte Ignore(TBI) on Armv8-A When TBI is enabled, the top byte of a virtual address is ignored when using it as an input for address translation. 4 bits of the top byte are used to provide the key.   As there are a imited number of tag bits available, it cannot be guaranteed that two memory allocations will have different tags for any specific execution.\nMTE impl in arch MTE adds a new memory type. Normal Tagged Memory.\n Loads and stores to this new memory type perform an access where the tag present in the top byte of the address register is compared with the tag stored in memory.  Software support for MTE  [The Arm64 memory tagging extension in Linux]()  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/mem-safe/ptr-meta/tag-ptr/in-fat/",
	"title": "In-Fat Pointer",
	"tags": [],
	"description": "",
	"content": " References:\n In-Fat Pointer: Hardware-Assisted Tagged-Pointer Spatial Memory Safety Defense with Subobject Granularity Protection  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/coding/error-notes/",
	"title": "错误笔记",
	"tags": [],
	"description": "",
	"content": " 反转括号子串 反转每对括号间的子串\n使用最直接的解体思路：\n 定位一对括号（可从最里面开始） 反转括号内子串 去除括号（可替换为空格，或其他“非法”字符） 重复1直到找不到括号 返回结果  汉明距离 汉明距离\n两个二进制数中位数不同的个数。用ＸＯＲ，数１的个数。\n2的幂 2的幂\n给定一个整数ｘ，判断ｘ是否是２的幂(2^y = x)。\n已知ｘ为３２位二进制数。\nTips:\n 给定一个３２位二进制数，求最高位二进制的位数：右移1/2/4/8/16取或，将所有后续位置为１，最后加一除２。\n// // 100000 --\u0026gt; 110000 --\u0026gt; 111100 --\u0026gt; 111111 --\u0026gt; ...  int getMSB(int m){ long n = m; n |= n \u0026gt;\u0026gt; 1; //最高位及后变为两个１ n |= n \u0026gt;\u0026gt; 2; // 最高位及后\u0026lt;=４个１ n |= n \u0026gt;\u0026gt; 4; // 最高位及后\u0026lt;=8个１ n |= n \u0026gt;\u0026gt; 8; // 最高位及后\u0026lt;=16个１ n |= n \u0026gt;\u0026gt; 16; // 最高位及后\u0026lt;=32个１ n = n + 1; return (n\u0026gt;\u0026gt;1); } 另解：用除２取余的方式检查最高位后面的位数，直到发现非０或到达最高位（除2得１)．\n  目标和表达式 目标和\n给定数组，用正负串联每个数，最终结果为Target的串联方式的个数。\n题解：使用递归，每个元素取正负两种情况，记下ｓｕｍ，最终结果是Target，返回１．\n另解：动态规划dp\n一题四解：宫水三叶\n 问题转化：数组总和为sum, 目标为Target, 则问题可以是，找出数组中的数和为(sum-Target)/2的组合的个数。  最后一块石头的重量 最后一块石头的重量\n一堆石头，整数数组stones表示每一块的重量。 任意选择两块石头，相撞，重量相互抵消，剩余量非零则再放入数组中。 求不同的相撞方案，最后一块石头的最小重量。\n题解：递归，遍历，每次生成新数组，取全局最小。-\u0026gt;超时。\n另解：动态规划：石头分为正数堆和负数堆，求解两堆只差最小值。或者：石头总重sum，求解子数组总和不大于sum/2的最大值。dp[i][j]: 前i块石头，总和不大于ｊ的最大值。\ndp[i][j] = max(dp[i-1][j], dp[i-1][j-stones[i]] + stones[i])\n 维度[i]可优化掉。i = 1 初始化每个dp[j]; 之后的i, 每次j从最大开始遍历，dp[j-x]就存储的是i-1的值。  完全平方数 完全平方数\n给定正整数ｎ，找到若干个完全平方数（比如，１，４，９，１６，……）使得他们的和等于n。 需要让组成和的完全平方数的个数最少。\n给定一个正整数n,返回和为n的完全平方数的最少数量。\n题解：动态规划: dp[i][j] 前ｉ个完全平方数中，和为j的平方数的最少个数。\ndp[i][j] = min(dp[i-1][j], dp[i-1][j-x*sq[i]] + x)\n 优化：去掉维度[i]，i=1时初始化所有j; 之后的ｉ，每次从最大的ｊ开始遍历。 注意：ｉ最大为$\\lfloor\\sqrt{n}\\rfloor$.  汉明距离总和 汉明距离总和\n问题：给你一个整数数组 nums, 请你计算并返回 nums 中任意两个数之间汉明距离的总和。\n问题转化：数0和１的个数并利用乘法原理。题解\n第一个错误的版本 题目：\n思路：二进制搜索。\n错误：long与int的除法运算、类型转换的运算次序：\nmiddle = (int)(((long)start + (long)end)/2); =\u0026gt; long -\u0026gt; /2 -\u0026gt; int =\u0026gt; good. middle = (int)((long)start + (long)end)/2; =\u0026gt; long-\u0026gt; int -\u0026gt; /2 =\u0026gt; wrong, negitive 寻找两个正序数组的中位数 思路：同时扫描两个数组，直到找到第n/2个。\n判定两个字符串是否可以互为重排 题目\n注意：字符串指针 char *str; 取字符比较使用 *str == 'A'；下一个字符可用str++.\n  Expand me...   bool CheckPermutation(char* s1, char* s2){ // check length, false if not equal in length  int s1len = strlen(s1); int s2len = strlen(s2); if (s1len != s2len){ return false; } // printf(\u0026#34;string len: %d\\n\u0026#34;, s1len);  // if length is equal,  // pick one element, search over another array  // if not found return false;  // if found, remove both from array; continue until no element left.  char *s1cur = s1; while (*s1cur != \u0026#39;\\0\u0026#39;){ // printf(\u0026#34;current s1 char %c\\n\u0026#34;, *s1cur);  // if (*s1cur == (char)-1) {  // s1cur++;  // continue;  // }  // search s1cur in s2  char *s2cur = s2; bool found = false; while (*s2cur != \u0026#39;\\0\u0026#39;){ // printf(\u0026#34;compare with s2 char: %c\\n\u0026#34;, *s2cur);  if (*s2cur == (char)-1) { s2cur ++; continue; } if (*s1cur == *s2cur){ // printf(\u0026#34;found s1 char: %c in s2\\n\u0026#34;, *s1cur);  found = true; *s1cur = (char)-1; *s2cur = (char)-1; break; } s2cur ++; } if (!found) return false; s1cur ++; } return true; }   字符串ＵＲＬ化 题目\n注意：理解题意：其中的“真实”长度指字符串的有意义的子串长度。\n  Expand me...   char* replaceSpaces(char* S, int length){ if (length == 0) return NULL; int spaceLength = strlen(S); // two pointers, one to the end of length, another to the end of S  char *end = S + spaceLength; // put a \u0026#39;\\0\u0026#39; at the end of new S  // and skip this char  *end = \u0026#39;\\0\u0026#39;; end --; // scan the S from the last char in S.  char *lastChar = S + length - 1; int currentLength = 0; // start moving every char at lastChar and replace space char with %20  while (lastChar \u0026gt;= S \u0026amp;\u0026amp; end \u0026gt;= S){ // printf(\u0026#34;handling char %c, lastChar at %d, end pointing to %d\\n\u0026#34;,  // *lastChar, (lastChar - S), (end - S));  if (*lastChar != \u0026#39; \u0026#39;){ // if lastChar is non-space, just copy it to *end  // printf(\u0026#34;move to end\\n\u0026#34;);  *end = *lastChar; lastChar --; end --; }else if (*lastChar == \u0026#39; \u0026#39;){ // if lastChar is space, add %20 to *end  // printf(\u0026#34;refill with %20\\n\u0026#34;);  *end = \u0026#39;0\u0026#39;; end --; *end = \u0026#39;2\u0026#39;; end --; *end = \u0026#39;%\u0026#39;; end --; lastChar --; } currentLength ++; } while (currentLength \u0026lt; length){ // printf(\u0026#34;there is still space left, fill in with %20\\n\u0026#34;);  if (end \u0026gt; S){ *end = \u0026#39;0\u0026#39;; end --; *end = \u0026#39;2\u0026#39;; end --; *end = \u0026#39;%\u0026#39;; end --; currentLength ++; }else{ printf(\u0026#34;Error? reaching the beginning of S, but still need more space to insert?\\n\u0026#34;); return S; } } if (lastChar \u0026lt; S \u0026amp;\u0026amp; end \u0026gt;= S){ S = ++end; } return S; }   LFU缓存 题目\n注意：struct 用法\n typedef struct 数组与struct指针数组的不同使用方式。(本题中仅仅使用了struct数组，未用指针数组) 固定容量的双向链表，无论ｎｏｄｅ是否存有数据，都要需处理好各个ｎｏｄｅ之间的链接， 容量边界值（０）的处理    Expand me...   // struct CacheNode; struct CacheNode { struct CacheNode *prev; struct CacheNode *next; int key; int value; int freq; }; typedef struct CacheNode CacheNode; typedef struct { CacheNode *head; CacheNode *tail;// least frequently used at tail.  int size; int capacity; } LFUCache; void printCache(LFUCache *obj){ int size = obj-\u0026gt;size; CacheNode *cur = obj-\u0026gt;head-\u0026gt;next; int i = 0; while (i\u0026lt;size){ printf(\u0026#34;[%d] freq: %d, key: %d, value: %d\\n\u0026#34;, i, cur-\u0026gt;freq, cur-\u0026gt;key, cur-\u0026gt;value); i ++; cur = cur-\u0026gt;next; } } LFUCache* lFUCacheCreate(int capacity) { // printf(\u0026#34;creating cache with capacity %d ...\u0026#34;, capacity);  LFUCache *cache = (LFUCache *)calloc(1,sizeof(LFUCache)); // keep head as a special node as a fence node.  CacheNode *head = (CacheNode *)malloc((capacity+1)*sizeof(CacheNode)); cache-\u0026gt;head = \u0026amp;head[0]; cache-\u0026gt;tail = cache-\u0026gt;head; // tail pointing to last element  cache-\u0026gt;size = 0; cache-\u0026gt;capacity = capacity; if (capacity \u0026gt; 0){ // initialize the links between nodes  head[0].prev=\u0026amp;head[capacity]; head[0].next = \u0026amp;head[1]; for (int i = 1; i \u0026lt; capacity; i++){ head[i].next = \u0026amp;head[i+1]; head[i].prev = \u0026amp;head[i-1]; } head[capacity].prev = \u0026amp;head[capacity-1]; head[capacity].next = \u0026amp;head[0]; } // printf(\u0026#34;done.\\n\u0026#34;);  return cache; } // update the list after cur-\u0026gt;freq is updated. void postUpdateFreq(LFUCache *obj, CacheNode *cur){ if (obj-\u0026gt;capacity == 0) return; // move cur forward if cur-\u0026gt;freq is larger, until it reaches the head  // find the insertion point  CacheNode *insertAfter = cur-\u0026gt;prev; while (insertAfter != obj-\u0026gt;head \u0026amp;\u0026amp; insertAfter-\u0026gt;freq \u0026lt;= cur-\u0026gt;freq){ // the node freq is equal or lower, then move cur before it  // - equal case: this will guarantte the newest one accessed is always near to head.  insertAfter = insertAfter-\u0026gt;prev; } // the pointer does not move, cur is already at best position  if (insertAfter == cur-\u0026gt;prev) return; // move cur to the position after `insertAfter`  // remove cur from original position  CacheNode *prev = cur-\u0026gt;prev; CacheNode *next = cur-\u0026gt;next; prev-\u0026gt;next = next; next-\u0026gt;prev = prev; // update tail pointer if cur is tail  if (cur == obj-\u0026gt;tail) obj-\u0026gt;tail = prev; // insert cur after \u0026#39;insertAfter\u0026#39;  prev = insertAfter; next = insertAfter-\u0026gt;next; cur-\u0026gt;next = next; cur-\u0026gt;prev = prev; next-\u0026gt;prev = cur; prev-\u0026gt;next = cur; } int lFUCacheGet(LFUCache* obj, int key) { CacheNode *cur = obj-\u0026gt;head-\u0026gt;next; int ret = -1; // printf(\u0026#34;searching key: \u0026lt;%d\u0026gt; .... \u0026#34;, key);  for (int i = 0; i \u0026lt; obj-\u0026gt;size; i ++){ if (cur-\u0026gt;key == key){ // found = true;  cur-\u0026gt;freq ++; postUpdateFreq(obj, cur); ret = cur-\u0026gt;value; // printf(\u0026#34; value: \u0026lt;%d\u0026gt;\\n\u0026#34;, ret);  // printCache(obj);  return ret; } cur = cur-\u0026gt;next; } // printf(\u0026#34; value not found\\n\u0026#34;);  // printCache(obj);  return ret; } // void removeNode(LFUCache *obj, CacheNode *toRemove){ // CacheNode *next = toRemove-\u0026gt;next; // CacheNode *prev = toRemove-\u0026gt;prev; // next-\u0026gt;prev = prev; // prev-\u0026gt;next = next; // // put node after the tail // toRemove-\u0026gt;next = obj-\u0026gt;tail-\u0026gt;next; // obj-\u0026gt;tail-\u0026gt;next = toRemove;  // }  void lFUCachePut(LFUCache* obj, int key, int value) { if(obj-\u0026gt;capacity \u0026lt;= 0) return; // printf(\u0026#34;putting key,value: %d, %d\\n\u0026#34;, key, value);  // search for the key  CacheNode *cur = obj-\u0026gt;head-\u0026gt;next; for (int i = 0; i \u0026lt; obj-\u0026gt;size; i ++){ if (cur-\u0026gt;key == key){ // printf(\u0026#34;found key\\n\u0026#34;);  cur-\u0026gt;value = value; cur-\u0026gt;freq ++; postUpdateFreq(obj, cur); return; } cur = cur-\u0026gt;next; } // key does not exist, insert it  //  // if size is full, remove last one  // remove is just moving the tail cursor  if (obj-\u0026gt;size == obj-\u0026gt;capacity){ // remove last node, move tail pointer one ahead  CacheNode *lastN = obj-\u0026gt;tail-\u0026gt;prev; obj-\u0026gt;tail = lastN; obj-\u0026gt;size --; } // printf(\u0026#34;inserting \u0026lt;key,value\u0026gt;: \u0026lt;%d, %d\u0026gt; with size/capacity: %d/%d\\n\u0026#34;,  // key, value, obj-\u0026gt;size, obj-\u0026gt;capacity);  // if size is 0 \u0026lt;= size \u0026lt; capacity, update tail pointer and insert it as last one  //  cur = obj-\u0026gt;tail-\u0026gt;next; cur-\u0026gt;freq = 1; cur-\u0026gt;key = key; cur-\u0026gt;value = value; obj-\u0026gt;tail = cur; obj-\u0026gt;size ++; // printf(\u0026#34;update freq for \u0026lt;key,value\u0026gt;: \u0026lt;%d, %d\u0026gt;\\n\u0026#34;, key, value);  // printCache(obj);  // update freq to reflect latest usage  postUpdateFreq(obj, cur); // printf(\u0026#34;done put \u0026lt;key,value\u0026gt;: \u0026lt;%d, %d\u0026gt;\\n\u0026#34;, key, value);  // printCache(obj); } void lFUCacheFree(LFUCache* obj) { free(obj-\u0026gt;head); free(obj); } /** * Your LFUCache struct will be instantiated and called as such: * LFUCache* obj = lFUCacheCreate(capacity); * int param_1 = lFUCacheGet(obj, key); * lFUCachePut(obj, key, value); * lFUCacheFree(obj); */   数位成本和为目标值的最大数字 题目\n超时思路：动态规划dp[i][j]: 数字长度为i位，成本为j时的最大数字。\n   Expand me...   // cost[i] : dp[i][target] = max(dp[i-1][target], dp[i-1][target-cost[i]]) // i is the number of digits in the number. from 1 to target. // target is the total cost target, from 1 to target. // dp[i][target] means the max number (string) with i digits and target.  char ***dp; // return true if s1 \u0026gt; s2 int isGreater(char *s1, char*s2){ int isG = 0; // compare string length  int len1 = strlen(s1); int len2 = strlen(s2); if (len1 \u0026gt; len2 ) isG = 1; else if (len1 \u0026lt; len2) isG = 0; else { // len1 == len2  // check if equal  if (strcmp(s1,s2) == 0) isG = 0; // compare each digits  // find the first different digits and test which is bigger.  for (int i = 0; i\u0026lt;len1; i++){ int comp = s1[i] - s2[i]; if (comp == 0) continue; else if (comp \u0026gt; 0){ isG = 1; break; }else if (comp \u0026lt; 0){ isG = 0; break; } } } return isG; } int isEqual(char *s1, char *s2){ return (strcmp(s1,s2) == 0); } // insert a new digit into dest string, form a larger number // result `dest` string will have a sorted digits char * insertDigit(char *dest, char* newdigit){ // check if dest is 0, just replace 0  if (strcmp(dest, \u0026#34;0\u0026#34;) == 0){ dest[0] = newdigit[0]; return dest; } int len = strlen(dest); // append a \\0 to dest  dest[len + 1] = \u0026#39;\\0\u0026#39;; int i = len; for ( ; i \u0026gt; 0; i --){ // if the digit is smaller than newdigit, move to least significant bit  if (dest[i-1] - newdigit[0] \u0026lt; 0){ dest[i] = dest[i-1]; }else{ // found the insertion point dest[i]  // jump out  break; } } dest[i] = newdigit[0]; return dest; } char * largestNumber(int* cost, int costSize, int target){ // compute the maxDigits  int maxDigits = target; // find the smallest cost  int smallestCost = target; for (int i = 0; i \u0026lt; costSize; i ++){ if (cost[i] \u0026lt; smallestCost) smallestCost = cost[i]; } maxDigits = target/smallestCost + 1; // initialize the dp[0...maxDigits]  // the largest possible value is |9...999999| with length of target  dp = (char ***) malloc (sizeof (char*) * (maxDigits+1)); for (int i = 0; i \u0026lt; maxDigits+1; i ++){ dp[i] = (char **) malloc(sizeof(char*) * (target + 1)); for(int j = 0; j \u0026lt; target + 1; j ++){ dp[i][j] = (char *) malloc(maxDigits + 1); strcpy(dp[i][j], \u0026#34;0\u0026#34;); } } // when there is only one digits in the number  // update dp[1].  for(int ti = 1; ti \u0026lt;= target; ti ++){ // scan the costs find if there is a cost that is exactly = ti  for (int i = 0; i \u0026lt; costSize; i ++){ if (ti == cost[i]){ char dig[2]; sprintf(dig, \u0026#34;%d\u0026#34;, i+1); // printf(\u0026#34;digit: %s\\n\u0026#34;, dig);  // choose the larger one  if (isGreater(dig, dp[1][ti])){ strcpy(dp[1][ti], dig); // printf(\u0026#34;dp[1][%d] initialized to %s\\n\u0026#34;, ti, dp[1][ti]);  } } } } // update dp[2-\u0026gt;maxDigits]  // dp[i][target] = max (dp[i-1][target], insertSort(dp[i-1][target-any(cost)], any(cost)))  for (int i = 2; i \u0026lt;= maxDigits; i++){ // compute the maxNumber with i digits for each targets  // int updated = 0;  for (int t = target; t \u0026gt; 0; t--){ // no digits added. the oldMax.  char *oldMax = dp[i-1][t]; // printf(\u0026#34;i = %d; t = %d, to compute, oldMax:%s\\n\u0026#34;,i,t, oldMax);  // try to add one more digits to dp[i-1][t-costs[d]]  char newMax[target + 1]; strcpy(newMax, oldMax); // initialize as oldMax  //printf(\u0026#34;newMax initialized to %s\\n\u0026#34;, newMax);  for (int d = 0; d \u0026lt; costSize; d ++){ // printf(\u0026#34;start iter d = %d\\n\u0026#34;, d);  // ignore the cost if target is smaller  if (t \u0026lt; cost[d]) continue; char *lessTarget = dp[i-1][t-cost[d]]; // a number with less digits  // printf(\u0026#34;Less Target: %s, dp[%d][%d]\\n\u0026#34;,  // lessTarget, i-1, t-cost[d]);  // if dp[i-1][t-cost[d]] is 0, then invalid choice  if ((t-cost[d]) \u0026gt; 0 \u0026amp;\u0026amp; strcmp(lessTarget, \u0026#34;0\u0026#34;) == 0) { // printf(\u0026#34;ignore\\n\u0026#34;);  continue; } // printf(\u0026#34;i = %d, t = %d; cost[%d] = %d, lessTarget=%s\\n\u0026#34;,  // i, t, d, cost[d], lessTarget);  char digit[2]; sprintf(digit, \u0026#34;%d\u0026#34;, d + 1); char tempMax[target+1]; strcpy(tempMax, lessTarget); // backup the string  // insert digit into lessTarget, to get a bigger number.  char *newNumber = insertDigit(tempMax, digit); if (isGreater(newNumber, newMax)){ // update the newMax if get a bigger newNumber  // printf(\u0026#34;update new max: %s (i=%d, t=%d, d=%d)\\n\u0026#34;, newNumber, i, t, d);  strcpy(newMax, newNumber); // updated ++;  } // printf(\u0026#34;done iter d = %d\\n\u0026#34;, d);  } // printf(\u0026#34;i = %d; t = %d, done compute: %s\\n\u0026#34;,i,t, newMax);  strcpy(dp[i][t], newMax); // printf(\u0026#34;i = %d; t = %d, done compute: %s\\n\u0026#34;,i,t, newMax);  } // if (updated \u0026lt; 1) break;  } char *strRet = dp[maxDigits][target]; return strRet; }   优化思路：题解: 分两部考虑问题：１，用动态规划求出最多数位的个数；２，从大数位到小数位构造数字。\n  Expand me...   ???   石子游戏 一堆堆石子排成一行，每堆都有正整数颗石子。piles[i]\n亚历克斯和李轮流从 piles两端取一堆石子，直到没有石子剩下。\n最后石子最多的人获胜。\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/arch/basics/arm/vmsa/",
	"title": "VMSA: Virtual Memory System Architecture",
	"tags": [],
	"description": "",
	"content": " References:\n ARMv8-A Reference Manual  A VMSA (in AArch64 state) provides a Memory Management Unit(MMU), that controls address translation, access permissions, and memory attribute determination and checking, for memory accesses made by the PE.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/coding/dyn/knapsack/",
	"title": "Knapsack",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/coding/dyn/",
	"title": "Dynamic Programming",
	"tags": [],
	"description": "",
	"content": " References:\n Dynamic Programming How to solve a Dynamic Programming Problem Tabulation \u0026amp; Memoization  What is dynamic programming  Dynamic programming is mainly an optimization over plain recursion. Wherever we see a recursive solution that has repeated calls for same inputs, we can optimize it using dynamic programming. The idea is to simply store the results of subproblems, so that we do not have to re-compute them when needed later. This simple optimization reduces time complexities from exponential to polynomial. For example, if we write simple recursive solution for Fibonacci Numbers, we get exponential time complexity and if we optimize it by storing solutions of subproblems, time complexity reduces to linear.\n // recursion: exponential int fib(int n){ if (n \u0026lt;= 1) return n; return fib(n-1) + fib(n-2); } // dynamic programming: linear  int fib(int n){ int f[n]; f[0] = 0; f[1] = 1; for (int i = 2; i \u0026lt;= n; i++){ f[i] = f[i-1] + f[i-2]; } return f[n]; } Solve DP problems Steps to solve a DP:\n1) Identify if it is a DP problem. 2) Decide a state expression with least parameters 3) Formulate state relationship 4) Do tabulation (or add memoization)\n1. Identify a dynamic programming problem 2. Deciding the state DP problems are all about state and their transition.\nThe state transition depends on the choice of state definition you make.\nA state can be defined as the set of parameters that can uniquely identify a certain position or standing in the given problem. This set of parameters should be as small as possible to reduce state space.\nFor example, in Knapsack problem, we define our state by two parameters index and weight, i.e. DP[index][weight]. Here DP[][] tells us the maximum profit it can make by taking items from range 0 to index having the capacity of sack to be weight. Therefore, here the parameters index and weight together can uniquely identify a subproblem for the knapsack problem.\nDP is all about using calculated results to formulate the final result. So, our next step will be to find a relation between previous states to reach the current state.\n3. Formulating a relation among the states 4. Adding memoization or tabulation for the state Tabulation vs Memoization Tabulation(Bottom up)\nMemoization(Top down)\nTabulation \u0026ndash; Bottom Up Dynamic Programming DP problem: find dp[n] by computing from dp[0] to dp[n]\n// tabulation version to find factorial x // state transition: dp[x+1] = dp[x] * (x+1)  int dp[MAXN]; // base case int dp[0] = 1; for (int i = 1; i \u0026lt;= n; i++){ dp[i] = dp[i-1] * i; } From above example, the dp table is being populated sequentially and we are directly accessing the calculated states from the table itself and hence,we call it tabulation method.\nMemoization \u0026ndash; Top down dynamic programming To find dp[n], start from dp[n] then until reach dp[0]\n// Memoized version to find factorial x. // to speed up we store the values of calculated states  // initialized to -1 int dp[MAXN]; // return fact x int solve(int x){ if (x == 0){ return 1; } if (dp[x]!= -1){ return dp[x]; } return (dp[x] = x * solve(x - 1)); } As we can see, we are storing the most recent cache up to a limit so that if next time we got a call from the same state se simply return it from the memory. So, this is why we call it memoization as we are storing the most recent state values.\nA list of DP problems References:\n 宫水三叶的刷题日记-背包问题 Dynamic programming problems  More  Knapsack   References: reference More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/practice/coding/",
	"title": "Coding",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  错误笔记  反转括号子串 反转每对括号间的子串 使用最直接的解体思路： 定位一对括号（可从最里面开始） 反转括号内子串 去除括号（可替换为空格，或其他“非法”字符\n Dynamic Programming  References: Dynamic Programming How to solve a Dynamic Programming Problem Tabulation \u0026amp; Memoization What is dynamic programming Dynamic programming is mainly an optimization over plain recursion. Wherever we see a recursive solution that has repeated calls for same inputs, we can optimize it using dynamic programming. The idea is to simply store the results of subproblems, so that we do not have to re-compute them when needed later. This simple\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/cheri/cheri-fm/2019-rigorous/",
	"title": "2019 Rigorous",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  Is there any bug that cannot (or hard to) be found without the formal model in the paper?\n In section VI, subtle bugs are found in CHERI ISA: CLC instruction: load data without permission check;  bug in arch document and L3 model.  legacy MIPS store allowed writing one byte past the region of the memory the code had permission to, and, if the code had access to the end of the address space, stores could write to the beginning of the address space. (In L3) unaligned MIPS loads allowed loading from a region of memory without permission. (In the L3 model and the Bluespec hardware impl.) CBuildCap instruction created a capability with the wrong base. (In L3) Exception return (ERET) could access a system register (the EPCC) without permission. (In L3) CCallFast instruction, which invokes capabilities, exposed the unsealed code capability, breaking isolation between compartments that can invoke each other\u0026rsquo;s capabilities. (In L3)  What is the benefits of using fm?\n automate generated hardware validation tests, run before hw is implemented; clear to explain complex designs; assess whether the security properties are hold; over all executions of arbitrary code.  Is there any vendor in industry using similar tech?\n Yes. It is Reid et al.\u0026rsquo;s work within Arm, shifting essentially the entire ARMv8-M and ARMv8-A sequential ISA specifications from pseudocode to machine-readable definitions, which are now used for documentation and hardware verification 1 2 3 4.  What is the relationship between the verification here and the verification in the EDA (Electronic Design Automation)?\n  References:\n Rigorous enginieering for hardware security: formal modelling and proof in the CHERI design and implementation process, by Kyndylan Nienhuis, Alexandre Joannou, Anthony Fox, Micheal Roe, Thomas Bauereiss, Brian Campbell, Matthew Naylor, Robert M. Norton, Simon W. Moore, Peter G. Newmann, Ian Stark, Robert N. M. Watson, Peter Sewell. UCAM-CL-TR-940.  Overview  We use formal models of the complete instruction-set architecture (ISA) at the heart of the design and engineering process, both in lightweight ways that support and improve normal engineering practice \u0026ndash; as documentaion, in emulators used as a test oracle for hardware and for running software, and for test generation \u0026ndash; and for formal verification.\nWe formalise key intended security properties of the design, and establish that these hold with mechanised proof. This is for the same complete ISA models (complete enough to boot operating systems), without idealisation.\nWe do this for CHERI, an architecture with hardware capabilities that supports fine-grained memory protection and scalable secure compartmentalization, while offering a smooth adoption path for existing software.\n  prose/pseudocode ISA descriptions ==\u0026gt; rigorous definitions in (L3/Sail), on software/hardware interface.\n security properties are stated precisely and formally in relatively simple terms, using basic operations over sets and quantified formulas. (Isabelle)\n security properties are mathematically proved. (Isabelle)\n  Backgroud Two fundamental problems for memory safety bugs:\n mainstream hardware architectures and languages (dating back to 1970s, C/C++) only support coarse-grained memory protection, via MMU. mainstream systems are typically developed using test-and-debug engineering methods.  good to build systems that are sufficiantly functionally correct under normal use; but fail to build secure systems, where an easily missed corner case could be actively found by attackers, and could be used to compromise the entire system.   CHERI\u0026rsquo;s two foundamental principles:\n Principle of least privilege.  C/C++ objects; Javascript engine vs. SSL connection keys.s  Principle of intentional use. A program clearly states which permission it uses to authorise its action.  avoid the confused deputy problem5. e.g. OS vs user processes. More restricted permissions on the user space buffer for OS code.  \u0026ldquo;For example, an operating system may need to hold permission to access the entirety of a user process(e.g. for paging), but when that process makes a read() system call, passing a pointer to a user-space buffer, CHERI lets the relavant OS code to use the more restricted permission to just that buffer.\u0026rdquo;    CHERI\u0026rsquo;s work\n a bluespec fpga hardware implementation, and a software stack above it, adapting LLVM and FreeBSD to CHERI-MIPS/RISC-V/ARM. extensive work on:  the interaction between the capability system and systems aspects of memory management(static and dynamic linking, process creation, context switching, page swapping and signal delivery) 6; the overhead of compiling pointers to capabilities 7 8; the compartmentalization of legacy software 9; the performance overhead of the tagged memory 10; the performance overhead of the protection-domain switches 11;   Lightweight rigorous engineering UCAM-CL-TR-940, chapter 3.\nGoal: simultaneously enabling formal statement and proof of security properties of their [security, architecture, and operating systems researchers and developers] actual design, not just some idealised model thereof. To improve their engineering practice in multiple lightweight ways, with immediate benefits long before the formal proof was complete:\nUse L3 and Sail ISA Models:\n to replace informal pseudocode for ISA design specifications. to automatically generate emulators as oracles for testing the Bluespec FPGA hardware implementation; to routinely bring up new software above the executable formal models while helping to narrow down the source of any bugs with ease. to automatic generate tests with authoritative formal models.  One can simply compare hardware vs model running arbitrary code, so can be automated. To generate random sequences of instructions that achieve good coverage in the presence of a large number of security tests in the capability instructions, it was important to control which instructions could generate a processor exception and why. We used a combination of symbolic execution of the L3 specification and automatic constraint solving[^c35] to find an initial processor state where only the chosen instruction would fault.   Industrial processor architecture specifications:\n AMD64, IBM POWER, Intel 64, MIPS, RISC-V, and SPARC; define their envelops of programmer-visible allowed behaviour with documents containing a mix of prose and pseudocode. typically multi-thousand-page books containing masses of detail, about instruction behaviour, encodings, address translation, interrupts, etc. NOT computational artefacts, so vendors also develop internal \u0026ldquo;golden\u0026rdquo; reference models to use as oracles for hardware testing, often in conventional programming languages such as C++. ARM, exceptionally, have recently transitioned to a machine-processed pseudocode, so what is in their manual can actually be tested against 12.  CHERI\u0026rsquo;s architecture specifications:\n started off in 2011 with traditional pseudocode descriptions, together with experimental formal modeling (unpublished) of key instructions in PVS13. In 2014, starting the work on complete formal models in the L3 [^c32] Instruction Description Language (IDL). More recently in Sail 14.  L3 and Sail:\n both strongly typed, first-order imperative language. aim to be accessible to engineers without a formal background. build a complete model includes everything that is necessary to boot an operating system, including exceptions, the translation lookaside buffer (TLB), and the programmable interrupt controller(PIC). parse and type-check their input, immediately catching errors that are easy to make in non-mechanised pseudocode specifications. allow no ambiguity. Sail differs from L3:\n mainly in providing a rich but decidable type system; with lightweight dependent types to let computed bitvector lengths be statically checked.  both around 7k lines of specification.\n  Stating architectural security properties UCAM-CL-TR-940, chapter 4.\nFormal vs Prose security properties:\n Prose properties are prone to ambiguities; Formal ones can help to identify and resolve these ambiguities. Prose properties are hard to prove; Formal ones stated in L3 and Sail can be automatically exported to theorem prover (Isabelle/HOL, HOL4, Coq).  Example of ambiguity: the capability monotonicity\n Prose documentation: \u0026ldquo;new capabilities must be derived from existing capabilities only via valid manipulations that may narrow (but never broaden) rights ascribed to the original capability.\u0026rdquo;  ambiguity: What is \u0026ldquo;broadening the rights of a capability\u0026rdquo;? Broadening bounds? Unsealing a capability?  Prose documentation: \u0026ldquo;controlled violation of monotonicity can be achieved via the exception delivery mechanism [\u0026hellip;] and also by the CCall instruction\u0026rdquo;.  ambiguity: What is the definition of \u0026ldquo;controlled violation\u0026rdquo;?  Prose documentation: \u0026ldquo;monotonicity allows reasoning about the set of reachable rights for executing code, as they are limited to the rights in any capability registers, and inductively, the set of any rights reachable from those capabilities\u0026rdquo;.  ambiguity: It does not define when a right is reachable from a capability, so one cannot know exactly what the upper bound of the rights is.   Security property definitions for CHERI:\n Define an order over capabilities to clarify what \u0026ldquo;broadening the rights of a capability\u0026rdquo; should mean; Define an abstraction of CHERI-MIPS with abstract actions for each type of memory access and capability manipulation, capturing the intentions of CHERI-MIPS instructions by mapping them onto these actions.  for each action we state under what conditions it can be performed, and what effects it has. Amongst other things, this precisely states the effects of instructions that can broaden the rights of a capability, clarifying what \u0026ldquo;controlled violation of capability monotonicity\u0026rdquo; should mean. It also states properties that have no prose counterparts in the CHERI documentation, but that are nonetheless crucial to the capability system.  Characterize which capabilities a (potentially compromised) compartment could access or construct if it is allowed to execute arbitrary code.\n which part of memory and which registers the compartment can overwrite, capturing the \u0026ldquo;reachable rights for executing code\u0026rdquo;.  For application cases, we state what assumptions need to be satisfied in order to isolate a compartment from the rest of the program, and which guarantees CHERI-MIPS then offers.\n  Capability order $\\le$:\n The authorities of sealed and unsealed capabilities are incomparable even if they have the same bounds and permissions.  unsealed capability can authorize memory accesses but the sealed capability cannot, while the sealed capability can be invoked (with the right permissions) but the unsealed one cannot.  Invalid capabilities have no authority. Sealed capabilities are immutable while they stay sealed. Unsealed capabilities can be restricted by shrinking their bounds or removing their permissions. the virtual address of unsealed capabilities can be changed to any value without affecting the authority.  This leads to the following definition.\nAbstract Actions Define properties about the effects of a single execution step, abstracting from the detailed behaviour of CHERI-MIPS instructions defined by L3 (or Sail) model.\nGoals:\n Capture the principle of intentional use by mapping instructions onto abstract actions;  Define an abstract action for each kind of memory accesses: loading data, storing data, loading cap, storing cap. each kind of cap manipulation: restricting, sealing, unsealing, invoking. hardware exceptions. Abstract actions contain some extra information, for example: the register index of the capability that is used as authority (if applicable) 180 instructions -\u0026gt; 9 abstract actions. abstract away from many details but retain the ability to define different security properties for different intentions.  Define security properties that are strong enough to imply more complex security properties (reachable capabilities, compartment isolation)  define invariants about address translation, kernel mode, and the exception-control \u0026lsquo;CP0\u0026rsquo; registers define properties that describe what happens when a certain abstract action is not intended. e.g. if the instruction does not intend to store anything to an address a, then the memory at a should remain unchanged. (???assuming no concurrent; no physical misfunction)   Action examples, non-domain-crossing:\n LoadDataAction, parameters:  reg auth, the register of the capability that is used as authority; reg a, the physical address of the data; l, the length of the data that is loaded.  StoreDataAction, parameters: LoadCapAction  reg auth reg a, physical address of the capability; reg r, the destination register.  StoreCapAction, parameters:  reg auth reg r, the source register reg a, physical address of the destination  RestrictCapAction  reg r, the source register reg r', the destination register where a restricted version of the source is copied to.  SealCapAction  reg auth reg r, the source register reg r', the destination register where a sealed version of the source is copied to  UnsealCapAction.  reg auth reg r reg r'   Domain crossing actions:\n RaiseException, no parameter. InvokeCapability, parameters:  reg r, code capability reg r', data capability  SwitchDomain, parameter:  Action a, an action that yields the execution to another domain.  KeepDomain, parameter:  actions, a set of actions that continue the execution in same domain.   Mapping instructions to actions:\n The CSeal cd, cs, ct instruction maps to KeepDomain {SealCapAction ct cs rd}  Actions refers to physical memory, but the instructions refer to virtual memory. When mapping these instructions, we therefore translate the addresses. (??? Correctness Verifiable??? Does the translation has the equal effects with the real translation in the full system deployment???)\nInstructions that load capabilities map to both a LoadCapAction and a LoadDataAction, because they can indirectly be used to load data (for example, by loading data into a capability register and inspecting the fields of the capability).\nDefine security properties for the abstraction For each action, define a property that states the prerequisites and effects of that action. These are properties of an arbitrary CHERI-MIPS ISA semantics sem, which we later prove hold of the actual semantics.\nProperty 2: Restricting capabilities. The simplest, requiring only the the resulting capability is less than or equal to the original.\nRestrictCapProp sem is defined as for all s s\u0026#39; actions r r\u0026#39;. if StateIsValid s and (KeepDomain actions, s\u0026#39;) $\\in$ sem s and RestrictCapAction r r\u0026#39; $\\in$ actions then CapReg s\u0026#39; r\u0026#39; $\\le$ CapReg s r  An ISA semantics sem satisfies the RestrictCapProp property only when, for all states s s', actions, registers r, r':\n state s is valid; execution step from s to s' with the intention to keep the domain, while perform a number of actions; one of the actions is RestrictCapAction r r'; CapReg s' r' $\\le$ CapReg s r: the less than or equal cap order.  Property 3: Storing data. To store data, one needs a valid, unsealed capability with the PermitStore permission, and the physical addresses stored to should correspond to virtual addresses that lie within the bounds of the capability.\nStoreDataProp sem is defined as for all s s\u0026#39; actions auth a ln. if StateIsValid s and (KeepDomain actions, s\u0026#39;) \\in sem s and StoreDataAction auth a ln \\in actions then Tag (CapReg s auth) The semantics sem satisfies the StoreDataProp property if the following holds:\n StateIsValid s: s is a valid state; (KeepDomain actions, s') $\\in$ sem s: consider an execution step s to s' with the intention to keep the domain and perform a num of actions. StoreDataAction auth a ln $\\in$ actions: assume StoreDataAction auth a ln is one of the actions. Tag(CapReg s auth): the capability auth has a tag not IsSealed(CapReg s auth): auth is not sealed PermitStore(CapReg s auth): auth has PermitStore permission ln != 0: the lengh ln of the stored segment is not zero `  Reachable Capabilities Build a Compartment (User Space) Proving the architectural security properties Mechanised all our proofs in Isabelle15.\nAutomated proof methods, tailored to L3 specifications. Use Eisbach [^c41], an extension of Isabelle\u0026rsquo;s proof language.\n Our custom tactics can automatically prove the security properties for most CHERI-MIPS instructions that do not directly interact with the capability mechanisms.  Use python scripts to generate the statements and proofs of many lemmas.\nEvaluation - Bugs found with CHERI-MIPS.\nSix Bugs found by proof work:\n CLC instruction: load cap with PERMIT_LOAD_CAPABILITY; could load even if no perm, but loaded without cap tag. In arch document and L3 model. Legacy MIPS store: write pass one byte; could pass after the end of address space and write to the beginning. In L3. unaligned MIPS loads allowed loading from a region of memory without permission. In L3 model and the Bluespec impl. CBuildCap instruction: create cap with wrong base. In L3. ERET: access a system register (EPCC) without permission. In L3. CCallFast: invokes capabilities; exposed unsealed code capability, breaking isolation between compartments that can invoke each other\u0026rsquo;s capabilities. In L3.  From L3 to Sail Sail generates emulators in OCaml and C, as well as theorem prover definitions for Isabelle/HOL, HOL4, and Coq.\nSail definitions can be integrated with multicore relaxed memory models.\nSail models: CHERI-MIPS, ARMv8-A, RISC-V, CHERI-RISC-V.\nCons Cannot yet verify CHERI as a whole \u0026ldquo;is secure\u0026rdquo;:\n Does not prove the hardware implementation correct with respect to the architecture; Does not prove correctness or security properties of system software above the architecture; Cannot prove about side-channel information flow via timing behaviour or power consumption; A loose defined architecture to admit variations: Cannot prove about architecturally visible information flow: a (compromised or adversarial) hardware implementation could leak information while conforming to this loose architecture specification.  do exclude architecturally visible capability flow.  Only covers the uniprocessor case.  of processors with ISA-Formal,” in International Conference on Computer Aided Verification. Springer, 2016, pp. 42–58.\nMore   A. Reid, R. Chen, A. Deligiannis, D. Gilday, D. Hoyes, W. Keen, A. Pathirane, O. Shepherd, P. Vrabel, and A. Zaidi, “End-to-end verification ↩ A. Reid, “Trustworthy Specifications of Arm v8-A and v8-M system Level Architecture,” in Proceedings of Formal Methods in Computer-Aided Design (FMCAD 2016), October 2016, pp. 161–168. [Online]. Available: https://alastairreid.github.io/papers/fmcad2016-trustworthy.pdf ↩ A. Reid, “Defining interfaces between hardware and software: Quality and performance,” Ph.D. dissertation, School of Computing Science, University of Glasgow, March 2019. ↩ A. Reid, “Who guards the guards? Formal validation of the Arm v8-M architecture specification,” Proceedings of the ACM on Programming Languages, vol. 1, no. OOPSLA, p. 88, 2017. ↩ N. Hardy. \u0026ldquo;The confused deputy (or why capabilities might have been invented),\u0026rdquo; ACM SIGOPS Operating Systems Review, vol. 22, no. 4, pp 36-38, 1988. ↩ B. Davis, R. N. Watson, A. Richardson, P. G. Neumann, S. W. Moore, J. Baldwin, D. Chisnall, J. Clarke, N. W. Filardo, K. Gudka et al., “CheriABI: Enforcing valid pointer provenance and minimizing pointer privilege in the POSIX C run-time environment,” University of Cambridge, Computer Laboratory, Tech. Rep., 2019. ↩ J. Woodruff, R. N. Watson, D. Chisnall, S. W. Moore, J. Anderson, B. Davis, B. Laurie, P. G. Neumann, R. Norton, and M. Roe, “The CHERI capability model: Revisiting RISC in an age of risk,” in ACM/IEEE 41st International Symposium on Computer Architecture, ISCA 2014, Minneapolis, MN, USA, June 14-18, 2014, 2014, pp. 457–468. ↩ J. Woodruff, A. Joannou, H. Xia, B. Davis, P. G. Neumann, R. N. M. Watson, S. Moore, A. Fox, R. Norton, and D. Chisnall, “Cheri concentrate: Practical compressed capabilities,” IEEE Transactions on Computers, 2019. ↩ K. Gudka, R. N. Watson, J. Anderson, D. Chisnall, B. Davis, B. Laurie, I. Marinos, P. G. Neumann, and A. Richardson, “Clean application compartmentalization with SOAAP,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. ACM, 2015, pp. 1016–1031. ↩ A. Joannou, J. Woodruff, R. Kovacsics, S. W. Moore, A. Bradbury, H. Xia, R. N. Watson, D. Chisnall, M. Roe, B. Davis et al., “Efficient tagged memory,” in Computer Design (ICCD), 2017 IEEE International Conference on. IEEE, 2017, pp. 641–648. ↩ R. N. Watson, R. M. Norton, J. Woodruff, S. W. Moore, P. G. Neumann, J. Anderson, D. Chisnall, B. Davis, B. Laurie, M. Roe et al., “Fast protection-domain crossing in the CHERI capability-system architecture,” IEEE Micro, vol. 36, no. 5, pp. 38–49, 2016. ↩ A. Reid, R. Chen, A. Deligiannis, D. Gilday, D. Hoyes, W. Keen, A. Pathirane, O. Shepherd, P. Vrabel, and A. Zaidi, “End-to-end verification of processors with ISA-Formal,” in International Conference on Computer Aided Verification. Springer, 2016, pp. 42–58. ↩ “PVS specification and verification system,” http://pvs.csl.sri.com/. ↩ A. Armstrong, T. Bauereiss, B. Campbell, A. Reid, K. E. Gray, R. M. Norton, P. Mundkur, M. Wassell, J. French, C. Pulte, S. Flur, I. Stark, N. Krishnaswami, and P. Sewell, “ISA semantics for ARMv8-A, RISC-V, and CHERI-MIPS,” in POPL 2019: Proc. 46th ACM SIGPLAN Symposium on Principles of Programming Languages, 2019. ↩ T. Nipkow, L. C. Paulson, and M. Wenzel, Isabelle/HOL: A Proof Assistant for Higher-Order Logic. Springer, 2012. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/verified/certikos/",
	"title": "Certikos",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/defences/verified/",
	"title": "Verified",
	"tags": [],
	"description": "",
	"content": " References:\n PSOS CompCert seL4 CertiKOS  More  PSOS  The Provably Secure Operating System (PSOS) project began in 1973 and continued until 1983. The 1980 PSOS final report includes the system architecture and many of the basic hardware and operating system layers, plus some illustrative applications (all formal specified in the SPECIAL language of HDM, the Hierarchical Development Methodology). The Feiertag/Neumann paper summarizing the architecture as of 1979 is available in a retyped, more or less correct, hand-edited pdf form.\n Certikos   References: reference More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/logics/book-soft/v1-lf/coq/",
	"title": "Coq",
	"tags": [],
	"description": "",
	"content": " References:\n Basics: Functional Programming in Coq  Functional style of programming is founded on simple, everyday mathematical intuition: If a procedure or method has no side effects, then (ignoring efficiency) all we need to understand about it is how it maps input to outputs.\nThe direct connection between programs and simple mathematical objects supports both formal correctness proofs and sound informal reasoning about program behavior.\nFeatures of functional programming in Coq:\n Function as first-class values \u0026ndash; can be passed as argument to other functions. Algebraic data types Pattern matching Polymorphic type systems  Language Gallina in Coq Gallina is Coq\u0026rsquo;s native functional programming language.\nData and Functions Enumerated Types\nInductive and Definition\nDays of the Week:\nType name is day, members are monday, tuesday, etc.\nInductive day: Type := | monday | tuesday | wednesday | thursday | friday | saturday | sunday. A function that operate on days:\nDefinition next_weekday (d:day) : day := match d with | monday =\u0026gt; tuesday | tuesday =\u0026gt; wednesday | wednesday =\u0026gt; thursday | thursday =\u0026gt; friday | friday =\u0026gt; monday | saturday =\u0026gt; monday | sunday =\u0026gt; monday end. Compute, Example\nTo check the function works on examples, in three ways:\n use command Compute to evaluate a compound expression:\nCompute (next_weekday monday). use Coq Example with expected values and proof or define it:\nExample test_next_weekday: (next_weekday (next_weekday monday)) = wednesday. Proof. simpl. reflexivity. Qed. use Coq to extract a program in another more conventional programming language with a high-performance compiler.\n  Notation\nThe Notation command defines a new symbolic notation for an existing definition.\nNotation \u0026#34;x \u0026amp;\u0026amp; y\u0026#34; := (andb x y). Notation \u0026#34;x || y\u0026#34; := (orb x y). Notation \u0026#34;x + y\u0026#34; := (plus x y) (at level 50, left associativity) : nat_scope. Notation \u0026#34;x - y\u0026#34; := (minus x y) (at level 50, left associativity) : nat_scope. Notation \u0026#34;x * y\u0026#34; := (mult x y) (at level 40, left associativity) : nat_scope. Check ((0 + 1) + 1) : nat. Example test_orb5: false || false || true = true. Proof. simpl. reflexivity. Qed. The level, associativity, and nat_scope annotations control how these notations are treated by Coq\u0026rsquo;s parser.\nlevel is for precedence. Precedence level of n is specified by writing at level n; This helps Coq compound expressions.\nThe associativity setting helps to disambiguate expressions containing multiple occurrences of the same symbol.\nCoq uses precedence levels from 0 to 100, and left, right, or no associativity.\nEach notation symbol is also associated with a notation scope. Coq tries to guess what scope is meant from context, so when it sees S (O x O) it guesses nat_scope. Occasionally, it is necessary to help it out with percent-notation by writing (axb)%nat; sometimes in what Coq prints it will use %nat to indicate what scope a notation is in.\nAdmitted\nThe Admitted command can be used as a placeholder for an incomplete proof. It tells Coq that we want to skip to prove the theorem and just accept it as a given.\nFixpoint factorial (n:nat) : nat (* REPLACE THIS LINE WITH \u0026#34;:= _your_definition_ .\u0026#34; *). Admitted. Example test_factorial1: (factorial 3) = 6. (* FILL IN HERE *) Admitted. Example test_factorial2: (factorial 5) = (mult 10 12). (* FILL IN HERE *) Admitted. Check\nThe Check command\n prints the type of the expression; if the expression is followed by a colon and a type, Coq will verify the expression matches the type and halt with error if not. It can be used to examine the statements of previously declared lemmas and theorems.\nCheck true. (* ==\u0026gt; true : bool *) Check (negb true) : bool. Check negb : bool -\u0026gt; bool. (* Function types are written with arrows *) Check andb : bool -\u0026gt; bool -\u0026gt; bool. Check mult_n_0. (* ==\u0026gt; forall n : nat, 0 = n * 0 *)  Types Types\nNew Types from Old\nTypes can be inductively defined by constructor expressions.\nInductive rgb : Type := | red | green | blue. (* `red`, `green`, and `blue` are the only constructor expressions belonging to `rgb`, a set of constructor expressions. *) Inductive color : Type := | black | white | primary (p : rgb). (* `black` and `white` belong the the set color; if `p` is a constructor expression belonging to the set `rgb`, then `primary p` is a constructor expression blonging to the set `color`.*)  Constructors, such as red, primary, true, false, etc. Constructor expressions are formed by applying a constructor to zero or more other constructors, or constructor expressions. E.g.,\n red true primary primary red red primary red true \u0026hellip;  Inductive definition carves out a subset of the whole space of constructor expressions and gives it a name, as Type, like bool, rgb, or color.\n  Functions Define functions using pattern matching:\nDefinition monochrome (c : color) : bool := match c with | black =\u0026gt; true | white =\u0026gt; true | primary p =\u0026gt; false end. Definition isred (c : color) : bool := match c with | primary red =\u0026gt; true | _ =\u0026gt; false end. Compute isred primary blue. Computer isred primary red. Modules Coq\u0026rsquo;s module system to aid in organizing large developments.\nOne feature: if we enclose a collection of declarations between Module X and End X markers, then, in the remainder of the file after the End, these definitions are referred to by names like X.foo instead of just foo.\nModule Playground. Definition b : rgb := blue. End Playground. Definition b : bool := true. Check Playground.b : rgb. Check b : bool. Tuples A single constructor with multiple parameters can be used to create a tuple type.\nA tuple of four bits nybble:\nInductive bit : Type := | B0 | B1. Inductive nybble : Type := | bits (b0 b1 b2 b3 : bit). Check (bits B0 B1 B0 B0) : nybble. (* the `bits` constructor acts as a wrapper for its contents. Unwrapping can be done by pattern matching.*) Definition all_zero (nb : nybble) : bool := match nb with | bits B0 B0 B0 B0 =\u0026gt; true | bits _ _ _ _ =\u0026gt; false end. Compute (all_zero (bits B0 B0 B0 B0)). Compute (all_zero (bits B0 B1 B0 B0)). Numbers Example of natrual numbers definition, an infinite set.\nA representation is simpler than binary.\nIt makes proofs simpler.\nThe unary, base 1.\nIn Coq datatype, we use two constructors:\n Capital-letter O, represents zero; Captial-letter S, stands for \u0026ldquo;successor\u0026rdquo;. When the S constructor is applied to the representation of the natural number n, the result is the representation of n+1.\nInductive nat : Type := | O | S (n : nat). (* zero is represented by `O` , 1 by `S O`, 2 by `S (S O)`, and so on.*) (* the names `O` and `S` are arbitrary, just two different marks. It is the same meaning with definition below:*) Inductive nat\u0026#39; : Type := | stop | tick (foo : nat\u0026#39;).  Coq provides a tiny bit of built-in magic for parsing and printing natrual numbers (for constructors S and O)\nCheck (S (S O)). (* ==\u0026gt; 4 : nat *) Definition minusTwo (n : nat) : nat := match n with | O =\u0026gt; O | S O =\u0026gt; O | S (S n\u0026#39;) =\u0026gt; n\u0026#39; end. Compute (minusTwo (S (S (S (S O))))). (* ==\u0026gt; 2 : nat *) Compute (minusTwo 4). (* ==\u0026gt; 2 : nat *) Fixpoint To define functions with recursion, use keyword Fixpoint instead of Definition.\nTo check a numer n is even or odd:\nFixpoint evenb (n:nat) : bool := match n with | O =\u0026gt; true | S O =\u0026gt; false | S (S n\u0026#39;) =\u0026gt; evenb n\u0026#39; end. Definition oddb (n:nat) : bool := negb (evenb n). Example test_oddb1: oddb 1 = true. Proof. simpl. reflexivity. Qed. Example test_oddb2: oddb 4 = false. Proof. simpl. reflexivity. Qed. Fixpoint mult (n m : nat) : nat := match n with | O =\u0026gt; O | S n\u0026#39; =\u0026gt; plus m (mult n\u0026#39; m) end. Example test_mult1: (mult 3 9) = 27. Proof. simpl. reflexivity. Qed. Proof by Simplification. Use simpl to simplify both sides of the equation;\nUse reflexivity to check that both sides contain identical values. It can also:\n do simplification as simpl; Adding simpl command allow us to see the intermediate state. do more simplification than simpl. For example, it tries \u0026ldquo;unfolding\u0026rdquo; defined terms, replacing them with their right-hand sides.\nTheorem plus_O_n\u0026#39; : forall n : nat, 0 + n = n. Proof. intros n. reflexivity. Qed. Theorem plus_O_n\u0026#39;\u0026#39; : forall n : nat, 0 + n = n. Proof. intros m. reflexivity. Qed. Theorem plus_1_l: forall n:nat, 1+n = S n. Proof. intros n. reflexivity. Qed. Theorem mult_0_l: forall n:nat, 0 * n = 0. Proof. intros n. reflexivity. Qed.  Use intros n or intros m to move n from the qualifier in the goal to a context of current assumptions.\nUse Example, Theorem, or Lemma, Fact, Remark keywords to define a property.\nTactics\nA tactic is a command that is used between Proof and Qed to guide the process of checking some claim we are making.\nThe keywords intros, simpl, and reflexivity are examples of tactics.\nProof by Rewriting. To prove:\nTheorem plus_id_example : forall n m : nat, n = m -\u0026gt; n + n = m + m. we need to assume we are given such numbers n and m. We also need to assume the hypothesis n = m. The intros tactic will serve to move all three of these from the goal into assumptions in the current context.\nSince n and m are arbitrary numbers, we can\u0026rsquo;t just use simplification to prove this theorem. Instead, we prove it by observing that, if we are assuming n = m, then we can replace n with m in the goal statement and obtain an equality with the same expression on both sides. The tactic that tells Coq to perform this replacement is called rewrite.\nTheorem plus_id_example : forall n m : nat, n = m -\u0026gt; n + n = m + m. Proof. (* move both quantifiers into the context: *) intros n m. (* move the hypothsis `n=m` into the context and give it the name H. *) intros H. (* rewrite the current goal `n+n=m+m` by replacing the left side of the equality hypothsis H with the right side. *) rewrite -\u0026gt; H. reflexivity. Qed. The arrow symbol in the rewrite has nothing to do with implication: it tells Coq to apply the rewrite from left to right. To rewrite from right to left, you can use rewrite \u0026lt;-.\n rewrite tactic can be used with a previously proved theorem instead of a hypothesis from the context.  If the statement of the previously proved theorem involves quantified variables, as in the example below, Coq tries to instantiate them by matching with the current goal.\nCheck mult_n_O. (* mult_n_O : forall n : nat, 0 = n * 0 *) Theorem mult_n_0_m_0 : forall p q : nat, (p * 0) + (q * 0) = 0. Proof. intros p q. (* rewrite -\u0026gt; mult_n_O. ==\u0026gt; Unable to find an instance for the variable n. *) rewrite \u0026lt;- mult_n_O. rewrite \u0026lt;- mult_n_O. Proof by Case Analysis \u0026ndash; destruct destruct tactic tells Coq to consider, separately, different cases for the problem, such as cases for an unknown argument.\nTheorem plus_1_neq_0 : forall n : nat, (n+1) =? 0 = false. Proof. intros n. destruct n as [| n\u0026#39;] eqn:E. - reflexivity. - reflexivity. Qed. as [|n'] is called an intro pattern. It tells what variable names to introduce in each subgoal. Between the square brackets is a list of lists of names, separated by |.\nIn this case, first component is empty, since the O constructor is nullary. The second component gives a single name, n', since S is a unary constructor. (???)\neqn:E tells destruct to give the name E to the equation of n=0 and n=S n' which are assumptions about n that are relevant for subgoals. It can be elided but it is better practice to keep these for the sake of documentation.\n- sign are called bullets, optional, each for one subgoal. Can also be other signs such as +, *, or -- ***, or using pairs of (nested) curly braces {}\n destruct can be used with any inductively defined datatype.\nTheorem negb_involutive : forall b : bool, negb (negb b) = b. Proof. intros b. destruct b eqn:E. (* no as clause because no need of variable names) - reflexivity. (* b = true *) - reflexivity. (* b = false *) Qed. destruct can be invoked inside a subgoal.\nTheorem andb_commutative : forall b c, andb b c = andb c b. Proof. intros b c. destruct b eqn:Eb. - destruct c eqn:Ec. + reflexivity. + reflexivity. - destruct c eqn:Ec. + reflexivity. + reflexivity. Qed. destruct [] shorthand with intros.\n intros [|n], means intros n. destruct n as [|n]. intros [] [], means intros x y. destruct x. destruct y.\n(* [] --\u0026gt; destruct *) Theorem plus_1_neq_0\u0026#39; : forall n : nat, (n + 1) =? 0 = false. Proof. intros [|n]. - reflexivity. - reflexivity. Qed. Theorem andb_commutative\u0026#39; : forall b c, andb b c = andb c b. Proof. intros [] [] - reflexivity. - reflexivity. - reflexivity. - reflexivity. Qed.   true = false Exercise: Prove\nTheorem andb_true_elim2 : forall b c : bool, andb b c = true -\u0026gt; c = true. Proof. Admitted.(*https://gist.github.com/kencoba/933961#file-sf_1-v-L363*) Theorem andb_true_elim2\u0026#39; : forall b c : bool, andb b c = true -\u0026gt; c = true. Proof. intros b c H. destruct c eqn:Ec. - reflexivity. - rewrite \u0026lt;- H. destruct b. * reflexivity. * reflexivity. Qed. (*https://www.reddit.com/r/Coq/comments/855k3n/beginner_question/*) Theorem andb_true_elim2\u0026#39;\u0026#39; : forall b c : bool, andb b c = true -\u0026gt; c = true. Proof. intros b c. intros H. destruct c. - reflexivity. - destruct b. -- simpl in H. discriminate. -- simpl in H. discriminate. Qed. discriminate is a tactic that searches for primitive contradictions in the context and immediately solve the goal if it finds one (for assume a false statement, you can prove anything).\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/verify/1967/1962/",
	"title": "1962 Towards a Mathematical Theory of Computation",
	"tags": [],
	"description": "",
	"content": " References:\n J. McCarthy, Towards a mathematical theory(science) of computation. 1962.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/compilers/verify/1967/",
	"title": "1967 Correctness of a Compiler for Arithmetic Expressions",
	"tags": [],
	"description": "",
	"content": " Q\u0026amp;A  What is the tool used to verify the correctness?  A proof of the correctness of a simple compiling algorithm for compiling arithmetic expressions into machine language.\n The definition of correctness. The formalism used to express the description of source language, object language, and compiler. The methods of proof.  Ultimate goal, is to make it possible to use a computer to check proofs that compilers are correct.\nConceptions inherited from [c3]:\n Abstract syntax. State vector. The use of an interpreter for defining the semantics of a programming language. The definition of correctness of a compiler.  Example expression:\n$(x+3) + (x+(y+2))$\nAssembly example:\nload x sto t li 3 add t sto t load x sto t+1 load y sto t+2 li 2 add t+2 add t+1 add t # Abstract syntax will be used, so there is no commitment to a precise form for the object code. Source language Abstract analytic syntax of the source expressions:\n   predicate associated functions     isconst(e)    isvar(e)    issum(e) s1(e) s2(e)    ==\u0026gt; Expressions comprise constants, variables and binary sums; Each sum $e$ has summands $s1(e)$ and $s2(e).\nSemantics:\n(2.1) value$(e,\\xi)$ = if isconst(e) then val(e) else if isvar(e) then $c(e,\\xi)$ else if issum(e) then value$(s1(e),\\xi)$ + value$(s2(e),\\xi)$.\n==\u0026gt; val(e) gives the numerical value of an expression e representing a constant; $c(e,\\xi)$ gives the value of the variable e in the state vector $\\xi$ and $+$ is some binary operation.\n For our present purposes we do not have to give a synthetic syntax for the source language expressions since both the interpreter and the compiler use only the analytic syntax. However, we shall need the following induction principle for expressions: Suppose $\\Phi$ is a predicate applicable to expressions, and suppose that for all expressions $e$ we have:\nisconst(e) $\\supset \\Phi$(e) and\nisvar(e) $\\supset \\Phi$(e) and\nissum(e) $\\supset \\Phi(s1(e)) \\wedge \\Phi(s2(e)) \\supset \\Phi(e)$.\n==\u0026gt; Then we may conclude that $\\Phi(e)$ is true for all expressions $e$.\n Object language  We must give both the analytic and synthetic syntaxes for the object language because the interpreter defining its semantics uses the analytic syntax and the compiler uses the synthetic syntax.\n Analytic and synthetic syntaxes for instructions:\n   operation predicate analytic operation synthetic operation     li $\\alpha$ isli(s) arg(s) mkli($\\alpha$)   load x isload(x) adr(s) mkload(x)   sto x issto (s) adr (s) mksto (x)   add x isadd(s) addr(s) mkadd(x)    References:\n John McCarthy and James Painter, Correctness of a Compiler for Arithmetic Expressions. 1967. [c3]: J. McCarthy, Towards a mathematical theory(science) of computation. 1962.  More  1962 Towards a Mathematical Theory of Computation   References: J. McCarthy, Towards a mathematical theory(science) of computation. 1962. More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/ai/history/",
	"title": "History",
	"tags": [],
	"description": "",
	"content": " References:\n 人工智能简史（图灵出品），尼克，人民邮电出版社，2017-11   人工智能是一门新学科，历史的读物并不多。波登的《认知科学历史》（Boden 2008）和尼尔森的 《人工智能探究》（Nilsson 2010）是两本严肃的读物。 Nilson是人工智能学科的早期参与者，也一直是领导者之一，他多年担任SRI的人工智能部门负责人和 斯坦福大学计算机主任。\nPamela McCorduck, 1979 \u0026lt;能思考的机器\u0026gt;（Machines Who Think），取材立意都略微过时。\n雅各布森（Annie Jacobsen）的《五角大楼大脑》(Pentagon\u0026rsquo;s Brain)是关于ARPA的详实而有趣 的历史。从这本书中我们可以看到信息科技一直不是ARPA的主打方向，但互联网这个ARPA歪打正着的项目 却是它最好的投资。\n 自动定理证明的起源 数学哲学有三大派：逻辑主义、形式主义、直觉主义。\n逻辑主义的代表人物是罗素，主旨是把数学归约到逻辑，这样只要把逻辑问题解决了，之上的数学问题自然 就解决了。也就是说，把逻辑玩转了，数学就不算事儿。\n希尔伯特主导的形式主义是另一派，他的梦想是把数学形式化，数学过程就是把一串符号变成另一串符号。 希尔伯特设想，如果能设计一个大一统的算法，那么所有的数学问题都可以由这个算法来解答。这和逻辑主义 精神有一定想通之处。哥德尔后来证明这一切是不可能的。\n机器定理证明的研究从某种意义上继承了罗素和希尔伯特的思想：用机器来证明和判定那些可以证明和判定 的问题。纽厄尔和司马贺的“逻辑理论家”就是早期的机器定理证明程序，他们曾经给罗素写信，期盼能得到 伟人的首肯，罗素在回信时说：“我相信演绎逻辑里的所有事，机器都能干”。\n人工智能中符号派的思想源头和理论基础就是定理证明，不懂定理证明就没法深入了解符号派。 戴维斯（Martin Davis，1928 \u0026ndash;）1954年完成了第一个定理证明程序，所用的机器是普林斯顿高等研究院的一台 以冯诺依曼昵称“强尼”（Johnie）命名的电子管计算机“大强尼”（JOHNNIAC），而文章则迟至1957年才 公开发表。\n戴维斯(1928 \u0026ndash; )是富有成就的数学家和逻辑学家。戴维斯家境不好，大学时上了被称为“穷人哈佛”的 纽约市立学院（CCNY）\u0026ndash; 那学校不收学费。在那儿他遇见了坡斯特（Emil Post）。 在1957年写的教科书《可计算性和不可解性》最早系统地介绍了坡斯特（Emil Post） 的工作，外界才开始得知坡斯特的名字。戴维斯最重要的贡献是和哲学家普特南（Hilary Putnam）等人 解决了希尔伯特第十问题。机器定理证明是他一直感兴趣的副业。\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2020-ucam-sirius/",
	"title": "Enclave-Aware Compartmentalization and Secure Sharing with Sirius",
	"tags": [],
	"description": "",
	"content": " References:\n Tarkhani, Zahra, and Anil Madhavapeddy. \u0026ldquo;Sirius: Enabling System-Wide Isolation for Trusted Execution Environments.\u0026rdquo; arXiv preprint arXiv:2009.01869 (2020).  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2020-ucam-utiles/",
	"title": "μTiles: Efficient Intra-Process Privilege Enforcement of Memory Regions",
	"tags": [],
	"description": "",
	"content": " References:\n Tarkhani, Zahra, and Anil Madhavapeddy. \u0026ldquo;$\\mu $ Tiles: Efficient Intra-Process Privilege Enforcement of Memory Regions.\u0026rdquo; arXiv preprint arXiv:2004.04846 (2020).  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2020-isca-nested-sgx/",
	"title": "2020 Isca Nested Sgx",
	"tags": [],
	"description": "",
	"content": " References:\n Park, Joongun, Naegyeong Kang, Taehoon Kim, Youngjin Kwon, and Jaehyuk Huh. \u0026ldquo;Nested enclave: supporting fine-grained hierarchical isolation with SGX.\u0026rdquo; In 2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA), pp. 776-789. IEEE, 2020.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2020-sec-civet/",
	"title": "Civet: An Efficient Java Partitioning Framework for Hardware Enclaves",
	"tags": [],
	"description": "",
	"content": " References:\n Tsai, Chia-Che, Jeongseok Son, Bhushan Jain, John McAvey, Raluca Ada Popa, and Donald E. Porter. \u0026ldquo;Civet: An Efficient Java Partitioning Framework for Hardware Enclaves.\u0026rdquo; In 29th {USENIX} Security Symposium ({USENIX} Security 20). 2020.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2020-sec-donky/",
	"title": "Donky: Domain Keys – Efficient In-Process Isolationfor RISC-V and x86",
	"tags": [],
	"description": "",
	"content": " References:\n Schrammel, David, Samuel Weiser, Stefan Steinegger, Martin Schwarzl, Michael Schwarz, Stefan Mangard, and Daniel Gruss. \u0026ldquo;Donky: Domain Keys–Efficient In-Process Isolation for RISC-V and x86.\u0026rdquo; In 29th {USENIX} Security Symposium ({USENIX} Security 20), pp. 1677-1694. 2020.  Evaluation Three realistic use cases:\n Secure V8 Sandboxing; Software Vaults; Untrusted Third-party libraries;  Two Implementations:\n RISC-V Ariane CPU, Synthesized on FPGA Intel-MPK-based emulation for X86  Cross-domain switches are 16-116x faster than regular process context switches.\nFully protecting the mbedTLS cryptographic operations has a 4% overhead.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/surveys/2020-iot-sec/",
	"title": "On the State of Internet of Things Security: Vulnerabilities,Attacks, and Recent Countermeasures",
	"tags": [],
	"description": "",
	"content": " References:\n SISODIA, DEVKISHEN. \u0026ldquo;On the State of Internet of Things Security: Vulnerabilities, Attacks, and Recent Countermeasures.\u0026rdquo; University of Oregon, Tech. Rep (2020).  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/sys-sec/surveys/",
	"title": "Surveys",
	"tags": [],
	"description": "",
	"content": " References:\n reference  More  On the State of Internet of Things Security: Vulnerabilities,Attacks, and Recent Countermeasures   References: SISODIA, DEVKISHEN. \u0026ldquo;On the State of Internet of Things Security: Vulnerabilities, Attacks, and Recent Countermeasures.\u0026rdquo; University of Oregon, Tech. Rep (2020). More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/1989-id/",
	"title": "1989 SP: A Secure Identity-Based Capability System",
	"tags": [],
	"description": "",
	"content": " References:\n Gong, Li. \u0026ldquo;A Secure Identity-Based Capability System.\u0026rdquo; In IEEE symposium on security and privacy, pp. 56-63. 1989.  ICAP: An Identity-based CAPability protection system.\nMore  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2012-sec-adsplit/",
	"title": "2012&#39;SEC AdSplit: Separating smartphone advertising from applications",
	"tags": [],
	"description": "",
	"content": " References:\n Shekhar, Shashi, Michael Dietz, and Dan S. Wallach. \u0026ldquo;Adsplit: Separating smartphone advertising from applications.\u0026rdquo; In Presented as part of the 21st {USENIX} Security Symposium ({USENIX} Security 12), pp. 553-567. 2012.  More  "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2008-osdi-loki/",
	"title": "2008 Osdi Loki",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  Hardware enforcement of application security policies using tagged memory. 2008, OSDI. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2011-xoar/",
	"title": "Xoar: Breaking up is hard to do: security and functionality in a commodity hypervisor",
	"tags": [],
	"description": "",
	"content": "Reference 1\nXoar: a modified version of Xen.\n Breaks the control VM into multiple single-purpose components called service VMs.    Colp, Patrick, Mihir Nanavati, Jun Zhu, William Aiello, George Coker, Tim Deegan, Peter Loscocco, and Andrew Warfield. \u0026ldquo;Breaking up is hard to do: security and functionality in a commodity hypervisor.\u0026rdquo; In Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles, pp. 189-202. 2011. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2016-sp-shreds/",
	"title": "2016 Sp Shreds",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  reference ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2016-osdi-lwc/",
	"title": "2016 OSDI Light-weight Contexts: An OS Abstraction for Safety and Performance",
	"tags": [],
	"description": "",
	"content": " light-weight Context (lwC) A first-class OS abstraction that extends the POSIX API, and present common coding patterns demonstrating its different uses.\nA process may contain multiple lwCs, each with their own virtual memory mappings, file descriptor bindings, and credentials, and those can also be selectively shared.\nlwCs are not schedulable entities: they are completely orthogonal to threads that may execute within a process.\nA thread may start in lwC a, then invoke a system call to switch to lwC b.\nThe lwC switch atomically changes the VM mappings, file table entries, permissions, instructino and stack pointers of the thread.\nMultiple threads may execute simultaneously within the same lwC.\nlwCs maintain per-thread state to ensure a thread that enters a lwC resumes at the point where it was created or last switched out of the lwC. (?? in this case, is the thread scheduled out or ?)\nA range of new in-process capabilities:\n fast roll-back; protection rings (by credential restriction); session isolation; protected compartments (using VM and resource mappings). can be used to\n implement efficient in-process reference monitors to check security invariants. isolate components of an app that deal with encryption keys or other private information. efficiently roll back the process state.    Evaluation Session isolation in production web servers, both process-oriented (Apache, via roll-back) and event-driven (nginx, via memory isolation).\n Efficient snapshotting to provide session isolation on web-based applications using a PHP-based MVC application on nginx. Create isolated data compartments within a process to render sensitive data (such as private keys) immune to external attacks (such as private keys) in cryptographic libraries such as OpenSSL. Implement in-process reference monitors, again for industrial-scale servers such as Apache and nginx, that can intropsect on system calls and memory.  Evaluate lwCs using a range of micro-benchmarks and application scenarios.\nRelated work Wedge [^c5], sthreads.\nShreds [^c9], memory domains in ARM CPUs, compiler support, kernel support.\nSpaceJMP[^c12], address spaces are first-class objects separate from processes. Use memory larger than the available virtual address bits; Maintain pointer-based data structure beyond process lifetime; Does not support isolation or privilege separation within a process.\nDune [^c4], provides a kernel module API,\nReference 1\n  James Litton, Anjo Vahldiek-Oberwagner, Eslam Elnikety, Deepak Garg, Bobby Bhattacharjee, and Peter Druschel. Light-weight Contexts: An OS Abstractions for Safety and Performance. OSDI. 2016. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2015-atc-arbiter/",
	"title": "2015 Atc Arbiter",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  J. Wang, X. Xiong, and P. Liu. Between Mutual Trust and Mutual Distrust: Practical Fine-grained Privilege Separation in Multithreaded Applications. In 2015 USENIX Annual Technical Conference (USENIX ATC 15), pages 361–373, Santa Clara, CA, July 2015. USENIX Association. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2015-salus/",
	"title": "2015 Salus",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  R. Strackx, P. Agten, N. Avonds, and F. Piessens. Salus: Kernel Support for Secure Process Compartments. EAI Endorsed Transactions on Security and Safety, 15(3), 1 2015. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2008-nsdi-wedge/",
	"title": "2008 Nsdi Wedge",
	"tags": [],
	"description": "",
	"content": " Reference:\n A. Bittau, P. Marchenko, M. Handley, and B. Karp. Wedge: Splitting Applications into Reduced-privilege Compartments. In Proceedings of the 5th USENIX Symposium on Networked Systems Design and Implementation, NSDI’08, pages 309–322, Berkeley, CA, USA, 2008. USENIX Association.  Evaluation Apache/OpenSSL  Introducing compartments to preserve the confidentiality and integrity of SSL connnections.  protect the server\u0026rsquo;s RSA private key prevent one user from obtaining the cleartext sent over another user\u0026rsquo;s SSL connection or prevent one user from injecting content to another user\u0026rsquo;s SSL connection.   SSL Session key is computed from three inputs:\n random value supplied by the server, clear text; random value supplied by the client, clear text; random value supplied by the client, encrypted using server\u0026rsquo;s public key;  OpenSSH Goals for partitioning OpenSSH:\n Minimize the code with access to the server\u0026rsquo;s private key. Before authentication, run with minimal privilege, so that exploits are contained; After authentication, run with full privileges for the authenticated user; Prevent bypassing of authentication, even if the minimally privileged code is exploited.  Started partitioning with OpenSSH version 3.1p1, the last version prior to the introduction of privilege separation.\n The network-facing code during authentication \u0026ndash;\u0026gt; unprivileged sthread.  explicitly give the sthread:  read access to the server\u0026rsquo;s public key and configuration options read/write access to the connection\u0026rsquo;s file descriptor. running it in unprivileged user; setting its filesystem root to an empty directory.   Callgate 1: 280 lines of C.  secret key is protected behind this gate.  Callgate 2: for password. Callgate 3: for DSA key-based. Callgate 4: for S/Key challenge-response authentication.   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2016-ccs-smv/",
	"title": "2016 CCS SMV",
	"tags": [],
	"description": "",
	"content": " Questions  How to determine and represent boundaries?\n Which level of the page is tagged? Virtual or Physical?\n ANS: virtual page is tagged with permissions. Memory protection domain is defined as a countigous range of virtual memory.  How to design a secure call gate to cross boundaries?\n How many compartments in the benchmarks?\n  Reference 1\n3 generations of privilege separation 1st gen: split a process into different single-process compartments. e.g. OpenSSH by Provos et al., Privtrans, Wedge2 introduced capabilities, Salus3 introduced dynamic security policy.\n2nd gen: isolation in multi-threaded applications. Arbiter4, global barrier to tag memory pages for capabilities; human retrofitting efforts are non-trivial.\n3nd gen: secure memory views (SMV) for monolithic applications: a model and architecture that efficiently enforces differential security and fault isolation policies in monolithic multithreaded applications at negligible overheads.\nEvaluation    Benchmark LoC Overhead     PARSEC 2 2%   Cherokee 2 0.69%   Apache httpd 2 0.93%   Firefox 12 1.89%    SMV model Three abstractions: memory protection domains, secure memory views (SMVs), SMVthreads,\nMemory protection domain A contiguous range of virtual memory.\nSecure Memory Views (SMVs) A thread container, which maintains a collection of memory protection domains for each SMVthreads in the container. Each SMVthreads must follow the privilege settings in SMV.\nFocused on restricting memory views for individual threads, and had no control over the accessing permissions for kernel APIs.\nKernel enforcement Entire kernel is trusted in this paper.\nSMV kernel module. exchanging messages between the user space and kernel memory management subsystem. Implemented using Netlink socket family.\nKernel memory management subsystem changes:\n added SMV metadata management, to record the memory access privileges for the SMVs.  memdom_struct: metadata for tracing the virtual memory area and the memory domains mappings. SMV_struct: SMV privilege metadata for accessing memory domains.  modified page table management logic, to support partially shared page tables. added additional checks in the page fault handler (section 4.5). The fault address must be in a valide memory domain with proper access permission in the current SMVThread.  Partially shared memory space Separates the memory space of SMVs by using a page global directory (pgd_t) for each SMV.\nloads thread-private pgd_t into the CR3 register during a context switch.\n==\u0026gt; different page table map for same address space ==\u0026gt; overhead?\nUser space library memdom_create to create a memory domain.\nmemdom_alloc to allocate memory blocks private to SMVthreads.\nmemdom_priv_grant to grant an SMV the privileges to access a memory domain.\nmemdom_priv_revoke to revoke the privileges to access a memory domain from an SMV.\nCMTS Weaknesses:\nThe way to determine the boundaries is largely depends on the human understanding of the program\u0026rsquo;s functionalities.\nKernel has to be trusted. Isolation only works for user space applications. No isolation inside kernrel.\nCompatibility: original pthreads assumes sharing of all pages, but SMVthreads assumes all pages as private and require explicit sharing with other SMVthreads. Using SMVthreads increases the burden on developers to setup the correct page sharing. Sometime it can be hard to reason about which page should be shared and which shouldn\u0026rsquo;t, especially when it comes to data being pointed to by pointer variables and those passed around by third party libraries.\nOverhead/Scalability: use different page table directory for different threads and switch page table during thread switch, this is conceptually constructing a heavy weight thread to be much like a process. If the number of threads goes up, the performance is likely to drop dramatically because of context switch and synchronization of shared page mappings.\n  Hsu, Terry Ching-Hsiang, Kevin Hoffman, Patrick Eugster, and Mathias Payer. \u0026ldquo;Enforcing least privilege memory views for multithreaded applications.\u0026rdquo; In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 393-405. 2016. ↩ A. Bittau, P. Marchenko, M. Handley, and B. Karp. Wedge: Splitting Applications into Reduced-privilege Compartments. In Proceedings of the 5th USENIX Symposium on Networked Systems Design and Implementation, NSDI’08, pages 309–322, Berkeley, CA, USA, 2008. USENIX Association. ↩ R. Strackx, P. Agten, N. Avonds, and F. Piessens. Salus: Kernel Support for Secure Process Compartments. EAI Endorsed Transactions on Security and Safety, 15(3), 1 2015. ↩ J. Wang, X. Xiong, and P. Liu. Between Mutual Trust and Mutual Distrust: Practical Fine-grained Privilege Separation in Multithreaded Applications. In 2015 USENIX Annual Technical Conference (USENIX ATC 15), pages 361–373, Santa Clara, CA, July 2015. USENIX Association. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2019-pyronia/",
	"title": "2019 Pyronia",
	"tags": [],
	"description": "",
	"content": "Reference 1\nIoT devices are mostly single-purpose running a dedicated, single application. As a result, vulnerabilities in third party libraries within a process pose a much bigger threat than on traditional platforms.\nPyronia: protects against untrusted third-party code with unmodified source code.\nGoals:\n control how an application may obtain data from files/devices; control how in-memory data is propagated within an application, specifically between lib and app; control to which remote network destinations an application may export data  Design:\nfunction level access rules: developer specifies access rules of which third-party functions can access which private data;\ngood: developer does not need to reason about third-party code (e.g. to track the data flow);\n3 Techniques:\n system call interposition: control OS resources; stack inspection: indentify all lib functions in the call chain that led to a given system call; Checks the runtiem call stack to determine where to grant access to a requested resource based on the full provenance of the intercepted system call; memory domains: sensitive in memory data; call stack; managed dynamically by page permissions (LLM: IoT usually dont have pages\u0026hellip;);  Evaluation:\n Intel Core i7-3770, 3.4GHz, 1.95 GB of RAM; Ubuntu 18.04 LTS Three IoT Applications:  twitterPhoto, alexa, plant_watering (AWS).   ==\u0026gt; LLM: not a regular IoT, but a \u0026lsquo;high performance\u0026rsquo; IoT device.\n  Pyronia: Redesigning Least Privilege and Isolation for the Age of IoT. arXiv, 2019. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2012accs-android-ad/",
	"title": "AsiaCCS&#39;12 AdDroid: Privilege Separation for Applications and Advertisers in Android",
	"tags": [],
	"description": "",
	"content": " References:\n AdDroid: Privilege Separation for Applications and Advertisers in Android. By Paul Pearce, Adrienne Porter Felt, Gabriel Nunez, and David Wagner. AsiaCCS, 2012.  Overview: Problem from Study: Overprivileging of ads:\n 49% of android apps contain at least one ad library; these libraries overprivilege 46% of ad-supported apps; 56% of apps with ads that request location (34% of all apps) only because of ads;  Solution: a new ad framework, AdDroid, to apply privilege separation to advertising libraries:\n new ad API with corresponding ad permissions.  A userspace library that is part of the Android SDK; A new Android system service; New Android permissions;  allow applications to show ads without requesting privacy-sensitive permissions.  Challenges:\n Two existing separation strategies are inadequate:  Intra-process separation, e.g. by assigning each Java class with its own protection domains. But two technical problems: Applications can have native libraries, which will violate the integrity of the VM running in the same process; Dalvik virtual machine does not support isolation between portions of code within the same virtual machine; Inter-process separation, e.g. by putting advertising libraries into separate, standalone applications. But the problem can come from four aspects: Users can uninstall the ad application; Difficult to enforce the ADVERTISING permission: Many other user applications can also access the ad app, and this can be hard to be prevented; Need to resolve install-time dependencies, as well as the runtime application dependencies. Adding such support will change Android platform, and can cause unforeseen abuse opportunities. Need to prevent the distribution of impostor advertising networks. The impostor advertising network would collect all of the information sent to it without paying the developer and without the privacy policy of a reputable ad network.   Evaluation  Measurement Study: a static permission analysis for overprivilege study. That answers:  How often applications request permissions solely for advertising; How many ad libraries have access to dangerous permissions that are not necessary for advertising  Usability Discussion: how difficult it would be for developers to switch to AdDroid.  Two Goals:  a) a signle API able to support multiple ad networks; b) easily port for developers to the new AdDroid API;  Two sample applications, with home built ad servers (for ethical reason):  First sample uses the AdDroid API to fetch AdMob advertisements; Second sample uses the AdDroid API to fetch Millennial Media advertisements;  Hacks in implementation:  Use home built servers for ethical reason; Replace AdDroid system service with existing advertising libraries;    Can we do the same thing? No. The idea must come after some internal knowledge of the Android system, especially for the advertisement internals, which I am not familiar with. That is, it is hard to think out this idea in the first place.\nEven if we know this idea is novel and can be useful, due to the limited knowledge of Android ecosystem, it might take for a while to get familiar with the Android platform and implement this.\n "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2018-hardscope/",
	"title": "Hardscope",
	"tags": [],
	"description": "",
	"content": "Reference 1\nNon-control data attacks: DOP.\nLexical scope for every variable in C/C++: Statically checked at compile time but can be violated at runtime, leveraged by DOP.\nSolution:\nRun-time Scope Enforcement (RSE):\n fine-grained compartmentalization of data memory within programs. hardware assisted RSE scheme:  a set of six new instructions; compiler instrumentation; creating runtime rules defining which code blocks can access which pieces of memory. rules as a stack; check on every load/store; check simultaneously with ???.     HardScope: Thwarting DOP attacks with Hardware-assisted Run-time Scope Enforcement. arXiv, 2018 v2. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2018-micro-stache/",
	"title": "2018 Micro Stache",
	"tags": [],
	"description": "",
	"content": "Reference 1\n  MicroStache: A lightweight Execution Context for In-Process Safe Region Isolation. ↩   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/pri-sep/2018-breakapp/",
	"title": "BreakApp: Automated, Flexible Application Compartmentalization",
	"tags": [],
	"description": "",
	"content": " Vasilakis, Nikos, Ben Karel, Nick Roessler, Nathan Dautenhahn, André DeHon, and Jonathan M. Smith. \u0026ldquo;BreakApp: Automated, Flexible Application Compartmentalization.\u0026rdquo; In NDSS. 2018.   "
},
{
	"uri": "https://cnlelema.github.io/memo/en/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cnlelema.github.io/memo/en/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cnlelema.github.io/memo/en/",
	"title": "Welcome",
	"tags": [],
	"description": "",
	"content": " 学而时习之，不亦说乎1 Hellooo! Practice makes perfect. Here is hosted my memo tracking my practices of study! I will try to keep them organized. However, they will look like memory flakes while my interests keep changing and expanding.\nTodos  How to remove Compilers from trusted computing base, especially when compiler are heavily used for security solutions?\n CompCert, etc.  What is proof carrying code? How to generate such code?\n Automatic program partition?\n Automatic program partition for privilege separation?\n Automatic program partition for parallelism?\n How does it looks like if all kinds of human activities are assisted and/or replaced by AI?\n Automated education? Automated factory working tasks? Automated farm farming tasks? Automated hospital health operations? Automated economical/Business activities? Automated law composing and enforcements? Automated human eating, clothing, housing, transportation? Will we need mouth to eat?  How about a tiny farmer inside your body and generates energy to your muscle without eating from the mouth?  Will we need wear cloth? Will we need clothes?  How about a AI assisted skin that will automatically on and off your skin based on your needs?    Update History    cmt # Date Description     - Mon, 27 Feb 2023 23:37:40 CST(+0800) up to date   1684 Mon, 27 Feb 2023 20:37:55 +0800 todo capmode in cheri   1683 Mon, 27 Feb 2023 20:33:24 +0800 verilog module syntax   1682 Mon, 27 Feb 2023 20:24:17 +0800 UPEC: auto derived model. But how?   1681 Thu, 23 Feb 2023 11:35:00 +0800 todo upec continuing   1680 Wed, 22 Feb 2023 21:15:40 +0800 ibex and cheri-ibex notes   1679 Wed, 22 Feb 2023 12:01:18 +0800 Merge branch \u0026lsquo;master\u0026rsquo;   1678 Wed, 22 Feb 2023 12:00:55 +0800 updates: ibex todo; move sonic-boom to riscv/sonic-boom; verilog notes   1677 Mon, 20 Feb 2023 14:19:21 +0800 cheriot   1676 Thu, 16 Feb 2023 21:17:23 +0800 todo upec cheri iot   1675 Tue, 14 Feb 2023 11:17:34 +0800 upec \u0026ndash; ctl \u0026ndash; path quantifiers and linear-time operators   1674 Wed, 8 Feb 2023 17:03:15 +0800 updates - update Readme.md - update default, use ## title - add j-ext for riscv - todo upec paper for detecting side channels in arch using fm - update asan notes   1673 Wed, 8 Feb 2023 10:04:33 +0800 reorder docs:   1672 Tue, 7 Feb 2023 12:06:40 +0800 add symbols, math 220 duality   1671 Tue, 7 Feb 2023 11:23:23 +0800 math 220 update; sf class link   1670 Tue, 7 Feb 2023 10:53:35 +0800 add video links   1669 Tue, 7 Feb 2023 10:49:12 +0800 add class links from peking: sa and sf   1668 Thu, 2 Feb 2023 17:56:26 +0800 software foudation class from xiong yingfei   1667 Tue, 31 Jan 2023 15:48:04 +0800 hoare triples; boolean exprs;   1666 Sun, 29 Jan 2023 14:58:28 +0800 intro cheri   1665 Sun, 29 Jan 2023 13:59:36 +0800 inductive reasoning vs deductive reasoning, examples   1664 Sun, 29 Jan 2023 10:22:33 +0800 fm class: equality, func evaluation   1663 Fri, 20 Jan 2023 18:10:45 +0800 logics: class notes    \u0026hellip;\n 子曰：‘学而时习之，不亦说乎？有朋自远方来，不亦乐乎？人不知而不愠，不亦君子乎？’ 《论语·学而》，English translation: The Master said, \u0026ldquo;Is it not pleasant to learn with a constant perseverance and application? Is it not delightful to have friends coming from distant quarters? Is he not a man of complete virtue, who feels no discomposure though men may take no note of him? ↩   "
}]